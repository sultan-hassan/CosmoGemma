["  We discuss the synergy of the cosmic shear and CMB lensing experiments to\nsimultaneously constrain the neutrino mass and dark energy properties. Taking\nfully account of the CMB lensing, cosmic shear, CMB anisotropies, and their\ncross correlation signals, we clarify a role of each signal, and investigate\nthe extent to which the upcoming observations by a high-angular resolution\nexperiment of CMB and deep galaxy imaging survey can tightly constrain the\nneutrino mass and dark energy equation-of-state parameters. Including the\nprimary CMB information as a prior cosmological information, the Fisher\nanalysis reveals that the time varying equation-of-state parameters, given by\nw(a)=w_0+w_a(1-a), can be tightly constrained with the accuracies of 5% for w_0\nand 15% for w_a, which are comparable to or even better than those of the\nstage-III type surveys neglecting the effect of massive neutrinos. In other\nwords, including the neutrino mass in the parameter estimation would not\ndrastically alter the Figure-of-Merit estimates of dark energy parameters from\nthe weak lensing measurements. For the neutrino mass, a clear signal for total\nneutrino mass with 0.1 eV can be detected with 2-sigma significance. The\nrobustness and sensitivity of these results are checked in detail by allowing\nthe setup of cosmic shear experiment to vary as a function of observation time\nor exposure time, showing that the improvement of the constraints very weakly\ndepends on the survey parameters, and the results mentioned above are nearly\noptimal for the dark energy parameters and the neutrino mass.\n", "  Future lensing surveys will be nearly full-sky and reach an unprecedented\ndepth, probing scales closer and closer to the Hubble radius. This motivates\nthe study of the cosmic shear beyond the small-angle approximation and\nincluding general relativistic corrections that are usually suppressed on\nsub-Hubble scales. The complete expression of the reduced cosmic shear at\nsecond order including all relativistic effects was derived in [1]. In the\npresent paper we compute the resulting cosmic shear bispectrum when all these\neffects are properly taken into account and we compare it to primordial\nnon-Gaussianity of the local type. The new general relativistic effects are\ngenerically smaller than the standard non-linear couplings. However, their\nrelative importance increases at small multipoles and for small redshifts of\nthe sources. The dominant effect among these non standard corrections is due to\nthe inhomogeneity of the source redshift. In the squeezed limit, its amplitude\ncan become of the order of the standard couplings when the redshift of the\nsources is below 0.5. Moreover, while the standard non-linear couplings depend\non the angle between the short and long mode, the relativistic corrections do\nnot and overlap almost totally with local type non-Gaussianity. We find that\nthey can contaminate the search for a primordial local signal by f_NL>10.\n", "  This paper discusses a connection between the relativistic number counts of\ncosmological sources and the observed galaxy luminosity function (LF).\nObservational differential number densities are defined and obtained from\npublished LF data using such connection. We observe a distortion in the\nobservational quantities that increases with higher redshift values as compared\nto the theoretical predictions. The use of different cosmological distance\nmeasures plays a role in such a distortion\n", "  By undertaking deep long-slit spectroscopy with the focal reducer SCORPIO of\nthe Russian 6m telescope, we studied stellar population properties and their\nvariation with radius in 15 nearby S0 galaxies sampling a wide range of\nluminosities and environments. For the large-scale stellar disks of S0s, we\nhave measured SSP-equivalent metallicities ranging from the solar one down to\n[Z/H]=-0.4 - -0.7, rather high magnesium-to-iron ratios, [Mg/Fe] > +0.2, and\nmostly old SSP-equivalent ages. Nine of 15 (60%) galaxies have large-scale\nstellar disks older than 10 Gyr, and among those we find all the galaxies which\nreside in denser environments. The isolated galaxies may have intermediate-age\nstellar disks which are 7-9 Gyr old. Only two galaxies of our sample, NGC 4111\nand NGC 7332, reveal SSP-equivalent ages of their disks of 2-3 Gyrs. Just these\ntwo young disks appear to be thin, while the other, older disks have scale\nheights typical for thick stellar disks. The stellar populations in the bulges\nat radii of 0.5r_eff are on the contrary more metal-rich than the solar\nmetallicity, with the ages homogeneously distributed between 2 and 15 Gyr,\nbeing almost always younger than the disks. We conclude that S0 galaxies could\nnot form in groups at z=0.4 as is thought now; a new scenario of the general\nevolution of disk galaxies is proposed instead.\n", "  We present 65 Sloan Digital Sky Survey (SDSS) spectra of 62 star-forming\ngalaxies with oxygen abundances 12 + logO/H ~ 7.5-8.4. Redshifts of selected\ngalaxies are in the range z~0.36-0.70. This allows us to detect the redshifted\nMgII 2797,2803 emission lines. Our aim is to use these lines for the magnesium\nabundance determination. The MgII emission was detected in ~2/3 of the\ngalaxies. We find that the MgII 2797 emission-line intensity follows a trend\nwith the excitation parameter x= O^{2+}/O that is similar to that predicted by\nCLOUDY photoionised HII region models, suggesting a nebular origin of MgII\nemission. The Mg/O abundance ratio is lower by a factor ~2 than the solar\nratio. This is probably the combined effect of interstellar MgII absorption and\ndepletion of Mg onto dust. However, the effect of dust depletion in selected\ngalaxies, if present, is small, by a factor of ~2 lower than that of iron.\n", "  We verified the validity of the empirical method to derive the 4He abundance\nused in our previous papers by applying it to CLOUDY (v13.01) models. Using\nnewly published HeI emissivities, for which we present convenient fits as well\nas the output CLOUDY case B hydrogen and HeI line intensities, we found that\nthe empirical method is able to reproduce the input CLOUDY 4He abundance with\nan accuracy of better than 1%. The CLOUDY output data also allowed us to derive\nthe non-recombination contribution to the intensities of the strongest Balmer\nhydrogen Halpha, Hbeta, Hgamma, and Hdelta emission lines and the ionisation\ncorrection factors for He. With these improvements we used our updated\nempirical method to derive the 4He abundances and to test corrections for\nseveral systematic effects in a sample of 1610 spectra of low-metallicity\nextragalactic HII regions, the largest sample used so far. From this sample we\nextracted a subsample of 111 HII regions with Hbeta equivalent width EW(Hbeta)\n> 150A, with excitation parameter x = O^{2+}/O > 0.8, and with helium mass\nfraction Y derived with an accuracy better than 3%. With this subsample we\nderived the primordial 4He mass fraction Yp = 0.254+/-0.003 from linear\nregression Y-O/H. The derived value of Yp is higher at the 68% confidence level\n(CL) than that predicted by the standard big bang nucleosynthesis (SBBN) model,\npossibly implying the existence of different types of neutrino species in\naddition to the three known types of active neutrinos. Using the most recently\nderived primordial abundances D/H = (2.60+/-0.12)x10^{-5} and Yp =\n0.254+/-0.003 and the chi^2 technique, we found that the best agreement between\nabundances of these light elements is achieved in a cosmological model with\nbaryon mass density Omegab h^2 = 0.0234+/-0.0019 (68% CL) and an effective\nnumber of the neutrino species Neff = 3.51+/-0.35 (68% CL).\n", "  The GRavitational lEnsing Accuracy Testing 3 (GREAT3) challenge is the third\nin a series of image analysis challenges, with a goal of testing and\nfacilitating the development of methods for analyzing astronomical images that\nwill be used to measure weak gravitational lensing. This measurement requires\nextremely precise estimation of very small galaxy shape distortions, in the\npresence of far larger intrinsic galaxy shapes and distortions due to the\nblurring kernel caused by the atmosphere, telescope optics, and instrumental\neffects. The GREAT3 challenge is posed to the astronomy, machine learning, and\nstatistics communities, and includes tests of three specific effects that are\nof immediate relevance to upcoming weak lensing surveys, two of which have\nnever been tested in a community challenge before. These effects include\nrealistically complex galaxy models based on high-resolution imaging from\nspace; spatially varying, physically-motivated blurring kernel; and combination\nof multiple different exposures. To facilitate entry by people new to the\nfield, and for use as a diagnostic tool, the simulation software for the\nchallenge is publicly available, though the exact parameters used for the\nchallenge are blinded. Sample scripts to analyze the challenge data using\nexisting methods will also be provided. See http://great3challenge.info and\nhttp://great3.projects.phys.ucl.ac.uk/leaderboard/ for more information.\n", "  (abridged) We studied a large sample of ~14000 dwarf star-forming galaxies\nwith strong emission lines selected from the Sloan Digital Sky Survey (SDSS)\nand distributed in the redshift range of z~0-0.6. We modelled spectral energy\ndistributions (SED) of all galaxies which were based on the SDSS spectra in the\nvisible range of 0.38-0.92 micron and included both the stellar and ionised gas\nemission. These SEDs were extrapolated to the UV and mid-infrared ranges to\ncover the wavelength range of 0.1-22 micron. The SDSS spectroscopic data were\nsupplemented by photometric data from the GALEX, SDSS, 2MASS, WISE, IRAS, and\nNVSS all-sky surveys. We derived global characteristics of the galaxies, such\nas their element abundances, luminosities, and stellar masses. The luminosities\nand stellar masses range within the sample over ~5 orders of magnitude, thereby\nlinking low-mass and low-luminosity blue compact dwarf (BCD) galaxies to\nluminous galaxies, which are similar to high-redshift Lyman-break galaxies\n(LBGs). The luminosity L(Hbeta) of the Hbeta emission line, a characteristic of\nthe youngest stellar population with an age of a few Myr, is correlated with\nluminosities in other wavelength ranges. This implies that the most recent\nburst of star formation makes a significant contribution to the emission in the\nvisible range and dominates in other wavelength ranges. We found 20 galaxies\nwith very red WISE mid-infrared m(3.4micron)-m(4.6micron) colour (>2 mag),\nwhich suggests the important contribution of the hot (with a temperature of\nseveral hundred degree) dust emission in these galaxies. Our analysis of the\nbalance between the luminosity in the WISE bands that covered a wavelength\nrange of 3.4-22 micron and the luminosity of the emission absorbed at shorter\nwavelengths showed that the luminosity of the hot dust emission is increased\nwith increasing L(Hbeta) and EW(Hbeta).\n", "  The 355 optically polarized QSOs have redshifts from 0.061 to 3.94 and are\nspread out over the sky except for a 60 degree band centered on the Galactic\nEquator. The data we analyze was measured, collected and published by others.\nHere, we apply tests suitable for large-scale samples and find that the\npolarization directions align with a significance of p = 1% by one test and are\ncorrelated by a second test with p = 5%, each p-value uncertain within a factor\nof about 2. The tests return a preferred Cartesian coordinate system that\nfortuitously aligns well with the Milky Way Galaxy with a significance of p =\n3%. Thus, the Hub Tests' results combined together imply the polarization\ndirections are correlated with a significance that is much less than 1%, which\nis remarkable for such a large-scale sample.\n", "  We present near-infrared spectroscopic observations of the high-intensity HeI\n10830 emission line in 45 low-metallicity HII regions. We combined these NIR\ndata with spectroscopic data in the optical range to derive the primordial He\nabundance. The use of the HeI 10830A line, the intensity of which is very\nsensitive to the density of the HII region, greatly improves the determination\nof the physical conditions in the He^+ zone. This results in a considerably\ntighter Y - O/H linear regression compared to all previous studies. We\nextracted a final sample of 28 HII regions with Hbeta equivalent width\nEW(Hbeta)>150A, excitation parameter O^2+/O>0.8, and with helium mass fraction\nY derived with an accuracy better than 3%. With this final sample we derived a\nprimordial He mass fraction Yp = 0.2551+/-0.0022. The derived value of Yp is\nhigher than the one predicted by the standard big bang nucleosynthesis (SBBN)\nmodel. Using our derived Yp together with D/H = (2.53+/-0.04)x10^-5, and the\nchi^2 technique, we found that the best agreement between these light element\nabundances is achieved in a cosmological model with a baryon mass density\nOmega_b h^2 = 0.0240+/-0.0017 (68% CL), +/-0.0028 (95.4% CL), +/-0.0034 (99%\nCL) and an effective number of neutrino species Neff = 3.58+/-0.25 (68% CL),\n+/-0.40 (95.4% CL), +/-0.50 (99% CL). A non-standard value of Neff is preferred\nat the 99% CL, implying the possible existence of additional types of neutrino\nspecies.\n", "  We present a fully relativistic calculation of the observed galaxy number\ncounts in the linear regime. We show that besides the density fluctuations and\nredshift-space distortions, various relativistic effects contribute to\nobservations at large scales. These effects all have the same physical origin:\nthey result from the fact that our coordinate system, namely the galaxy\nredshift and the incoming photons' direction, is distorted by inhomogeneities\nin our universe. We then discuss the impact of the relativistic effects on the\nangular power spectrum and on the two-point correlation function in\nconfiguration space. We show that the latter is very well adapted to isolate\nthe relativistic effects since it naturally makes use of the symmetries of the\ndifferent contributions. In particular, we discuss how the Doppler effect and\nthe gravitational redshift distortions can be isolated by looking for a dipole\nin the cross-correlation function between a bright and a faint population of\ngalaxies.\n", "  We derive an analytical expression for a novel large-scale structure\nobservable: the line correlation function. The line correlation function, which\nis constructed from the three-point correlation function of the phase of the\ndensity field, is a robust statistical measure allowing the extraction of\ninformation in the non-linear and non-Gaussian regime. We show that, in\nperturbation theory, the line correlation is sensitive to the coupling kernel\nF_2, which governs the non-linear gravitational evolution of the density field.\nWe compare our analytical expression with results from numerical simulations\nand find a 1-sigma agreement for separations r<30 Mpc/h. Fitting formulae for\nthe power spectrum and the non-linear coupling kernel at small scales allow us\nto extend our prediction into the strongly non-linear regime where we find a\n1-sigma agreement with the simulations for r<2 Mpc/h. We discuss the advantages\nof the line correlation relative to standard statistical measures like the\nbispectrum. Unlike the latter, the line correlation is independent of the bias,\nin the regime where the bias is local and linear. Furthermore, the variance of\nthe line correlation is independent of the Gaussian variance on the modulus of\nthe density field. This suggests that the line correlation can probe more\nprecisely the non-linear regime of gravity, with less contamination from the\npower spectrum variance.\n", "  We present first results from the third GRavitational lEnsing Accuracy\nTesting (GREAT3) challenge, the third in a sequence of challenges for testing\nmethods of inferring weak gravitational lensing shear distortions from\nsimulated galaxy images. GREAT3 was divided into experiments to test three\nspecific questions, and included simulated space- and ground-based data with\nconstant or cosmologically-varying shear fields. The simplest (control)\nexperiment included parametric galaxies with a realistic distribution of\nsignal-to-noise, size, and ellipticity, and a complex point spread function\n(PSF). The other experiments tested the additional impact of realistic galaxy\nmorphology, multiple exposure imaging, and the uncertainty about a\nspatially-varying PSF; the last two questions will be explored in Paper II. The\n24 participating teams competed to estimate lensing shears to within systematic\nerror tolerances for upcoming Stage-IV dark energy surveys, making 1525\nsubmissions overall. GREAT3 saw considerable variety and innovation in the\ntypes of methods applied. Several teams now meet or exceed the targets in many\nof the tests conducted (to within the statistical errors). We conclude that the\npresence of realistic galaxy morphology in simulations changes shear\ncalibration biases by $\\sim 1$ per cent for a wide range of methods. Other\neffects such as truncation biases due to finite galaxy postage stamps, and the\nimpact of galaxy type as measured by the S\\'{e}rsic index, are quantified for\nthe first time. Our results generalize previous studies regarding sensitivities\nto galaxy size and signal-to-noise, and to PSF properties such as seeing and\ndefocus. Almost all methods' results support the simple model in which additive\nshear biases depend linearly on PSF ellipticity.\n", "  We use Minkowski Functionals to explore the presence of non-Gaussian\nsignatures in simulated cosmic microwave background (CMB) maps. Precisely, we\nanalyse the non-Gaussianities produced from the angular power spectra emerging\nfrom a class of inflationary models with a primordial step-like potential. This\nclass of models are able to perform the best-fit of the low-$\\ell$ `features',\nrevealed first in the CMB angular power spectrum by the WMAP experiment and\nthen confirmed by the Planck collaboration maps. Indeed, such models generate\noscillatory features in the primordial power spectrum of scalar perturbations,\nthat are then imprinted in the large scales of the CMB field. Interestingly, we\ndiscover Gaussian deviations in the CMB maps simulated from the power spectra\nproduced by these models, as compared with Gaussian $\\Lambda$CDM maps.\nMoreover, we also show that the kind and level of the non-Gaussianities\nproduced in these simulated CMB maps are compatible with that found in the four\nforeground-cleaned Planck maps. Our results indicate that inflationary models\nwith a step-like potential are not only able to improve the best-fit respect to\nthe $\\Lambda$CDM model accounting well for the `features' observed in the CMB\nangular power spectrum, but also suggesting a possible origin for certain\nnon-Gaussian signatures observed in the Planck data.\n", "  We investigate the impact of coulomb screening on primordial nucleosynthesis\nin a universe having scale factor that evolves linearly with time. Coulomb\nscreening affects primordial nucleosynthesis via enhancement of thermonuclear\nreaction rates. This enhancement is determined by the solving Poisson equation\nwithin the context of mean field theory (under appropriate conditions during\nthe primordial nucleosynthesis). Using these results, we claim that the mean\nfield estimates of coulomb screening hardly affect the predicted element\nabundances and nucleosynthesis parameters$, \\{\\eta_9,\\xi_e\\}$. The deviations\nfrom mean field estimates are also studied in detail by boosting genuine\nscreening results with the screening parameter ($\\omega_s$). These deviations\nshow negligible effect on the element abundances and on nucleosynthesis\nparameters. This work thus rules out the coulomb screening effects on\nprimordial nucleosynthesis in slow evolving models and confirms that\nconstraints in ref.[7] on nucleosynthesis parameters remain unaltered.\n", "  It has been shown recently that relativistic distortions generate a dipolar\nmodulation in the two-point correlation function of galaxies. To measure this\nrelativistic dipole it is necessary to cross-correlate different populations of\ngalaxies with for example different luminosities or colours. In this paper, we\nconstruct an optimal estimator to measure the dipole with multiple populations.\nWe show that this estimator increases the signal-to-noise of the dipole by up\nto 35 percent. Using 6 populations of galaxies, in a survey with halos and\nnumber densities similar to those of the millennium simulation, we forecast a\ncumulative signal-to-noise of 4.4. For the main galaxy sample of SDSS at low\nredshift z<0.2 our optimal estimator predicts a cumulative signal-to-noise of\n2.4. Finally we forecast a cumulative signal-to-noise of 7.4 in the upcoming\nDESI survey. These forecasts indicate that with the appropriate choice of\nestimator the relativistic dipole should be detectable in current and future\nsurveys.\n", "  It is usually assumed that in the linear regime the two-point correlation\nfunction of galaxies contains only a monopole, quadrupole and hexadecapole.\nLooking at cross-correlations between different populations of galaxies, this\nturns out not to be the case. In particular, the cross-correlations between a\nbright and a faint population of galaxies contain also a dipole. In this paper\nwe present the first attempt to measure this dipole. We discuss the four types\nof effects that contribute to the dipole: relativistic distortions, evolution\neffect, wide-angle effect and large-angle effect. We show that the first three\ncontributions are intrinsic anti-symmetric contributions that do not depend on\nthe choice of angle used to measure the dipole. On the other hand the\nlarge-angle effect appears only if the angle chosen to extract the dipole\nbreaks the symmetry of the problem. We show that the relativistic distortions,\nthe evolution effect and the wide-angle effect are too small to be detected in\nthe LOWz and CMASS sample of the BOSS survey. On the other hand with a specific\ncombination of angles we are able to measure the large-angle effect with high\nsignificance. We emphasise that this large-angle dipole does not contain new\nphysical information, since it is just a geometrical combination of the\nmonopole and the quadrupole. However this measurement, which is in excellent\nagreement with theoretical predictions, validates our method for extracting the\ndipole from the two-point correlation function and it opens the way to the\ndetection of relativistic effects in future surveys like e.g. DESI.\n", "  A few years ago Baker \\cite{baker} proposed a metric which interpolates\nsmoothly between the Schwarzschild metric at small scales and the\nFriedmann-Lema$\\hat{i}$tre-Robertson-Walker (FLRW) metric at large scales which\nwas rejected as incompatible with Newtonian solar system data. Based on the\nadiabatic approximation, we find a unique solution within the variants of the\nsame construction scheme which avoids this problem. In this metric, a MOND-like\nnon-Newtonian acceleration arises, which we have termed VMOND, where the MOND\nacceleration $a_0$ is replaced by a cosmological acceleration which depends on\nthe background matter density. We give two circumstances in which VMOND mimics\nMOND without the need for additional dark matter. \\newline\n  1) We show that a reasonable overdensity at recombination, normally\nconsidered too small without additional mass, is sufficient to permit\nturnaround and collapse to a tight central region before $z\\sim 14$. \\newline\n2) The velocity dispersions of a large mass spherical galaxy can match the\nobserved profiles, at large distances obeying the Faber-Jackson relation with a\nVMOND-like acceleration of comparable values to the phenomenological MOND\nacceleration $a_0$. \\\\ This is not a universal panacea to the problems\nencouraging dark matter but, we suggest, presents a new baseline for\ncalculation.\n", "  Euclid is a European Space Agency medium class mission selected for launch in\n2020 within the Cosmic Vision 2015 2025 program. The main goal of Euclid is to\nunderstand the origin of the accelerated expansion of the universe. Euclid will\nexplore the expansion history of the universe and the evolution of cosmic\nstructures by measuring shapes and redshifts of galaxies as well as the\ndistribution of clusters of galaxies over a large fraction of the sky. Although\nthe main driver for Euclid is the nature of dark energy, Euclid science covers\na vast range of topics, from cosmology to galaxy evolution to planetary\nresearch. In this review we focus on cosmology and fundamental physics, with a\nstrong emphasis on science beyond the current standard models. We discuss five\nbroad topics: dark energy and modified gravity, dark matter, initial\nconditions, basic assumptions and questions of methodology in the data\nanalysis. This review has been planned and carried out within Euclid's Theory\nWorking Group and is meant to provide a guide to the scientific themes that\nwill underlie the activity of the group during the preparation of the Euclid\nmission.\n", "  Most statistical inference from cosmic large-scale structure relies on\ntwo-point statistics, i.e.\\ on the galaxy-galaxy correlation function (2PCF) or\nthe power spectrum. These statistics capture the full information encoded in\nthe Fourier amplitudes of the galaxy density field but do not describe the\nFourier phases of the field. Here, we quantify the information contained in the\nline correlation function (LCF), a three-point Fourier phase correlation\nfunction. Using cosmological simulations, we estimate the Fisher information\n(at redshift $z=0$) of the 2PCF, LCF and their combination, regarding the\ncosmological parameters of the standard $\\Lambda$CDM model, as well as a Warm\nDark Matter (WDM) model and the $f(R)$ and Symmetron modified gravity models.\nThe galaxy bias is accounted for at the level of a linear bias. The relative\ninformation of the 2PCF and the LCF depends on the survey volume, sampling\ndensity (shot noise) and the bias uncertainty. For a volume of $1h^{-3}\\rm\nGpc^3$, sampled with points of mean density $\\bar{n} = 2\\times10^{-3} h^{3}\\\n\\rm Mpc^{-3}$ and a bias uncertainty of 13\\%, the LCF improves the parameter\nconstraints by about 20\\% in the $\\Lambda$CDM cosmology and potentially even\nmore in alternative models. Finally, since a linear bias only affects the\nFourier amplitudes (2PCF), but not the phases (LCF), the combination of the\n2PCF and the LCF can be used to break the degeneracy between the linear bias\nand $\\sigma_8$, present in 2-point statistics.\n", "  We present a public version of the code COFFE (COrrelation Function Full-sky\nEstimator) available at https://github.com/JCGoran/coffe. The code computes the\ngalaxy two-point correlation function and its multipoles in linear perturbation\ntheory, including all relativistic and wide angle corrections. COFFE also\ncalculates the covariance matrix for two physically relevant estimators of the\ncorrelation function multipoles. We illustrate the usefulness of our code by a\nsimple but relevant example: a forecast of the detectability of the lensing\nsignal in the multipoles of the two-point function. In particular, we show that\nlensing should be detectable in the multipoles of the two-point function, with\na signal-to-noise larger than 10, in future surveys like Euclid or the SKA.\n", "  We consider a unified dissipative dark fluid model. Our fluid contains an\nadiabatic part plus a bulk viscous one. The adiabatic part has the ability to\nasymptote between two power laws and so can interpolate between the dust and\ndark energy equations of state at early and late times. The dissipative part is\na bulk viscous part with constant viscosity coefficient. The model is analyzed\nusing the phase space methodology which helps to understand the dynamical\nbehavior of the model in a robust manner without reference to the system\nsolution. The parameters of the model are constrained through its asymptotic\nbehavior and also through many observational constraints. We solve the Hubble\nparameter equation using numerical methods and results are plotted against the\nnewest set of Hubble data. The model is tested using the $Om(z)$ test which\nshows that this model although is a quintessence-like model, it slides through\nthe phantom barrier. We study the model expectations for the evolution of the\nuniverse by studying the evolution of the deceleration parameter, the density\nof the universe, the effective equation of state parameter of the model and of\nits underlying dark energy package. We estimate the value of the present day\nviscosity coefficient of the cosmic fluid as $8 \\times 10^6 Pa.s$, which agrees\nwith the work of many authors, e.g., Velten and Schwartz [26], Wang and Meng\n[27], and Sasidharan and Mathew [29]. We argue that this model is able to\nexplain the behavior of the universe evolution.\n", "  We present methods for interpolating between the 1-D flux power spectrum of\nthe Lyman-$\\alpha$ forest, as output by cosmological hydrodynamic simulations.\nInterpolation is necessary for cosmological parameter estimation due to the\nlimited number of simulations possible. We construct an emulator for the\nLyman-$\\alpha$ forest flux power spectrum from $21$ small simulations using\nLatin hypercube sampling and Gaussian process interpolation. We show that this\nemulator has a typical accuracy of 1.5% and a worst-case accuracy of 4%, which\ncompares well to the current statistical error of 3 - 5% at $z < 3$ from BOSS\nDR9. We compare to the previous state of the art, quadratic polynomial\ninterpolation. The Latin hypercube samples the entire volume of parameter\nspace, while quadratic polynomial emulation samples only lower-dimensional\nsubspaces. The Gaussian process provides an estimate of the emulation error and\nwe show using test simulations that this estimate is reasonable. We construct a\nlikelihood function and use it to show that the posterior constraints generated\nusing the emulator are unbiased. We show that our Gaussian process emulator has\nlower emulation error than quadratic polynomial interpolation and thus produces\ntighter posterior confidence intervals, which will be essential for future\nLyman-$\\alpha$ surveys such as DESI.\n", "  We compute the galaxy-galaxy correlation function of low-luminosity SDSS-DR7\ngalaxies $(-20 < M_{\\rm r} - 5\\log_{10}(h) < -18)$ inside cosmic voids\nidentified in a volume limited sample of galaxies at $z=0.085$. To identify\nvoids, we use bright galaxies with $M_{\\rm r} - 5\\log_{10}(h) < -20.0$. We find\nthat structure in voids as traced by faint galaxies is mildly non-linear as\ncompared with the general population of galaxies with similar luminosities.\nThis implies a redshift-space correlation function with a similar shape than\nthe real-space correlation albeit a normalization factor. The redshift space\ndistortions of void galaxies allow to calculate pairwise velocity distributions\nwhich are consistent with an exponential model with a pairwise velocity\ndispersion of $w \\sim 50-70$ km/s, significantly lower than the global value of\n$w \\sim 500$ km/s. We also find that the internal structure of voids as traced\nby faint galaxies is independent of void environment, namely the correlation\nfunctions of galaxies residing in void-in-void or void-in-shell regions are\nidentical within uncertainties. We have tested all our results with the\nsemi-analytic catalogue MDPL2-\\textsc{Sag} finding a suitable agreement with\nthe observations in all topics studied.\n", "  The cross-correlation between cosmic microwave background (CMB) gravitational\nlensing and large-scale structure tracers will be an important cosmological\nprobe in the coming years. Quadratic estimators provide a simple and powerful\n(if suboptimal) way to reconstruct the CMB lensing potential and are widely\nused. For Gaussian fields, the cross-correlation of a quadratic-estimator CMB\nlensing reconstruction with a tracer is exactly unbiased if the power spectra\nare known and consistent analytic lensing mode response functions are used.\nHowever, the bispectrum induced by non-linear large-scale structure growth and\npost-Born lensing can introduce an additional bias term ($N_L^{(3/2)}$) in the\ncross-correlation spectrum, similar to the $N_L^{(3/2)}$ bias in the\nauto-spectrum demonstrated in recent works. We give analytic flat-sky results\nfor the cross-correlation bias using approximate models for the post-Born and\nlarge-scale structure cross-bispectra, and compare with N-body simulation\nresults using ray-tracing techniques. We show that the bias can be at the\n5-15\\% level in all large-scale structure cross-correlations using small-scale\nCMB temperature lensing reconstruction, but is substantially reduced using\npolarization-based lensing estimators or simple foreground-projected\ntemperature estimators. The relative magnitude of these effects is almost three\ntimes higher than in the CMB lensing auto-correlation, but is small enough that\nit can be modelled to sufficient precision using simple analytic models. We\nshow that $N_L^{(3/2)}$ effects in cross-correlation will be detected with high\nsignificance when using data of future surveys and could affect systematic\neffects marginalization in cosmic shear measurements mimicking galaxy intrinsic\nalignment.\n", "  We develop a novel method to extract key cosmological information, which is\nprimarily carried by the baryon acoustic oscillations and redshift space\ndistortions, from spectroscopic galaxy surveys based on a joint principal\ncomponent analysis (PCA) and massive optimized parameter estimation and data\ncompression (MOPED) algorithm. We apply this method to galaxy samples from BOSS\nDR12, and find that a PCA manipulation is effective at extracting the\ninformative modes in the 2D correlation function, giving a tighter constraint\non BAO and RSD parameters compared to that using the lowest three multipole\nmoments by the traditional method; i.e. the Figure of Merit of BAO and RSD\nparameters is improved by $\\sim20\\%$. We then perform a compression of the\ninformative PC modes for BAO and RSD parameters using the MOPED scheme,\nreducing the dimension of the data vector to the number of interesting\nparameters, manifesting the joint PCA and MOPED as a powerful tool for\nclustering analysis with almost no loss of constraining power.\n", "  We discuss the impact of the preheating stage in radiative corrections due to\ninteraction of the inflaton to fermions to $\\phi^4$ inflation with non-minimal\ncoupling in Palatini formulation. In Palatini inflation with large non-minimal\ncoupling the field is allow to return to the plateau region during the\nreheating stage, so the average equation of state per oscillations is closer to\n$-1$ than to $1/3$. The incursion in the plateau leads, however, to a highly\nefficient tachyonic instability able to reheat the Universe in less than one\ne-fold. By taking into account prescription II discussed in the literature, in\nthe wide range of $\\kappa-\\xi$, we figure out spectral index $n_s$ and\ntensor-to-scalar ratio $r$ which are compatible with the data given by the Keck\nArray/BICEP2 and Planck collaborations.\n", "  The present study reveals observational constraints on the coupling between\ndark components of anisotropic Bianchi type I universe. We assume interaction\nbetween dark matter and dark energy and split the continuity equation with\ninclusion of interaction term $\\Gamma$. Two scenarios have been considered (i)\nwhen coupling between dark components is constant and (ii) when it is a\nfunction of redshift ($z$). Metropolis-Hasting algorithm has been used to\nperform Monte Carlo Markov Chain (MCMC) analysis by using observational Hubble\ndata obtained from cosmic chronometric (CC) technique, cosmic microwave\nbackground (CMB) baryon acoustic oscillation (BAO), Pantheon compilation of\nSupernovae type Ia (SNIa), their joint combination and a Gaussian prior on the\nHubble parameter $H_{0}$. It is obtained that the combination of all databases\nplus $H_{0}$ prior marginalized over a present dark energy density gives\nstringent constraints on the current value of coupling as $-0.001<\\delta<0.041$\nin constant coupling model and $-0.042<\\delta<0.053$ in varying coupling model\nat 68\\% confident level. In general, for both models, we found\n$\\omega^{X}\\approx -1$ and $\\delta(\\delta_{0})\\approx 0$ which indicate that\nstill recent data favor uncoupled $\\Lambda$CDM model. Our estimations show that\nin constant coupling model $(H_{0}=73.9^{+1.5}_{-0.95},\n\\delta=0.023^{+0.017}_{-0.024})$ which naturally leads to consistent value of\nthe Hubble constant. This result is interesting because the previous works show\nthat such a high value of Hubble constant requires the significant value of\ncoupling parameter $\\delta$. It has been also observed that in the constant\ncoupling model, we do not find any disagreement between the estimated $H_{0}$\nand those reported by Hubble space telescope (HST) and large scale structure\n(LSS) experiments.\n", "  The subject of this paper is optimisation of weak lensing tomography: We\ncarry out numerical minimisation of a measure of total statistical error as a\nfunction of the redshifts of the tomographic bin edges by means of a\nNelder-Mead algorithm in order to optimise the sensitivity of weak lensing with\nrespect to different optimisation targets. Working under the assumption of a\nGaussian likelihood for the parameters of a $w_0 w_a$CDM-model and using\nEuclid's conservative survey specifications, we compare an equipopulated,\nequidistant and optimised bin setting and find that in general the\nequipopulated setting is very close to the optimal one, while an equidistant\nsetting is far from optimal and also suffers from the ad hoc choice of a\nmaximum redshift. More importantly, we find that nearly saturated information\ncontent can be gained using already few tomographic bins. This is crucial for\nphotometric redshift surveys with large redshift errors. We consider a large\nrange of targets for the optimisation process that can be computed from the\nparameter covariance (or equivalently, from the Fisher-matrix), extend these\nstudies to information entropy measures such as the Kullback-Leibler-divergence\nand conclude that in many cases equipopulated binning yields results close to\nthe optimum, which we support by analytical arguments.\n", "  We study the position-dependent power spectrum and the integrated bispectrum\nstatistic for 2D cosmological fields on the sphere (integrated angular\nbispectrum). First, we derive a useful, $m$-independent, formula for the\nfull-sky integrated angular bispectrum, based on the construction of\nazimuthally symmetric patches. We then implement a pipeline for integrated\nangular bispectrum estimation, including a mean-field correction to account for\nspurious isotropy-breaking effects in realistic conditions (e.g., inhomogenous\nnoise, sky masking). Finally, we show examples of applications of this\nestimator to CMB analysis, both using simulations and actual Planck data. Such\nexamples include $f_\\mathrm{NL}$ estimation, analyses of non-Gaussianity from\nsecondary anisotropies (ISW-lensing and ISW-tSZ-tSZ bispectra) and studies of\nnon-Gaussian signatures from foreground contamination.\n", "  We show that correlations between the phases of the galaxy density field in\nredshift space provide additional information about the growth rate of\nlarge-scale structure that is complementary to the power spectrum multipoles.\nIn particular, we consider the multipoles of the line correlation function\n(LCF), which correlates phases between three collinear points, and use the\nFisher forecasting method to show that the LCF multipoles can break the\ndegeneracy between the measurement of the growth rate of structure $f$ and the\namplitude of perturbations $\\sigma_8$ that is present in the power spectrum\nmultipoles at large scales. This leads to an improvement in the measurement of\n$f$ and $\\sigma_8$ by up to 220 per cent for $k_{\\rm max} = 0.15 \\,\nh\\mathrm{Mpc}^{-1}$ and up to 50 per cent for $k_{\\rm max} = 0.30 \\,\nh\\mathrm{Mpc}^{-1}$ at redshift $z=0.25$, with respect to power spectrum\nmeasurements alone for the upcoming generation of galaxy surveys like DESI and\nEuclid. The average improvements in the constraints on $f$ and $\\sigma_8$ for\n$k_{\\rm max} = 0.15 \\, h\\mathrm{Mpc}^{-1}$ are $\\sim 90$ per cent for the DESI\nBGS sample with mean redshift $\\overline{z}=0.25$, $\\sim 40$ per cent for the\nDESI ELG sample with $\\overline{z}=1.25$, and $\\sim 40$ per cent for the Euclid\nH$\\alpha$ galaxies with $\\overline{z}=1.3$. For $k_{\\rm max} = 0.30 \\,\nh\\mathrm{Mpc}^{-1}$, the average improvements are $\\sim 40$ per cent for the\nDESI BGS sample and $\\sim 20$ per cent for both the DESI ELG and Euclid\nH$\\alpha$ galaxies.\n", "  At cosmic dawn, the 21-centimeter signal from intergalactic hydrogen was\ndriven by Lyman-$\\alpha$ photons from some of the earliest stars, producing a\nspatial pattern that reflected the distribution of galaxies at that time. Due\nto the large foreground, it is thought that around redshift 20 it is only\nobservationally feasible to detect 21-cm fluctuations statistically, yielding a\nlimited, indirect probe of early galaxies. Here we show that 21-cm images at\ncosmic dawn should actually be dominated by large (tens of comoving\nmegaparsecs), high contrast bubbles surrounding individual galaxies. We\ndemonstrate this using a substantially upgraded semi-numerical simulation code\nthat realistically captures the formation and 21-cm effects of the small\ngalaxies expected during this era. Small number statistics associated with the\nrarity of early galaxies, combined with the multiple scattering of photons in\nthe blue wing of the Lyman-$\\alpha$ line, create the large bubbles and also\nenhance the 21-cm power spectrum by a factor of 2--7 and add to it a feature\nthat measures the typical brightness of galaxies. These various signatures of\ndiscrete early galaxies are potentially detectable with planned experiments\nsuch as the Square Kilometer Array or the Hydrogen Epoch of Reionization Array,\neven if the early stars formed in dark matter halos with masses as low as\n$10^8\\, M_\\odot$, ten thousand times smaller than the Milky Way halo.\n", "  CMB-S4---the next-generation ground-based cosmic microwave background (CMB)\nexperiment---is set to significantly advance the sensitivity of CMB\nmeasurements and enhance our understanding of the origin and evolution of the\nUniverse, from the highest energies at the dawn of time through the growth of\nstructure to the present day. Among the science cases pursued with CMB-S4, the\nquest for detecting primordial gravitational waves is a central driver of the\nexperimental design. This work details the development of a forecasting\nframework that includes a power-spectrum-based semi-analytic projection tool,\ntargeted explicitly towards optimizing constraints on the tensor-to-scalar\nratio, $r$, in the presence of Galactic foregrounds and gravitational lensing\nof the CMB. This framework is unique in its direct use of information from the\nachieved performance of current Stage 2--3 CMB experiments to robustly forecast\nthe science reach of upcoming CMB-polarization endeavors. The methodology\nallows for rapid iteration over experimental configurations and offers a\nflexible way to optimize the design of future experiments given a desired\nscientific goal. To form a closed-loop process, we couple this semi-analytic\ntool with map-based validation studies, which allow for the injection of\nadditional complexity and verification of our forecasts with several\nindependent analysis methods. We document multiple rounds of forecasts for\nCMB-S4 using this process and the resulting establishment of the current\nreference design of the primordial gravitational-wave component of the Stage-4\nexperiment, optimized to achieve our science goals of detecting primordial\ngravitational waves for $r > 0.003$ at greater than $5\\sigma$, or, in the\nabsence of a detection, of reaching an upper limit of $r < 0.001$ at $95\\%$ CL.\n", "  We present a sample of luminous red-sequence galaxies to study the\nlarge-scale structure in the fourth data release of the Kilo-Degree Survey. The\nselected galaxies are defined by a red-sequence template, in the form of a\ndata-driven model of the colour-magnitude relation conditioned on redshift. In\nthis work, the red-sequence template is built using the broad-band optical+near\ninfrared photometry of KiDS-VIKING and the overlapping spectroscopic data sets.\nThe selection process involves estimating the red-sequence redshifts, assessing\nthe purity of the sample, and estimating the underlying redshift distributions\nof redshift bins. After performing the selection, we mitigate the impact of\nsurvey properties on the observed number density of galaxies by assigning\nphotometric weights to the galaxies. We measure the angular two-point\ncorrelation function of the red galaxies in four redshift bins, and constrain\nthe large scale bias of our red-sequence sample assuming a fixed $\\Lambda$CDM\ncosmology. We find consistent linear biases for two luminosity-threshold\nsamples (dense and luminous). We find that our constraints are well\ncharacterized by the passive evolution model.\n", "  The power spectrum has long been the workhorse summary statistics for\nlarge-scale structure cosmological analyses. However, gravitational non-linear\nevolution moves precious cosmological information from the two-point statistics\n(such as the power spectrum) to higher-order correlations. Moreover,\ninformation about the primordial non-Gaussian signal lies also in higher-order\ncorrelations. Without tapping into these, that information remains hidden.\nWhile the three-point function (or the bispectrum), even if not extensively,\nhas been studied and applied to data, there has been only limited discussion\nabout the four point/trispectrum. This is because the high-dimensionality of\nthe statistics (in real space a skew-quadrilateral has 6 degrees of freedom),\nand the high number of skew-quadrilaterals, make the trispectrum numerically\nand algorithmically very challenging. Here we address this challenge by\nintroducing the i-trispectrum, an integrated trispectrum that only depends on\nfour $k$-modes moduli. We model and measure the matter i-trispectrum from a set\nof 5000 \\textsc{Quijote} N-body simulations both in real and redshift space,\nfinding good agreement between simulations outputs and model up to mildly\nnon-linear scales. Using the power spectrum, bispectrum and i-trispectrum joint\ndata-vector covariance matrix estimated from the simulations, we begin to\nquantify the added-value provided by the i-trispectrum. In particular, we\nforecast the i-trispectrum improvements on constraints on the local primordial\nnon-Gaussianity amplitude parameters $f_\\mathrm{nl}$ and $g_\\mathrm{nl}$. For\nexample, using the full joint data-vector, we forecast $f_\\mathrm{nl}$\nconstraints up to two times ($\\sim32\\%$) smaller in real (redshift) space than\nthose obtained without i-trispectrum.\n", "  Covariance matrices are among the most difficult pieces of end-to-end\ncosmological analyses. In principle, for two-point functions, each component\ninvolves a four-point function, and the resulting covariance often has hundreds\nof thousands of elements. We investigate various compression mechanisms capable\nof vastly reducing the size of the covariance matrix in the context of cosmic\nshear statistics. This helps identify which of its parts are most crucial to\nparameter estimation. We start with simple compression methods, by isolating\nand \"removing\" 200 modes associated with the lowest eigenvalues, then those\nwith the lowest signal-to-noise ratio, before moving on to more sophisticated\nschemes like compression at the tomographic level and, finally, with the\nMassively Optimized Parameter Estimation and Data compression (MOPED). We find\nthat, while most of these approaches prove useful for a few parameters of\ninterest, like $\\Omega_m$, the simplest yield a loss of constraining power on\nthe intrinsic alignment (IA) parameters as well as $S_8$. For the case\nconsidered -- cosmic shear from the first year of data from the Dark Energy\nSurvey -- only MOPED was able to replicate the original constraints in the\n16-parameter space. Finally, we apply a tolerance test to the elements of the\ncompressed covariance matrix obtained with MOPED and confirm that the IA\nparameter $A_{\\mathrm{IA}}$ is the most susceptible to inaccuracies in the\ncovariance matrix.\n", "  We study the flat-sky approximation for galaxy number counts including\nrelativistic effects, and assess its performance and accuracy with respect to\nthe full-sky result. We find an agreement of up to 5% for the local and lensing\ncontributions to the 2-point correlation function and its multipoles at $z >\n0.5$, and up to 1% for the multipoles alone at $z > 1$ and separations\n$\\lesssim 250$ Mpc/$h$, with a speed-up of over a factor of 1000. Using a\nsemi-analytic method, which has been implemented in a new version of the code\nCOFFE, along with the Limber approximation for the integrated contributions, we\nfurther increase the performance, allowing the computation of the flat-sky\nmultipoles to be done over 10000 times faster than in the full-sky calculation,\nwhich could be used to greatly speed-up Markov chain Monte Carlo sampling for\ncosmological parameter estimation.\n", "  We describe the BeyondPlanck project in terms of motivation, methodology and\nmain products, and provide a guide to a set of companion papers that describe\neach result in fuller detail. We implement a complete end-to-end Bayesian\nanalysis framework for the Planck LFI observations. The primary product is a\nfull joint posterior distribution $P(\\omega|d)$, where $\\omega$ represents the\nset of all free instrumental, astrophysical, and cosmological parameters.\nNotable advantages of this approach are seamless end-to-end propagation of\nuncertainties; accurate modeling of both astrophysical and instrumental effects\nin the most natural basis for each uncertain quantity; optimized computational\ncosts with little or no need for intermediate human interaction between various\nanalysis steps; and a complete overview of the entire analysis process within\none single framework. We focus in particular on low-$\\ell$ CMB polarization\nreconstruction with Planck LFI. We identify several important new effects that\nhave not been accounted for in previous pipelines, including gain\nover-smoothing and time-variable and non-$1/f$ correlated noise in the 30 and\n44 GHz channels. We find that all results are consistent with the $\\Lambda$CDM\nmodel, and we constrain the reionization optical depth to $\\tau=0.066\\pm0.013$,\nwith a low-resolution $\\chi^2$ probability-to-exceed of 32%. This uncertainty\nis about 30% larger than the official pipelines, arising from taking into\naccount a more complete instrumental model. The marginal CMB Solar dipole\namplitude is $3362.7\\pm1.4\\mu\\mathrm{K}$, where the error bar is derived\ndirectly from the posterior distribution without the need of any ad-hoc\ninstrumental corrections. We are currently not aware of any significant\nunmodelled systematic effects remaining in the Planck LFI data, and, for the\nfirst time, the 44 GHz channel is fully exploited. (Abridged.)\n", "  We present a Gibbs sampling solution to the map-making problem for CMB\nmeasurements, building on existing destriping methodology. Gibbs sampling\nbreaks the computationally heavy destriping problem into two separate steps;\nnoise filtering and map binning. Considered as two separate steps, both are\ncomputationally much cheaper than solving the combined problem. This provides a\nhuge performance benefit as compared to traditional methods, and allows us for\nthe first time to bring the destriping baseline length to a single sample. We\napply the Gibbs procedure to simulated Planck 30 GHz data. We find that gaps in\nthe time-ordered data are handled efficiently by filling them with simulated\nnoise as part of the Gibbs process. The Gibbs procedure yields a chain of map\nsamples, from which we may compute the posterior mean as a best-estimate map.\nThe variation in the chain provides information on the correlated residual\nnoise, without need to construct a full noise covariance matrix. However, if\nonly a single maximum-likelihood frequency map estimate is required, we find\nthat traditional conjugate gradient solvers converge much faster than a Gibbs\nsampler in terms of total number of iterations. The conceptual advantages of\nthe Gibbs sampling approach lies in statistically well-defined error\npropagation and systematic error correction, and this methodology forms the\nconceptual basis for the map-making algorithm employed in the BeyondPlanck\nframework, which implements the first end-to-end Bayesian analysis pipeline for\nCMB observations.\n", "  The holographic dark energy models provide an alternative description of the\ndark energy. These models are motivated by the possible application of\nholographic principle to the dark energy problem. We study the one parameter Li\nholographic dark energy and the two parameter Barrow holographic dark energy\nmodels using configuration entropy of the matter distribution in the Universe.\nThe configuration entropy rate exhibits a distinct minimum at a specific scale\nfactor that corresponds to the epoch, beyond which the dark energy takes a\ndriving role in the accelerated expansion of the Universe. We find that the\nlocation of the minimum and magnitude of the entropy rate at the minimum are\nsensitive to the parameters of the models. We find the best fit relations\nbetween these quantities and the parameters of each model. We propose that\nthese relations can be used to constrain the parameters of the holographic dark\nenergy models from the future measurements of the configuration entropy at\nmultiple redshifts. Further, the Barrow holographic dark energy model is based\non Barrow entropy which modifies the standard Bekenstein-Hawking entropy, to\ncapture the deformation of the black-hole surface due to quantum gravitational\neffects. We find that the location and amplitude of the minimum of the\nconfiguration entropy rate is strongly sensitive to the deformation exponent\n$\\Delta$ in the Barrow model. Our study suggests that signatures of the quantum\ngravitational effects on the future event horizon may be detected from the\nstudy of the configuration entropy of the matter distribution on large-scales.\n", "  We present a Bayesian calibration algorithm for CMB observations as\nimplemented within the global end-to-end BeyondPlanck (BP) framework, and apply\nthis to the Planck Low Frequency Instrument (LFI) data. Following the most\nrecent Planck analysis, we decompose the full time-dependent gain into a sum of\nthree orthogonal components: One absolute calibration term, common to all\ndetectors; one time-independent term that can vary between detectors; and one\ntime-dependent component that is allowed to vary between one-hour pointing\nperiods. Each term is then sampled conditionally on all other parameters in the\nglobal signal model through Gibbs sampling. The absolute calibration is sampled\nusing only the orbital dipole as a reference source, while the two relative\ngain components are sampled using the full sky signal, including the orbital\nand Solar CMB dipoles, CMB fluctuations, and foreground contributions. We\ndiscuss various aspects of the data that influence gain estimation, including\nthe dipole/polarization quadrupole degeneracy and anomalous jumps in the\ninstrumental gain. Comparing our solution to previous pipelines, we find good\nagreement in general, with relative deviations of -0.67% (-0.84%) for 30 GHz,\n0.12% (-0.04%) for 44 GHz and -0.03% (-0.64%) for 70 GHz, compared to Planck\nDR4 (Planck 2018). The deviations we find are within expected error bounds, and\nwe attribute them to differences in data usage and general approach between the\npipelines. In particular, the BP calibration is performed globally, resulting\nin better inter-frequency consistency. Additionally, WMAP observations are used\nactively in the BP analysis, which breaks degeneracies in the Planck data set\nand results in better agreement with WMAP. Although our presentation and\nalgorithm are currently oriented toward LFI processing, the procedure is fully\ngeneralizable to other experiments.\n", "  We constrain polarized foreground emission between 30 and 70 GHz with the\nPlanck Low Frequency Instrument (LFI) and WMAP data within the global Bayesian\nBeyondPlanck framework. We combine for the first time full-resolution Planck\nLFI time-ordered data with low-resolution WMAP sky maps at 33, 40 and 61 GHz.\nSpectral parameters are fit with a likelihood defined at the native resolution\nof each frequency channel. This analysis represents the first implementation of\ntrue multi-resolution component separation applied to CMB observations for both\namplitude and spectral energy distribution (SED) parameters. For synchrotron\nemission, we approximate the SED as a power-law in frequency and find that the\nlow signal-to-noise ratio of the current data strongly limits the number of\nfree parameters that may be robustly constrained. We partition the sky into\nfour large disjoint regions (High Latitude; Galactic Spur; Galactic Plane; and\nGalactic Center), each associated with its own power-law index. We find that\nthe High Latitude region is prior-dominated, while the Galactic Center region\nis contaminated by residual instrumental systematics. The two remaining regions\nappear to be signal-dominated, and for these we derive spectral indices of\n$\\beta_{\\mathrm s}^{\\mathrm{Spur}}=-3.17\\pm0.06$ and $\\beta_{\\mathrm\ns}^{\\mathrm{Plane}}=-3.03\\pm0.07$, in good agreement with previous results. For\nthermal dust emission we assume a modified blackbody model and we fit a single\npower-law index across the full sky. We find $\\beta_{\\mathrm{d}}=1.64\\pm0.03$,\nwhich is slightly steeper than reported from Planck HFI data, but still\nstatistically consistent at the 2$\\sigma$ confidence level.\n", "  Curiously, our Universe was born in a low entropy state, with abundant free\nenergy to power stars and life. The form that this free energy takes is usually\nthought to be gravitational: the Universe is almost perfectly smooth, and so\ncan produce sources of energy as matter collapses under gravity. It has\nrecently been argued that a more important source of low-entropy energy is\nnuclear: the Universe expands too fast to remain in nuclear statistical\nequilibrium (NSE), effectively shutting off nucleosynthesis in the first few\nminutes, providing leftover hydrogen as fuel for stars. Here, we fill in the\nastrophysical details of this scenario, and seek the conditions under which a\nUniverse will emerge from early nucleosynthesis as almost-purely iron. In so\ndoing, we identify a hitherto-overlooked character in the story of the origin\nof the second law: matter-antimatter asymmetry.\n", "  We present an emulator for the two-point clustering of biased tracers in real\nspace. We construct this emulator using neural networks calibrated with more\nthan $400$ cosmological models in a 8-dimensional cosmological parameter space\nthat includes massive neutrinos an dynamical dark energy. The properties of\nbiased tracers are described via a Lagrangian perturbative bias expansion which\nis advected to Eulerian space using the displacement field of numerical\nsimulations. The cosmology-dependence is captured thanks to a\ncosmology-rescaling algorithm. We show that our emulator is capable of\ndescribing the power spectrum of galaxy formation simulations for a sample\nmimicking that of a typical Emission-Line survey at $z \\sim 1$ with an accuracy\nof $1-2\\%$ up to nonlinear scales $k \\sim 0.7 h \\mathrm{Mpc}^{-1}$.\n", "  Galaxy clusters are assembled via merging of smaller structures, in a process\nthat generates shocks and turbulence in the intra cluster medium and produces\nradio diffuse emission in the form of halos and relics. The cluster pair\nA399-A401 represents a special case: both clusters host a radio halo. Recent\nLow Frequency Array (LOFAR) observations at 140 MHz revealed the presence of a\nradio bridge connecting the two clusters along with two relic candidates. These\nrelics include one South of A399 and the other in between the two clusters, in\nproximity of a shock front detected in X-ray observations. In this paper we\npresent observations of the A399-A401 cluster pair at 1.7, 1.4, 1.2 GHz and 346\nMHz from the Westerbork Synthesis Radio Telescope (WSRT). We detect the radio\nhalo in the A399 cluster at 346 MHz, extending up to $\\sim 650$ kpc and with a\n$125 \\pm 6$ mJy flux density. Its spectral index between 140 MHz and 346 MHz is\n$\\alpha = 1.75 \\pm 0.14$. The two candidate relics are also seen at 346 MHz and\nwe determine their spectral indices to be $\\alpha = 1.10 \\pm 0.14$ and $\\alpha\n= 1.46 \\pm 0.14$. The low surface brightness bridge connecting the two clusters\nis below the noise level at 346 MHz, therefore we constrain the bridge average\nspectral index to be steep, i.e. $\\alpha > 1.5$ at 95% confidence level. This\nresult favours the scenario where dynamically-induced turbulence is a viable\nmechanism to reaccelerate a population of mildly relativistic particles and\namplify magnetic fields on scales of a few Mpcs.\n  Key words: galaxies: clusters: general - galaxies: clusters: individual:\nAbell 399 - radio continuum: general\n", "  The NASA/IPAC Extragalactic Database (NED) is an impressive tool for finding\nnear-exhaustive information on millions of astrophysical objects. Here, we\noutline a small systematic error that occurs in NED because a low-redshift\napproximation is used when making the correction from redshifts in the\nheliocentric frame to the cosmic microwave background (CMB) rest frame. It\nmeans that historically NED systematically misreported the values of CMB-frame\nredshifts by up to $\\sim10^{-3}z$ (about 0.001 at redshift of 1). This is a\nsystematic error, and therefore the impact on applications requiring precise\nredshifts has the potential to be significant -- for example, a systematic\nredshift error of $\\sim10^{-4}$ at low redshift could resolve the Hubble\ntension. We have consulted with the NED team and they are updating the software\nto remove this systematic error so these corrections are accurate at all\nredshifts. Here, we explain the changes and how they impact the redshift values\nNED currently reports.\n", "  The dipole anisotropy in the Cosmic Microwave Background Radiation (CMBR) has\ngiven a peculiar velocity vector 370 km s$^{-1}$ along\n$l=264^\\circ,b=48^\\circ$. However, some other dipoles, for instance, from the\nnumber counts, sky brightness or redshift distributions in large samples of\ndistant Active Galactic Nuclei (AGNs), have yielded values of the peculiar\nvelocity many times larger than that from the CMBR, though surprisingly, in all\ncases the directions agreed with the CMBR dipole. Here we determine our\npeculiar motion from a sample of ~0.28 million AGNs, selected from the Mid\nInfra Red Active Galactic Nuclei (MIRAGN) sample comprising more than a million\nsources. From this, we find a peculiar velocity, which is more than four times\nthe CMBR value, although the direction seems to be within $\\sim 2\\sigma$ of the\nCMBR dipole. A genuine value of the solar peculiar velocity should be the same\nirrespective of the data or the technique employed to estimate it. Therefore,\nsuch discordant dipole amplitudes, might mean that the explanation for these\ndipoles, including that of the CMBR, might in fact be something else. But, the\nobserved fact that the direction in all cases, is the same, though obtained\nfrom completely independent surveys using different instruments and techniques,\nby different sets of people employing different computing routines, might\nnonetheless indicate that these dipoles are not merely due to some systematics,\notherwise why would they all be pointing along the same direction. It might\ninstead suggest a preferred direction in the Universe, implying a genuine\nanisotropy, which would violate the Cosmological Principle, the core of the\nmodern cosmology.\n", "  This paper introduces a new approach to reconstruct cosmological functions\nusing artificial neural networks based on observational measurements with\nminimal theoretical and statistical assumptions. By using neural networks, we\ncan generate computational models of observational datasets, and then we\ncompare them with the original ones to verify the consistency of our method.\nThis methodology is applicable to even small-size datasets. In particular, we\ntest the proposed method with data coming from cosmic chronometers, $f\\sigma_8$\nmeasurements, and the distance modulus of the Type Ia supernovae. Furthermore,\nwe introduce a first approach to generate synthetic covariance matrices through\na variational autoencoder, using the systematic covariance matrix of the Type\nIa supernova compilation.\n", "  We provide a systematic study of the position-dependent correlation function\nin weak lensing convergence maps and its relation to the squeezed limit of the\nthree-point correlation function (3PCF) using state-of-the-art numerical\nsimulations. We relate the position-dependent correlation function to its\nharmonic counterpart, i.e., the position-dependent power spectrum or\nequivalently the integrated bispectrum. We use a recently proposed improved\nfitting function, BiHalofit, for the bispectrum to compute the theoretical\npredictions as a function of source redshifts. In addition to low redshift\nresults ($z_s=1.0-2.0$), we also provide results for maps inferred from lensing\nof the cosmic microwave background, i.e., $z_s=1100$. We include a {\\em\nEuclid}-type realistic survey mask and noise. In agreement with the recent\nstudies on the position-dependent power spectrum, we find that the results from\nsimulations are consistent with the theoretical expectations when appropriate\ncorrections are included. Performing a rough estimate, we find that the (S/N)\nfor the detection of the position-dependent correlation function from {\\em\nEuclid}-type mask with $f_{sky}=0.35$, can range between $6-12$ depending on\nthe value of the intrinsic ellipticity distribution parameter\n$\\sigma_{\\epsilon} = 0.3-1.0$. For reconstructed $\\kappa$ maps using an ideal\nCMB survey the (S/N) $\\approx 1.8$. We also found that a $10\\%$ deviation in\n$\\sigma_8$ can be detected using IB for the optimistic case of\n$\\sigma_\\epsilon=0.3$ with a (S/N) $\\approx 5$. The (S/N) for such detection in\ncase of $\\Omega_M$ is lower.\n", "  With the dramatic rise in high-quality galaxy data expected from Euclid and\nVera C. Rubin Observatory, there will be increasing demand for fast\nhigh-precision methods for measuring galaxy fluxes. These will be essential for\ninferring the redshifts of the galaxies. In this paper, we introduce Lumos, a\ndeep learning method to measure photometry from galaxy images. Lumos builds on\nBKGnet, an algorithm to predict the background and its associated error, and\npredicts the background-subtracted flux probability density function. We have\ndeveloped Lumos for data from the Physics of the Accelerating Universe Survey\n(PAUS), an imaging survey using a 40 narrow-band filter camera (PAUCam). PAUCam\nimages are affected by scattered light, displaying a background noise pattern\nthat can be predicted and corrected for. On average, Lumos increases the SNR of\nthe observations by a factor of 2 compared to an aperture photometry algorithm.\nIt also incorporates other advantages like robustness towards distorting\nartefacts, e.g. cosmic rays or scattered light, the ability of deblending and\nless sensitivity to uncertainties in the galaxy profile parameters used to\ninfer the photometry. Indeed, the number of flagged photometry outlier\nobservations is reduced from 10% to 2%, comparing to aperture photometry.\nFurthermore, with Lumos photometry, the photo-z scatter is reduced by ~10% with\nthe Deepz machine learning photo-z code and the photo-z outlier rate by 20%.\nThe photo-z improvement is lower than expected from the SNR increment, however\ncurrently the photometric calibration and outliers in the photometry seem to be\nits limiting factor.\n", "  Hydrogen deuteride (HD) is prevalent in a wide variety of astrophysical\nenvironments, and measuring its large-scale distribution at different epochs\ncan in principle provide information about the properties of these\nenvironments. In this paper, we explore the prospects for accessing this\ndistribution using line intensity mapping of emission from the lowest\nrotational transition in HD, focusing on observations of the epoch of\nreionization ($z\\sim6-10$) and earlier. We find the signal from the epoch of\nreionization to be strongest most promising, through cross-correlations within\nexisting [CII] intensity mapping surveys. While the signal we predict is out of\nreach for current-generation projects, planned future improvements should be\nable to detect reionization-era HD without any additional observations, and\nwould help to constrain the properties of the star-forming galaxies thought to\nplay a key role in reionization. We also investigate several avenues for\nmeasuring HD during \"cosmic dawn\" ($z\\sim10-30$), a period in which HD could\nprovide one of the only complementary observables to 21$\\,$cm intensity maps.\nWe conclude that existing and planned facilities are poorly matched to the\nspecifications desirable for a significant detection, though such a measurement\nmay be achievable with sustained future effort. Finally, we explain why HD\nintensity mapping of the intergalactic medium during the cosmic dark ages\n($z\\gtrsim 30$) appears to be out of reach of any conceivable experiment.\n", "  Inflationary model driven by a scalar field whose potential has a step in the\nsecond derivative with respect to the field is considered. For the best fit\npotential parameter values, the 3-point function and the non-Gaussianity\nassociated with the featured model is calculated. We study the shape and scale\ndependence of the 3-point function. The distinctive feature of this model is\nits characteristic ringing behaviour of $f_{NL}$. We can see that the\noscillations in $f_{NL}$ in this model last for a much longer range of k\nvalues, as compared to the previously studied models. In that sense, this model\nis potentially distinguishable from models with other features in the\npotential.\n", "  Measurements of the clustering of galaxies in Fourier space, and at low\nwavenumbers, offer a window into the early Universe via the possible presence\nof scale dependent bias generated by Primordial Non Gaussianites. On such large\nscales a Newtonian treatment of density perturbations might not be sufficient\nto describe the measurements, and a fully relativistic calculation should be\nemployed. The interpretation of the data is thus further complicated by the\nfact that relativistic effects break statistical homogeneity and isotropy and\nare potentially divergent in the Infra-Red (IR). In this work we compute for\nthe first time the ensemble average of the most used Fourier space estimator in\nspectroscopic surveys, including all general relativistic (GR) effects, and\nallowing for an arbitrary choice of angular and radial selection functions. We\nshow that any observable is free of IR sensitivity once all the GR terms,\nindividually divergent, are taken into account, and that this cancellation is a\nconsequence of the presence of the Weinberg adiabatic mode as a solution to\nEinstein's equations. We then study the importance of GR effects, including\nlensing magnification, in the interpretation of the galaxy power spectrum\nmultipoles, finding that they are in general a small, less than ten percent\nlevel, correction to the leading redshift space distortions term. This work\nrepresents the baseline for future investigations of the interplay between\nPrimordial Non Gaussianities and GR effects on large scales and in Fourier\nspace.\n", "  Parametric resonance in a single-field inflationary model with a periodic\nstructure on the potential gives rise to curvature perturbations with large\namplitudes on small scales, which could result in observable primordial black\nholes (PBHs) and concomitant gravitational waves (GWs) induced by curvature\nperturbations in the radiation-dominated era. In such a model, GWs associated\nwith the PBH formation were investigated in Ref. [1]. In this paper, we\nconsider a stochastic GW background sourced by inflaton perturbations\nresonantly amplified during inflation. We compute the energy spectra of induced\nGWs produced both during inflation and in the radiation-dominated era, and find\nthat the peak of the energy spectrum of the former is much higher than that of\nthe latter, but is located at a lower frequency. Moreover, the energy spectrum\nof induced GWs produced during inflation exhibits a unique oscillating\ncharacter in the ultraviolet region. Both the stochastic GW backgrounds are\nexpected to be detected by future space-based laser interferometers.\n", "  Peculiar motion of the solar system, determined from the dipole anisotropy in\nthe Cosmic Microwave Background Radiation (CMBR), has given a velocity $370$ km\ns$^{-1}$ along RA$=168^{\\circ}$, Dec$=-7^{\\circ}$. Subsequent peculiar motion\ndeterminations from the number counts, sky brightness or redshift dipoles\nobserved in large samples of distant radio galaxies and quasars yielded\npeculiar velocities two to ten times larger than CMBR, though in all cases the\ndirections matched with the CMBR dipole. Here we introduce a novel technique\nfor determining the peculiar motion from the magnitude-redshift ($m_{\\rm B}-z$)\nHubble diagram of Type Ia Supernovae (SN Ia), one of the best standard candles\navailable. We find a peculiar velocity $1.6\\pm 0.5 \\times 10^3$ km s$^{-1}$,\nlarger than the CMBR value roughly by a factor of four, along\nRA$=173^{\\circ}\\pm12^{\\circ}$, Dec$=10^{\\circ}\\pm9^{\\circ}$, the direction\nbeing within $\\stackrel{<}{_{\\sim}}2\\sigma$ of the CMBR dipole. Since a genuine\nsolar motion would not depend upon the method or the dataset employed, large\ndiscrepancies seen among various dipole amplitudes could imply that these\ndipoles, including the CMBR one, might not pertain to observer's peculiar\nmotion. However, a common direction for various dipoles might indicate a\npreferred direction in the universe, implying an intrinsic anisotropy, in\nviolation of the cosmological principle, a cornerstone of the modern cosmology.\n", "  We measure the small-scale clustering of the Data Release 16 extended Baryon\nOscillation Spectroscopic Survey Luminous Red Galaxy sample, corrected for\nfibre-collisions using Pairwise Inverse Probability weights, which give\nunbiased clustering measurements on all scales. We fit to the monopole and\nquadrupole moments and to the projected correlation function over the\nseparation range $7-60\\,h^{-1}$Mpc with a model based on the Aemulus\ncosmological emulator to measure the growth rate of cosmic structure,\nparameterized by $f\\sigma_8$. We obtain a measurement of\n$f\\sigma_8(z=0.737)=0.408\\pm0.038$, which is $1.4\\sigma$ lower than the value\nexpected from 2018 Planck data for a flat $\\Lambda$CDM model, and is more\nconsistent with recent weak-lensing measurements. The level of precision\nachieved is 1.7 times better than more standard measurements made using only\nthe large-scale modes of the same sample. We also fit to the data using the\nfull range of scales $0.1-60\\,h^{-1}$Mpc modelled by the Aemulus cosmological\nemulator and find a $4.5\\sigma$ tension in the amplitude of the halo velocity\nfield with the Planck+$\\Lambda$CDM model, driven by a mismatch on the\nnon-linear scales. This may not be cosmological in origin, and could be due to\na breakdown in the Halo Occupation Distribution model used in the emulator.\nFinally, we perform a robust analysis of possible sources of systematics,\nincluding the effects of redshift uncertainty and incompleteness due to target\nselection that were not included in previous analyses fitting to clustering\nmeasurements on small scales.\n", "  We present a new, model-independent measurement of the clustering amplitude\nof galaxies and the growth of cosmic large-scale structures from the Baryon\nOscillation Spectroscopic Survey (BOSS) 12th data release (DR12). This is\nachieved by generalising harmonic-space power spectra for galaxy clustering to\nmeasure separately the magnitudes of the density and the redshift-space\ndistortion terms, respectively related to the clustering amplitude of\nstructures, $b\\sigma_8(z)$, and their growth, $f\\sigma_8(z)$. We adopt a\ntomographic approach with 15 redshift bins in $z\\in[0.15,0.67]$. We restrict\nour analysis to strictly linear scales, implementing a redshift-dependent\nmaximum multipole for each bin. The measurements do not appear to suffer from\nsystematic effects and show excellent agreement with the theoretical\npredictions from the Planck cosmic microwave background analysis assuming a\n$\\Lambda$CDM cosmology. Our results also agree with previous analyses by the\nBOSS collaboration. Furthermore, our method provides the community with a new\ntool for data analyses of the cosmic large-scale structure complementary to\nstate-of-the-art approaches in configuration or Fourier space. Amongst its\nmerits, we list: it being more agnostic with respect to the underlying\ncosmological model; its roots in a well-defined and gauge-invariant observable;\nthe possibility to account naturally for wide-angle effects and even\nrelativistic corrections on ultra-large scales; and the capability to perform\nan almost arbitrarily fine redshift binning with little computational effort.\nThese aspects are all the more relevant for the oncoming generation of\ncosmological experiments such as Euclid, the Dark Energy Spectroscopic\nInstrument (DESI), the Legacy Survey of Space and Time (LSST), and the SKA\nProject.\n", "  In this paper, we have investigated a scalar field cosmological model of\naccelerating Universe with the simplest parametrization of equation of state\nparameter of the scalar field. We used $H(z)$ data, pantheon compilation of SN\nIa data and BAO data to constrained the model parameters using $\\chi^{2}$\nminimization technique. We obtain the present values of Hubble constant $H_{0}$\nas $66.2^{+1.42}_{-1.34}$, $70.7^{+0.32}_{-0.31}$ and $67.74^{+1.24}_{-1.04}$\nfor $H(z)$, $H(z)$ + Pantheon and $H(z)$ + BAO respectively. Also, we have\nestimated the present age of the Universe in derived model $t_{0} =\n14.38^{+0.63}_{-0.64}$ for joint $H(z)$ and pantheon compilation of SN Ia data\nwhich has only $0.88~\\sigma$ tension with its empirical value obtained in Plank\ncollaboration \\cite{Ade/2016}. Moreover, the present values of the deceleration\nparameter $q_{0}$ come out to be $-0.55^{+0.031}_{-0.038}$,\n$-0.61^{+0.030}_{-0.021}$ and $-0.627^{+0.022}_{-0.025}$ by bounding the\nUniverse in derived model with $H(z)$, $H(z)$ + Pantheon compilation of SN Ia\nand $H(z)$ + BAO data sets respectively. We also have performed the\nstate-finder diagnostics to discover the nature of dark energy.\n", "  This work presents a new physically-motivated supervised machine learning\nmethod, Hydro-BAM, to reproduce the three-dimensional Lyman-$\\alpha$ forest\nfield in real and in redshift space learning from a reference hydrodynamic\nsimulation, thereby saving about 7 orders of magnitude in computing time. We\nshow that our method is accurate up to $k\\sim1\\,h\\,\\rm{Mpc}^{-1}$ in the one-\n(PDF), two- (power-spectra) and three-point (bi-spectra) statistics of the\nreconstructed fields. When compared to the reference simulation including\nredshift space distortions, our method achieves deviations of $\\lesssim2\\%$ up\nto $k=0.6\\,h\\,\\rm{Mpc}^{-1}$ in the monopole, $\\lesssim5\\%$ up to\n$k=0.9\\,h\\,\\rm{Mpc}^{-1}$ in the quadrupole. The bi-spectrum is well reproduced\nfor triangle configurations with sides up to $k=0.8\\,h\\,\\rm{Mpc}^{-1}$. In\ncontrast, the commonly-adopted Fluctuating Gunn-Peterson approximation shows\nsignificant deviations already neglecting peculiar motions at configurations\nwith sides of $k=0.2-0.4\\,h\\,\\rm{Mpc}^{-1}$ in the bi-spectrum, being also\nsignificantly less accurate in the power-spectrum (within 5$\\%$ up to\n$k=0.7\\,h\\,\\rm{Mpc}^{-1}$). We conclude that an accurate analysis of the\nLyman-$\\alpha$ forest requires considering the complex baryonic thermodynamical\nlarge-scale structure relations. Our hierarchical domain specific machine\nlearning method can efficiently exploit this and is ready to generate accurate\nLyman-$\\alpha$ forest mock catalogues covering large volumes required by\nsurveys such as DESI and WEAVE.\n", "  The increasingly large amount of cosmological data coming from ground-based\nand space-borne telescopes requires highly efficient and fast enough data\nanalysis techniques to maximise the scientific exploitation. In this work, we\nexplore the capabilities of supervised machine learning algorithms to learn the\nproperties of the large-scale structure of the Universe, aiming at constraining\nthe matter density parameter, Omega m. We implement a new Artificial Neural\nNetwork for a regression data analysis, and train it on a large set of galaxy\ntwo-point correlation functions in standard cosmologies with different values\nof Omega m. The training set is constructed from log-normal mock catalogues\nwhich reproduce the clustering of the Baryon Oscillation Spectroscopic Survey\n(BOSS) galaxies. The presented statistical method requires no specific\nanalytical model to construct the likelihood function, and runs with negligible\ncomputational cost, after training. We test this new Artificial Neural Network\non real BOSS data, finding Omega m=0.309p/m0.008, which is remarkably\nconsistent with standard analysis results.\n", "  We have studied how local density perturbations could reconcile the Hubble\ntension. We reproduced a local void through a perturbed FLRW metric with a\npotential $\\Phi$ which depends on both time and space. This method allowed us\nto obtain a perturbed luminosity distance, which is compared with both local\nand cosmological data. However, when constraining local cosmological parameters\nwith previous results, we found that neither $\\Lambda$CDM nor\n$\\Lambda(\\omega)$CDM cannot solve the Hubble tension.\n", "  In this study we present constraints on the deceleration (q) and jerk (j)\nparameters using the late time integrated Sachs-Wolfe effect, type Ia\nsupernovae, and H(z) data . We first directly measure the deceleration and jerk\nparameters using the cosmic chronometers data with the Taylor series expression\nof H(z).However, due to the unusual variations in the deceleration parameter\nwith slight changes in other parameters like snap (s) and lerk (l), we found\nthat direct measurements using the series expression of the H(z) is not a\nsuitable method for non-Lambda-CDM models and so we will need to derive the\ndeceleration parameter after constraining density parameters and dark energy\nequation of state parameters. Then we present derived values of the\ndeceleration parameter from Lambda CDM, WCDM and CPL models. We also discuss\nthe transition redshift (zt) in relation with the deceleration parameter.\n", "  With the advent of the first luminous sources at Cosmic Dawn (CD), the\nredshifted 21-cm signal, from the neutral hydrogen in the Inter-Galactic Medium\n(IGM), is predicted to undergo a transition from absorption to emission against\nthe CMB. Using simulations, we show that the redshift evolution of the sign and\nthe magnitude of the 21-cm bispectrum can disentangle the contributions from\nLy$\\alpha$ coupling and X-ray heating of the IGM, the two most dominant\nprocesses which drive this transition. This opens a new avenue to probe the\nfirst luminous sources and the IGM physics at CD.\n", "  We examine the prospects for measurement of the Hubble parameter $H_0$ via\nobservation of the secular parallax of other galaxies due to our own motion\nrelative to the cosmic microwave background rest frame. Peculiar velocities\nmake distance measurements to individual galaxies highly uncertain, but a\nsurvey sampling many galaxies can still yield a precise $H_0$ measurement. We\nuse both a Fisher information formalism and simulations to forecast errors in\n$H_0$ from such surveys, marginalizing over the unknown peculiar velocities.\nThe optimum survey observes $\\sim 10^2$ galaxies within a redshift\n$z_\\mathrm{max}=0.06$. The required errors on proper motion are comparable to\nthose that can be achieved by Gaia and future astrometric instruments. A\nmeasurement of $H_0$ via parallax has the potential to shed light on the\ntension between different measurements of $H_0$.\n", "  The polarization of the 21-cm radiation from the epoch of reionization arises\nfrom Thomson scattering of 21-cm photons from free electrons and provides\ninformation that complements that from the intensity fluctuation. Previous work\nshowed that a direct detection of this signal will be difficult, and hinted\nthat the signal might be enhanced via correlation with other tracers. Here, we\ndiscuss the cross-correlation between the cosmic microwave background (CMB)\npolarization and the 21-cm polarization. We treat reionization using an\nanalytical model with parameters calibrated by semi-numerical simulations. We\nthen derive the cross-correlation angular power spectrum using the\ntotal-angular-momentum formalism. We also provide a noise analysis to test\nagainst two closely related, but subtly different, null hypotheses. First, we\nassume no reionization as a null hypothesis, and determine how well this null\nhypothesis could be ruled out by an observed 21cm-CMB polarization correlation.\nSecond, we determine how well the null hypothesis of no 21-cm polarization can\nbe ruled out by seeking the cross-correlation, assuming reionization is\nestablished from the CMB. We find that the first question could be answered by\na synergy of ambitious next-generation 21-cm and CMB missions, whereas the\nsecond question will still remain out of reach.\n", "  Quasars are quadruply lensed only when they lie within the diamond caustic of\na lensing galaxy. This precondition produces a Malmquist-like selection effect\nin observed populations of quadruply lensed quasars, overestimating the true\ncaustic area. The bias toward high values of the inferred logarithmic area,\n$\\ln A_{inf}$, is proportional to the square of the error in that area,\n$\\sigma^2_{\\ln{A}}$. In effect, Malmquist's correction compensates post-hoc for\na failure to incorporate a prior into parameter optimization. Inferred time\ndelays are proportional to the square root of the inferred caustic area of the\nlensing galaxy. Model time delays are biased long, leading to overestimates of\nthe Hubble constant. Crude estimates of $\\sigma_{\\ln A}$ for a sample of 13\nquadruple systems give a median value of 0.16.\n  We identify a second effect, \"inferred magnification bias,'' resulting from\nthe combination of selection by apparent magnitude and errors in model\nmagnification. It is strongly anti-correlated with caustic area bias, and\nalmost always leads to underestimates of the Hubble constant. Malmquist's\nscheme can be adapted to priors on multiple parameters, but for quad lenses,\nthe negative covariances between caustic area and absolute magnitude are poorly\nknown. Inferred magnification bias may even cancel out caustic area bias,\ndepending upon (among other things) the slope of the number magnitude relation\nfor the sample.\n  Proper correction for these combined effects can, in principle, be built into\nBayesian modeling schemes as priors, eliminating the need for Malmquist-style\napproximation, but is likely to be challenging in practice.\n", "  We study the small-scale asymptotic behaviour of the cosmic\ndensity-fluctuation power spectrum in the Zel'dovich approximation. For doing\nso, we extend Laplace's method in arbitrary dimensions and use it to prove that\nthis power spectrum necessarily develops an asymptotic tail proportional to\n$k^{-3}$ , irrespective of the cosmological model and the power spectrum of the\ninitial matter distribution. The exponent $-3$ is set only by the number of\nspatial dimensions. We derive the complete asymptotic series of the power\nspectrum and compare the leading- and next-to-leading-order terms to derive\ncharacteristic scales for the onset of non-linear structure formation,\nindependent of the cosmological model and the type of dark matter. Combined\nwith earlier results on the mean-field approximation for including particle\ninteractions, this asymptotic behaviour is likely to remain valid beyond the\nZel'dovich approximation. Due to their insensitivity to cosmological\nassumptions, our results are generally applicable to particle distributions\nwith positions and momenta drawn from a Gaussian random field. We discuss an\nanalytically solvable toy model to further illustrate the formation of the\n$k^{-3}$ asymptotic tail.\n", "  We calculated morphological parameters for 70821 galaxies from VIPERS\n(spectroscopic galaxy survey performed on VIMOS spectroscope at VLT). These\nparameters includes Gini, M20, Concentration, Asymmetry and Smoothness. Results\ncorrelate with the distribution of these parameters for other simulated and\nobserved samples. We also studied dependence of these parameters with Sersic\npower index of radial distribution of surface brightness of galaxy image. Our\naim was to find a clear separation of VIPERS galaxies on elliptical and spiral.\nThis is necessary for testing the method of Sersic index (ns) calculation in\nstatmorph program. To find such bimodality we use B-V color index from VIPERS\ndatabase.\n  To perform the error analysis of morphological parameters we simulated galaxy\nimages with random background of different magnitude and estimated the errors\nas dispersion of the parameters. We also found asymptotic values of errors of\nmorphological parameters by increasing the numbers of mock images.\n  To analyse the possible variation of each morphological parameter during the\nconvolution of close galactic images, we have simulated them to research. In\nthe result of this investigation we have analysed the dependence of the every\nmorphological parameter from CAS and Gini/M20 statistics from the distance\nbetween galactic centers.\n  The differences between our results for VIPERS and Gini-M20 distribution for\nPanStarrs galaxies at z<0.5 could be explained it by cosmological evolution of\ngalaxies. We found out that in modern Universe there are much more elliptical\ngalaxies than at z>0.5 which corresponds to VIPERS sample. Also we concluded\nthat galaxy mergers were more frequent in the early Universe.\n", "  We propose to use Self-Organizing Maps (SOM) to map the impact of physical\nmodels onto observables. Using this approach, we are be able to determine how\ntheories relate to each other given their signatures. In cosmology this will be\nparticularly useful to determine cosmological models (such as dark energy,\nmodified gravity or inflationary models) that should be tested by the new\ngeneration of experiments. As a first example, we apply this approach to the\nrepresentation of a subset of the space of modified gravity theories probed by\ncosmic shear. We therefore train a SOM on shear correlation functions in the\n$f(R)$, dilaton and symmetron models. The results indicate these three theories\nhave similar signatures on shear for small values of their parameters but the\ndilaton has different signature for higher values. We also show that modified\ngravity (especially the dilaton model) has a different impact on cosmic shear\ncompared to a dynamical dark energy so both need to be tested by galaxy\nsurveys.\n", "  Whilst the underlying assumption of the Friedman-Lema\\^itre-Robertson-Walker\n(FLRW) cosmological model is that matter is homogeneously distributed\nthroughout the universe, gravitational influences over the life of the universe\nhave resulted in mass clustered on a range of scales. Hence we expect that, in\nour inhomogeneous universe, the view of an observer will be influenced by the\nlocation and local environment. Here we analyse the one-point probability\ndistribution functions and angular power spectra of weak-lensing (WL)\nconvergence and magnification numerically to investigate the influence of our\nlocal environment on WL statistics in relativistic $N$-body simulations. To\nachieve this, we numerically solve the null geodesic equations which describe\nthe propagation of light bundles backwards in time from today, and develop a\nray-tracing algorithm, and from these calculate various WL properties. Our\nfindings demonstrate how cosmological observations of large-scale structure\nthrough WL can be impacted by the locality of the observer. We also calculate\nthe constraints on the cosmological parameters as a function of redshift from\nthe theoretical and numerical study of the angular power spectrum of WL\nconvergence. This study concludes the minimal redshift for the constraint on\nthe parameter $\\Omega_m$ ($H_0$) is $z \\sim 0.2$ $(z \\sim 0.6 )$ beyond which\nthe local environment's effect is negligible and the data from WL surveys are\nmore meaningful above that redshift. The outcomes of this study will have\ndirect consequences for future surveys, where percent-level-precision is\nnecessary.\n", "  Our motion through the Universe generates a dipole in the temperature\nanisotropies of the Cosmic Microwave Background (CMB) and also in the angular\ndistribution of sources. If the cosmological principle is valid, these two\ndipoles are directly linked, such that the amplitude of one determines that of\nthe other. However, it is a longstanding problem that number counts of radio\nsources and of quasars at low and intermediate redshifts exhibit a dipole that\nis well aligned with that of the CMB but with about twice the expected\namplitude, leading to a tension reaching up to $4.9 \\sigma$. In this paper, we\nrevisit the theoretical derivation of the dipole in the sources number counts,\nexplicitly accounting for the redshift evolution of the population of sources.\nWe argue that if the spectral index and magnification bias of the sources vary\nwith redshift, the standard theoretical description of the dipole may be\ninaccurate. We provide an alternative expression which does not depend on the\nspectral index, but instead on the time evolution of the population of sources.\nWe then determine the values that this evolution rate should have in order to\nremove the tension with the CMB dipole.\n", "  We examine the cosmological constraining power from two cross-correlation\nprobes between galaxy and CMB surveys: the cross-correlation of lens galaxy\ndensity with CMB lensing convergence $\\langle\\delta\\kappa\\rangle$, and source\ngalaxy weak lensing shear with CMB lensing convergence\n$\\langle\\gamma\\kappa\\rangle$. These two cross-correlation probes provide an\nindependent cross-check of other large-scale structure constraints and are\ninsensitive to galaxy-only or CMB-only systematic effects. In addition, when\ncombined with other large-scale structure probes, the cross-correlations can\nbreak degeneracies in cosmological and nuisance parameters, improving both the\nprecision and robustness of the analysis. In this work, we study how the\nconstraining power of $\\langle\\delta\\kappa\\rangle+\\langle\\gamma\\kappa\\rangle$\nchanges from Stage-III (ongoing) to Stage-IV (future) surveys. Given the\nflexibility in selecting the lens galaxy sample, we also explore systematically\nthe impact on cosmological constraints when we vary the redshift range and\nmagnitude limit of the lens galaxies using mock galaxy catalogs. We find that\nin our setup, the contribution to cosmological constraints from\n$\\langle\\delta\\kappa\\rangle$ and $\\langle\\gamma\\kappa\\rangle$ are comparable in\nthe Stage-III datasets; but in Stage-IV surveys, the noise in\n$\\langle\\delta\\kappa\\rangle$ becomes subdominant to cosmic variance, preventing\n$\\langle\\delta\\kappa\\rangle$ to further improve the constraints. This implies\nthat to maximize the cosmological constraints from future\n$\\langle\\delta\\kappa\\rangle+\\langle\\gamma\\kappa\\rangle$ analyses, we should\nfocus more on the requirements on $\\langle\\gamma\\kappa\\rangle$ instead of\n$\\langle\\delta\\kappa\\rangle$. Furthermore, the selection of the lens sample\nshould be optimized in terms of our ability to characterize its redshift or\ngalaxy bias instead of its number density.\n", "  Baryon Acoustic Oscillations (BAO) datasets use very precise measurements of\nthe spatial distribution of large-scale structures as a distance ladder to help\nconstrain cosmological parameters. In a recent article \\cite{Benisty:2020otr},\nwe combined 17 uncorrelated BAO measurements in the effective redshift range\n$0.106 \\le z \\le 2.36$ with the Cosmic Chronometers data, the Pantheon Type Ia\nsupernova and the Hubble Diagram of Gamma Ray Bursts and Quasars to obtain that\nthe $\\Lambda$CDM model fit infers for the Hubble constant: $69.85 \\pm\n1.27km/sec/Mpc$ and for the sound horizon distance: $146.1 \\pm 2.15Mpc$. Beyond\nthe $\\Lambda$CDM model we test $\\Omega_k$CDM and wCDM and we get $\\Omega_k =\n-0.076 \\pm 0.012$, $w = -0.989 \\pm 0.049$ accordingly. In this proceeding we\npresent elaborate on our findings and we compare them to other recent results\nin the literature.\n", "  Damped Lyman-$\\alpha$ Absorber(DLA) of HI 21cm system is an ideal probe to\ndirectly measure cosmic acceleration in real-time cosmology via\nSandage-Loeb(SL) test. During short observations toward two DLAs in the\ncommissioning progress of FAST, we manage to exhibit an HI 21cm absorption\nfeature from PKS1413+135 spectrum in one epoch with our highest resolution up\nto 100 Hz, preliminarily validating the frequency consistency under different\nresolutions and bandwidths. We make a Gaussian fitting to extract the spectral\nfeatures, introduce two theoretical indicators to describe the fitted velocity\nuncertainty, and ultimately give a mean redshift and its constraint of\n$z_\\mathrm{M}=0.24670045\\pm0.00000036$ in accord with most literature. But our\nredshift error of the target is still three magnitudes higher than the level we\ncan reach the drift signal. Though our first preparation has some flaws in time\nrecording and diode settings, it still proves the correctness of our data\nprocess. Confined by limited observing time, we do not strech FAST's ability to\nobtain a better velocity constraint, so further researchs are needed and in\nschedule. With fine sensitivity and improving spectral resolution, such\nobservations in FAST could have reasonable possibility to explore cosmic\nacceleration in late time universe practically.\n", "  Galaxy superclusters, the largest galaxy structures in the cosmic web, are\nformed due to the gravitational collapse (although they are not usually\ngravitationally bound). Their geometrical properties can shed light on the\nstructure formation process on cosmological scales, hence on the fundamental\nproperties of gravity itself. In this work we study the distributions of the\nshape, topology and morphology of the superclusters extracted from SDSS DR 12\nmain galaxy sample and defined in two different ways - using fixed and adaptive\ndensity threshold in the luminosity-density field. To assess the geometry and\ntopology of each individual supercluster, we employ Minkowski functionals and\nShapefinders, precisely calculated by the shape diagnostic tool SURFGEN2. Both\nsupercluster samples produce similar shape distributions. Not surprisingly,\nmost superclusters are spherical in shape with trivial topology. However, large\nsuperclusters with volumes $V \\gtrsim 10^{4}$ Mpc$^{3}$ are statistically found\nto be filamentary with non-zero genus values. The results, shape distributions\nand catalogues have been made publicly available.\n", "  The main aim of this paper is to perform a model comparison for some\nreconstructions of the key properties that describe the dark energy of the\nUniverse i.e. energy density and the equation of state (EoS). We carry out this\nprocess by using a binning and a linear interpolation methodologies, and on top\nof that, we incorporate a correlation function mechanism. An extension of the\ntwo of them was also introduced, where internal amplitudes are allowed to vary\nin height as well as in position. The reconstructions were made with data from\nthe Hubble parameter, Supernovae Type Ia and Baryon Acoustic Oscillations\n(H+SN+BAO), all of which span a range from $z=0.01$ to $z=2.34$. First we\nperform the parameter estimation for each of the reconstructions to then\nprovide a model selection through the Bayesian Evidence. Throughout our process\nwe found a better fit to the data, up to $4\\sigma$ compared to $\\Lambda$CDM,\nand the presence of some interesting features, i.e. an oscillatory behaviour at\nlate times, a decrease in the dark energy density component at early times and\na transition to the phantom divide-line in the EoS. To discern these features\nfrom noisy contributions, we include a principal component analysis and found\nthat some of these characteristics should be taken into account to satisfy\ncurrent observations.\n", "  We present a forward-modelled velocity field reconstruction algorithm that\nperforms the reconstruction of the mass density field using only peculiar\nvelocity data. Our method consistently accounts for the inhomogeneous Malmquist\nbias using analytic integration along the line-of-sight. By testing our method\non a simulation, we show that our method gives an unbiased reconstruction of\nthe velocity field. We show that not accounting for the inhomogeneous Malmquist\nbias can lead to significant biases in the forward-modelled reconstructions. We\napplied our method to a peculiar velocity data set consisting of the SFI++ and\n2MTF Tully-Fisher catalogues and the A2 supernovae compilation, thus obtaining\na novel velocity reconstruction in the local Universe. Our velocity\nreconstructions have a cosmological power spectrum consistent with the\ntheoretical expectation. Furthermore, we obtain a full description of the\nuncertainties on reconstruction through samples of the posterior distribution.\nWe validate our velocity reconstruction of the local Universe by comparing it\nto an independent reconstruction using the 2M++ galaxy catalogue, obtaining\ngood agreement between the two reconstructions. Using Bayesian model\ncomparison, we find that our velocity model performs better than the adaptive\nkernel smoothed velocity with the same peculiar velocity data. However, our\nvelocity model does not perform as well as the velocity reconstruction from the\n2M++ galaxy catalogue, due to the sparse and noisy nature of the peculiar\nvelocity tracer samples. The method presented here provides a way to include\npeculiar velocity data in initial condition reconstruction frameworks.\n", "  Weak gravitational lensing is one of the few direct methods to map the\ndark-matter distribution on large scales in the Universe, and to estimate\ncosmological parameters. We study a Bayesian inference problem where the data\ncovariance $\\mathbf{C}$, estimated from a number $n_{\\textrm{s}}$ of numerical\nsimulations, is singular. In a cosmological context of large-scale structure\nobservations, the creation of a large number of such $N$-body simulations is\noften prohibitively expensive. Inference based on a likelihood function often\nincludes a precision matrix, $\\Psi = \\mathbf{C}^{-1}$. The covariance matrix\ncorresponding to a $p$-dimensional data vector is singular for $p \\ge\nn_{\\textrm{s}}$, in which case the precision matrix is unavailable. We propose\nthe likelihood-free inference method Approximate Bayesian Computation (ABC) as\na solution that circumvents the inversion of the singular covariance matrix. We\npresent examples of increasing degree of complexity, culminating in a realistic\ncosmological scenario of the determination of the weak-gravitational lensing\npower spectrum for the upcoming European Space Agency satellite Euclid. While\nwe found the ABC parameter estimate variances to be mildly larger compared to\nlikelihood-based approaches, which are restricted to settings with $p <\nn_{\\textrm{s}}$, we obtain unbiased parameter estimates with ABC even in\nextreme cases where $p / n_{\\textrm{s}} \\gg 1$. The code has been made publicly\navailable to ensure the reproducibility of the results.\n", "  The cross-correlation between 21-cm intensity mapping experiments and\nphotometric surveys of galaxies (or any other cosmological tracer with a broad\nradial kernel) is severely degraded by the loss of long-wavelength radial modes\ndue to Galactic foreground contamination. Higher-order correlators are able to\nrestore some of these modes due to the non-linear coupling between them and the\nlocal small-scale clustering induced by gravitational collapse. We explore the\npossibility of recovering information from the bispectrum between a photometric\ngalaxy sample and an intensity mapping experiment, in the context of the\nclustering-redshifts technique. We demonstrate that the bispectrum is able to\ncalibrate the redshift distribution of the photometric sample to the required\naccuracy of future experiments such as the Rubin Observatory, using future\nsingle-dish and interferometric 21-cm observations, in situations where the\ntwo-point function is not able to do so due to foreground contamination. We\nalso show how this calibration is affected by the photometric redshift width\n$\\sigma_{z,0}$ and maximum scale $k_{\\mathrm{max}}$. We find that it is\nimportant to reach scales $k \\gtrsim 0.3\\,h\\,\\mathrm{Mpc}^{-1}$, with the\nconstraints saturating at around $k\\sim 1\\,h\\,\\mathrm{Mpc}^{-1}$ for\nnext-generation experiments.\n", "  We present a novel analysis for cluster cosmology that fully forward models\nthe abundances, weak lensing, and the clustering of galaxy clusters. Our\nanalysis notably includes an empirical model for the anisotropic boosts\nimpacting the lensing and clustering signals of optical clusters. These boosts\narise from a preferential selection of clusters surrounded by anisotropic large\nscale structure, a consequence of the limited discrimination between\nline-of-sight interlopers and true cluster members offered by photometric\nsurveys. We validate our analysis via a blind cosmology challenge on mocks, and\nfind that we can obtain tight and unbiased cosmological constraints without\ninformative priors or external calibrations on any of our model parameters. We\nthen apply our analysis on the SDSS redMaPPer clusters, and find results\nfavoring low $\\Omega_\\mathrm{m}$ and high $\\sigma_8$, combining to yield the\nlensing strength constraint $S_8 = 0.718_{-0.021}^{+0.024}$. We investigate\npotential drivers behind these results through a series of post-unblinding\ntests, noting that our results are consistent with existing cluster cosmology\nconstraints but clearly inconsistent with other CMB/LSS based cosmology\nresults. From these tests, we find hints that a suppression in the cluster\nlensing signal may be driving our results.\n", "  $H_0$ constraints from galaxy surveys are sourced by the geometric properties\nof two standardisable rulers: the sound horizon scale, $r_s$, and the\nmatter-radiation equality scale, $k_{\\rm eq}$. While most analyses over the\nlast decade have focused on the first scale, recent work has emphasised that\nthe second can provide an independent source of information about the expansion\nrate of the universe. Recent approaches to obtain a sound-horizon-independent\nmeasurement of $H_0$ from the equality scale have avoided $r_s$-based\ninformation by removing the sound-horizon-calibrating prior on the baryon\ndensity. We present a new method to marginalise over $r_s$; this allows baryon\ninformation to be retained enabling tighter parameter constraints. For a\nEuclid-like spectroscopic survey, we forecast sound-horizon-independent $H_0$\nconstraints of $\\sigma_{H_0} = 0.7\\rm{\\ km\\ s^{-1}\\ Mpc^{-1}}$ for our method\nusing the equality scale, compared with $\\sigma_{H_0} = 0.5\\rm{\\ km\\ s^{-1}\\\nMpc^{-1}}$ from the sound horizon. Upcoming equality scale $H_0$ measurements\nthus can be highly competitive, although we caution that the impact of\nobservational systematics on such measurements still needs to be investigated\nin detail. Applying our new approach to the BOSS power spectrum gives $H_0 =\n69.5^{+3.0}_{-3.5}\\rm{\\ km\\ s^{-1}\\ Mpc^{-1}}$ from equality alone, somewhat\ntighter than previous constraints. Consistency of $r_s$- and $k_{\\rm eq}$-based\n$H_0$ measurements can provide a valuable internal consistency test of the\ncosmological model; as an example, we consider the change in $H_0$ created by\nearly dark energy. Assuming the \\textit{Planck}+SH0ES best-fit EDE model we\nfind a $2.6\\sigma$ shift ($\\Delta H_0 = 2.6\\rm{\\ km\\ s^{-1}\\ Mpc^{-1}}$)\nbetween the two measurements for Euclid; if we instead assume the ACT best-fit\nmodel, this increases to $9.0\\sigma$ ($\\Delta H_0 = 7.8\\rm{\\ km\\ s^{-1}\\\nMpc^{-1}}$).\n", "  Cosmological $N$-body simulations provide numerical predictions of the\nstructure of the Universe against which to compare data from ongoing and future\nsurveys, but the growing volume of the Universe mapped by surveys requires\ncorrespondingly lower statistical uncertainties in simulations, usually\nachieved by increasing simulation sizes at the expense of computational power.\nIt was recently proposed to reduce simulation variance without incurring\nadditional computational costs by adopting fixed-amplitude initial conditions.\nThis method has been demonstrated not to introduce bias in various statistics,\nincluding the two-point statistics of galaxy samples typically used for\nextracting cosmological parameters from galaxy redshift survey data, but\nrequires us to revisit current methods for estimating covariance matrices of\nclustering statistics for simulations. In this work, we find that it is not\ntrivial to construct covariance matrices analytically for fixed-amplitude\nsimulations, but we demonstrate that EZmock (Effective Zel'dovich approximation\nmock catalogue), the most efficient method for constructing mock catalogues\nwith accurate two- and three-point statistics, provides reasonable covariance\nmatrix estimates for such simulations. We further examine how the variance\nsuppression obtained by amplitude-fixing depends on three-point clustering,\nsmall-scale clustering, and galaxy bias, and propose intuitive explanations for\nthe effects we observe based on the EZmock bias model.\n", "  We discuss an implementation of a deep learning framework to gain insight\ninto dark matter (DM) structure formation. We investigate the impact of initial\nvelocity and density field information on the construction of halo mass\nfunction (HMF) through cosmological $N$-body simulations. We train a\nConvolutional Neural Network (CNN) on the initial snapshot of a DM-only\nsimulation to predict the HMF that individual particles fall into at $z=0$, in\nthe halo mass range of $10.5< \\log(M / M_{\\odot})<14$. Our results show a\nnegligible improvement from including the velocity in addition to the density\ninformation when considering simulations based on ($\\Lambda$CDM) with the\namplitude of initial scalar perturbations $A_s = 2\\times10^{-9}$. To\ninvestigate the effect of the initial velocity field in constructing the halo\nmass function, we increase the initial power spectrum such that we see the\neffect of velocities in larger halos visible to the resolution of our\nsimulations. The CNN model trained on the simulation snapshots with large $A_s$\nshows a considerable improvement in the HMF prediction when adding the velocity\nfield information. Eventually, for the simulation with $A_s = 8 \\times\n10^{-8}$, the model trained with only density information shows at least $80\\%$\nincrease in the mean squared error relative to the model with both velocity and\ndensity information, which indicates the failure of the density-only model to\npredict the halo mass function in this case. Our work shows the\ninterpretability and ability of CNNs to read higher-order information from\nsimple images, making them an excellent tool for cosmological studies.\n", "  We present a fast methodology to produce mock observations of the thermal and\nkinetic Sunyaev-Zel'dovich (SZ) effects based on the dark matter only $N$-body\nsimulations coupled with the analytic intra-cluster medium model. The methods\nemploy two different approaches: halo-based pasting (HP) and particle-based\npasting (PP). The former pastes gas density and pressure onto halos and\nrequires only a halo catalogue, and the latter considers the contribution from\nfield particles as well, i.e., particles that do not belong to any halos and\nthus utilise the full particle information. Therefore, the PP algorithm\nincorporates secondary effects beyond the HP algorithm: asphericity of halos\nand contribution from diffuse gas. In particular, such a diffuse component is\nthe dominant source of the kinetic SZ effect. As validation of our methods, we\nhave produced 108 all-sky maps with HP and 108 flat-sky maps, which cover $5\n\\times 5 \\, \\mathrm{deg}^2$ with both HP and PP, and measured power spectra of\nthe maps. Our method can produce a mock map within a few hours, even for\nall-sky coverage with a parallel computational environment. The power spectra\nof HP maps are consistent with the halo model prediction of the thermal SZ\neffect. On the other hand, the power spectra of PP maps are suppressed due to\nthe halo asphericity but can reproduce better the theoretical prediction for\nthe kinetic SZ effect. We discuss the utility of baryon-pasted mock SZ maps for\nestimating the covariance matrix of SZ statistics and modelling the selection\nand projection effects for cluster cosmology.\n", "  We describe the computational infrastructure for end-to-end Bayesian CMB\nanalysis implemented by the BeyondPlanck collaboration. This code is called\ncommander3, and provides a statistically consistent framework for global\nanalysis of CMB and microwave observations, and may be useful for a wide range\nof legacy, current, and future experiments. The paper has three main goals.\nFirstly, we provide a high-level overview of the existing code base, aiming to\nguide readers who wish to extend and adapt the code according to their own\nneeds, or to reimplement it from scratch in a different programming language.\nSecondly, we discuss some critical computational challenges that arise within\nany global CMB analysis framework, for instance in-memory compression of\ntime-ordered data, FFT optimization, and parallelization and load-balancing.\nThirdly, we quantify the CPU and RAM requirements for the current BeyondPlanck\nanalysis, and find that a total of 1.5 TB of RAM is required for efficient\nanalysis, and the total cost of a full Gibbs sample is 170 CPU-hrs, including\nboth low-level processing and high-level component separation, which is well\nwithin the capabilities of current low-cost computing facilities. The existing\ncode base is made publicly available under a GNU General Public Library (GPL)\nlicense.\n", "  We constrain the level of polarized anomalous microwave emission (AME) on\nlarge angular scales using $\\textit{Planck}$ LFI and $\\textit{WMAP}$\npolarization data within a Bayesian CMB analysis framework. We model\nsynchrotron emission with a power-law spectral energy distribution, and the sum\nof AME and thermal dust emission through linear regression with the\n$\\textit{Planck}$ HFI 353 GHz data. This template-based dust emission model\nallows us to constrain the level of polarized AME while making minimal\nassumptions on its frequency dependence. We neglect cosmic microwave background\nfluctuations, but show through simulations that these have a minor impact on\nthe results. We find that the resulting AME polarization fraction confidence\nlimit is sensitive to the polarized synchrotron spectral index prior, and for\npriors steeper than $\\beta_{\\mathrm{s}} = -3.1\\pm0.1$ we find an upper limit of\n$p_{\\mathrm{AME}}^{\\rm max}\\lesssim 0.6\\,\\%$ ($95\\,\\%$ confidence). In\ncontrast, for $\\beta_{\\mathrm{s}}=-3.0\\pm0.1$, we find a nominal detection of\n$p_{\\mathrm{AME}}=2.5\\pm1.0\\,\\%$ ($95\\,\\%$ confidence). These data are thus not\nstrong enough to simultaneously and robustly constrain both polarized\nsynchrotron emission and AME, and our main result is therefore a constraint on\nthe AME polarization fraction explicitly as a function of $\\beta_\\mathrm{s}$.\nCombining the current $\\textit{Planck}$ and $\\textit{WMAP}$ observations with\nmeasurements from high-sensitivity low-frequency experiments such as C-BASS and\nQUIJOTE will be critical to improve these limits further.\n", "  We present the intensity foreground algorithms and model employed within the\nBeyondPlanck analysis framework. The BeyondPlanck analysis is aimed at\nintegrating component separation and instrumental parameter sampling within a\nglobal framework, leading to complete end-to-end error propagation in the\n$Planck$ Low Frequency Instrument (LFI) data analysis. Given the scope of the\nBeyondPlanck analysis, a limited set of data is included in the component\nseparation process, leading to foreground parameter degeneracies. In order to\nproperly constrain the Galactic foreground parameters, we improve upon the\nprevious $\\texttt{Commander}$ component separation implementation by adding a\nsuite of algorithmic techniques. These algorithms are designed to improve the\nstability and computational efficiency for weakly constrained posterior\ndistributions. These are: 1) joint foreground spectral parameter and amplitude\nsampling, building on ideas from Miramare; 2) component-based monopole\ndetermination; 3) joint spectral parameter and monopole sampling; and 4)\napplication of informative spatial priors for component amplitude maps. We find\nthat the only spectral parameter with a significant signal-to-noise ratio using\nthe current BeyondPlanck data set is the peak frequency of the anomalous\nmicrowave emission component, for which we find $\\nu_{\\mathrm{p}}=25.3\\pm0.5$\nGHz; all others must be constrained through external priors. Future works will\nbe aimed at integrating many more data sets into this analysis, both map and\ntime-ordered based, thereby gradually eliminating the currently observed\ndegeneracies in a controlled manner with respect to both instrumental\nsystematic effects and astrophysical degeneracies. When this happens, the\nsimple LFI-oriented data model employed in the current work will need to be\ngeneralized to account for both a richer astrophysical model and additional\ninstrumental effects.\n", "  We carry out a thermal energy census of hot baryons at $z < 1$, by\ncross-correlating the \\emph{Planck} MILCA y-map with 0.8 million\nclusters/groups selected from the Yang et.al (2021) catalog. The thermal\nSunyaev-Zel'dovich (tSZ) effect around these clusters/groups are reliably\nobtained, which enables us to make our model constraints based on one-halo (1h)\nand two-halo (2h) contributions, respectively. (1) The total measurement S/N of\nthe one-halo term is 63. We constrain the $Y$-$M$ relation over the halo mass\nrange of $10^{13}$-$10^{15} M_\\odot/h$, and find $Y\\propto M^{\\alpha}$ with\n$\\alpha= 1.8$ at $z=0.14$ ($\\alpha=2.1$ at $z=0.75$). The total thermal energy\nof gas bound to clusters/groups increases from $0.1\\ \\rm meV/cm^3$ at $z=0.14$\nto $0.22\\ \\rm meV/cm^3$ at $z=0.75$. (2) The two-halo term is used to constrain\nthe bias-weighted electron pressure $\\langle b_yP_e \\rangle$. We find that\n$\\langle b_yP_e \\rangle$ (in unit of $\\rm meV/cm^3$) increases from $0.24\\pm\n0.02$ at $z=0.14$ to $0.45\\pm 0.02$ at $z=0.75$. These results lead to several\nimplications. (i) The hot gas fraction $f_{\\rm gas}$ in clusters/groups\nmonotonically increase with halo mass, where $f_{\\rm gas}$ of a $10^{14}\nM_\\odot/h$ halo is $\\sim 50\\%$ ($25\\%$) of the cosmic mean at $z=0.14\\ (0.75)$.\n(ii) By comparing the 1h- and 2h-terms, we obtain tentative constraint on the\nthermal energy of unbound gas. (iii) The above results lead to significant\nsuppression of matter and weak lensing power spectrum at small scales. These\nimplications are important for astrophysics and cosmology, and we will further\ninvestigate them with improved data and gas modeling.\n", "  Arguably our current cosmological paradigm, the so-called $\\Lambda$CDM\n`concordance model', faces an existential crisis. This has largely been brought\nabout by its reliance on the twin concepts of dark matter and dark energy, and\nthe continued inability of the observational and theoretical physics community\nto find viable candidates for these postulated phenomena. While it is still\npossible that this search will eventually prove successful, it is perhaps\nworthwhile looking at alternatives, and in particular, re-examining the very\nfoundations of our current cosmological model to see whether an entirely new\ncosmological paradigm might provide a better explanation.\n  The main failures of the prevailing cosmological paradigm were reviewed,\nconcentrating on the coincidences and contradictions presented by the\nrelationship between dark matter and dark energy. Revisiting the core features\nof this paradigm, the Friedman-Lema\\^itre-Robertson-Walker (FLRW) metric is\nidentified as the likely root cause of current issues with the $\\Lambda$CDM\nmodel. Building on the concept of a `timeless' universe suggested by a number\nof theorists in recent years, the exochronous metric is introduced and is shown\nto give rise to a static solution to the Einstein field equations. The\ncosmological implications of this model are explored, and we demonstrate that\nit can result in a universe with a critical energy density that is close to the\ncurrently observed baryonic matter density, without the need to invoke dark\nmatter or dark energy.\n", "  In light of recent developments in the field, we re-evaluate the effect of\nlocal-type non-Gaussianity on the primordial black hole (PBH) abundance (and\nconsequently, upon constraints on the primordial power spectrum arising from\nPBHs). We apply peaks theory to the full, non-linear compaction, finding that,\nwhilst the effect of non-Gaussianity is qualitatively similar to previous\nfindings, the effect is much less significant. It is found the non-Gaussianity\nparameters $f_\\mathrm{NL}^\\mathrm{local}$ and $g_\\mathrm{NL}^\\mathrm{local}$\ntypically need to be approximately 1 or 2 orders of magntiude larger\nrespectively to have a similar to that previously found. The effect will be to\nweaken the dependance of PBH constraints on the primordial power spectrum on\nthe non-Gaussianity parameters, as well as to dramatically weaken constraints\non the non-Gaussianity parameters (and/or PBH abundance) arising from the\nnon-observation of dark matter isocurvature modes. We also consider the\ncorrelation between the curvature perturbation $\\zeta$ and the compaction $C$,\nfinding that, whilst PBHs may form at rare peaks in $C$ these do not\nnecessarily correspond to rare peaks in $\\zeta$ - casting some doubt on many of\nthe existing calculations of the PBH abundance.\n", "  We present a detection of 21-cm emission from large-scale structure (LSS)\nbetween redshift 0.78 and 1.43 made with the Canadian Hydrogen Intensity\nMapping Experiment (CHIME). Radio observations acquired over 102 nights are\nused to construct maps which are foreground filtered and stacked on the angular\nand spectral locations of luminous red galaxies (LRG), emission line galaxies\n(ELG), and quasars (QSO) from the eBOSS clustering catalogs. We find decisive\nevidence for a detection when stacking on all three tracers of LSS, with the\nlogarithm of the Bayes Factor equal to 18.9 (LRG), 10.8 (ELG), and 56.3 (QSO).\nAn alternative frequentist interpretation, based on the likelihood-ratio test,\nyields a detection significance of $7.1\\sigma$ (LRG), $5.7\\sigma$ (ELG), and\n$11.1\\sigma$ (QSO). These are the first 21-cm intensity mapping measurements\nmade with an interferometer. We constrain the effective clustering amplitude of\nneutral hydrogen (HI), defined as $\\mathcal{A}_{\\rm HI}\\equiv\n10^{3}\\,\\Omega_\\mathrm{HI}\\left(b_\\mathrm{HI}+\\langle\\,f\\mu^{2}\\rangle\\right)$,\nwhere $\\Omega_\\mathrm{HI}$ is the cosmic abundance of HI, $b_\\mathrm{HI}$ is\nthe linear bias of HI, and $\\langle\\,f\\mu^{2}\\rangle=0.552$ encodes the effect\nof redshift-space distortions at linear order. We find\n$\\mathcal{A}_\\mathrm{HI}=1.51^{+3.60}_{-0.97}$ for LRGs $(z=0.84)$,\n$\\mathcal{A}_\\mathrm{HI}=6.76^{+9.04}_{-3.79}$ for ELGs $(z=0.96)$, and\n$\\mathcal{A}_\\mathrm{HI}=1.68^{+1.10}_{-0.67}$ for QSOs $(z=1.20)$, with\nconstraints limited by modeling uncertainties at nonlinear scales. We are also\nsensitive to bias in the spectroscopic redshifts of each tracer, and find a\nnon-zero bias $\\Delta\\,v= -66 \\pm 20 \\mathrm{km/s}$ for the QSOs. We split the\nQSO catalog into three redshift bins and have a decisive detection in each,\nwith the upper bin at $z=1.30$ producing the highest redshift 21-cm intensity\nmapping measurement thus far.\n", "  We introduce CRK-HACC, an extension of the Hardware/Hybrid Accelerated\nCosmology Code (HACC), to resolve gas hydrodynamics in large-scale structure\nformation simulations of the universe. The new framework couples the HACC\ngravitational N-body solver with a modern smoothed particle hydrodynamics (SPH)\napproach called CRKSPH. $\\underline{\\text{C}}$onservative\n$\\underline{\\text{R}}$eproducing $\\underline{\\text{K}}$ernel\n$\\underline{\\text{SPH}}$ utilizes smoothing functions that exactly interpolate\nlinear fields while manifestly preserving conservation laws (momentum, mass,\nand energy). The CRKSPH method has been incorporated to accurately model\nbaryonic effects in cosmology simulations - an important addition targeting the\ngeneration of precise synthetic sky predictions for upcoming observational\nsurveys. CRK-HACC inherits the codesign strategies of the HACC solver and is\nbuilt to run on modern GPU-accelerated supercomputers. In this work, we\nsummarize the primary solver components and present a number of standard\nvalidation tests to demonstrate code accuracy, including idealized hydrodynamic\nand cosmological setups, as well as self-similarity measurements.\n", "  X-ray observations of the hot intra-cluster medium (ICM) in galaxy groups and\nclusters provide quantities such as their gas mass, X-ray luminosity, and\ntemperature. The analysis of the scaling relations between these observable\nproperties gives considerable insight into the physical processes taking place\nin the ICM. Furthermore, an understanding of the scaling relations between ICM\nproperties and the total cluster mass is essential for cosmological studies\nwith clusters. For these reasons, the X-ray scaling relations of groups and\nclusters have been a major focus of research over the past several decades. In\nthis Chapter, after presenting the expectations from the self-similar model,\nbased on the assumption that only gravity drives the evolution of the ICM, we\ndiscuss how the processes of gas cooling and non-gravitational heating are\nbelieved to be responsible for the observed deviations from the self-similar\nscenario. We also describe important complications that must be considered when\nmeasuring and interpreting the scaling relations.\n", "  The power spectrum has been a workhorse for cosmological studies of\nlarge-scale structure. However, the present-day matter distribution is highly\nnon-Gaussian and significant cosmological information is also contained in\nhigher-order correlation functions. Meanwhile, baryon physics (particularly AGN\nfeedback) has previously been shown to strongly affect the two-point statistics\nbut there has been limited exploration of its effects on higher-order functions\nto date. Here we use the BAHAMAS suite of cosmological hydrodynamical\nsimulations to explore the effects of baryon physics and massive neutrinos on\nthe halo bispectrum. In contrast to matter clustering which is suppressed by\nbaryon physics, we find that the halo clustering is typically enhanced. The\nstrength of the effect and the scale over which it extends depends on how\nhaloes are selected. On small scales (k > 1 $h$ Mpc$^{-1}$, dominated by\nsatellites of groups/clusters), we find that the bispectrum is highly sensitive\nto the efficiency of star formation and feedback, making it an excellent\ntesting ground for galaxy formation models. We show that the effects of\nfeedback and the effects of massive neutrinos are largely separable\n(independent of each other) and that massive neutrinos strongly suppress the\nhalo bispectrum on virtually all scales up to the free-streaming length (apart\nfrom the smallest scales, where baryon physics dominates). The strong\nsensitivity of the bispectrum to neutrinos on the largest scales and galaxy\nformation physics on the smallest scales bodes well for upcoming precision\nmeasurements from the next generation of wide-field surveys.\n", "  We investigate the model where electrons and dark matter interact with dark\nenergy through the rolling of a scalar field which comes from extra dimensional\ntheories such as the braneworld theory and Brans-Dicke theory. In this model,\ndark energy couples to dark matter and electrons, which leads to larger values\nof the mass energies of dark matter and electrons in the early universe. We\nalso fit our model to the cosmological data. By analyzing the data from Planck,\nbaryon acoustic oscillation (BAO), light curves (Pantheon), and type-Ia\nsupernovae (SH0ES), it can be seen that the Hubble tension is relieved in our\nmodel and the coupling parameter prefers a non-zero value with a significance\nof over 2{\\sigma}.\n", "  We study the small-scale asymptotic behaviour of the cold dark matter density\nfluctuation power spectrum in the Zel'dovich approximation, without introducing\nan ultraviolet cut-off. Assuming an initially correlated Gaussian random field\nand spectral index $0 < n_s < 1$, we derive the small-scale asymptotic\nbehaviour of the initial momentum-momentum correlations. This result is then\nused to derive the asymptotics of the power spectrum in the Zel'dovich\napproximation. Our main result is an asymptotic series, dominated by a $k^{-3}$\ntail at large wave-numbers, containing higher-order terms that differ by\ninteger powers of $k^{n_s-1}$ and logarithms of $k$. Furthermore, we show that\ndark matter power spectra with an ultraviolet cut-off develop an intermediate\nrange of scales where the power spectrum is accurately described by the\nasymptotics of dark matter without a cut-off. These results reveal information\nabout the mathematical structure that underlies the perturbative terms in\nkinetic field theory and thus the non-linear power spectrum. We also discuss\nthe sensitivity of the small-scale asymptotics to the spectral index $n_s$.\n", "  Counts of galaxy clusters offer a high-precision probe of cosmology, but\ncontrol of systematic errors will determine the accuracy of this measurement.\nUsing Buzzard simulations, we quantify one such systematic, the triaxiality\ndistribution of clusters identified with the redMaPPer optical cluster finding\nalgorithm, which was used in the Dark Energy Survey Year-1 (DES Y1) cluster\ncosmology analysis. We test whether redMaPPer selection biases the clusters'\nshape and orientation and find that it only biases orientation, preferentially\nselecting clusters with their major axes oriented along the line of sight.\nModeling the richness-mass relation as a log-linear relation, we find that the\nlog-richness amplitude $\\ln(A)$ is boosted from the lowest to highest\norientation bin with a significance of $14\\sigma$, while the orientation\ndependence of the richness-mass slope and intrinsic scatter is minimal. We also\nfind that the weak lensing shear-profile ratios of cluster-associated dark\nhalos in different orientation bins resemble a \"bottleneck\" shape that can be\nquantified with a Cauchy function. We test the correlation of orientation with\ntwo other leading systematics in cluster cosmology -- miscentering and\nprojection -- and find a null correlation. Analytic templates for the\ntriaxiality bias of observed-richness and lensing profiles are mapped as\ncorrections to the observable of richness-binned lensing profiles for redMaPPer\nclusters. The resulting mass bias confirms the DES Y1 finding that triaxiality\nis a leading source of bias in cluster cosmology. However, the\nrichness-dependence of the bias confirms that triaxiality does not fully\nresolve the tension at low-richness between DES Y1 cluster cosmology and other\nprobes. Our model can be used for quantifying the impact of triaxiality bias on\ncosmological constraints for upcoming weak lensing surveys of galaxy clusters.\n", "  Features in the primordial power spectrum represent the imprinted signal in\nthe density perturbations of the physics and evolution of the early Universe. A\nmeasurement of such signals will represents the need to go beyond the minimal\nassumption made for the initial conditions of the cosmological perturbations.\nFor the first time, we study different templates with undamped oscillations or\na bump from the two-point correlation function measured from BOSS DR12 galaxies\nconstraining the amplitude of the features to be at most a few percent.\nConstraints are competitive to the ones obtained with {\\em Planck} DR3.\n", "  We present the first application of the Cosmoglobe analysis framework by\nanalyzing 9-year $\\mathit{WMAP}$ time-ordered observations using similar\nmachinery as BeyondPlanck utilizes for $\\mathit{Planck}$ LFI. We analyze only\nthe $\\mathit Q$-band (41 GHz) data and report on the low-level analysis process\nfrom uncalibrated time-ordered data to calibrated maps. Most of the existing\nBeyondPlanck pipeline may be reused for $\\mathit{WMAP}$ analysis with minimal\nchanges to the existing codebase. The main modification is the implementation\nof the same preconditioned biconjugate gradient mapmaker used by the\n$\\mathit{WMAP}$ team. Producing a single $\\mathit{WMAP}$ $\\mathit Q$1-band\nsample requires 22 CPU-hrs, which is slightly more than the cost of a\n$\\mathit{Planck}$ 44 GHz sample of 17 CPU-hrs; this demonstrates that full\nend-to-end Bayesian processing of the $\\mathit{WMAP}$ data is computationally\nfeasible. In general, our recovered maps are very similar to the maps released\nby the $\\mathit{WMAP}$ team, although with two notable differences. In\ntemperature we find a $\\sim2\\,\\mathrm{\\mu K}$ quadrupole difference that most\nlikely is caused by different gain modeling, while in polarization we find a\ndistinct $2.5\\,\\mathrm{\\mu K}$ signal that has been previously called\npoorly-measured modes by the $\\mathit{WMAP}$ team. In the Cosmoglobe\nprocessing, this pattern arises from temperature-to-polarization leakage from\nthe coupling between the CMB Solar dipole, transmission imbalance, and\nsidelobes. No traces of this pattern are found in either the frequency map or\nTOD residual map, suggesting that the current processing has succeeded in\nmodelling these poorly measured modes within the assumed parametric model by\nusing $\\mathit{Planck}$ information to break the sky-synchronous degeneracies\ninherent in the $\\mathit{WMAP}$ scanning strategy.\n", "  A weighted, semi-discrete, fast optimal transport (OT) algorithm for\nreconstructing the Lagrangian positions of proto-halos from their evolved\nEulerian positions is presented. The algorithm makes use of a mass estimate of\nthe biased tracers and of the distribution of the remaining mass (the `dust'),\nbut is robust to errors in the mass estimates. Tests with state-of-art\ncosmological simulations show that if the dust is assumed to have a uniform\nspatial distribution, then the shape of the OT-reconstructed pair correlation\nfunction of the tracers is very close to linear theory, enabling sub-percent\nprecision in the BAO distance scale that depends weakly, if at all, on a\ncosmological model. With a more sophisticated model for the dust, OT returns an\nestimate of the displacement field which yields superb reconstruction of the\nproto-halo positions, and hence of the shape and amplitude of the initial pair\ncorrelation function of the tracers. This enables direct and independent\ndeterminations of the bias factor $b$ and the smearing scale $\\Sigma$,\npotentially providing new methods for breaking the degeneracy between $b$ and\n$\\sigma_8$.\n", "  We present a variational-Bayes solution to compute non-Gaussian posteriors\nfrom extremely expensive likelihoods. Our approach is an alternative for\nparameter inference when MCMC sampling is numerically prohibitive or\nconceptually unfeasible. For example, when either the likelihood or the\ntheoretical model cannot be evaluated at arbitrary parameter values, but only\npreviously selected values, then traditional MCMC sampling is impossible,\nwhereas our variational-Bayes solution still succeeds in estimating the full\nposterior. In cosmology, this occurs e.g. when the parametric model is based on\ncostly simulations that were run for previously selected input parameters. We\ndemonstrate the applicability of our posterior construction on the KiDS-450\nweak lensing analysis, where we reconstruct the original KiDS MCMC posterior at\n0.6% of its former numerical posterior evaluations. The reduction in numerical\ncost implies that systematic effects which formerly exhausted the numerical\nbudget could now be included.\n", "  In this paper, we propose a self-consistent test for a Hubble constant\nestimate using galaxy cluster and type Ia supernovae (SNe Ia) observations. The\napproach consists, in a first step, of obtaining the observational value of the\ngalaxy cluster scaling-relation $Y_{SZE}D_{A}^{2}/C_{XSZ}Y_X = C $ by combining\nthe X-Ray and SZ observations of galaxy clusters at low redshifts ($z < 0.1$)\nfrom the first {\\it Planck mission} all-sky data set ($0.044 \\leq z \\leq\n0.444$), along with SNe Ia observations and making use of the cosmic distance\nduality relation validity. Then, by considering a flat $\\Lambda$CDM model for\n$D_A$, the constant $C$ from the first step and the Planck prior on $\\Omega_M$\nparameter, we obtain $H_0$ by using the galaxy cluster data with $z>0.1$. As a\nresult, we obtain $H_0 = 73.014^{+7.435}_{-6.688}$ km/s/Mpc, which represents\n$9.7\\%$ accuracy measurement on the Hubble constant.. We also compare our\nmethod with that one where the $C$ parameter is obtained from hydrodynamical\nsimulations of massive galaxy clusters.\n", "  Detecting and measuring a non-Gaussian signature of primordial origin in the\ndensity field is a major science goal of next-generation galaxy surveys. The\nsignal will permit us to determine primordial physics processes and constrain\nmodels of cosmic inflation. While traditional approaches utilise a limited set\nof statistical summaries of the galaxy distribution to constrain primordial\nnon-Gaussianity, we present a field-level approach by Bayesian\nforward-modelling the entire three-dimensional galaxy survey. Our method\nnaturally and fully self-consistently exploits the entirety of the large-scale\nstructure, e.g., higher-order statistics, peculiar velocity fields, and\nscale-dependent galaxy bias, to extract information on the local\nnon-Gaussianity parameter, $\\fnl$. We demonstrate the performance of our\napproach through various tests with mock galaxy data emulating relevant\nfeatures of the \\sdssiii{}-like survey, and additional tests with a\n\\textit{Stage IV} mock data set. These tests reveal that the method infers\nunbiased values of $\\fnl$ by accurately handling survey geometries, noise, and\nunknown galaxy biases. We demonstrate that our method can achieve constraints\nof $\\sigma_{\\fnl} \\approx 8.78$ for \\sdssiii{}-like data, an improvement of a\nfactor $\\sim 2.5$ over currently published constraints. Tests with\nnext-generation mock data show that significant further improvements are\nfeasible with sufficiently high resolution. Furthermore, the results\ndemonstrate that our method can consistently marginalise all nuisance\nparameters of the data model. The method further provides an inference of the\nthree-dimensional primordial density field, providing opportunities to explore\nadditional signatures of primordial physics.\n", "  We analyze clustering measurements of BOSS galaxies using a simulation-based\nemulator of two-point statistics. We focus on the monopole and quadrupole of\nthe redshift-space correlation function, and the projected correlation\nfunction, at scales of $0.1\\sim60~h^{-1}$Mpc. Although our simulations are\nbased on $w$CDM with general relativity (GR), we include a scaling parameter of\nthe halo velocity field, $\\gamma_f$, defined as the amplitude of the halo\nvelocity field relative to the GR prediction. We divide the BOSS data into\nthree redshift bins. After marginalizing over other cosmological parameters,\ngalaxy bias parameters, and the velocity scaling parameter, we find\n$f\\sigma_{8}(z=0.25) = 0.413\\pm0.031$, $f\\sigma_{8}(z=0.4) = 0.470\\pm0.026$ and\n$f\\sigma_{8}(z=0.55) = 0.396\\pm0.022$. Compared with Planck observations using\na flat $\\Lambda$CDM model, our results are lower by $1.9\\sigma$, $0.3\\sigma$\nand $3.4\\sigma$ respectively. These results are consistent with other recent\nsimulation-based results at non-linear scales, including weak lensing\nmeasurements of BOSS LOWZ galaxies, two-point clustering of eBOSS LRGs, and an\nindependent clustering analysis of BOSS LOWZ. All these results are generally\nconsistent with a combination of $\\gamma_f^{1/2}\\sigma_8\\approx 0.75$. We note,\nhowever, that the BOSS data is well fit assuming GR, i.e. $\\gamma_f=1$. We\ncannot rule out an unknown systematic error in the galaxy bias model at\nnon-linear scales, but near-future data and modeling will enhance our\nunderstanding of the galaxy--halo connection, and provide a strong test of new\nphysics beyond the standard model.\n", "  We derive an estimator for the lensing potential from galaxy number counts\nwhich contains a linear and a quadratic term. We show that this estimator has a\nmuch larger signal-to-noise ratio than the corresponding estimator from\nintensity mapping. This is due to the additional lensing term in the number\ncount angular power spectrum which is present already at linear order. We\nestimate the signal-to-noise ratio for future photometric surveys. Particularly\nat high redshifts, $z\\gtrsim 1.5$, the signal to noise ratio can become of\norder 30. Therefore, the number counts in photometric surveys would be an\nexcellent means to measure tomographic lensing spectra.\n", "  Joint analyses of cross-correlations between measurements of galaxy\npositions, galaxy lensing, and lensing of the cosmic microwave background (CMB)\noffer powerful constraints on the large-scale structure of the Universe. In a\nforthcoming analysis, we will present cosmological constraints from the\nanalysis of such cross-correlations measured using Year 3 data from the Dark\nEnergy Survey (DES), and CMB data from the South Pole Telescope (SPT) and\nPlanck. Here we present two key ingredients of this analysis: (1) an improved\nCMB lensing map in the SPT-SZ survey footprint, and (2) the analysis\nmethodology that will be used to extract cosmological information from the\ncross-correlation measurements. Relative to previous lensing maps made from the\nsame CMB observations, we have implemented techniques to remove contamination\nfrom the thermal Sunyaev Zel'dovich effect, enabling the extraction of\ncosmological information from smaller angular scales of the cross-correlation\nmeasurements than in previous analyses with DES Year 1 data. We describe our\nmodel for the cross-correlations between these maps and DES data, and validate\nour modeling choices to demonstrate the robustness of our analysis. We then\nforecast the expected cosmological constraints from the galaxy survey-CMB\nlensing auto and cross-correlations. We find that the galaxy-CMB lensing and\ngalaxy shear-CMB lensing correlations will on their own provide a constraint on\n$S_8=\\sigma_8 \\sqrt{\\Omega_{\\rm m}/0.3}$ at the few percent level, providing a\npowerful consistency check for the DES-only constraints. We explore scenarios\nwhere external priors on shear calibration are removed, finding that the joint\nanalysis of CMB lensing cross-correlations can provide constraints on the shear\ncalibration amplitude at the 5 to 10% level.\n", "  Cross-correlations of galaxy positions and galaxy shears with maps of\ngravitational lensing of the cosmic microwave background (CMB) are sensitive to\nthe distribution of large-scale structure in the Universe. Such\ncross-correlations are also expected to be immune to some of the systematic\neffects that complicate correlation measurements internal to galaxy surveys. We\npresent measurements and modeling of the cross-correlations between galaxy\npositions and galaxy lensing measured in the first three years of data from the\nDark Energy Survey with CMB lensing maps derived from a combination of data\nfrom the 2500 deg$^2$ SPT-SZ survey conducted with the South Pole Telescope and\nfull-sky data from the Planck satellite. The CMB lensing maps used in this\nanalysis have been constructed in a way that minimizes biases from the thermal\nSunyaev Zel'dovich effect, making them well suited for cross-correlation\nstudies. The total signal-to-noise of the cross-correlation measurements is\n23.9 (25.7) when using a choice of angular scales optimized for a linear\n(nonlinear) galaxy bias model. We use the cross-correlation measurements to\nobtain constraints on cosmological parameters. For our fiducial galaxy sample,\nwhich consist of four bins of magnitude-selected galaxies, we find constraints\nof $\\Omega_{m} = 0.272^{+0.032}_{-0.052}$ and $S_{8} \\equiv \\sigma_8\n\\sqrt{\\Omega_{m}/0.3}= 0.736^{+0.032}_{-0.028}$ ($\\Omega_{m} =\n0.245^{+0.026}_{-0.044}$ and $S_{8} = 0.734^{+0.035}_{-0.028}$) when assuming\nlinear (nonlinear) galaxy bias in our modeling. Considering only the\ncross-correlation of galaxy shear with CMB lensing, we find $\\Omega_{m} =\n0.270^{+0.043}_{-0.061}$ and $S_{8} = 0.740^{+0.034}_{-0.029}$. Our constraints\non $S_8$ are consistent with recent cosmic shear measurements, but lower than\nthe values preferred by primary CMB measurements from Planck.\n", "  Reliable extraction of cosmological information from observed cosmic\nmicrowave background (CMB) maps may require removal of strongly foreground\ncontaminated regions from the analysis. In this article, we employ an\nartificial neural network (ANN) to predict the full sky CMB angular power\nspectrum between intermediate to large angular scales from the partial sky\nspectrum obtained from masked CMB temperature anisotropy map. We use a simple\nANN architecture with one hidden layer containing $895$ neurons. Using $1.2\n\\times 10^{5}$ training samples of full sky and corresponding partial sky CMB\nangular power spectra at Healpix pixel resolution parameter $N_{side} = 256$,\nwe show that predicted spectrum by our ANN agrees well with the target spectrum\nat each realization for the multipole range $2 \\leq l \\leq 512$. The predicted\nspectra are statistically unbiased and they preserve the cosmic variance\naccurately. Statistically, the differences between the mean predicted and\nunderlying theoretical spectra are within approximately $3\\sigma$. Moreover,\nthe probability densities obtained from predicted angular power spectra agree\nvery well with those obtained from `actual' full sky CMB angular power spectra\nfor each multipole. Interestingly, our work shows that the significant\ncorrelations in input cut-sky spectra, due to mode-mode coupling introduced on\nthe partial sky, are effectively removed since the ANN learns the hidden\npattern between the partial sky and full sky spectra preserving the entire\nstatistical properties. The excellent agreement of statistical properties\nbetween the predicted and the ground-truth demonstrates the importance of using\nartificial intelligence systems in cosmological analysis more widely.\n", "  Unparticle cosmology gives an unconventional outlook on the dark sector of\ncosmology, increasingly challenging $\\Lambda\\mbox{CDM}$ by $H_0$-tension. This\nmodel derives from a finite temperature broken conformal symmetry of radiation,\ndescribed by a non-radiative correction with unknown sign in energy density.\nThis symmetry breaking has a sign ambiguity, in which corrections about the IR\nfixed point are normal or tachyonic. While the first has been ruled out in a\nrecent study, the latter possesses a late-time temperature $T_c\\simeq\n4\\,T_{CMB}$ associated with $\\Omega_{\\cal U}\\simeq 1$ ($\\Omega_{\\cal U} \\simeq\n10^4 \\Omega_{CMB}$), where $T_{CMB}$ denotes the temperature of the Cosmic\nMicrowave Background (CMB). Thus exposed to the enormous heat bath of\nunparticles, $T_{CMB}$ is constrained by the astronomical age of the Universe\n$T_{u,0}$. The relative temperature shift $\\Delta T/T$ in any heat exchange to\nthe CMB is hereby limited to the uncertainty of a few percent in $T_{u,0}$.\nThis bounds the effective cross-section of unparticles interactions with CMB\nphotons to $\\sigma _{\\gamma \\mathcal{U}} \\lesssim 10^{-40}\\ \\mbox{m}^2=10^{-3}\\\n\\mbox{nb}$. Assuming a standard cross-section across the broadband mass and\nenergy spectrum of unparticles, a more stringent bound $\\sigma _{\\gamma\n\\mathcal{U}} \\lesssim 10^{-3}\\,\\mbox{pb}$ derives from COBE-FIRAS constraints\non spectral distortions. The first is midway of photon-neutrino\n$\\sigma_{\\gamma\\nu}$ and photon-photon cross sections $\\sigma_{\\gamma\\gamma}$,\nthe second is on par with $\\sigma_{\\gamma\\nu}$. These constraints put late-time\nunparticle cosmology, if present, at the edge of the standard model.\n", "  For the past decade, the BICEP/Keck collaboration has been operating a series\nof telescopes at the Amundsen-Scott South Pole Station measuring degree-scale\n$B$-mode polarization imprinted in the Cosmic Microwave Background (CMB) by\nprimordial gravitational waves (PGWs). These telescopes are compact refracting\npolarimeters mapping about 2% of the sky, observing at a broad range of\nfrequencies to account for the polarized foreground from Galactic synchrotron\nand thermal dust emission. Our latest publication \"BK18\" utilizes the data\ncollected up to the 2018 observing season, in conjunction with the publicly\navailable WMAP and Planck data, to constrain the tensor-to-scalar ratio $r$. It\nparticularly includes (1) the 3-year BICEP3 data which is the current deepest\nCMB polarization map at the foreground-minimum 95 GHz; and (2) the Keck 220 GHz\nmap with a higher signal-to-noise ratio on the dust foreground than the Planck\n353 GHz map. We fit the auto- and cross-spectra of these maps to a\nmulticomponent likelihood model ($\\Lambda$CDM+dust+synchrotron+noise+$r$) and\nfind it to be an adequate description of the data at the current noise level.\nThe likelihood analysis yields $\\sigma(r)=0.009$. The inference of $r$ from our\nbaseline model is tightened to $r_{0.05}=0.014^{+0.010}_{-0.011}$ and\n$r_{0.05}<0.036$ at 95% confidence, meaning that the BICEP/Keck $B$-mode data\nis the most powerful existing dataset for the constraint of PGWs. The up-coming\nBICEP Array telescope is projected to reach $\\sigma(r) \\lesssim 0.003$ using\ndata up to 2027.\n", "  Recent developments of Perturbation Theory (PT), specifically the Effective\nField Theory of Large Scale Structure (EFTofLSS) and its equivalents, have\nproven powerful in analyzing galaxy clustering statistics such as the galaxy\npower spectrum and bispectrum. To further this pursuit, we have devised a novel\nspherical-bispectrum visualization scheme that collapses configuration\ndependencies to highlight the scale dependence of the bispectrum. The resulting\none-dimensional curves facilitate the comparison between different bispectra,\nfor example, from simulation and PT calculation. Using the new scheme, we\npresent a quantitative analysis of the accuracy of PT modeling by comparing\nPT's analytical prediction to the result from a suite of Quijote simulations.\nSpecifically, we determine $k_{\\rm NL}$, the wavenunmber below which the\nanalytical prediction matches well with the N-body result by inspecting both\nleading order (LO) and next-to-leading order (NLO) power spectrum and\nbispectrum at redshifts $z=0$, $0.5$, $1$, $2$, $3$. We also quantify the\nbinning effect in Fourier space and show that an appropriate correction must be\napplied to the analytic predictions in order to compare them with the discrete\nFourier transform results obtained from N-body-simulation or real data.\n", "  Planck's Cosmic Microwave Background temperature and polarization\nobservations are the premier dataset for constraining cosmological models.\nCosmic variance limited temperature at large and intermediate scales today\ndominates the constraints; polarization provides additional constraining power\nand further scrutiny of the models. To complete this picture from Planck,\nground-based experiments, such as the Atacama Cosmology Telescope (ACT) and the\nSouth Pole Telescope (SPT) continue to add temperature and polarization\nmeasurements at small scales, allowing for the extraction of competitive\ncosmological constraints from the $TE$ and $EE$ power spectra. Matching at the\nsame time all these stringent probes is a key challenge and validation step for\nany cosmological model. In particular, $\\Lambda$CDM requires a tight\nconsistency between the temperature and polarization measurements. In this\npaper, we present a number of methods to identify and quantify possible\ninconsistencies between temperature and polarization, we apply them to the\nlatest Planck, ACT and SPT data and find no evidence for a deviation from\n$\\Lambda$CDM. Application of these methods will have increased importance for\nfuture, more constraining CMB data.\n", "  We demonstrate that the Bayesian evidence can be used to find a good\napproximation of the ground truth likelihood function of a dataset, a goal of\nthe likelihood-free inference (LFI) paradigm. As a concrete example, we use\nforward modelled sky-averaged 21-cm signal antenna temperature datasets where\nwe artificially inject noise structures of various physically motivated forms.\nWe find that the Gaussian likelihood performs poorly when the noise\ndistribution deviates from the Gaussian case e.g. heteroscedastic radiometric\nor heavy-tailed noise. For these non-Gaussian noise structures, we show that\nthe generalised normal likelihood is on a similar Bayesian evidence scale with\ncomparable sky-averaged 21-cm signal recovery as the ground truth likelihood\nfunction of our injected noise. We therefore propose the generalised normal\nlikelihood function as a good approximation of the true likelihood function if\nthe noise structure is a priori unknown.\n", "  Gravitationally lensed supernovae (LSNe) are important probes of cosmic\nexpansion, but they remain rare and difficult to find. Current cosmic surveys\nlikely contain and 5-10 LSNe in total while next-generation experiments are\nexpected to contain several hundreds to a few thousands of these systems. We\nsearch for these systems in observed Dark Energy Survey (DES) 5-year SN fields\n-- 10 3-sq. deg. regions of sky imaged in the $griz$ bands approximately every\nsix nights over five years. To perform the search, we utilize the DeepZipper\napproach: a multi-branch deep learning architecture trained on image-level\nsimulations of LSNe that simultaneously learns spatial and temporal\nrelationships from time series of images. We find that our method obtains a LSN\nrecall of 61.13% and a false positive rate of 0.02% on the DES SN field data.\nDeepZipper selected 2,245 candidates from a magnitude-limited ($m_i$ $<$ 22.5)\ncatalog of 3,459,186 systems. We employ human visual inspection to review\nsystems selected by the network and find three candidate LSNe in the DES SN\nfields.\n", "  UNIONS is an ongoing deep photometric multi-band survey of the Northern sky.\nAs part of UNIONS, CFIS provides r-band data which we use to study weak-lensing\npeak counts for cosmological inference. We assess systematic effects for\nweak-lensing peak counts and their impact on cosmological parameters for the\nUNIONS survey. In particular, we present results on local calibration,\nmetacalibration shear bias, baryonic feedback, the source galaxy redshift\nestimate, intrinsic alignment, and the cluster member dilution. For each\nuncertainty and systematic effect, we describe our mitigation scheme and the\nimpact on cosmological parameter constraints. We obtain constraints on\ncosmological parameters from MCMC using CFIS data and MassiveNuS N-body\nsimulations as a model for peak counts statistics. Depending on the calibration\n(local versus global, and the inclusion of the residual multiplicative shear\nbias), the mean matter density parameter $\\Omega_m$ can shift up to $-0.024$\n($-0.5\\sigma$). We also see that including baryonic corrections can shift\n$\\Omega_m$ by $+0.027$ ($+0.5 \\sigma$) with respect to the DM-only simulations.\nReducing the impact of the intrinsic alignment and cluster member dilution\nthrough signal-to-noise cuts can lead to a shift in $\\Omega_m$ of $+0.027$\n($+0.5 \\sigma$). Finally, with a mean redshift uncertainty of $\\Delta \\bar{z} =\n0.03$, we see that the shift of $\\Omega_m$ ($+0.001$ which corresponds to\n$+0.02 \\sigma$) is not significant. This paper investigates for the first time\nwith UNIONS weak-lensing data and peak counts the impact of systematic effects.\nThe value of $\\Omega_m$ is the most impacted and can shift up to $\\sim 0.03$\nwhich corresponds to $0.5\\sigma$ depending on the choices for each systematics.\nWe expect constraints to become more reliable with future (larger) data\ncatalogues, for which the current pipeline will provide a starting point.\n", "  Galactic outflows driven by star formation and active galactic nuclei blow\nbubbles into their local environments, causing galactic magnetic fields to be\ncarried into intergalactic space. We explore the redshift-dependent effect of\nthese magnetized bubbles on the Faraday Rotation Measure (RM) of extragalactic\nradio sources. Using the IllustrisTNG cosmological simulations, we separate the\ncontribution from magnetic bubbles from that of the volume-filling magnetic\ncomponent expected to be due to the seed field originating in the Early\nUniverse. We use this separation to extract the redshift dependence of each\ncomponent and to compare TNG model predictions with observation measurements of\nthe NRAO VLA Sky Survey (NVSS). We find that magnetized bubbles provide a\nsizeable contribution to the extragalactic RM, with redshift-independent\n$\\langle |{\\rm RM}| \\rangle \\simeq 13$ rad/m$^2$ for sources at redshifts $z\\ge\n2$. This is close to the mean residual RM of $16$ rad/m$^2$ found from NVSS\ndata in this redshift range. Using the IllustrisTNG simulations, we also\nevaluate a simple model for the contribution to residual RM from individual\nhost galaxies and show that this contribution is negligible at high-redshift.\nWhile the contribution from magnetic bubbles in the IllustrisTNG model is\ncurrently compatible with observational measurements of residual RM, the\nnext-generation RM sky surveys, which will be free from the wrapping\nuncertainty, have larger statistics and better sensitivity should be able to\nobserve predicted flat contribution from magnetic bubbles at large redshifts.\nThis should allow to experimentally probe magnetic bubbles and check models of\ngalaxy feedback in cosmological simulations.\n", "  To recover the 21 cm hydrogen line, it is essential to separate the\ncosmological signal from the much stronger foreground contributions at radio\nfrequencies. The BINGO radio telescope is designed to measure the 21 cm line\nand detect BAOs using the intensity mapping technique. This work analyses the\nperformance of the GNILC method, combined with a power spectrum debiasing\nprocedure. The method was applied to a simulated BINGO mission, building upon\nprevious work from the collaboration. It compares two different synchrotron\nemission models and different instrumental configurations, in addition to the\ncombination with ancillary data to optimize both the foreground removal and\nrecovery of the 21 cm signal across the full BINGO frequency band, as well as\nto determine an optimal number of frequency bands for the signal recovery. We\nhave produced foreground emissions maps using the Planck Sky Model, the\ncosmological Hi emission maps are generated using the FLASK package and thermal\nnoise maps are created according to the instrumental setup. We apply the GNILC\nmethod to the simulated sky maps to separate the Hi plus thermal noise\ncontribution and, through a debiasing procedure, recover an estimate of the\nnoiseless 21 cm power spectrum. We found a near optimal reconstruction of the\nHi signal using a 80 bins configuration, which resulted in a power spectrum\nreconstruction average error over all frequencies of 3%. Furthermore, our tests\nshowed that GNILC is robust against different synchrotron emission models.\nFinally, adding an extra channel with CBASS foregrounds information, we reduced\nthe estimation error of the 21 cm signal. The optimisation of our previous\nwork, producing a configuration with an optimal number of channels for binning\nthe data, impacts greatly the decisions regarding BINGO hardware configuration\nbefore commissioning.\n", "  We consider a simple system consisting of matter, radiation and vacuum\ncomponents to model the impact of thermal inflation on the evolution of\nprimordial perturbations. The vacuum energy magnifies the primordial modes\nentering the horizon before its domination, making them potentially observable,\nand the resulting transfer function reflects the phase changes and energy\ncontents. To determine the transfer function, we follow the curvature\nperturbation from well outside the horizon during radiation domination to well\noutside the horizon during vacuum domination and evaluate it on a constant\nradiation density hypersurface, as is appropriate for the case of thermal\ninflation. The shape of the transfer function is determined by the ratio of\nvacuum energy to radiation at matter-radiation equality, which we denote by\n$\\upsilon$, and has two characteristic scales, $k_{\\rm a}$ and $k_{\\rm b}$,\ncorresponding to the horizon sizes at matter radiation equality and the\nbeginning of the inflation, respectively. If $\\upsilon \\ll 1$, the universe\nexperiences radiation, matter and vacuum domination eras and the transfer\nfunction is flat for $k \\ll k_{\\rm b}$, oscillates with amplitude $1/5$ for $\nk_{\\rm b} \\ll k \\ll k_{\\rm a}$ and oscillates with amplitude $1$ for $k \\gg\nk_{\\rm a}$. For $\\upsilon \\gg 1$, the matter domination era disappears, and the\ntransfer function reduces to being flat for $k \\ll k_{\\rm b}$ and oscillating\nwith amplitude $1$ for $k \\gg k_{\\rm b}$.\n", "  The scalar induced gravitational waves are produced from primordial curvature\nperturbations in the second order of perturbations. We constrain the fractional\nenergy density of scalar induced gravitational waves from gravitational waves\nobservations. If there is no detection of the scalar induced gravitational\nwaves, the fractional energy density of scalar induced gravitational waves is\nconstrained by some upper limits. Depends on these upper limits, we can obtain\nthe constraints on the power spectrum of the primordial curvature\nperturbations. For a power-law scalar power spectrum, the constraints on the\npower spectrum are affected by adding the upper limit of scalar induced\ngravitational waves from Square Kilometer Array (SKA). In the standard model,\nthe mean values of the scalar amplitude and the spectral index shift to lower\nvalues when SKA is added to the combination of Cosmic Microwave Background\n(CMB) and Baryon Acoustic Oscillation (BAO) datasets, namely\n$\\ln(10^{10}A_s)=3.038\\pm0.013$ and $n_s=0.9589^{+0.0021}_{-0.0011}$ at $68\\%$\nconfidence level. We also consider the effects of the existing ground-based\ngravitational-wave detectors, the existing Pulsar Timing Arrays (PTAs) and\nFive-hundred-meter Aperture Spherical radio Telescope (FAST), while the\nconstraints from CMB+BAO datasets are totally within their upper limits of\nscalar induced gravitational waves. Furthermore, we characterize the scalar\nfluctuation spectrum in terms of the spectral index $n_s$ and its first two\nderivatives. We calculate corresponding power spectrum of scalar induced\ngravitational waves theoretically and give the constraints on the running of\nthe spectral index and the running of the running of the spectral index.\n", "  The gas mass fraction in galaxy clusters is a convenient probe to use in\ncosmological studies, as it can help derive constraints on a collection of\ncosmological parameters. It is however subject to various effects from the\nbaryonic physics inside galaxy clusters, which may bias the obtained\ncosmological constraints. Among different aspects of the baryonic physics, in\nthis paper we focus on the impact of the hydrostatic equilibrium assumption. We\nanalyse the hydrostatic mass bias $B$, constraining a possible mass and\nredshift evolution of this quantity and its impact on the cosmological\nconstraints. To that end we consider cluster observations of the {\\it\nPlanck}-ESZ sample and evaluate the gas mass fraction using X-ray counterpart\nobservations. We show a degeneracy between the redshift dependence of the bias\nand cosmological parameters. In particular we find a $3.8 \\sigma$ evidence for\na redshift dependence of the bias when assuming a {\\it Planck} prior on\n$\\Omega_m$. On the other hand, assuming a constant mass bias would lead to the\nextreme large value of $\\Omega_m > 0.849$. We however show that our results are\nentirely dependent on the cluster sample we consider. In particular, the mass\nand redshift trends that we find for the lowest mass-redshift and highest\nmass-redshift clusters of our sample are not compatible. Nevertheless, in all\nthe analyses we find a value for the amplitude of the bias that is consistent\nwith $B \\sim 0.8$, as expected from hydrodynamical simulations and local\nmeasurements, but still in tension with the low value of $B \\sim 0.6$ derived\nfrom the combination of cosmic microwave background primary anisotropies with\ncluster number counts.\n", "  We present a percent-level accurate model of the line-of-sight velocity\ndistribution of galaxies around dark matter halos as a function of projected\nradius and halo mass. The model is developed and tested using synthetic galaxy\ncatalogs generated with the UniverseMachine run on the Multi-Dark Planck 2\nN-body simulations. The model decomposes the galaxies around a cluster into\nthree kinematically distinct classes: orbiting, infalling, and interloping\ngalaxies. We demonstrate that: 1) we can statistically distinguish between\nthese three types of galaxies using only projected line-of-sight velocity\ninformation; 2) the halo edge radius inferred from the line-of-sight velocity\ndispersion is an excellent proxy for the three-dimensional halo edge radius; 3)\nwe can accurately recover the full velocity dispersion profile for each of the\nthree populations of galaxies. Importantly, the velocity dispersion profiles of\nthe orbiting and infalling galaxies contain five independent parameters --\nthree distinct radial scales and two velocity dispersion amplitudes -- each of\nwhich is correlated with mass. Thus, the velocity dispersion profile of galaxy\nclusters has inherent redundancies that allow us to perform nontrivial\nsystematics check from a single data set. We discuss several potential\napplications of our new model for detecting the edge radius and constraining\ncosmology and astrophysics using upcoming spectroscopic surveys.\n", "  NASA will launch the Nancy Grace Roman Space Telescope (Roman) in the second\nhalf of this decade, which will allow for a generation-defining measurement of\ndark energy through multiple probes, including Type Ia supernovae (SNe Ia). To\nimprove decisions on survey strategy, we have created the first simulations of\nrealistic Roman images that include artificial SNe Ia injected as point sources\nin the images. Our analysis combines work done on Roman simulations for weak\ngravitational lensing studies as well as catalog-level simulations of SN\nsamples. We have created a time series of images over two years containing\n$\\sim$ 1,050 SNe Ia, covering a 1 square degree subarea of a planned 5 square\ndegree deep survey. We have released these images publicly for community use\nalong with input catalogs of all injected sources. We create secondary products\nfrom these images by generating coadded images and demonstrating recovery of\ntransient sources using image subtraction. We perform first-use analyses on\nthese images in order to measure galaxy-detection efficiency, point\nsource-detection efficiency, and host-galaxy association biases. The simulated\nimages can be found here:\nhttps://roman.ipac.caltech.edu/sims/SN_Survey_Image_sim.html.\n", "  We present the analysis of the halo bispectrum in redshift-space in terms of\nits multipoles, monopole, quadrupole and hexadecapole, measured from a large\nset of simulations. We fit such measurements with a tree-level model in\nperturbation theory that depends on linear and nonlinear bias parameters as\nwell as on the growth rate $f$ of density fluctuations. The likelihood analysis\ntakes advantage of a very large set of mock catalogs, enabling a robust\nestimation of the covariance properties for all multipoles. We compare the\nnumerical estimate of the covariance matrix to its Gaussian prediction finding\ndiscrepancies of 10% or less for all configurations with the sole exception of\nthe squeezed triangles in the monopole case. We find the range of validity of\nthe tree-level model, for the total simulation volume of about 1000 $h^{-3}\\,\n{\\rm Gpc}^3$, reaches a maximum wavenumber of $0.08 \\, h \\, {\\rm Mpc}^{-1}$ for\nthe monopole, while it is limited to $0.06$ and $0.045\\, h \\, \\rm{Mpc}^{-1}$\nrespectively for quadrupole and hexadecapole. Despite this, the addition of the\nquadrupole to the analysis allows for significant improvements on the\ndetermination of the model parameters and specifically on $f$, similarly to the\npower spectrum case. Finally, we compare our numerical estimate for the full\ncovariance with its theoretical prediction in the Gaussian approximation and\nfind the latter to work remarkably well in the context of simulation boxes with\nperiodic boundary condition.\n", "  Multi-frequency matched filters (MMFs) are routinely used to detect galaxy\nclusters from CMB data through the thermal Sunyaev-Zeldovich (tSZ) effect,\nleading to cluster catalogues that can be used for cosmological inference. In\norder to be applied, MMFs require knowledge of the cross-frequency power\nspectra of the noise in the maps. This is typically estimated from the data and\ntaken to be equal to the power spectra of the data, assuming the contribution\nfrom the tSZ signal of the detections to be negligible. Using both analytical\narguments and \\textit{Planck}-like mock observations, we show that doing so\ncauses the MMF noise to be overestimated, inducing a loss of signal-to-noise.\nFurthermore, the MMF cluster observable (the amplitude $\\hat{y}_0$ or the\nsignal-to-noise $q$) does not behave as expected, which can potentially bias\ncosmological inference. In particular, the observable becomes biased with\nrespect to its theoretical prediction and displays a variance that also differs\nfrom its predicted value. We propose an iterative MMF (iMMF) approach designed\nto mitigate these effects. In this approach, after a first standard MMF step,\nthe noise power spectra are reestimated by masking the detections from the\ndata, delivering an updated iterative cluster catalogue. Applying our iMMF to\nour \\textit{Planck}-like mock observations, we find that the aforementioned\neffects are completely suppressed. This leads to a signal-to-noise gain\nrelative to the standard MMF, with more significant detections and a higher\nnumber of them, and to a cluster observable with the expected theoretical\nproperties, thus eliminating any potential biases in the cosmological\nconstraints.\n", "  We present Classification of Cluster GAlaxy MEmbers (C$^2$-GaMe), a\nclassification algorithm based on a suite of machine learning models that\ndifferentiates galaxies into orbiting, infalling, and background (interloper)\npopulations, using phase space information as input. We train and test\nC$^2$-GaMe with the galaxies from UniverseMachine mock catalog based on\nMulti-Dark Planck 2 N-body simulations. We show that probabilistic\nclassification is superior to deterministic classification in estimating the\nphysical properties of clusters, including density profiles and velocity\ndispersion. We propose a set of estimators to get an unbiased estimation of\ncluster properties. We demonstrate that C$^2$-GaMe can recover the distribution\nof orbiting and infalling galaxies' position and velocity distribution with\n$<1\\%$ statistical error when using probabilistic predictions in the presence\nof interlopers in the projected phase space. Additionally, we demonstrate the\nrobustness of trained models by applying them to a different simulation.\nFinally, adding a specific star formation rate and the ratio of the galaxy's\nhalo mass to the cluster's halo mass as additional features improves the\nclassification performance. We discuss potential applications of this technique\nto enhance cluster cosmology and galaxy quenching.\n", "  The scale-free gravothermal fluid formalism has long proved effective in\ndescribing the evolution of self-interacting dark matter halos with a constant\ndark matter particle cross section. However, whether the gravothermal fluid\nsolutions match numerical simulations for velocity-dependent cross-section\nscenarios remains untested. In this work, we provide a fast mapping method that\nrelates the constant-cross-section gravothermal solution to models with\narbitrary velocity dependence in the cross section. We show that the\ngravothermal solutions after mapping are in good agreement with Arepo N-Body\nsimulation results. We illustrate the power of this approach by applying this\nfast mapping method to a halo hosting a low surface brightness galaxy UGC 128.\nWe show that this fast mapping method can be used to constrain free parameters\nin a physically motivated cross-section model and illustrate parameter space\nfavored by the rotation curve measurement.\n", "  The kinetic Sunyaev Zel'dovich effect is a secondary CMB temperature\nanisotropy that provides a powerful probe of the radial-velocity field of\nmatter distributed across the Universe. This velocity field is reconstructed by\ncombining high-resolution CMB measurements with galaxy survey data, and it\nprovides an unbiased tracer of matter perturbations in the linear regime. In\nthis paper, we show how this measurement can be used to probe primordial\nnon-Gaussianity of the local type, particularly focusing on the trispectrum\namplitude $\\tau_{\\rm NL}$, as may arise in a simple two-field inflation model\nthat we provide by way of illustration. Cross-correlating the\nvelocity-field-derived matter distribution with the biased large-scale galaxy\ndensity field allows one to measure the scale-dependent bias factor with sample\nvariance cancellation. We forecast that a configuration corresponding to CMB-S4\nand VRO results in a sensitivity of $\\sigma_{f_{\\rm NL}} \\approx 0.59$ and\n$\\sigma_{\\tau_{\\rm NL}} \\approx 1.5$. These forecasts predict improvement\nfactors of 10 and 195 for $\\sigma_{f_{\\rm NL}}$ and $\\sigma_{\\tau_{\\rm NL}}$,\nrespectively, over the sensitivity using VRO data alone, without internal\nsample variance cancellation. Similarly, for a configuration corresponding to\nDESI and SO, we forecast a sensitivity of $\\sigma_{f_{\\rm NL}} \\approx 3.1$ and\n$\\sigma_{\\tau_{\\rm NL}} \\approx 69$, with improvement factors of 2 and 5,\nrespectively, over the use of the DESI data-set in isolation. We find that a\nhigh galaxy number density and large survey volume considerably improve our\nability to probe the amplitude of the primordial trispectrum for the\nmulti-field model considered.\n", "  In this work, we perform a full-spectrum fitting of 350 massive and passive\ngalaxies selected as cosmic chronometers from the LEGA-C ESO public survey to\nderive their stellar ages, metallicities, and star-formation histories. We\nextensively test our results by assessing their dependence on the possible\ncontribution of dust, calibration of noise and signal, and the use of\nphotometric data in addition to spectral information; we as well identify\nindicators of the correct convergence of the results, including the shape of\nthe posterior distributions, the analysis of specific spectral features, and\nthe correct reproduction of the observed spectrum. We derive a clear\nage-redshift trend compatible with the aging in a standard cosmological model,\nshowing a clear downsizing pattern, with more massive galaxies being formed at\nhigher redshift ($z_f\\sim2.5$) with respect to lower massive ones ($z_f\\sim2$).\nFrom these data, we measure the differential aging of this population of cosmic\nchronometers to derive a new measurement of the Hubble parameter, obtaining\n$H(z=0.8) = 113.1 \\pm 15.1 (\\mathrm{stat.}) ^{+29.1}_{-11.3} (\\mathrm{syst.})\\\n\\mathrm{ km\\ s^{-1}\\ Mpc^{-1}}$. This analysis allows us for the first time to\ncompare the differential ages of cosmic chronometers measured on the same\nsample with two completely different methods, the full-spectrum fit (this work)\nand the analysis of Lick indices, known to correlate with the age and\nmetallicity of the stellar populations \\citep{Borghi2022a}. Albeit an\nunderstood offset in the absolute ages, the differential ages have proven to be\nextremely compatible between the two methods, despite the very different data,\nassumptions, and models considered, demonstrating the robustness of the method.\n", "  The search for primordial $B$-mode polarization of the CMB is limited by the\nsample variance of $B$-modes produced at later times by gravitational lensing.\nConstraints can be improved by `delensing': using some proxy of the matter\ndistribution to partially remove the lensing-induced $B$-modes. Current and\nsoon-upcoming experiments will infer a matter map -- at least in part -- from\nthe temperature anisotropies of the CMB. These reconstructions are contaminated\nby extragalactic foregrounds: radio-emitting galaxies, the cosmic infrared\nbackground, or the Sunyaev--Zel'dovich effects. Using the Websky simulations,\nwe show that the foregrounds add spurious power to the angular auto-spectrum of\ndelensed $B$-modes via non-Gaussian higher-point functions, biasing constraints\non the tensor-to-scalar ratio, $r$. We consider an idealized experiment similar\nto the Simons Observatory, with no Galactic or atmospheric foregrounds. After\nremoving point sources detectable at 143 GHz and reconstructing lensing from\nCMB temperature modes $l<3500$ using a Hu-Okamoto quadratic estimator (QE), we\ninfer a value of $r$ that is $1.5\\,\\sigma$ higher than the true $r=0$.\nReconstructing instead from a minimum-variance ILC map only exacerbates the\nproblem, bringing the bias above $3\\,\\sigma$. When the $TT$ estimator is\nco-added with other QEs or with external matter tracers, new couplings ensue\nwhich partially cancel the diluted bias from $TT$. We provide a simple and\neffective prescription to model these effects. In addition, we demonstrate that\nthe point-source-hardened or shear-only QEs can not only mitigate the biases to\nacceptable levels, but also lead to lower power than the Hu-Okamoto QE after\ndelensing. Thus, temperature-based reconstructions remain powerful tools in the\nquest to measure $r$.\n", "  Structures in the Universe are arranged into the cosmic web. Distributions,\nstatistics, and evolutions of the structures can be used as probes for\ncosmological models. We investigate the number density of voids and dark matter\nhalos-in-voids in the Excursion Set Theory (EST). We study the Markov and\nnon-Markov frameworks of EST in both spherical and ellipsoidal collapse models.\nAfterward, we compare the number density of voids and halos-in-voids in the\nstandard $\\Lambda$CDM and the reconstructed model. The reconstructed model is a\nmodel-independent reconstruction based on background observations. This work\nexplores the effects of the collapse model barrier in the different EST\nframeworks on the statistics of voids and the statistics of halos-in-voids.\nFinally, we find the hint that cosmological models can be distinguished by the\nnumber density of halos-in-voids in the $1.0-2.5$ redshift range. The maximum\ndifference is observed in $z\\sim1.9$.\n", "  The cross-correlation between the 21 cm field and the galaxy distribution is\na potential probe of the Epoch of Reionization (EoR). The 21 cm signal traces\nneutral gas in the intergalactic medium and, on large spatial scales, this\nshould be anti-correlated with the high-redshift galaxy distribution which\npartly sources and tracks the ionized gas. In the near future, interferometers\nsuch as the Hydrogen Epoch of Reionization Array (HERA) are projected to\nprovide extremely sensitive measurements of the 21 cm power spectrum. At the\nsame time, the Nancy Grace Roman Space Telescope (Roman) will produce the most\nextensive catalog to date of bright galaxies from the EoR. Using semi-numeric\nsimulations of reionization, we explore the prospects for measuring the\ncross-power spectrum between the 21 cm and galaxy fields during the EoR. We\nforecast a 14$\\sigma$ detection between HERA and Roman, assuming an overlapping\nsurvey area of 500 deg$^2$, redshift uncertainties of $\\sigma_z = 0.01$ (as\nexpected for the high-latitude spectroscopic survey of Ly$\\alpha$-emitting\ngalaxies), and an effective Ly$\\alpha$ emitter duty cycle of $f_\\mathrm{LAE} =\n0.1$. Thus the HERA-Roman cross-power spectrum may be used to help verify 21 cm\ndetections from HERA. We find that the shot-noise in the galaxy distribution is\na limiting factor for detection, and so supplemental observations using Roman\nshould prioritize deeper observations, rather than covering a wider field of\nview.\n", "  Galaxy rotation curves are considered to be convincing evidence for dark\nmatter or some dynamically equivalent alternative mechanism. Starting only from\nthe rotation curve data, we present a model independent approach of testing a\ngeneral hypothesis that dark matter has the properties of a barotropic fluid.\nIt is shown how the speed of sound squared can be expressed in terms of\nrotation curve data and their radial derivatives and how model independent\nconstraints can be obtained from the requirements that it is confined between 0\nand $c^2$. Using the Milky Way rotation curve data available in the literature,\nwe obtain the constraints on the barotropic fluid speed of sound and illustrate\nthe potential of this approach. Technical challenges, limitations and possible\nfuture extensions and improvements of the proposed approach are discussed.\n", "  We investigate the capability of Einstein Telescope to constrain the\ncosmological parameters of the non-flat $\\Lambda$CDM cosmological model. Two\ntypes of mock datasets are considered depending on whether or not a short\nGamma-Ray Burst is detected and associated with the gravitational wave emitted\nby binary neutron stars merger using the THESEUS satellite. Depending on the\nmock dataset, two statistical estimators are applied: one assumes that the\nredshift is known, while the other marginalizes over it assuming a specific\nredshift prior distribution. We demonstrate that {\\em (i)} using mock catalogs\ncollecting gravitational wave signals emitted by binary neutron stars systems\nto which a short Gamma-Ray Burst has been associated, Einstein Telescope may\nachieve an accuracy on the cosmological parameters of $\\sigma_{H_0}\\approx\n0.40$ km s$^{-1}$ Mpc$^{-1}$, $\\sigma_{\\Omega_{k,0}}\\approx 0.09$, and\n$\\sigma_{\\Omega_{\\Lambda,0}}\\approx 0.07$; while {\\em (ii)} using mock catalogs\ncollecting all gravitational wave signals emitted by binary neutron stars\nsystems for which an electromagnetic counterpart has not been detected,\nEinstein Telescope may achieve an accuracy on the cosmological parameters of\n$\\sigma_{H_0}\\approx 0.04$ km s$^{-1}$ Mpc$^{-1}$,\n$\\sigma_{\\Omega_{k,0}}\\approx 0.01$, and $\\sigma_{\\Omega_{\\Lambda,0}}\\approx\n0.01$, once the redshift probability distribution of GW events is known from\npopulation synthesis simulations and/or the measure of the tidal deformability\nparameter. These results show an improvement of a factor 2-75 with respect to\nearlier results using complementary datasets.\n", "  When applied to the non-linear matter distribution of the universe, neural\nnetworks have been shown to be very statistically sensitive probes of\ncosmological parameters, such as the linear perturbation amplitude $\\sigma_8$.\nHowever, when used as a \"black box\", neural networks are not robust to baryonic\nuncertainty. We propose a robust architecture for constraining primordial\nnon-Gaussianity $f_{NL}$, by training a neural network to locally estimate\n$\\sigma_8$, and correlating these local estimates with the large-scale density\nfield. We apply our method to N-body simulations, and show that\n$\\sigma(f_{NL})$ is 3.5 times better than the constraint obtained from a\nstandard halo-based approach. We show that our method has the same robustness\nproperty as large-scale halo bias: baryonic physics can change the\nnormalization of the estimated $f_{NL}$, but cannot change whether $f_{NL}$ is\ndetected.\n", "  One of the most significant discoveries in modern cosmology is that the\nuniverse is currently in a phase of accelerated expansion after a switch from a\ndecelerated expansion. The redshift corresponding to this epoch is referred to\nas the transition redshift $z_t$. In this work we put constraints on the $z_t$\nwith both model-independent and model-dependent approaches. We consider 32\nHubble parameter measurements and the Pantheon sample of Type Ia Supernovae\n(SNe). In order to include the possible systematic effects in this analysis, we\nuse the full covariance matrix of systematic uncertainties for the Hubble\nparameter measurements. We plot a Hubble Phase Space Portrait (HPSP) between\n$\\dot{H}(z)$ and $H(z)$ in a model-independent way. From this HPSP diagram, we\nestimate the transition redshift as well as the current value of the equation\nof state parameter $\\omega_0$ in a model-independent way. By considering H(z)\nmeasurements, we find the best fit value of $z_t=0.591^{+0.332}_{-0.332}$ and\n$\\omega_0=-0.677^{+0.238}_{-0.238}$. We obtain the best fit value of\n$z_t=0.849^{+0.117}_{-0.117}$ and $\\omega_0=-0.870^{+0.013}_{-0.013}$ using the\nPantheon database. Further, we also use a model dependent approach to determine\n$z_t$. Here, we consider a non-flat $\\Lambda$CDM model as a background\ncosmological model. We reconstruct the cosmic triangle plot among\n$\\log(\\Omega_{m0})$, $-\\log(2\\Omega_{\\Lambda0})$ and $3\\log(1+z_t)$ where the\nconstraints of each parameter are determined by the location in this triangle\nplot. Using $\\Omega_{m0}$ and $\\Omega_{\\Lambda0}$ values, we find the best\nvalue of the transition redshift $z_t=0.619^{+0.580}_{-0.758}$, which is in\ngood agreement with the Planck 2018 results at $1\\sigma$ confidence level. We\nalso simulate the observed Hubble parameter measurements in the redshift range\n$0<z<2$ and perform the same analysis to estimate the transition redshift.\n", "  We present an optimisation method for the assignment of photometric galaxies\ninto a chosen set of redshift bins. This is achieved by combining simulated\nannealing, an optimisation algorithm inspired by solid-state physics, with an\nunsupervised machine learning method, a self-organising map (SOM) of the\nobserved colours of galaxies. Starting with a sample of galaxies that is\ndivided into redshift bins based on a photometric redshift point estimate, the\nsimulated annealing algorithm repeatedly reassigns SOM-selected subsamples of\ngalaxies, which are close in colour, to alternative redshift bins. We optimise\nthe clustering cross-correlation signal between photometric galaxies and a\nreference sample of galaxies with well-calibrated redshifts. Depending on the\neffect on the clustering signal, the reassignment is either accepted or\nrejected. By dynamically increasing the resolution of the SOM, the algorithm\neventually converges to a solution that minimises the number of mismatched\ngalaxies in each tomographic redshift bin and thus improves the compactness of\ntheir corresponding redshift distribution. This method is demonstrated on the\nsynthetic LSST cosmoDC2 catalogue. We find a significant decrease in the\nfraction of catastrophic outliers in the redshift distribution in all\ntomographic bins, most notably in the highest redshift bin with a decrease in\nthe outlier fraction from 57 per cent to 16 per cent.\n", "  We study two of the most theoretically promising models of inflation, namely\nthe Natural inflation and the Mutated Hilltop inflation, in the Einstein-Gauss\nBonnet(EGB) gravity framework. In this work, we try to explore these models in\nEGB framework, keeping the observations from $GW170817$ on the speed of\ngravitational wave to be equal to the speed of light. This has direct\nimplication on the non-minimal coupling to the Gauss-Bonnet invariant in the\naction. Thus, the effective potential gets new features. We have not only\nanalysed the inflationary dynamics, but also the reheating dynamics and finally\nthe corresponding energy spectrum of the gravitational wave.\n", "  The recent rapid growth of the black hole (BH) catalog from gravitational\nwaves (GWs), has allowed us to study the substructure of black hole mass\nfunction (BHMF) beyond the simplest Power-Law distribution. However, the BH\nmasses inferred from binary BH merger events, may be systematically\n'brightened' or 'dimmed' by the gravitational lensing effect. In this work, we\ninvestigate the impact of gravitational lensing on the BHMF inference\nconsidering the detection of the third-generation GW detector -- the Einstein\nTelescope (ET). We focus on high redshift, $z=10$, in order to obtain the upper\nlimits of this effect. We use Monte Carlo (MC) method to simulate the data\nadopting 3 original BHMFs under Un-Lensed and Lensed scenarios, then recover\nthe parameters of BHMFs from the mock data, and compare the difference of\nresults, respectively. We found that all the parameters are well recovered\nwithin one standard deviation(std., 1$\\sigma$), and all 3 BHMF models are\nreconstructed within 68\\% credible interval, suggesting that lensing would not\nchange the main structure drastically, even at very high redshifts and with\nhigh precision of ET. And the modest influence beyond $50M_{\\odot}$, depends on\nthe modeling of the high mass tail or substructure of BHMF. We conclude that\nthe impact of lensing on BHMF inference with ET can be safely ignored in the\nforeseeable future. Careful handling of lensing effects is required only when\nfocusing on an accurate estimation of the high mass end of BHMF at high\nredshifts.\n", "  We have combined X-ray observations from Chandra with Sunyaev-Zel'dovich (SZ)\neffect data from Planck and Bolocam to measure intra-cluster medium pressure\nprofiles from 0.03R$_{500}$ $\\le$ R $\\le$ 5R$_{500}$ for a sample of 21 low-$z$\ngalaxy clusters with a median redshift $\\langle z \\rangle = 0.08$ and a median\nmass $\\langle \\textrm{M}_{500} \\rangle = 6.1 \\times 10^{14}$ M$_{\\odot}$ and a\nsample of 19 mid-$z$ galaxy clusters with $\\langle z \\rangle = 0.50$ and\n$\\langle \\textrm{M}_{500} \\rangle = 10.6 \\times 10^{14}$ M$_{\\odot}$. The mean\nscaled pressure in the low-$z$ sample is lower at small radii and higher at\nlarge radii, a trend that is accurately reproduced in similarly selected\nsamples from The300 simulations. This difference appears to be primarily due to\ndynamical state at small radii, evolution at intermediate radii, and a\ncombination of evolution and mass dependence at large radii. Furthermore, the\noverall flattening of the mean scaled pressure profile in the low-$z$ sample\ncompared to the mid-$z$ sample is consistent with expectations due to\ndifferences in mass accretion rate and the fractional impact of feedback\nmechanisms. In agreement with previous studies, the fractional scatter about\nthe mean scaled pressure profile reaches a minimum of $\\simeq 20$ per cent near\n0.5R$_{500}$. This scatter is consistent between the low-$z$ and mid-$z$\nsamples at all radii, suggesting it is not strongly impacted by sample\nselection, and this general behavior is reproduced in The300 simulations.\nFinally, analytic functions that approximately describe the mass and redshift\ntrends in mean pressure profile shape are provided.\n", "  The next generation of weak lensing surveys will measure the matter\ndistribution of the local Universe with unprecedented precision, allowing the\nresolution of non-Gaussian features of the convergence field. This encourages\nthe use of higher-order mass-map statistics for cosmological parameter\ninference. We extend the forward-modelling based methodology introduced in a\nprevious forecast paper to match these new requirements. We provide multiple\nforecasts for the wCDM parameter constraints that can be expected from stage 3\nand 4 weak lensing surveys. We consider different survey setups, summary\nstatistics and mass map filters including wavelets. We take into account the\nshear bias, photometric redshift uncertainties and intrinsic alignment. The\nimpact of baryons is investigated and the necessary scale cuts are applied. We\ncompare the angular power spectrum analysis to peak and minima counts as well\nas Minkowski functionals of the mass maps. We find a preference for Starlet\nover Gaussian filters. Our results suggest that using a survey setup with 10\ninstead of 5 tomographic redshift bins is beneficial. Adding cross-tomographic\ninformation improves the constraints on cosmology and especially on galaxy\nintrinsic alignment for all statistics. In terms of constraining power, we find\nthe angular power spectrum and the peak counts to be equally matched for stage\n4 surveys, followed by minima counts and the Minkowski functionals. Combining\ndifferent summary statistics significantly improves the constraints and\ncompensates the stringent scale cuts. We identify the most `cost-effective'\ncombination to be the angular power spectrum, peak counts and Minkowski\nfunctionals following Starlet filtering.\n", "  Primordial non-Gaussianity (PNG) is one of the most powerful probes of the\nearly Universe and measurements of the large scale structure of the Universe\nhave the potential to transform our understanding of this area. However\nrelating measurements of the late time Universe to the primordial perturbations\nis challenging due to the non-linear processes that govern the evolution of the\nUniverse. To help address this issue we release a large suite of N-body\nsimulations containing four types of PNG: \\textsc{quijote-png}. These\nsimulations were designed to augment the \\textsc{quijote} suite of simulations\nthat explored the impact of various cosmological parameters on large scale\nstructure observables. Using these simulations we investigate how much\ninformation on PNG can be extracted by extending power spectrum and bispectrum\nmeasurements beyond the perturbative regime at $z=0.0$. This is the first joint\nanalysis of the PNG and cosmological information content accessible with power\nspectrum and bispectrum measurements of the non-linear scales. We find that the\nconstraining power improves significantly up to $k_\\mathrm{max}\\approx 0.3\nh/{\\rm Mpc}$, with diminishing returns beyond as the statistical probes\nsignal-to-noise ratios saturate. This saturation emphasizes the importance of\naccurately modelling all the contributions to the covariance matrix. Further we\nfind that combining the two probes is a powerful method of breaking the\ndegeneracies with the $\\Lambda$CDM parameters.\n", "  Future Large Scale Structure surveys are expected to improve over current\nbounds on primordial non-Gaussianity (PNG), with a significant impact on our\nunderstanding of early Universe physics. The level of such improvements will\nhowever strongly depend on the extent to which late time non-linearities erase\nthe PNG signal on small scales. In this work, we show how much primordial\ninformation remains in the bispectrum of the non-linear dark matter density\nfield by implementing a new, simulation-based, methodology for joint estimation\nof PNG amplitudes ($f_{\\rm NL}$) and standard $\\Lambda$CDM parameters. The\nestimator is based on optimally compressed statistics, which, for a given input\ndensity field, combine power spectrum and modal bispectrum measurements, and\nnumerically evaluate their covariance and their response to changes in\ncosmological parameters. We train and validate the estimator using a large\nsuite of N-body simulations (QUIJOTE-PNG), including different types of PNG\n(local, equilateral, orthogonal). We explicitly test the estimator's\nunbiasedness, optimality and stability with respect to changes in the total\nnumber of input realizations. While the dark matter power spectrum itself\ncontains negligible PNG information, as expected, including it as an ancillary\nstatistic increases the PNG information content extracted from the bispectrum\nby a factor of order $2$. As a result, we prove the capability of our approach\nto optimally extract PNG information on non-linear scales beyond the\nperturbative regime, up to $k_{\\rm max} = 0.5~h\\,{\\rm Mpc}^{-1}$, obtaining\nmarginalized $1$-$\\sigma$ bounds of $\\Delta f_{\\rm NL}^{\\rm local} \\sim 16$,\n$\\Delta f_{\\rm NL}^{\\rm equil} \\sim 77$ and $\\Delta f_{\\rm NL}^{\\rm ortho} \\sim\n40$ on a cubic volume of $1~(\\mathrm{Gpc}/h)^3$ at $z=1$. At the same time, we\ndiscuss the significant information on cosmological parameters contained on\nthese scales.\n", "  Marked power spectra are two-point statistics of a marked field obtained by\nweighting each location with a function that depends on the local density\naround that point. We consider marked power spectra of the galaxy field in\nredshift space that up-weight low density regions, and perform a Fisher matrix\nanalysis to assess the information content of this type of statistics using the\nMolino mock catalogs built upon the Quijote simulations. We identify four\ndifferent ways to up-weight the galaxy field, and compare the Fisher\ninformation contained in their marked power spectra to the one of the standard\ngalaxy power spectrum, when considering monopole and quadrupole of each\nstatistic. Our results show that each of the four marked power spectra can\ntighten the standard power spectrum constraints on the cosmological parameters\n$\\Omega_{\\rm m}$, $\\Omega_{\\rm b}$, $h$, $n_s$, $M_\\nu$ by $15-25\\%$ and on\n$\\sigma_8$ by a factor of 2. The same analysis performed by combining the\nstandard and four marked power spectra shows a substantial improvement compared\nto the power spectrum constraints that is equal to a factor of 6 for $\\sigma_8$\nand $2.5-3$ for the other parameters. Our constraints may be conservative,\nsince the galaxy number density in the Molino catalogs is much lower than the\nones in future galaxy surveys, which will allow them to probe lower density\nregions of the large-scale structure.\n", "  We present two new diagnostics based on the intrinsic shape alignments of\ngroup/cluster size dark matter halos to disentangle the effect of $f(R)$\ngravity from that of massive neutrinos. Using the snapshot data from a series\nof the {\\small DUSTGRAIN}-{pathfinder} $N$-body simulations for the Planck\n$\\Lambda$CDM cosmology and three $f(R)$ gravity models with massive neutrinos\n($\\nu$), we first determine the probability density functions of the alignment\nangles between the shape orientations of massive halos and the minor principal\naxes of the local tidal fields. The numerically obtained results turn out to\nagree very well with the analytic formula derived under the assumption that the\nanisotropic merging along the cosmic web induces the halo shape alignments. The\nfour cosmologies, which several standard diagnostics failed to discriminate,\nare found to yield significantly different best-fit values of the single\nparameter that characterizes the analytic formula. We also numerically\ndetermine the spatial cross-correlations between the shape orientations of\nneighbor group/cluster halos, and find them to be in good agreements with a\nfitting formula characterized by two parameters, whose best-fit values are\nfound to substantially differ among the four models. We also discuss the\nlimitations and caveats of these new diagnostics that must be overcome for the\napplication to real observational data.\n", "  In this paper, we explore the power of the cosmic microwave background (CMB)\npolarization (E-mode) data to corroborate four potential anomalies in CMB\ntemperature data: the lack of large angular-scale correlations, the alignment\nof the quadrupole and octupole (Q-O), the point-parity asymmetry, and the\nhemispherical power asymmetry. We use CMB simulations with noise representative\nof three experiments -- the Planck satellite, the Cosmology Large Angular Scale\nSurveyor (CLASS), and the LiteBIRD satellite -- to test how current and future\ndata constrain the anomalies. We find the correlation coefficients $\\rho$\nbetween temperature and E-mode estimators to be less than $0.1$, except for the\npoint-parity asymmetry ($\\rho=0.17$ for cosmic-variance-limited simulations),\nconfirming that E-modes provide a check on the anomalies that is largely\nindependent of temperature data. Compared to Planck component-separated CMB\ndata (SMICA), the putative LiteBIRD survey would reduce errors on E-mode\nanomaly estimators by factors of $\\sim 3$ for hemispherical power asymmetry and\npoint-parity asymmetry, and by $\\sim 26$ for lack of large-scale correlation.\nThe improvement in Q-O alignment is not obvious due to large cosmic variance,\nbut we found the ability to pin down the estimator value will be improved by a\nfactor $\\gtrsim100$. Improvements with CLASS are intermediate to these.\n", "  We investigate the regularity of galaxy cluster gas density profiles and the\nlink to the relation between core-excised luminosity, LXc, and mass from the Yx\nproxy, MYx, for 93 SZE-selected objects. The sample spans masses M500=[0.5 -\n20] x 10e14 Msun, and lies at redshifts 0.05<z<1.13. Using XMM-Newton\nobservations, we derive an average ICM density profile for the SZE-selected\nsystems and determine its scaling with mass and redshift. This average profile\nevolves slightly stronger than self-similar (a_z = 2.09+/-0.02), and has\nsignificant dependence on mass (a_M = 0.22 +/- 0.01). Deviations from the\naverage scaling with radius indicate different evolution for the core regions\nand the bulk. We measure the radial variation of the intrinsic scatter, finding\na slight evolution with redshift. The average profile of the SZE-selected\nsystems describes that of X-ray-selected systems at low redshift. The scaled\ncore properties are positively skewed at later times, suggesting an increased\nincidence of centrally peaked objects at lower redshifts. The relation between\nLXc and MYx has an intrinsic scatter of 13%. Using simulations, we investigate\nthe impact of selection effects, intrinsic scatter, and covariance on this\nrelation. The slope is insensitive to selection and intrinsic scatter between\nquantities; however, the scatter is very dependent on the covariance between\nLXc and Yx. Accounting for our use of the Yx proxy to determine the mass, we\nestimate an upper limit to the intrinsic scatter with respect to the true mass\nof 22%. We probe the connection between the scatter in density profiles and\nthat in the LXc-M relation. Our results suggest that the ICM bulk evolves\napproximately self-similarly, with the core regions evolving separately;\nindicate a variation of the gas content with mass; and show that LXc has a\ntight relation to the underlying mass.\n", "  The search for the primordial B-modes of the cosmic microwave background\n(CMB) relies on the separation from the brighter foreground dust signal. In\nthis context, the characterisation of the spectral energy distribution (SED) of\nthermal dust in polarization has become a critical subject of study. We present\na power-spectra analysis of Planck data, which improves on previous studies by\nusing the newly released SRoll2 maps that correct residual data systematics,\nand by extending the analysis to regions near the Galactic plane. Our analysis\nfocuses on the lowest multipoles between l=4 and 32, and three sky areas with\nsky fractions of fsky = 80%, 90%, and 97%. The mean dust SED for polarization\nand the 353 GHz Q and U maps are used to compute residual maps at 100, 143 and\n217 GHz, highlighting spatial variations of the dust polarization SED.\nResiduals are detected at the three frequencies for the three sky areas. We\nshow that models based on total intensity data are underestimating by a\nsignificant factor the complexity of dust polarized CMB foreground. Our\nanalysis emphasizes the need to include variations of polarization angles of\nthe dust polarized CMB foreground. The frequency dependence of the EE and BB\npower spectra of the residual maps yields further insight. We find that the\nmoments expansion to the first order of the modified black-body (MBB) spectrum\nprovides a good fit to the EE power-spectra. This result suggests that the\nresiduals could follow mainly from variations of dust MBB spectral parameters.\nHowever, this conclusion is challenged by cross-spectra showing that the\nresiduals maps at the three frequencies are not fully correlated, and the fact\nthat the BB power-spectra do not match the first order moment expansion of a\nMBB SED. This work sets new requirements for simulations of the dust polarized\nforeground and component separation methods (abridged)\n", "  Observations of the Lyman-$\\alpha$ (Ly$\\alpha$) forest in spectra of distant\nquasars enable us to probe the matter power spectrum at relatively small\nscales. With several upcoming surveys, it is expected that there will be a\nmany-fold increase in the quantity and quality of data, and hence it is\nimportant to develop efficient simulations to forward model these data sets.\nOne such semi-numerical method is based on the assumption that the baryonic\ndensities in the intergalactic medium (IGM) follow a lognormal distribution. In\nthis work, we test the robustness of the lognormal model of the Ly$\\alpha$\nforest in recovering a set of IGM parameters by comparing with high-resolution\nSherwood SPH simulations. We study the recovery of the parameters $T_0$\n(temperature of the mean-density IGM), $\\gamma$ (slope of the\ntemperature-density relation) and $\\Gamma_{12}$ (hydrogen photoionization rate)\nat $z \\sim 2.5$ using a Markov Chain Monte Carlo (MCMC) technique for parameter\nestimation. Using three flux statistics, the probability distribution, the mean\nflux and the power spectrum, values of all three parameters, $T_0$, $\\gamma$\nand $\\Gamma_{12}$ implied in the SPH simulations are recovered within $1 -\n\\sigma$ ($\\sim$ 9, 4 and 1% respectively) of the median (best-fit) values. We\nverify the validity of our results at different baryon smoothing filter, SNR,\nbox size & resolution, and data seed and confirm that the lognormal model can\nbe used as an efficient tool for modelling the Ly$\\alpha$ transmitted flux at\n$z \\sim 2.5$.\n", "  We make the case that there can be no low-redshift solution to the $H_0$\ntension. To robustly answer this question, we use a very flexible\nparameterization for the dark energy equation of state such that every\ncosmological distance still allowed by data exists within this prior volume. To\nthen answer whether there exists a satisfactory solution to the $H_0$ tension\nwithin this comprehensive parameterization, we constrained the parametric form\nusing different partitions of the Planck cosmic microwave background,\nSDSS-IV/eBOSS DR16 baryon acoustic oscillation, and Pantheon supernova\ndatasets. When constrained by just the cosmic microwave background dataset,\nthere exists a set of equations of state which yields high $H_0$ values, but\nthese equations of state are ruled out by the combination of the supernova and\nbaryon acoustic oscillation datasets. In other words, the constraint from the\ncosmic microwave background, baryon acoustic oscillation, and supernova\ndatasets together does not allow for high $H_0$ values and converges around an\nequation of state consistent with a cosmological constant. Thus, since this\nvery flexible parameterization does not offer a solution to the $H_0$ tension,\nthere can be no solution to the $H_0$ tension that adds physics at only low\nredshifts. This is directly related to the expansion history of the Universe\nand its geometrical properties and would include models beyond those\nparametrized by $w(z)$.\n", "  This paper introduces a new Planck Catalog of Polarized and Variable Compact\nSources (PCCS-PV) comprising 153 sources, the majority of which are\nextragalactic. The data include both the total flux density and linear\npolarization measured by Planck with frequency coverage from 30 to 353 GHz, and\ntemporal spacing ranging from days to years. We classify most sources as\nbeamed, extragalactic radio sources; the catalog also includes several radio\ngalaxies, Seyfert galaxies, and Galactic and Magellanic Cloud sources,\nincluding H IIi regions and planetary nebulae. An advanced extraction method\napplied directly to the multifrequency Planck time-ordered data, rather than\nthe mission sky maps, was developed to allow an assessment of the variability\nof polarized sources. Our analysis of the time-ordered data from the Planck\nmission, tod2flux, allowed us to catalog the time-varying emission and\npolarization properties for these sources at the full range of polarized\nfrequencies employed by Planck, 30 to 353 GHz. PCCS-PV provides the time- and\nfrequency-dependent, polarized flux densities for all 153 sources. To\nillustrate some potential applications of the PCCS- PV, we conducted\npreliminary comparisons of our measurements of selected sources with published\ndata from other astronomical instruments. In summary, we find general agreement\nbetween the Planck and the Institut de Radioastronomie Millim\\'etrique (IRAM)\npolarization measurements as well as with the Mets\\\"ahovi 37 GHz values at\nclosely similar epochs. These combined measurements also show the value of\nPCCS-PV results and the PCCS2 catalog for filling in missing spectral (or\ntemporal) coverage and helping to define the spectral energy distributions of\nextragalactic sources. In turn, these results provide useful clues as to the\nphysical properties of the sources.\n", "  We present the results of a systematic X-ray analysis of optically rich\ngalaxy clusters detected by the Subaru HSC survey in the eROSITA eFEDS field.\nThrough a joint analysis of SRG/eROSITA and Subaru/HSC surveys, we aim to study\nthe dynamical status of the optically selected clusters and derive the cluster\nscaling relations. The sample consists of 43 optically selected galaxy clusters\nwith a richness $>40$ in $0.16<z<0.89$. We systematically analyzed the X-ray\nimages and spectra using the eROSITA data. We identified the BCG using the\noptical and far-infrared databases. We evaluated the cluster's dynamical status\nby measuring the offset between the X-ray peak and BCG position, the gas\nconcentration, and the number of galaxy-density peaks. We studied the\nluminosity-temperature and mass-luminosity relations based on eROSITA X-ray\nspectra and HSC weak-lensing data analyses. Based on the these measurements,\nthe fraction of relaxed clusters is $2(<39)$%, which is smaller than that of\nthe X-ray-selected cluster samples. After correcting for a selection bias due\nto the richness cut, we obtained a shallow $L-T$ slope of $2.1\\pm0.5$, which is\nconsistent with the predictions of the self-similar model and the baseline\nmodel incorporating a mass-concentration relation. The $L-M$ slope of\n$1.5\\pm0.3$ agrees with the above theoretical models and that of the\nshear-selected clusters in the eFEDs field. Our analysis of high-richness\noptical clusters yields a small fraction of relaxed clusters and a shallow\nslope for the luminosity-temperature relation. This suggests that the average\nX-ray properties of the optical clusters are likely to be different from those\nobserved in the X-ray samples. Thus, the joint eROSITA and HSC observations are\na powerful tool in extending the analysis to a larger sample and understanding\nthe selection effect with a view to establish cluster scaling relations.\n", "  In the pursuit of primordial non-Gaussianities, we hope to access smaller\nscales across larger comoving volumes. At low redshift, the search for\nprimordial non-Gaussianities is hindered by gravitational collapse, to which we\noften associate a scale $k_{\\rm NL}$. Beyond these scales, it will be hard to\nreconstruct the modes sensitive to the primordial distribution. When\nforecasting future constraints on the amplitude of primordial non-Gaussianity,\n$f_{\\rm NL}$, off-diagonal components are usually neglected in the covariance\nbecause these are small compared to the diagonal. We show that the induced\nnon-Gaussian off-diagonal components in the covariance degrade forecast\nconstraints on primordial non-Gaussianity, even when all modes are well within\nwhat is usually considered the linear regime. As a testing ground, we examine\nthe effects of these off-diagonal components on the constraining power of the\nmatter bispectrum on $f_{\\rm NL}$ as a function of $k_{\\rm max}$ and redshift,\nconfirming our results against N-body simulations out to redshift $z=10$. We\nthen consider these effects on the hydrogen bispectrum as observed from a\nPUMA-like 21-cm intensity mapping survey at redshifts $2<z<6$ and show that not\nincluding off-diagonal covariance over-predicts the constraining power on\n$f_{\\rm NL}$ by up to a factor of $5$. For future surveys targeting even higher\nredshifts, such as Cosmic Dawn and the Dark Ages, which are considered ultimate\nsurveys for primordial non-Gaussianity, we predict that non-Gaussian covariance\nwould severely limit prospects to constrain $f_{\\rm NL}$ from the bispectrum.\n", "  We present cosmological constraints from the analysis of two-point\ncorrelation functions between galaxy positions and galaxy lensing measured in\nDark Energy Survey (DES) Year 3 data and measurements of cosmic microwave\nbackground (CMB) lensing from the South Pole Telescope (SPT) and Planck. When\njointly analyzing the DES-only two-point functions and the DES\ncross-correlations with SPT+Planck CMB lensing, we find $\\Omega_{\\rm m} =\n0.344\\pm 0.030$ and $S_8 \\equiv \\sigma_8 (\\Omega_{\\rm m}/0.3)^{0.5} = 0.773\\pm\n0.016$, assuming $\\Lambda$CDM. When additionally combining with measurements of\nthe CMB lensing autospectrum, we find $\\Omega_{\\rm m} =\n0.306^{+0.018}_{-0.021}$ and $S_8 = 0.792\\pm 0.012$. The high signal-to-noise\nof the CMB lensing cross-correlations enables several powerful consistency\ntests of these results, including comparisons with constraints derived from\ncross-correlations only, and comparisons designed to test the robustness of the\ngalaxy lensing and clustering measurements from DES. Applying these tests to\nour measurements, we find no evidence of significant biases in the baseline\ncosmological constraints from the DES-only analyses or from the joint analyses\nwith CMB lensing cross-correlations. However, the CMB lensing\ncross-correlations suggest possible problems with the correlation function\nmeasurements using alternative lens galaxy samples, in particular the redMaGiC\ngalaxies and high-redshift MagLim galaxies, consistent with the findings of\nprevious studies. We use the CMB lensing cross-correlations to identify\ndirections for further investigating these problems.\n", "  A cosmological model with a time-varying mass of electrons seems a promising\nsolution for the so-called Hubble tension. We examine the big bang\nnucleosynthesis (BBN) constraints on the time-varying electron mass model,\nbecause a larger electron mass gives rise to the smaller neutron decay rate\nwhich could affect the light element abundance. Additionally, different\ninferred cosmological parameters, primarily baryon asymmetry, to keep the\ncosmic background power spectrum unchanged could affect the abundance of light\nelement. We find that the predicted helium fraction becomes larger and the\ndeuterium abundance becomes smaller as the electron mass at the BBN time\nbecomes larger. Thus, we conclude that an acceptable electron mass at the BBN\ntime would be only approximately 1% greater than the current electron mass.\n", "  We investigate the cosmological constraints on the Variable Chaplygin gas\nmodel from the latest observational data: SCP Union 2.1 compilation dataset of\nType Ia supernovae (SNe Ia), Pantheon sample of SNe Ia, Platinum Sample of\nGamma Ray Bursts (GRB) and GWTC-3 of gravitational wave merger events. Variable\nChaplygin gas is a model of interacting dark matter and dark energy, which\ninterpolates from a dust-dominated era to a quintessence-dominated era. The\nVariable Chaplygin gas model is shown to be compatible with Type Ia Supernovae\nand gravitational merger data. We have obtained tighter constraints on\ncosmological parameters $B_s$ and $n$, using the Pantheon sample. By using the\nMarkov chain Monte Carlo (MCMC) method on the Pantheon sample, we obtain\n$B_s$=0.108 $\\pm$ 0.034, n=1.157 $\\pm$ 0.513 and $H_0$=70.020 $\\pm$ 0.407, for\nGRBs, we obtain $B_s$=0.20 $\\pm$ 0.11, n=1.45 $\\pm$ 1.40 and $H_0$=70.41 $\\pm$\n0.67} and on GWTC-3, we obtain $B_s$=0.130 $\\pm$ 0.076, n=0.897 $\\pm$ 1.182 and\n$H_0$=69.838 $\\pm$ 3.007. The combined constraints from the above data sets are\n$B_s$=0.11 $\\pm$ 0.03, n=1.14 $\\pm$ 0.36 and $H_0$=70.34 $\\pm$ 0.61\n", "  The Euclid space telescope will survey a large dataset of cosmic voids traced\nby dense samples of galaxies. In this work we estimate its expected performance\nwhen exploiting angular photometric void clustering, galaxy weak lensing and\ntheir cross-correlation. To this aim, we implement a Fisher matrix approach\ntailored for voids from the Euclid photometric dataset and present the first\nforecasts on cosmological parameters that include the void-lensing correlation.\nWe examine two different probe settings, pessimistic and optimistic, both for\nvoid clustering and galaxy lensing. We carry out forecast analyses in four\nmodel cosmologies, accounting for a varying total neutrino mass, $M_\\nu$, and a\ndynamical dark energy (DE) equation of state, $w(z)$, described by the CPL\nparametrisation. We find that void clustering constraints on $h$ and $\\Omega_b$\nare competitive with galaxy lensing alone, while errors on $n_s$ decrease\nthanks to the orthogonality of the two probes in the 2D-projected parameter\nspace. We also note that, as a whole, the inclusion of the void-lensing\ncross-correlation signal improves parameter constraints by $10-15\\%$, and\nenhances the joint void clustering and galaxy lensing Figure of Merit (FoM) by\n$10\\%$ and $25\\%$, in the pessimistic and optimistic scenarios, respectively.\nFinally, when further combining with the spectroscopic galaxy clustering,\nassumed as an independent probe, we find that, in the most competitive case,\nthe FoM increases by a factor of 4 with respect to the combination of weak\nlensing and spectroscopic galaxy clustering taken as independent probes. The\nforecasts presented in this work show that photometric void-clustering and its\ncross-correlation with galaxy lensing deserve to be exploited in the data\nanalysis of the Euclid galaxy survey and promise to improve its constraining\npower, especially on $h$, $\\Omega_b$, the neutrino mass, and the DE evolution.\n", "  The intrinsic alignment (IA) of galaxies is potentially a major limitation in\nderiving cosmological constraints from weak lensing surveys. In order to\ninvestigate this effect we assign intrinsic shapes and orientations to galaxies\nin the light-cone output of the MICE simulation, spanning $\\sim5000\\,{\\rm\ndeg}^2$ and reaching redshift $z=1.4$. This assignment is based on a\n'semi-analytic' IA model that uses photometric properties of galaxies as well\nas the spin and shape of their host halos. Advancing on previous work, we\ninclude more realistic distributions of galaxy shapes and a luminosity\ndependent galaxy-halo alignment. The IA model parameters are calibrated against\nCOSMOS and BOSS LOWZ observations. The null detection of IA in observations of\nblue galaxies is accounted for by setting random orientations for these\nobjects. We compare the two-point alignment statistics measured in the\nsimulation against predictions from the analytical IA models NLA and TATT over\na wide range of scales, redshifts and luminosities for red and blue galaxies\nseparately. We find that both models fit the measurements well at scales above\n$8\\,h^{-1}{\\rm Mpc}$, while TATT outperforms NLA at smaller scales. The IA\nparameters derived from our fits are in broad agreement with various\nobservational constraints from red galaxies. Lastly, we build a realistic\nsource sample, mimicking DES Year 3 observations and use it to predict the IA\ncontamination to the observed shear statistics. We find this prediction to be\nwithin the measurement uncertainty, which might be a consequence of the random\nalignment of blue galaxies in the simulation.\n", "  We provide perturbation theory predictions for the HI intensity mapping power\nspectrum multipoles using the Effective Field Theory of Large Scale Structure\n(EFTofLSS), which should allow us to constrain cosmological parameters\nexploiting mildly nonlinear scales. Assuming survey specifications typical of\nproposed interferometric HI intensity mapping experiments like CHORD and PUMA,\nand realistic ranges of validity for the perturbation theory modelling, we run\nmock full shape MCMC analyses at a redshift bin centred at $z=0.5$, and compare\nwith Stage-IV optical galaxy surveys. We include the impact of 21cm foreground\nremoval using simulations-based prescriptions, and quantify the effects on the\nprecision and accuracy of the parameter estimation. We vary 11 parameters in\ntotal: 3 cosmological parameters, 7 bias and counterterms parameters, and the\nHI brightness temperature. Amongst them, the 4 parameters of interest are: the\ncold dark matter density, $\\omega_{\\rm c}$, the Hubble parameter, $h$, the\nprimordial amplitude of the power spectrum, $A_{\\rm s}$, and the linear HI\nbias, $b_1$. For the best case scenario, we obtain unbiased constraints on all\nparameters with $<3\\%$ errors at $68\\%$ confidence level. When we include the\nforeground removal effects, the parameter estimation becomes strongly biased\nfor $\\omega_{\\rm c}, h$, and $b_1$, while $A_{\\rm s}$ is less biased ($<\n2\\sigma$). We find that scale cuts $k_{\\rm min} \\geq 0.03 \\, h/{\\mathrm{Mpc}}$\nare required to return accurate estimates for $\\omega_{\\rm c}$ and $h$, at the\nprice of a decrease in the precision, while $b_1$ remains strongly biased. We\ncomment on the implications of these results for real data analyses.\n", "  Gaussian processes have been widely used in cosmology to reconstruct\ncosmological quantities in a model-independent way. However, the validity of\nthe adopted mean function and hyperparameters, and the dependence of the\nresults on the choice have not been well explored. In this paper, we study the\neffects of the underlying mean function and the hyperparameter selection on the\nreconstruction of the distance moduli from type Ia supernovae. We show that the\nchoice of an arbitrary mean function affects the reconstruction: a zero mean\nfunction leads to unphysical distance moduli and the best-fit LCDM to biased\nreconstructions. We propose to marginalize over a family of mean functions and\nover the hyperparameters to effectively remove their impact on the\nreconstructions. We further explore the validity and consistency of the results\nconsidering different kernel functions and show that our method is unbiased.\n", "  We investigate how much can be learnt about four types of primordial\nnon-Gaussianity (PNG) from small-scale measurements of the halo field. Using\nthe QUIJOTE-PNG simulations, we quantify the information content accessible\nwith measurements of the halo power spectrum monopole and quadrupole, the\nmatter power spectrum, the halo-matter cross spectrum and the halo bispectrum\nmonopole. This analysis is the first to include small, non-linear scales, up to\n$k_\\mathrm{max}=0.5 \\mathrm{h/Mpc}$, and to explore whether these scales can\nbreak degeneracies with cosmological and nuisance parameters making use of\nthousands of N-body simulations. We perform all the halo measurements in\nredshift space with a single sample comprised of all halos with mass $>3.2\n\\times 10^{13}~h^{-1}M_\\odot$. For local PNG, measurements of the scale\ndependent bias effect from the power spectrum using sample variance\ncancellation provide significantly tighter constraints than measurements of the\nhalo bispectrum. In this case measurements of the small scales add minimal\nadditional constraining power. In contrast, the information on equilateral and\northogonal PNG is primarily accessible through the bispectrum. For these\nshapes, small scale measurements increase the constraining power of the halo\nbispectrum by up to $\\times4$, though the addition of scales beyond $k\\approx\n0.3 \\mathrm{h/Mpc}$ improves constraints largely through reducing degeneracies\nbetween PNG and the other parameters. These degeneracies are even more\npowerfully mitigated through combining power spectrum and bispectrum\nmeasurements. However even with combined measurements and small scale\ninformation, equilateral non-Gaussianity remains highly degenerate with\n$\\sigma_8$ and our bias model.\n", "  We baseline with current cosmological observations to forecast the power of\nthe Dark Energy Spectroscopic Instrument (DESI) in two ways: 1. the gain in\nconstraining power of parameter combinations in the standard $\\Lambda$CDM\nmodel, and 2. the reconstruction of quintessence models of dark energy. For the\nformer task we use a recently developed formalism to extract the leading\nparameter combinations constrained by different combinations of cosmological\nsurvey data. For the latter, we perform a non-parametric reconstruction of\nquintessence using the Effective Field Theory of Dark Energy. Using mock DESI\nobservations of the Hubble parameter, angular diameter distance, and growth\nrate, we find that DESI will provide significant improvements over current\ndatasets on $\\Lambda$CDM and quintessence constraints. Including DESI mocks in\nour $\\Lambda$CDM analysis improves constraints on $\\Omega_m$, $H_0$, and\n$\\sigma_8$ by a factor of two, where the improvement results almost entirely\nfrom the angular diameter distance and growth of structure measurements. Our\nquintessence reconstruction suggests that DESI will considerably improve\nconstraints on a range of quintessence properties, such as the reconstructed\npotential, scalar field excursion, and the dark energy equation of state. The\nangular diameter distance measurements are particularly constraining in the\npresence of a non-$\\Lambda$CDM signal in which the potential cannot be\naccounted for by shifts in $H_0$ and $\\Omega_m$.\n", "  Intrinsic alignment (IA) modelling and photometric redshift estimation are\ntwo of the main sources of systematic uncertainty in weak lensing surveys. We\ninvestigate the impact of redshift errors and their interplay with different IA\nmodels. Generally, errors on the mean $\\delta_z$ and on the width $\\sigma_z$ of\nthe redshift bins can both lead to biases in cosmological constraints. We find\nthat such biases can, however, only be partially resolved by marginalizing over\n$\\delta_z$ and $\\sigma_z$. For Stage-III surveys, $\\delta_z$ and $\\sigma_z$\ncannot be well constrained due to limited statistics. The resulting biases are\nthus sensitive to prior volume effects. For Stage-IV surveys, we observe that\nmarginalizing over the redshift parameters has an impact and reduces the bias.\nWe derive requirements on the uncertainty of $\\sigma_z$ and $\\delta_z$ for both\nStage-III and Stage-IV surveys. We assume that the redshift systematic errors\non $S_8$ should be less than half of the statistical errors, and the median\nbias should be smaller than $0.25\\sigma$. We find that the uncertainty on\n$\\delta_z$ has to be $\\lesssim0.025$ for the NLA IA model with a Stage-III\nsurvey. For $\\sigma_z$, the requirement is met even for large uncertainties\n$\\leq0.3$. For the TATT IA model, the uncertainty on $\\delta_z$ has to be\n$\\lesssim0.02$ and the uncertainty on $\\sigma_z$ has to be $\\lesssim0.2$. For\nStage-IV surveys, the uncertainty on $\\delta_z$ has to be $\\lesssim0.005$ and\nthe uncertainty on $\\sigma_z$ should be $\\lesssim0.1$, with no significant\ndependence on the IA model. This required high precision will be a challenge\nfor the redshift calibration of these future surveys. Finally, we investigate\nwhether the interplay between redshift systematics and IA modelling can explain\nthe $S_8$-tension between cosmic shear results and CMB measurements. We find\nthat this is unlikely to explain the current $S_8$-tension.\n", "  The radial acceleration relation (RAR) represents a tight empirical relation\nbetween the inferred total and baryonic centripetal accelerations,\n$g_{\\rm{tot}}=GM_{\\rm{tot}}(<r)/r^2$ and $g_{\\rm{bar}}=GM_{\\rm{bar}}(<r)/r^2$,\nobserved in galaxies and galaxy clusters. The tight correlation between these\ntwo quantities can provide insight into the nature of dark matter. Here we use\nBAHAMAS, a state-of-the-art suite of cosmological hydrodynamical simulations,\nto characterize the RAR in cluster-scale halos for both cold and collisionless\ndark matter (CDM) and self-interacting dark matter (SIDM) models. SIDM halos\ngenerally have reduced central dark matter densities, which reduces the total\nacceleration in the central region when compared with CDM. We compare the RARs\nin galaxy clusters simulated with different dark matter models to the RAR\ninferred from CLASH observations. Our comparison shows that the cluster-scale\nRAR in the CDM model provides an excellent match to the CLASH RAR obtained by\nTian et al. including the high-acceleration regime probed by the brightest\ncluster galaxies (BCGs). By contrast, models with a larger SIDM cross-section\nyield increasingly poorer matches to the CLASH RAR. Excluding the BCG regions\nresults in a weaker but still competitive constraint on the SIDM cross-section.\nUsing the RAR data outside the central $r<100$kpc region, an SIDM model with\n$\\sigma/m=0.3$cm$^{2}$g$^{-1}$ is disfavored at the $3.8\\sigma$ level with\nrespect to the CDM model. This study demonstrates the power of the\ncluster-scale RAR for testing the collisionless nature of dark matter.\n", "  $ $Weak gravitational lensing is a powerful probe which is used to constrain\nthe standard cosmological model and its extensions. With the enhanced\nstatistical precision of current and upcoming surveys, high accuracy\npredictions for weak lensing statistics are needed to limit the impact of\ntheoretical uncertainties on cosmological parameter constraints. For this\npurpose, we present a comparison of the theoretical predictions for the\nnonlinear matter and weak lensing power spectra, based on the widely used\nfitting functions ($\\texttt{mead}$ and $\\texttt{rev-halofit}$), emulators\n($\\texttt{EuclidEmulator}$, $\\texttt{EuclidEmulator2}$,\n$\\texttt{BaccoEmulator}$ and $\\texttt{CosmicEmulator}$) and N-body simulations\n($\\texttt{Pkdgrav3}$). We consider the forecasted constraints on the $\\Lambda\n\\texttt{CDM}$ and $\\texttt{wCDM}$ models from weak lensing for stage III and\nstage IV surveys. We study the relative bias on the constraints and their\ndependence on the assumed prescriptions. Assuming a $\\Lambda \\texttt{CDM}$\ncosmology, we find that the relative agreement on the $S_8$ parameter is\nbetween $0.2-0.3\\sigma$ for a stage III-like survey between the above\npredictors. For a stage IV-like survey the agreement becomes $1.4-3.0\\sigma$.\nIn the $\\texttt{wCDM}$ scenario, we find broader $S_8$ constraints, and\nagreements of $0.18-0.26\\sigma$ and $0.7-1.7\\sigma$ for stage III and stage IV\nsurveys, respectively. The accuracies of the above predictors therefore appear\nadequate for stage III surveys, while the fitting functions would need\nimprovements for future stage IV weak lensing surveys. Furthermore, we find\nthat, of the fitting functions, $\\texttt{mead}$ provides the best agreement\nwith the emulators. We discuss the implication of these findings for the\npreparation of the future weak lensing surveys.\n", "  Taking advantage of $\\sim4700$ deg$^2$ optical coverage of the Southern sky\noffered by the VST ATLAS survey, we construct a new catalogue of\nphotometrically selected galaxy groups and clusters using the {\\sc orca}\ncluster detection algorithm. The catalogue contains $\\sim 22,000$ detections\nwith $N_{200}>10$ and $\\sim9,000$ with $N_{200}>20$. We estimate the\nphotometric redshifts of the clusters using machine learning and find the\nredshift distribution of the sample to extend to $z\\sim0.7$, peaking at\n$z\\sim0.25$. We calibrate the ATLAS cluster mass-richness scaling relation\nusing masses from the MCXC, Planck, ACT DR5 and SDSS redMaPPer cluster samples.\nWe estimate the ATLAS sample to be $>95\\%$ complete and $>85\\%$ pure at\n$z<0.35$ and in the $M_{\\rm 200m}$>$1\\times10^{14}h^{-1}{\\rm M}_\\odot$ mass\nrange. At $z<0.35$, we also find the ATLAS sample to be more complete than\nredMaPPer, recovering a $\\sim40\\%$ higher fraction of Abell clusters. This\nhigher sample completeness places the amplitude of the $z<0.35$ ATLAS cluster\nmass function closer to the predictions of a $\\Lambda$CDM model with parameters\nbased on the Planck CMB analyses, compared to the mass functions of the other\ncluster samples. However, strong tensions between the observed ATLAS mass\nfunctions and models remain. We shall present a detailed cosmological analysis\nof the ATLAS cluster mass functions in paper II. In the future, optical\ncounterparts to X-ray-detected eROSITA clusters can be identified using the\nATLAS sample. The catalogue is also well suited for auxiliary spectroscopic\ntarget selection in 4MOST. The ATLAS cluster catalogue is publicly available at\nhttp://astro.dur.ac.uk/cosmology/vstatlas/cluster_catalogue/.\n", "  The separable analytical solution in standard perturbation theory for an\nEinstein de Sitter (EdS) universe can be generalized to the wider class of such\ncosmologies (``generalized EdS'', or gEdS) in which a fraction of the\npressure-less fluid does not cluster. We derive the corresponding kernels in\nboth Eulerian perturbation theory (EPT) and Lagrangian perturbation theory,\ngeneralizing the canonical EdS expressions to a one-parameter family where the\nparameter can be taken to be the exponent $\\alpha$ of the growing mode linear\namplification $D(a) \\propto a^{\\alpha}$. For the power spectrum (PS) at one\nloop in EPT, the contribution additional to standard EdS is given, for each of\nthe `13' and `22' terms, as a function of two infra-red safe integrals. In the\nsecond part of the paper we show that the calculation of cosmology-dependent\ncorrections in perturbation theory in standard (e.g. LCDM-like) models can be\nsimplified, and their magnitude and parameter dependence better understood, by\nrelating them to our analytic results for gEdS models. At second order the time\ndependent kernels are equivalent to the analytic kernels of the gEdS model with\n$\\alpha$ replaced by a single redshift dependent effective growth rate\n$\\alpha_2(z)$. At third order the time evolution can be conveniently\nparametrized in terms of two additional such effective growth rates. For the PS\ncalculated at one loop order, the correction to the PS relative to the EdS\nlimit can be expressed in terms of just $\\alpha_2(z)$, one additional effective\ngrowth rate function and the four infra-red safe integrals of the gEdS limit.\nThis is much simplified compared to expressions in the literature that use six\nor eight red-shift dependent functions and are not explicitly infra-red safe.\nUsing the analytic gEdS expression for the PS with $\\alpha=\\alpha_2(z)$ gives a\ngood approximation (to $\\sim 25 \\%$) for the exact result.\n", "  Where the cosmic baryons lie in and around galactic dark matter halos is only\nweakly constrained. We develop a method to quickly paint on models for their\ndistribution. Our approach uses the statistical advantages of $N$-body\nsimulations, while painting on the profile of gas around individual halos in\nways that can be motivated by semi-analytic models or zoom-in hydrodynamic\nsimulations of galaxies. Possible applications of the algorithm include\nextragalactic dispersion measures to fast radio bursts (FRBs), the\nSunyaev-Zeldovich effect, baryonic effects on weak lensing, and cosmic metal\nenrichment. As an initial application, we use this tool to investigate how the\nbaryonic profile of foreground galactic-mass halos affects the statistics of\nthe dispersion measure (DM) towards cosmological FRBs.\n  We show that the distribution of DM is sensitive to the distribution of\nbaryons in galactic halos, with viable gas profile models having significantly\ndifferent probability distributions for DM to a given redshift. We also\ninvestigate the requirements to statistically measure the circumgalactic\nelectron profile for FRB analyses that stack DM with impact parameter to\nforeground galaxies, quantifying the size of the contaminating \"two-halo\" term\nfrom correlated systems and the number of FRBs for a high significance\ndetection. Publicly available Python modules implement our CGMBrush algorithm.\n", "  We constrain extensions to the $\\Lambda$CDM model using measurements from the\nDark Energy Survey's first three years of observations and external data. The\nDES data are the two-point correlation functions of weak gravitational lensing,\ngalaxy clustering, and their cross-correlation. We use simulated data and blind\nanalyses of real data to validate the robustness of our results. In many cases,\nconstraining power is limited by the absence of nonlinear predictions that are\nreliable at our required precision. The models are: dark energy with a\ntime-dependent equation of state, non-zero spatial curvature, sterile\nneutrinos, modifications of gravitational physics, and a binned $\\sigma_8(z)$\nmodel which serves as a probe of structure growth. For the time-varying dark\nenergy equation of state evaluated at the pivot redshift we find $(w_{\\rm p},\nw_a)= (-0.99^{+0.28}_{-0.17},-0.9\\pm 1.2)$ at 68% confidence with $z_{\\rm\np}=0.24$ from the DES measurements alone, and $(w_{\\rm p}, w_a)=\n(-1.03^{+0.04}_{-0.03},-0.4^{+0.4}_{-0.3})$ with $z_{\\rm p}=0.21$ for the\ncombination of all data considered. Curvature constraints of\n$\\Omega_k=0.0009\\pm 0.0017$ and effective relativistic species $N_{\\rm\neff}=3.10^{+0.15}_{-0.16}$ are dominated by external data. For massive sterile\nneutrinos, we improve the upper bound on the mass $m_{\\rm eff}$ by a factor of\nthree compared to previous analyses, giving 95% limits of $(\\Delta N_{\\rm\neff},m_{\\rm eff})\\leq (0.28, 0.20\\, {\\rm eV})$. We also constrain changes to\nthe lensing and Poisson equations controlled by functions $\\Sigma(k,z) =\n\\Sigma_0 \\Omega_{\\Lambda}(z)/\\Omega_{\\Lambda,0}$ and $\\mu(k,z)=\\mu_0\n\\Omega_{\\Lambda}(z)/\\Omega_{\\Lambda,0}$ respectively to\n$\\Sigma_0=0.6^{+0.4}_{-0.5}$ from DES alone and $(\\Sigma_0,\\mu_0)=(0.04\\pm\n0.05,0.08^{+0.21}_{-0.19})$ for the combination of all data. Overall, we find\nno significant evidence for physics beyond $\\Lambda$CDM.\n", "  We present an emulator that accurately predicts the power spectrum of\ngalaxies in redshift space as a function of cosmological parameters. Our\nemulator is based on a 2nd-order Lagrangian bias expansion that is displaced to\nEulerian space using cosmological $N$-body simulations. Redshift space\ndistortions are then imprinted using the non-linear velocity field of simulated\nparticles and haloes. We build the emulator using a forward neural network\ntrained with the simulations of the BACCO project, which covers an\n8-dimensional parameter space including massive neutrinos and dynamical dark\nenergy. We show that our emulator provides unbiased cosmological constraints\nfrom the monopole, quadrupole, and hexadecapole of a mock galaxy catalogue that\nmimics the BOSS-CMASS sample down to nonlinear scales\n($k\\sim0.6$[$h/$Mpc]$^{3}$). This work opens up the possibility of robustly\nextracting cosmological information from small scales using observations of the\nlarge-scale structure of the Universe.\n", "  The Universe is neither homogeneous nor isotropic, but it is close enough\nthat we can reasonably approximate it as such on suitably large scales. The\ninflationary-$\\Lambda$-Cold Dark Matter ($\\Lambda$CDM) concordance cosmology\nbuilds on these assumptions to describe the origin and evolution of\nfluctuations. With standard assumptions about stress-energy sources, this\nsystem is specified by just seven phenomenological parameters, whose precise\nrelations to underlying fundamental theories are complicated and may depend on\ndetails of those fields. Nevertheless, it is common practice to set the\nparameter that characterizes the spatial curvature, $\\Omega_K$, exactly to\nzero. This parameter-fixed $\\Lambda$CDM is awarded distinguished status as\nseparate model, \"flat $\\Lambda$CDM.'' Ipso facto this places the onus on\nproponents of \"curved $\\Lambda$CDM'' to present sufficient evidence that\n$\\Omega_K\\neq0$, and is needed as a parameter. While certain inflationary model\nLagrangians, with certain values of their parameters, and certain initial\nconditions, will lead to a present-day universe well-described as containing\nzero curvature, this does not justify distinguishing that subset of\nLagrangians, parameters and initial conditions into a separate model. Absent\nany theoretical arguments, we cannot use observations that suggest small\n$\\Omega_K$ to enforce $\\Omega_K=0$. Our track record in picking inflationary\nmodels and their parameters a priori makes such a choice dubious, and concerns\nabout tensions in cosmological parameters and large-angle\ncosmic-microwave-background anomalies strengthens arguments against this\nchoice. We argue that $\\Omega_K$ must not be set to zero, and that $\\Lambda$CDM\nremains a phenomenological model with at least 7 parameters.\n", "  We present a forecast study on the cross-correlation between cosmic shear\ntomography from the Chinese Survey Space Telescope (CSST) and CMB lensing from\nAli CMB Polarization Telescope (AliCPT-1) in Tibet. The correlated galaxy and\nCMB lensing signals were generated from Gaussian realizations based on inputted\nauto- and cross-spectra. To account for the error budget, we considered the CMB\nlensing reconstruction noise based on the AliCPT-1 lensing reconstruction\npipeline; shape noise of the galaxy lensing measurement; CSST photo-$z$ error;\nphoto-$z$ bias; intrinsic alignment effect, and multiplicative bias. The\nAliCPT-1 CMB lensing mock data were generated according to two experimental\nstages, namely the ``4 modules*yr'' and ``48 modules*yr'' cases. We estimate\nthe cross-spectra in 4 tomographic bins according to the CSST photo-$z$\ndistribution in the range of $z\\in[0,4)$. After reconstructing the\npseudo-cross-spectra from the realizations, we calculate the signal-to-noise\nratio (SNR). By combining the 4 photo-$z$ bins, the total cross-correlation\nSNR$\\approx15$ (AliCPT-1 ``4 modules*yr'') and SNR$\\approx22$ (AliCPT-1 ``48\nmodules*yr''). Finally, we study the cosmological application of this\ncross-correlation signal. Excluding intrinsic alignment (IA) in the template\nfitting would lead to roughly a $0.6\\sigma$ increment in $\\sigma_8$ due to the\nnegative IA contribution to the galaxy lensing data. For AliCPT-1 first and\nsecond stages, the cross-correlation of CSST cosmic shear with CMB lensing\ngives errors on the clustering amplitude $\\sigma_{\\sigma_8}=^{+0.043}_{-0.038}$\nor $\\sigma_{S_8}=\\pm 0.031$ and $\\sigma_{\\sigma_8}=^{+0.030}_{-0.027}$ or\n$\\sigma_{S_8}=\\pm 0.018$, respectively.\n", "  It has been recently shown that the astrophysics of reionization can be\nextracted from the Ly$\\alpha$ forest power spectrum by marginalizing the memory\nof reionization over cosmological information. This impact of cosmic\nreionization on the Ly$\\alpha$ forest power spectrum can survive cosmological\ntime scales because cosmic reionization, which is inhomogeneous, and subsequent\nshocks from denser regions can heat the gas in low-density regions to $\\sim\n3\\times10^4$ K and compress it to mean-density. Current approach of\nmarginalization over the memory of reionization, however, is not only\nmodel-dependent, based on the assumption of a specific reionization model, but\nalso computationally expensive. Here we propose a simple analytical template\nfor the impact of cosmic reionization, thereby treating it as a broadband\nsystematic to be marginalized over for Bayesian inference of cosmological\ninformation from the Ly$\\alpha$ forest in a model-independent manner. This\ntemplate performs remarkably well with an error of $\\leq 6 \\%$ at large scales\n$k \\approx 0.19$ Mpc$^{-1}$ where the effect of the memory of reionization is\nimportant, and reproduces the broadband effect of the memory of reionization in\nthe Ly$\\alpha$ forest correlation function, as well as the expected bias of\ncosmological parameters due to this systematic. The template can successfully\nrecover the morphology of forecast errors in cosmological parameter space as\nexpected when assuming a specific reionization model for marginalization\npurposes, with a slight overestimation of tens of per cent for the forecast\nerrors on the cosmological parameters. We further propose a similar template\nfor this systematic on the Ly$\\alpha$ forest 1D power spectrum.\n", "  Detecting the 21-cm hyperfine transition from neutral hydrogen in the\nintergalactic medium is our best probe for understanding the astrophysical\nprocesses driving the Epoch of Reionisation (EoR). The primary means for a\ndetection of this 21-cm signal is through a statistical measurement of the\nspatial fluctuations using the 21-cm power spectrum (PS). However, the 21-cm\nsignal is non-Gaussian meaning the PS, which only measures the Gaussian\nfluctuations, is sub-optimal for characterising all of the available\ninformation. The upcoming Square Kilometre Array (SKA) will perform a deep,\n1000 hr observation over 100 deg$.^{2}$ specifically designed to recover direct\nimages of the 21-cm signal. In this work, we use the Wavelet Scattering\nTransform (WST) to extract the non-Gaussian information directly from these\ntwo-dimensional images of the 21-cm signal. The key advantage of the WST is its\nstability with respect to statistical noise for measuring non-Gaussian\ninformation, unlike the bispectrum whose statistical noise diverges. We\nintroduce a novel method to isolate this non-Gaussian information from mock\n21-cm images and demonstrate its detection at 150 (177)~MHz ($z\\sim8.5$ and\n$\\sim7$) for a fiducial model with signal-to-noise of $\\sim$5~(8) assuming\nperfect foreground removal and $\\sim2$~(3) assuming foreground wedge avoidance.\n", "  The CRESST experiment observes an unexplained excess of events at low\nenergies. In the current CRESST-III data-taking campaign we are operating\ndetector modules with different designs to narrow down the possible\nexplanations. In this work, we show first observations of the ongoing\nmeasurement, focusing on the comparison of time, energy and temperature\ndependence of the excess in several detectors. These exclude dark matter,\nradioactive backgrounds and intrinsic sources related to the crystal bulk as a\nmajor contribution.\n", "  We present a new strong lensing (SL) model of the Hubble Frontier Fields\ngalaxy cluster Abell 2744, at z=0.3072, by exploiting archival Hubble Space\nTelescope (HST) multi-band imaging and Multi Unit Spectroscopic Explorer (MUSE)\nfollow-up spectroscopy. The lens model considers 90 spectroscopically confirmed\nmultiple images (from 30 background sources), which represents the largest\nsecure sample for this cluster field prior to the recently acquired James Webb\nSpace Telescope observations. The inclusion of the sub-structures within\nseveral extended sources as model constraints allows us to accurately\ncharacterize the inner total mass distribution of the cluster and the position\nof the cluster critical lines. We include the lensing contribution of 225\ncluster members, 202 of which are spectroscopically confirmed. We also measure\nthe internal velocity dispersion of 85 cluster galaxies to independently\nestimate the role of the subhalo mass component in the lens model. We\ninvestigate the effect of the cluster environment on the total mass\nreconstruction of the cluster core with two different mass parameterizations.\nWe consider the mass contribution from three external clumps, either based on\nprevious weak-lensing studies, or extended HST imaging of luminous members\naround the cluster core. In the latter case, the observed positions of the\nmultiple images are better reproduced, with a remarkable accuracy of 0.37\", a\nfactor of $\\sim2$ smaller than previous lens models. We develop and make\npublicly available a Strong Lensing Online Tool (SLOT) to exploit the\npredictive power and the full statistical information of this and future\nmodels, through a simple graphical interface. We plan to apply our\nhigh-precision SL model to the first analysis of the GLASS-JWST-ERS program,\nspecifically to measure the intrinsic physical properties of high-$z$ galaxies\nfrom robust magnification maps.\n", "  Modeling of strongly gravitationally lensed galaxies is often required in\norder to use them as astrophysical or cosmological probes. With current and\nupcoming wide-field imaging surveys, the number of detected lenses is\nincreasing significantly such that automated and fast modeling procedures for\nground-based data are urgently needed. This is especially pertinent to\nshort-lived lensed transients in order to plan follow-up observations.\nTherefore, we present in a companion paper (submitted) a neural network\npredicting the parameter values with corresponding uncertainties of a Singular\nIsothermal Ellipsoid (SIE) mass profile with external shear. In this work, we\npresent a newly-developed pipeline glee_auto.py to model consistently any\ngalaxy-scale lensing system. In contrast to previous automated modeling\npipelines that require high-resolution images, glee_auto.py is optimized for\nground-based images such as those from the Hyper-Suprime-Cam (HSC) or the\nupcoming Rubin Observatory Legacy Survey of Space and Time. We further present\nglee_tools.py, a flexible automation code for individual modeling that has no\ndirect decisions and assumptions implemented. Both pipelines, in addition to\nour modeling network, minimize the user input time drastically and thus are\nimportant for future modeling efforts. We apply the network to 31 real\ngalaxy-scale lenses of HSC and compare the results to the traditional models.\nIn the direct comparison, we find a very good match for the Einstein radius\nespecially for systems with $\\theta_E \\gtrsim 2$\". The lens mass center and\nellipticity show reasonable agreement. The main discrepancies are on the\nexternal shear as expected from our tests on mock systems. In general, our\nstudy demonstrates that neural networks are a viable and ultra fast approach\nfor measuring the lens-galaxy masses from ground-based data in the upcoming era\nwith $\\sim10^5$ lenses expected.\n", "  Headline constraints on cosmological parameters from current weak lensing\nsurveys are derived from two-point statistics that are known to be\nstatistically sub-optimal, even in the case of Gaussian fields. We study the\nperformance of a new fast implementation of the Quadratic Maximum Likelihood\n(QML) estimator, optimal for Gaussian fields, to test the performance of\nPseudo-Cl estimators for upcoming weak lensing surveys and quantify the gain\nfrom a more optimal method. Through the use of realistic survey geometries,\nnoise levels, and power spectra, we find that there is a decrease in the errors\nin the statistics of the recovered E-mode spectra to the level of ~20% when\nusing the optimal QML estimator over the Pseudo-Cl estimator on the largest\nangular scales, while we find significant decreases in the errors associated\nwith the B-modes for the QML estimator. This raises the prospects of being able\nto constrain new physics through the enhanced sensitivity of B-modes for\nforthcoming surveys that our implementation of the QML estimator provides. We\ntest the QML method with a new implementation that uses conjugate-gradient and\nfinite-differences differentiation methods resulting in the most efficient\nimplementation of the full-sky QML estimator yet, allowing us to process maps\nat resolutions that are prohibitively expensive using existing codes. In\naddition, we investigate the effects of apodisation, B-mode purification, and\nthe use of non-Gaussian maps on the statistical properties of the estimators.\nOur QML implementation is publicly available and can be accessed from GitHub.\n", "  We present the strong lensing analysis of two galaxy clusters: MACS\nJ0242.5-2132 (MACS J0242, $z=0.313$) and MACS J0949.8+1708 (MACS J0949,\n$z=0.383$). Their total matter distributions are constrained thanks to the\npowerful combination of observations with the Hubble Space Telescope and the\nMUSE instrument. Using these observations, we precisely measure the redshift of\nsix multiple image systems in MACS J0242, and two in MACS J0949. We also\ninclude four multiple image systems in the latter cluster identified in HST\nimaging without MUSE redshift measurements. For each cluster, our best-fit mass\nmodel consists of a single cluster-scale halo, and 57 (170) galaxy-scale halos\nfor MACS J0242 (MACS J0949). Multiple images positions are predicted with a\n$rms$ 0.39 arcsec and 0.15 arcsec for MACS J0242 and MACS J0949 models\nrespectively. From these mass models, we derive aperture masses of $M(R<$200\nkpc$) = 1.67_{-0.05}^{+0.03}\\times 10^{14} M_{\\odot}$, and $M(R<$200 kpc$) =\n2.00_{-0.20}^{+0.05}\\times 10^{14} M_{\\odot}$. Combining our analysis with\nX-ray observations from the XMM-Newton Observatory, we show that MACS J0242\nappears to be a relatively relaxed cluster, while conversely, MACS J0949 shows\na relaxing post-merger state. At 200 kpc, X-ray observations suggest the hot\ngas fraction to be respectively $f_g = 0.115^{+0.003}_{-0.004}$ and\n$0.053^{+0.007}_{-0.006}$ for MACS J0242 and MACS J0949. MACS J0242 being\nrelaxed, its density profile is very well fitted by a NFW distribution, in\nagreement with X-ray observations. Finally, the strong lensing analysis of MACS\nJ0949 suggests a flat dark matter density distribution in the core, between 10\nand 100 kpc. This appears consistent with X-ray observations.\n", "  We present for the first time a suite of cosmological simulations for a\nparticular class of interacting Dark Energy cosmologies characterised by a\nbackground expansion history constrained to be indistinguishable from $\\Lambda\n$CDM. Such Constrained Interacting Dark Energy scenario -- or CIDER -- has been\nrecently proposed by Barros et al. 2019 and has the appealing feature of\nsuppressing structure formation at late times, thereby possibly alleviating the\npersisting $\\sigma _{8}$ tension while leaving background observables\nunaffected. A crucial step to assess the viability of such scenarios is then\nrepresented by quantifying their impact on structure formation at non-linear\nscales, which is what we start investigating with the simulations discussed in\nthe present work. We show that -- for reasonable parameter choices -- the\nreconstructed scalar potential is close to an exponential for most of the\nmatter dominated epoch, and that the nonlinear evolution of structures in these\nmodels imprints specific footprints on matter and halo statistics that may\nallow to break degeneracies with standard cosmological parameters.\n", "  Supersonic relative motion between baryons and dark matter due to the\ndecoupling of baryons from the primordial plasma after recombination affects\nthe growth of the first small-scale structures. Large box sizes (greater than a\nfew hundred Mpc) are required to sample the full range of scales pertinent to\nthe relative velocity, while the effect of the relative velocity is strongest\non small scales (less than a few hundred kpc). This separation of scales\nnaturally lends itself to the use of `zoom' simulations, and here we present\nour methodology to self-consistently incorporate the relative velocity in zoom\nsimulations, including its cumulative effect from recombination through to the\nstart time of the simulation. We apply our methodology to a large-scale\ncosmological zoom simulation, finding that the inclusion of relative velocities\nsuppresses the halo baryon fraction by $46$--$23$ per cent between $z=13.6$ and\n$11.2$, in qualitative agreement with previous works. In addition, we find that\nincluding the relative velocity delays the formation of star particles by $\\sim\n20 {~\\rm Myr}$ Myr on average (of the order of the lifetime of a $\\sim 9~{\\rm\nM}_\\odot$ Population III star) and suppresses the final stellar mass by as much\nas $79$ per cent at $z=11.2$.\n", "  Dark matter haloes have long been recognized as one of the fundamental\nbuilding blocks of large scale structure formation models. Despite their\nimportance -- or perhaps because of it! -- halo definitions continue to evolve\ntowards more physically motivated criteria. Here, we propose a new definition\nthat is physically motivated, and effectively unique and parameter-free: ''A\ndark matter halo is comprised of the collection of particles orbiting in their\nown self-generated potential.'' This definition is enabled by the fact that,\neven with as few as $\\approx 300$ particles per halo, nearly every particle in\nthe vicinity of a halo can be uniquely classified as either orbiting or\ninfalling based on its dynamical history. For brevity, we refer to haloes\nselected in this way as physical haloes. We demonstrate that: 1) the mass\nfunction of physical haloes is Press-Schechter, provided the critical threshold\nfor collapse is allowed to vary slowly with peak height; and 2) the\npeak-background split prediction of the clustering amplitude of physical halos\nis statistically consistent with the simulation data, with an accuracy no worse\nthan $\\approx 5\\%$.\n", "  We infer the mean optical depth of a sample of optically-selected galaxy\nclusters from the Dark Energy Survey (DES) via the pairwise kinematic\nSunyaev-Zel'dovich (kSZ) effect. The pairwise kSZ signal between pairs of\nclusters drawn from the DES Year-3 cluster catalog is detected at $4.1 \\sigma$\nin cosmic microwave background (CMB) temperature maps from two years of\nobservations with the SPT-3G camera on the South Pole Telescope. After cuts,\nthere are 24,580 clusters in the $\\sim 1,400$ deg$^2$ of the southern sky\nobserved by both experiments. We infer the mean optical depth of the cluster\nsample with two techniques. The optical depth inferred from the pairwise kSZ\nsignal is $\\bar{\\tau}_e = (2.97 \\pm 0.73) \\times 10^{-3}$, while that inferred\nfrom the thermal SZ signal is $\\bar{\\tau}_e = (2.51 \\pm 0.55^{\\text{stat}} \\pm\n0.15^{\\rm syst}) \\times 10^{-3}$. The two measures agree at $0.6 \\sigma$. We\nperform a suite of systematic checks to test the robustness of the analysis.\n", "  We develop a machine learning algorithm to infer the 3D cumulative radial\nprofiles of total and gas mass in galaxy clusters from thermal\nSunyaev-Zel'dovich effect maps. We generate around 73,000 mock images along\nvarious lines of sight using 2,522 simulated clusters from the\n\\thethreehundred{} project at redshift $z< 0.12$ and train a model that\ncombines an autoencoder and a random forest. Without making any prior\nassumptions about the hydrostatic equilibrium of the clusters, the model is\ncapable of reconstructing the total mass profile as well as the gas mass\nprofile, which is responsible for the SZ effect. We show that the recovered\nprofiles are unbiased with a scatter of about $10\\%$, slightly increasing\ntowards the core and the outskirts of the cluster. We selected clusters in the\nmass range of $10^{13.5} \\leq M_{200} /(\\hMsun) \\leq 10^{15.5}$, spanning\ndifferent dynamical states, from relaxed to disturbed halos. We verify that\nboth the accuracy and precision of this method show a slight dependence on the\ndynamical state, but not on the cluster mass. To further verify the consistency\nof our model, we fit the inferred total mass profiles with an NFW model and\ncontrast the concentration values with those of the true profiles. We note that\nthe inferred profiles are unbiased for higher concentration values, reproducing\na trustworthy mass-concentration relation. The comparison with a widely used\nmass estimation technique, such as hydrostatic equilibrium, demonstrates that\nour method recovers the total mass that is not biased by non-thermal motions of\nthe gas.\n", "  Galaxy power spectrum and bispectrum signals are distorted by peculiar\nvelocities and other relativistic effects arising from a perturbed spacetime\nbackground. In addition, study of correlation functions of tracers in Fourier\nspace is often done in the plane-parallel approximation under which it is\nassumed that line-of-sight (LOS) vectors are parallel. In this work we show\nthat a simple perturbative procedure can be employed for a fast evaluation of\nbeyond plane-parallel (wide-angle) corrections to the power spectrum and\nbispectrum. We also show that evolution of linear matter density fluctuations\nin a relativistic context can be found from a simple method. For the power\nspectrum at linear level, we compare leading order wide-angle contributions to\nmultipoles of the galaxy power spectrum with those from non-integrated and\nintegrated relativistic corrections and estimate their possible contamination\non local fNL measurements to be of order a few. We also compute wide-angle\ncorrections in the presence of nonlinear terms at one-loop order. For the\nbispectrum, we show that wide-angle effects alone, even with fully symmetric\nchoices of LOS, give rise to imaginary, odd-parity multipoles of the galaxy\nbispectrum (dipole, octupole, etc.) which are in many cases larger than\npreviously known ones of relativistic origin. We calculate these contributions\nand provide an estimator for measuring the leading order bispectrum dipole from\ndata, using a symmetric LOS definition. Finally, we calculate the leading order\ncorrections to multipoles of real plane-parallel bispectrum multipoles and\nestimate the apparent local fNL induced to be of order unity.\n", "  We use an analytical forward model based on perturbation theory to predict\nthe neutral hydrogen (HI) overdensity maps at low redshifts. We investigate its\nperformance by comparing it directly at the field level to the simulated HI\nfrom the IllustrisTNG simulation TNG300-1 ($L=205\\ h^{-1}$ Mpc), in both real\nand redshift space. We demonstrate that HI is a biased tracer of the underlying\nmatter field and find that the cubic bias model describes the simulated HI\npower spectrum to within 1% up to $k=0.4 \\;(0.3) \\,h\\,{\\rm Mpc}^{-1}$ in real\n(redshift) space at redshifts $z=0,1$. Looking at counts in cells, we find an\nexcellent agreement between the theory and simulations for cells as small as 5\n$h^{-1}$ Mpc. These results are in line with expectations from perturbation\ntheory and they imply that a perturbative description of the HI field is\nsufficiently accurate given the characteristics of upcoming 21cm intensity\nmapping surveys. Additionally, we study the statistical properties of the model\nerror - the difference between the truth and the model. We show that on large\nscales this error is nearly Gaussian and that it has a flat power spectrum,\nwith amplitude significantly lower than the standard noise inferred from the HI\npower spectrum. We explain the origin of this discrepancy, discuss its\nimplications for the HI power spectrum Fisher matrix forecasts and argue that\nit motivates the HI field-level cosmological inference. On small scales in\nredshift space we use the difference between the model and the truth as a proxy\nfor the Fingers-of-God effect. This allows us to estimate the nonlinear\nvelocity dispersion of HI and show that it is smaller than for the typical\nspectroscopic galaxy samples at the same redshift. Finally, we provide a simple\nprescription based on the perturbative forward model which can be used to\nefficiently generate accurate HI mock data, in real and redshift space.\n", "  We present the first cosmological study of a sample of $eROSITA$ clusters,\nwhich were identified in the $eROSITA$ Final Equatorial Depth Survey (eFEDS).\nIn a joint selection on X-ray and optical observables, the sample contains\n$455$ clusters within a redshift range of $0.1<z<1.2$, of which $177$ systems\nare covered by the public data from the Hyper Suprime-Cam (HSC) survey that\nenables uniform weak-lensing cluster mass constraints. With minimal\nassumptions, at each cluster redshift $z$ we empirically model (1) the scaling\nrelations between the cluster halo mass and the observables, which include the\nX-ray count rate, the optical richness, and the weak-lensing mass, and (2) the\nX-ray selection in terms of the completeness function $\\mathtt{C}$. Using the\nrichness distribution of the clusters, we directly measure the X-ray\ncompleteness and adopt those measurements as informative priors for the\nparameters of $\\mathtt{C}$. In a blinded analysis, we obtain the cosmological\nconstraints $\\Omega_{\\mathrm{m}} = 0.245^{+0.048}_{-0.058}$, $\\sigma_{8} =\n0.833^{+0.075}_{-0.063}$ and $S_{8} \\equiv\n\\sigma_{8}\\left(\\Omega_{\\mathrm{m}}/0.3\\right)^{0.3}= 0.791^{+0.028}_{-0.031}$\nin a flat $\\Lambda$CDM cosmology. Extending to a flat $w$CDM cosmology leads to\nthe constraint on the equation of state parameter of the dark energy of $w =\n-1.25\\pm 0.47$. The eFEDS constraints are in good agreement with the results\nfrom the $Planck$ mission, the galaxy-galaxy lensing and clustering analysis of\nthe Dark Energy Survey, and the cluster abundance analysis of the SPT-SZ survey\nat a level of $\\lesssim1\\sigma$. With the empirical modelling, this work\npresents the first fully self-consistent cosmological constraints based on a\nsynergy between wide-field X-ray and weak lensing surveys.\n", "  Interacting dark energy models have been suggested as alternatives to the\nstandard cosmological model, $\\Lambda$CDM. We focus on a phenomenologically\ninteresting class of dark scattering models that is characterised by pure\nmomentum exchange between dark energy and dark matter. This model extends the\nparameter space with respect to $\\Lambda$CDM by two parameters, $w$ and $A$,\nwhich define the dark energy equation of state and the strength of the coupling\nbetween dark energy and dark matter, respectively. In order to test\nnon-standard cosmologies with Stage-IV galaxy clustering surveys, it is crucial\nto model mildly nonlinear scales and perform precision vs accuracy tests. We\nuse the Effective Field Theory of Large-Scale Structure, and we perform\nvalidation tests by means of an MCMC analysis using a large set of N-body\nsimulations. We find that adding the bispectrum monopole to the power spectrum\nmultipoles improves the constraints on the dark energy parameters by $\\sim 30\n\\%$ for $k_{\\mathrm{max}, B}^{l=0} = 0.11$ $h$ Mpc$^{-1}$ without introducing\nbiases in the parameter estimation. We also find that the same improvement can\nbe achieved with more moderate scale cuts and the use of bias relations, or\nwith the addition of the bispectrum quadrupole. Finally, we study degeneracies\nbetween the dark energy parameters and the scalar amplitude $A_\\mathrm{s}$ and\ndiscuss the corresponding projection effects, as well as degeneracies with\nother cosmological parameters.\n", "  We present the Sherwood-Relics simulations, a new suite of large cosmological\nhydrodynamical simulations aimed at modelling the intergalactic medium (IGM)\nduring and after the cosmic reionization of hydrogen. The suite consists of\nover 200 simulations that cover a wide range of astrophysical and cosmological\nparameters. It also includes simulations that use a new lightweight hybrid\nscheme for treating radiative transfer effects. This scheme follows the spatial\nvariations in the ionizing radiation field, as well as the associated\nfluctuations in IGM temperature and pressure smoothing. It is computationally\nmuch cheaper than full radiation hydrodynamics simulations and circumvents the\ndifficult task of calibrating a galaxy formation model to observational\nconstraints on cosmic reionization. Using this hybrid technique, we study the\nspatial fluctuations in IGM properties that are seeded by patchy cosmic\nreionization. We investigate the relevant physical processes and assess their\nimpact on the z > 4 Lyman-alpha forest. Our main findings are: (i) Consistent\nwith previous studies patchy reionization causes large scale temperature\nfluctuations that persist well after the end of reionization, (ii) these\nincrease the Lyman-alpha forest flux power spectrum on large scales, and (iii)\nresult in a spatially varying pressure smoothing that correlates well with the\nlocal reionization redshift. (iv) Structures evaporated or puffed up by\nphotoheating cause notable features in the Lyman-alpha forest, such as\nflat-bottom or double-dip absorption profiles.\n", "  We analyze the cooling and feedback properties of 48 galaxy clusters at\nredshifts $0.4 < z < 1.3$ selected from the South Pole Telescope (SPT) catalogs\nto evolve like the progenitors of massive and well-studied systems at\n$z{\\sim}0$. We estimate the radio power at the brightest cluster galaxy (BCG)\nlocation of each cluster from an analysis of Australia Telescope Compact Array\n(ATCA) data. Assuming that the scaling relation between radio power and active\ngalactic nucleus (AGN) cavity power $P_{\\mathrm{cav}}$ observed at low redshift\ndoes not evolve with redshift, we use these measurements in order to estimate\nthe expected AGN cavity power in the core of each system. We estimate the X-ray\nluminosity within the cooling radius $L_{\\mathrm{cool}}$ of each cluster from a\njoint analysis of the available $Chandra$ X-ray and SPT Sunyaev-Zel'dovich (SZ)\ndata. This allows us to characterize the redshift evolution of the\n$P_{\\mathrm{cav}} / L_{\\mathrm{cool}}$ ratio. When combined with low-redshift\nresults, these constraints enable investigations of the properties of the\nfeedback/cooling cycle across 9~Gyr of cluster growth. We model the redshift\nevolution of this ratio measured for cool core clusters by a log-normal\ndistribution $\\mathrm{Log}$-$\\mathcal{N}(\\alpha + \\beta z, \\sigma^2)$ and\nconstrain the slope of the mean evolution $\\beta = -0.05\\pm 0.47$. This\nanalysis improves the constraints on the slope of this relation by a factor of\ntwo. We find no evidence of redshift evolution of the feedback/cooling\nequilibrium in these clusters which suggests that the onset of radio-mode\nfeedback took place at an early stage of cluster formation. High values of\n$P_{\\mathrm{cav}} / L_{\\mathrm{cool}}$ are found at the BCG location of\nnon-cool core clusters which might suggest that the timescales of the AGN\nfeedback cycle and the cool core / non-cool core transition are different.\n", "  We investigate the dynamical friction (DF) acting on circularly-moving\nperturbers in fuzzy dark matter (FDM) backgrounds. After condensation, FDM is\ndescribed by a single wave function satisfying a Schr\\\"odinger-Poisson\nequation. An equivalent, hydrodynamic formulation can be obtained through the\nMadelung transform. Here, we consider both descriptions and restrict our\nanalysis to linear response theory. We take advantage of the hydrodynamic\nformulation to derive a fully analytic solution to the DF in steady-state and\nfor a finite time perturbation. We compare our prediction to a numerical\nimplementation of the wave approach that includes a non-vanishing FDM velocity\ndispersion $\\sigma$. Our solution is valid for both a single and a binary\nperturber in circular motion as long as $\\sigma$ does not significantly exceed\nthe orbital speed $v_\\text{circ}$. While the short-distance Coulomb divergence\nof the (supersonic) gaseous DF is no longer present, DF in the FDM case\nexhibits an infrared divergence which stems from the (also) diffusive nature of\nthe Schr\\\"odinger equation. Our analysis of the finite time perturbation case\nreveals that the density wake diffuses through the FDM medium until it reaches\nits outer boundary. Once this transient regime is over, both the radial and\ntangential DF oscillate about the steady-state solution with an exponentially\ndecaying envelope. Steady-state is thus never achieved. We use our results to\nrevisit the DF decay timescales of the 5 Fornax globular clusters. We also\npoint out that the inspiral of compact binary may stall because the DF torque\nabout the binary center-of-mass sometimes flips sign to become a thrust rather\nthan a drag (abridged).\n", "  Galactic dust emission is often accounted for in cosmic microwave background\n(CMB) analyses by fitting a simple two-parameter modified blackbody (MBB) model\nin each pixel, which nominally accounts for the temperature and opacity of the\ndust. While this may be a good approximation for individual dust clouds,\ntypically a number of such clouds are found along each line of sight and within\neach angular pixel, resulting in a superposition of their spectra. In this\npaper, we study the effects of this superposition on pixel-based foreground\nfitting strategies by modelling the spectral energy distribution (SED) in each\npixel as the integral of individual MBB spectra over various\nphysically-motivated statistical distributions of dust cloud properties. We\nshow that fitting these SEDs with the simple two-parameter MBB model generally\nresults in unbiased estimates of the CMB Stokes Q and U amplitudes in each\npixel, unless there are significant changes in both the dust SED and\npolarization angle along the line of sight, in which case significant ($ >\n10\\sigma$) biases are observed in an illustrative model. We also find that the\nbest-fit values of the dust temperature, $T_d$, and spectral index, $\\beta_d$,\nare significantly biased away from the mean/median of the corresponding\nstatistical distributions when the distributions are broad, suggesting that MBB\nmodel fits can give an unrepresentative picture of the physical properties of\nthe dust at microwave wavelengths if not interpreted carefully. Using a Fisher\nmatrix analysis, we also determine the experimental sensitivity required to\nrecover the parameters of the $T_d$ and $\\beta_d$ distributions themselves by\nfitting a probabilistic MBB model, finding that only the parameters of broad\ndistributions can be measured by SED fitting on a single line of sight.\n", "  We test the assumption of entropy conservation between Big Bang\nnucleosynthesis and recombination by considering a massive particle that decays\ninto a mixture of photons and other relativistic species. We employ Planck\ntemperature and polarization anisotropies, COBE/FIRAS spectral distortion\nbounds, and the observed primordial deuterium abundance to constrain these\ndecay scenarios. If between $56\\%$ and $71\\%$ of the decaying particle's energy\nis transferred to photons, then $N_{\\mathrm{eff}}$ at recombination is\nminimally altered, and Planck data alone allows for significant entropy\ninjection. If photons are injected by the decay, the addition of spectral\ndistortion bounds restricts the decay rate of the particle to be $\\Gamma_Y >\n1.91\\times10^{-6} \\text{s}^{-1}$ at $95\\%$ confidence level (C.L.). We find\nthat constraints on the energy density of the decaying particle are\nsignificantly enhanced by the inclusion of bounds on the primordial deuterium\nabundance, allowing the particle to contribute at most $2.35\\%$ ($95\\%$ C.L.)\nof the energy density of the universe before decaying.\n", "  The non-singular bouncing cosmology is an alternative paradigm to inflation,\nwherein the background energy density vanishes at the bounce point, in the\ncontext of Einstein gravity. Therefore, the non-linear effects in the evolution\nof density fluctuations ($\\delta \\rho$) may be strong in the bounce phase,\nwhich potentially provides a mechanism to enhance the abundance of primordial\nblack holes (PBHs). This article presents a comprehensive illustration for PBH\nenhancement due to the bounce phase. To calculate the non-linear evolution of\n$\\delta \\rho$, the Raychaudhuri equation is numerically solved here. Since the\nnon-linear processes may lead to a non-Gaussian probability distribution\nfunction for $\\delta \\rho$ after the bounce point, the PBH abundance is\ncalculated in a modified Press-Schechter formalism. In this case, the criterion\nof PBH formation is complicated, due to complicated non-linear evolutionary\nbehavior of $\\delta \\rho$ during the bounce phase. Our results indicate that\nthe bounce phase indeed has potential to enhance the PBH abundance\nsufficiently. Furthermore, the PBH abundance is applied to constrain the\nparameters of bounce phase, providing a complementary to the surveys of cosmic\nmicrowave background and large scale structure.\n", "  We analyse the BOSS DR12 galaxy power spectrum data jointly with BAO data for\nthree models of dark energy. We use recent measurements using a windowless\nestimator, and an independent and fast pipeline based on EFTofLSS implemented\nvia the FAST-PT algorithm to compute the redshift-space loop corrections. We\naccelerate our analysis by using the BACCO linear emulator instead of a\nBoltzmann solver. We perform two sets of analyses: one with $3\\sigma$ Planck\npriors on $A_s$ and $n_s$, and another that is CMB-free, without such priors.\nFirstly, we study $\\Lambda$CDM, reproducing previous results obtained with the\nsame estimator. We find a low value of $A_s$ in the CMB-free case, in agreement\nwith many previous full-shape analyses of the BOSS data. We then study $w$CDM,\nfinding a lower value of the amplitude in the CMB-free run, coupled with a\npreference for phantom dark energy with $w=-1.17^{+0.12}_{-0.11}$, again in\nbroad agreement with previous results. Finally, we investigate the dark\nscattering model, which we label $wA$CDM. In the CMB-free analysis, we find a\nlarge degeneracy between the interaction strength $A$ and the amplitude $A_s$,\nhampering measurements of those parameters. On the contrary, in our run with a\nCMB prior, we are able to constrain the dark energy parameters to be\n$w=-0.972^{+0.036}_{-0.029}$ and $A = 3.9^{+3.2}_{-3.7}$, which show a\n1$\\sigma$ hint of interacting dark energy. This is the first measurement of\nthis parameter and demonstrates the ability of this model to alleviate the\n$\\sigma_8$ tension. Our analysis can be used as a guide for any model with\nscale-independent growth. Finally, we study the dependence of the results on\nthe priors of the nuisance parameters and find these priors to be informative,\nwith their broadening creating shifts in the contours. We argue for an in depth\nstudy of this issue, which can affect current and forthcoming analyses of LSS\ndata.\n", "  We have taken a comprehensive approach to update the limits on the\ntensor-to-scalar ratio ($r$) and the tensor spectral index ($n_t$), using 10\ndatasets from the BICEP/Keck Array 2015 and 2018, Planck releases 3 and 4, and\nLIGO-Virgo-KAGRA Collaboration. By fitting the complete $\\Lambda$CDM+$r$+$n_t$\nmodel with two different approaches for the tensor sector, we have not only\nestablished which method is the most reliable, but have also achieved the\nstrongest constraint on the tensor-to-scalar ratio in current literature:\n$r<0.028$ and $-1.37 < n_t < 0.42$ at 95% confidence level. Furthermore, our\nexamination of the common signal detected by the NANOGrav Collaboration further\nconfirms that a simple power-law cannot reconcile the constraints from\ndifferent datasets if the NANOGrav detection is due to a primordial\ninflationary gravitational wave background, as previously shown in the\nliterature.\n", "  Combining different observational probes, such as galaxy clustering and weak\nlensing, is a promising technique for unveiling the physics of the Universe\nwith upcoming dark energy experiments. The galaxy redshift sample from the Dark\nEnergy Spectroscopic Instrument (DESI) will have a significant overlap with\nmajor ongoing imaging surveys specifically designed for weak lensing\nmeasurements: the Kilo-Degree Survey (KiDS), the Dark Energy Survey (DES) and\nthe Hyper Suprime-Cam (HSC) survey. In this work we analyse simulated redshift\nand lensing catalogues to establish a new strategy for combining high-quality\ncosmological imaging and spectroscopic data, in view of the first-year data\nassembly analysis of DESI. In a test case fitting for a reduced parameter set,\nwe employ an optimal data compression scheme able to identify those aspects of\nthe data that are most sensitive to the cosmological information, and amplify\nthem with respect to other aspects of the data. We find this optimal\ncompression approach is able to preserve all the information related to the\ngrowth of structure; we also extend this scheme to derive weights to be applied\nto individual galaxies, and show that these produce near-optimal results.\n", "  In this paper we present COMET, a Gaussian process emulator of the galaxy\npower spectrum multipoles in redshift-space. The model predictions are based on\none-loop perturbation theory and we consider two alternative descriptions of\nredshift-space distortions: one that performs a full expansion of the real- to\nredshift-space mapping, as in recent effective field theory models, and another\nthat preserves the non-perturbative impact of small-scale velocities by means\nof an effective damping function. The outputs of COMET can be obtained at\narbitrary redshifts (up to $z \\sim 3$), for arbitrary fiducial background\ncosmologies, and for a large parameter space that covers the shape parameters\n$\\omega_c$, $\\omega_b$, and $n_s$, as well as the evolution parameters $h$,\n$A_s$, $\\Omega_K$, $w_0$, and $w_a$. This flexibility does not impair COMET's\naccuracy, since we exploit an exact degeneracy between the evolution parameters\nthat allows us to train the emulator on a significantly reduced parameter\nspace. While the predictions are sped up by at least two orders of magnitude,\nvalidation tests reveal an accuracy of $0.1\\,\\%$ for the monopole and\nquadrupole ($0.3\\,\\%$ for the hexadecapole), or alternatively, better than\n$0.25\\,\\sigma$ for all three multipoles in comparison to statistical\nuncertainties expected for the Euclid survey with a tenfold increase in volume.\nWe show that these differences translate into shifts in mean posterior values\nthat are at most of the same size, meaning that COMET can be used with the same\nconfidence as the exact underlying models. COMET is a publicly available Python\npackage that also provides the tree-level bispectrum multipoles in\nredshift-space and Gaussian covariance matrices.\n", "  Context. Weak lensing and clustering statistics beyond two-point functions\ncan capture non-Gaussian information about the matter density field, thereby\nimproving the constraints on cosmological parameters relative to the mainstream\nmethods based on correlation functions and power spectra. Aims. This paper\npresents a cosmological analysis of the fourth data release of the Kilo Degree\nSurvey based on the density split statistics, which measures the mean shear\nprofiles around regions classified according to foreground densities. The\nlatter is constructed from a bright galaxy sample, which we further split into\nred and blue samples, allowing us to probe their respective connection to the\nunderlying dark matter density. Methods. We use the state-of-the-art model of\nthe density splitting statistics and validate its robustness against mock data\ninfused with known systematic effects such as intrinsic galaxy alignment and\nbaryonic feedback. Results. After marginalising over the photometric redshift\nuncertainty and the residual shear calibration bias, we measure for the full\nKiDS-bright sample a structure growth parameter of $S_8 = \\sigma_8\n\\sqrt{\\Omega_\\mathrm{m}/0.3} = 0.74^{+0.03}_{-0.02}$ that is competitive to and\nconsistent with two-point cosmic shear results, a matter density of\n$\\Omega_\\mathrm{m} = 0.28 \\pm 0.02$, and a constant galaxy bias of $b =\n1.32^{+0.12}_{-0.10}$.\n", "  Euclid's photometric galaxy cluster survey has the potential to be a very\ncompetitive cosmological probe. The main cosmological probe with observations\nof clusters is their number count, within which the halo mass function (HMF) is\na key theoretical quantity. We present a new calibration of the analytic HMF,\nat the level of accuracy and precision required for the uncertainty in this\nquantity to be subdominant with respect to other sources of uncertainty in\nrecovering cosmological parameters from Euclid cluster counts. Our model is\ncalibrated against a suite of N-body simulations using a Bayesian approach\ntaking into account systematic errors arising from numerical effects in the\nsimulation. First, we test the convergence of HMF predictions from different\nN-body codes, by using initial conditions generated with different orders of\nLagrangian Perturbation theory, and adopting different simulation box sizes and\nmass resolution. Then, we quantify the effect of using different halo-finder\nalgorithms, and how the resulting differences propagate to the cosmological\nconstraints. In order to trace the violation of universality in the HMF, we\nalso analyse simulations based on initial conditions characterised by\nscale-free power spectra with different spectral indexes, assuming both\nEinstein--de Sitter and standard $\\Lambda$CDM expansion histories. Based on\nthese results, we construct a fitting function for the HMF that we demonstrate\nto be sub-percent accurate in reproducing results from 9 different variants of\nthe $\\Lambda$CDM model including massive neutrinos cosmologies. The calibration\nsystematic uncertainty is largely sub-dominant with respect to the expected\nprecision of future mass-observation relations; with the only notable exception\nof the effect due to the halo finder, that could lead to biased cosmological\ninference.\n", "  Compensated isocurvature perturbations (CIPs) are relative density\nperturbations in which a baryon-density fluctuation is accompanied by a dark\nmatter density fluctuation such that the total-matter density is unperturbed.\nThese fluctuations can be produced primordially if multiple fields are present\nduring inflation, and therefore they can be used to differentiate between\ndifferent models for the early Universe. Kinetic Sunyaev-Zeldovich (kSZ)\ntomography allows for the reconstruction of the radial-velocity field of matter\nas a function of redshift. This technique can be used to reconstruct the\ntotal-matter-overdensity field, independent of the galaxy-density field\nobtained from large-scale galaxy surveys. We leverage the ability to measure\nthe galaxy- and matter-overdensity fields independently to construct a\nminimum-variance estimator for the primordial CIP amplitude, based on a\nmode-by-mode comparison of the two measurements. We forecast that a\nconfiguration corresponding to CMB-S4 and VRO will be able to detect (at\n$2\\sigma$) a CIP amplitude $A$ (for a scale-invariant power spectrum) as small\nas $A\\simeq 5\\times 10^{-9}$. Similarly, a configuration corresponding to SO\nand DESI will be sensitive to a CIP amplitude $A\\simeq 1\\times 10^{-7}$. These\nvalues are to be compared to current constraints $A \\leq {\\cal O}(0.01)$.\n", "  The fuzzy dark matter (FDM) scenario has received increased attention in\nrecent years due to the small-scale challenges of the vanilla Lambda cold dark\nmatter ($\\Lambda$CDM) cosmological model and the lack of any experimental\nevidence for any candidate particle. In this study, we use cosmological\n$N$-body simulations to investigate high-redshift dark matter halos and their\nresponsiveness to an FDM-like power spectrum cutoff on small scales in the\nprimordial density perturbations. We study halo density profiles, shapes and\nalignments in FDM-like cosmologies (the latter two for the first time) by\nproviding fits and quantifying departures from $\\Lambda$CDM as a function of\nthe particle mass $m$. Compared to $\\Lambda$CDM, the concentrations of FDM-like\nhalos are lower, peaking at an $m$-dependent halo mass and thus breaking the\napproximate universality of density profiles in $\\Lambda$CDM. The\nintermediate-to-major and minor-to-major shape parameter profiles are\nmonotonically increasing with ellipsoidal radius in $N$-body simulations of\n$\\Lambda$CDM. In FDM-like cosmologies, the monotonicity is broken, halos are\nmore elongated around the virial radius than their $\\Lambda$CDM counterparts\nand less elongated closer to the center. Finally, intrinsic alignment\ncorrelations, stemming from the deformation of initially spherically collapsing\nhalos in an ambient gravitational tidal field, become stronger with decreasing\n$m$. At $z\\sim 4$, we find a $6.4 \\sigma$-significance in the fractional\ndifferences between the isotropised linear alignment magnitudes\n$D_{\\text{iso}}$ in the $m=10^{-22}$ eV model and $\\Lambda$CDM. Such FDM-like\nimprints on the internal properties of virialised halos are expected to be\nstrikingly visible in the high-$z$ Universe.\n", "  CMB lensing maps probe the mass distribution in projection out to high\nredshifts, but significant sensitivity to low-redshift structure remains. In\nthis paper we discuss a method to remove the low-redshift contributions from\nCMB lensing mass maps by subtracting suitably scaled galaxy density maps,\nnulling the low redshift structure with a model-insensitive procedure that is\nsimilar to delensing. This results in a high-$z$-only mass map that can provide\na probe of structure growth at uniquely high redshifts: if systematics can be\ncontrolled, we forecast that CMB-S4 lensing combined with a Rubin-LSST-like\ngalaxy survey can probe the amplitude of structure at redshifts $z>3.75$\n($z>5$) to within $2.3\\%$ ($3.3\\%$). We then discuss other example applications\nof such high-$z$ CMB lensing maps. In standard analyses of CMB lensing,\nassuming the wrong dark energy model (or wrong model parametrization) can lead\nto biases in neutrino mass constraints. In contrast, we show with forecasts\nthat a high-$z$ mass map constructed from CMB-S4 lensing and LSST galaxies can\nprovide a nearly model-independent neutrino mass constraint, with only\nnegligible sensitivity to the presence of non-standard dark energy models,\nirrespective of their parametrization.\n", "  In this series of papers, we present a simulation-based model for the\nnon-linear clustering of galaxies based on separate modelling of clustering in\nreal space and velocity statistics. In the first paper, we present an emulator\nfor the real-space correlation function of galaxies, whereas the emulator of\nthe real-to-redshift space mapping based on velocity statistics is presented in\nthe second paper. Here, we show that a neural network emulator for real-space\ngalaxy clustering trained on data extracted from the Dark Quest suite of N-body\nsimulations achieves sub-per cent accuracies on scales $1 < r < 30 $ $h^{-1}\n\\,\\mathrm{Mpc}$, and better than $3\\%$ on scales $r < 1$ $h^{-1}\\mathrm{Mpc}$\nin predicting the clustering of dark-matter haloes with number density\n$10^{-3.5}$ $(h^{-1}\\mathrm{Mpc})^{-3}$, close to that of SDSS LOWZ-like\ngalaxies. The halo emulator can be combined with a galaxy-halo connection model\nto predict the galaxy correlation function through the halo model. We\ndemonstrate that we accurately recover the cosmological and galaxy-halo\nconnection parameters when galaxy clustering depends only on the mass of the\ngalaxies' host halos. Furthermore, the constraining power in $\\sigma_8$\nincreases by about a factor of $2$ when including scales smaller than $5$\n$h^{-1} \\,\\mathrm{Mpc}$. However, when mass is not the only property\nresponsible for galaxy clustering, as observed in hydrodynamical or\nsemi-analytic models of galaxy formation, our emulator gives biased constraints\non $\\sigma_8$. This bias disappears when small scales ($r < 10$\n$h^{-1}\\mathrm{Mpc}$) are excluded from the analysis. This shows that a vanilla\nhalo model could introduce biases into the analysis of future datasets.\n", "  Damped Lyman-$\\alpha$ Absorber (DLA), or HI 21cm Absorber (H21A), is an\nimportant probe to model-independently measure the acceleration of\nspectroscopic velocity ($v_\\mathrm{S}$) via the Sandage-Loeb (SL) effect.\nConfined by the shortage of DLAs and Background Radio Sources (BRSs) with\nadequate information, the detectable amount of DLAs is ambiguous in the bulk of\nprevious work. After differing the acceleration of scale factor ($\\ddot{a}$)\nfrom the first order time derivative of spectroscopic velocity\n($\\dot{v}_\\mathrm{S}$), we make a statistical investigation of the amount of\npotential DLAs in the most of this paper. Using Kernel Density Estimation (KDE)\nto depict general redshift distributions of BRSs, observed DLAs and a DLA\ndetection rate with different limitations (1.4GHz flux, HI column density and\nspin temperature), we provide fitted multi-Gaussian expressions of the three\ncomponents and their 1$\\sigma$ regions by bootstrap, with a proportional\nconstant of H21As in detected DLAs, leading to the measurable number\npredictions of H21As for FAST, ASKAP and SKA1-Mid in HI absorption blind\nsurvey. In our most optimistic condition ($F_\\mathrm{1.4GHz}$>10mJy,\n$N_\\mathrm{HI}>2\\times10^{20}\\mathrm{cm^{-2}}$ and $T_\\mathrm{S}$>500K), the\nFAST, AKSAP and SKA1-Mid would probe about 80, 500 and 600 H21As respectively.\n", "  Cosmological parameter constraints from recent galaxy imaging surveys are\nreaching $2-3\\%$-level accuracy. The upcoming Legacy Survey of Space and Time\n(LSST) of the Vera C. Rubin Observatory will produce sub-percent level\nmeasurements of cosmological parameters, providing a milestone test of the\n$\\Lambda$CDM model. To supply guidance to the upcoming LSST analysis, it is\nimportant to understand thoroughly the results from different recent galaxy\nimaging surveys and assess their consistencies. In this work we perform a\nunified catalog-level reanalysis of three cosmic shear datasets: the first year\ndata from the Dark Energy Survey (DES-Y1), the 1,000 deg$^{2}$ dataset from the\nKilo-Degree Survey (KiDS-1000), and the first year data from the Hyper\nSuprime-Cam Subaru Strategic Program (HSC-Y1). We utilize a pipeline developed\nand rigorously tested by the LSST Dark Energy Science Collaboration to perform\nthe reanalysis and assess the robustness of the results to analysis choices. We\nfind the $S_{8}$ constraint to be robust to two different small-scale modeling\napproaches, and varying choices of cosmological priors. Our unified analysis\nallows the consistency of the surveys to be rigorously tested and we find the\nthree surveys to be statistically consistent. Due to the partially overlapping\nfootprint, we model the cross-covariance between KiDS-1000 and HSC-Y1\napproximately when combining all three datasets, resulting in a $1.6-1.9\\%$\nconstraint on $S_8$ given different assumptions on the cross-covariance.\n", "  We investigate the origin of the large clustering signal detected in the\nangular distribution of the radio sources in the TGSS catalog. To do so, we\ncross-correlate the angular position of the radio sources with the Cosmic\nMicrowave Background (CMB) lensing maps from the Planck satellite, since\ncross-correlation is expected to be insensitive to source of possible\nsystematic errors that may generate a spurious clustering signal. The amplitude\nof the angular cross-correlation spectrum of TGSS-CMB lensing turns out to be\nmuch smaller than that of the TGSS auto-spectrum and consistent with that of\nthe NVSS-CMB lensing cross spectrum. A result that confirms the spurious origin\nof the TGSS large scale clustering signal. We further compare the two\ncross-spectra with theoretical predictions that use various prescriptions from\nthe literature, for the redshift counts of the radio sources, $N(z)$, and their\nbias $b(z)$. These models, that assume a $\\Lambda$CDM cosmology and that were\nproposed to fit the NVSS auto-spectrum, fail to match the cross-spectra on\nlarge scale, though not by far. When the bias relation is let free to vary\n(model predictions are rather insensitive to the choice of the N(z)) the\nquality of the fit improves but a large bias ($ b_g = 2.53 \\pm 0.11$) is\nrequired, which does not seem to be consistent with the observed clustering\namplitude of the radio sources in the local universe. Whether this large\ncross-correlation amplitude represents a problem for the radio sources models,\nor for the $\\Lambda$CDM framework itself, can only be clarified using next\ngeneration datasets featuring large number of objects. What our analysis does\nshow is the possibility to remove the $N(z)$ and $b(z)$ degeneracy by combining\nangular and cross-correlation analyses.\n", "  The kinetic Sunyaev-Zel'dovich (kSZ) effect, i.e., the Doppler boost of\ncosmic microwave background (CMB) photons caused by their scattering off free\nelectrons in galaxy clusters and groups with non-zero bulk velocity, is a\npowerful window on baryons in the universe. We present the first halo-model\ncomputation of the cross-power spectrum of the ``projected-field'' kSZ signal\nwith large-scale structure (LSS) tracers. We compare and validate our\ncalculations against previous studies, which relied on $N$-body-calibrated\neffective formulas rather than the halo model. We forecast results for CMB maps\nfrom the Atacama Cosmology Telescope (AdvACT), Simons Observatory (SO), and\nCMB-S4, and LSS survey data from the Dark Energy Survey, the Vera C.~Rubin\nObservatory (VRO), and \\textit{Euclid}. In cross-correlation with galaxy number\ndensity, for AdvACT $\\times$ \\textit{unWISE} we forecast an 18$\\sigma$\nprojected-field kSZ detection using data already in hand. Combining SO CMB maps\nand \\textit{unWISE} galaxy catalogs, we expect a $62\\sigma$ detection, yielding\nprecise measurements of the gas density profile radial slopes. Additionally, we\nforecast first detections of the kSZ -- galaxy weak lensing cross-correlation\nwith AdvACT $\\times$ VRO/\\textit{Euclid} (at 6$\\sigma$) and of the kSZ -- CMB\nweak lensing cross-correlation with SO (at 16$\\sigma$). Finally, $\\approx\n10-20$\\% precision measurements of the shape of the gas density profile should\nbe possible with CMB-S4 kSZ -- CMB lensing cross-correlation without using any\nexternal datasets.\n", "  The Dark Energy Spectroscopic Instrument (DESI) survey will measure\nlarge-scale structures using quasars as direct tracers of dark matter in the\nredshift range 0.9<z<2.1 and using Ly-alpha forests in quasar spectra at z>2.1.\nWe present several methods to select candidate quasars for DESI, using input\nphotometric imaging in three optical bands (g, r, z) from the DESI Legacy\nImaging Surveys and two infrared bands (W1, W2) from the Wide-field Infrared\nExplorer (WISE). These methods were extensively tested during the Survey\nValidation of DESI. In this paper, we report on the results obtained with the\ndifferent methods and present the selection we optimized for the DESI main\nsurvey. The final quasar target selection is based on a Random Forest algorithm\nand selects quasars in the magnitude range 16.5<r<23. Visual selection of\nultra-deep observations indicates that the main selection consists of 71%\nquasars, 16% galaxies, 6% stars and 7% inconclusive spectra. Using the spectra\nbased on this selection, we build an automated quasar catalog that achieves a\n>99% purity for a nominal effective exposure time of ~1000s. With a 310 per sq.\ndeg. target density, the main selection allows DESI to select more than 200\nQSOs per sq. deg. (including 60 quasars with z>2.1), exceeding the project\nrequirements by 20%. The redshift distribution of the selected quasars is in\nexcellent agreement with quasar luminosity function predictions.\n", "  The Dark Energy Spectroscopic Instrument (DESI) will precisely constrain\ncosmic expansion and the growth of structure by collecting $\\sim$40 million\nextra-galactic redshifts across $\\sim$80\\% of cosmic history and one third of\nthe sky. The Emission Line Galaxy (ELG) sample, which will comprise about\none-third of all DESI tracers, will be used to probe the Universe over the $0.6\n< z < 1.6$ range, which includes the $1.1<z<1.6$ range, expected to provide the\ntightest constraints.\n  We present the target selection of the DESI SV1 Survey Validation and Main\nSurvey ELG samples, which relies on the Legacy Surveys imaging. The Main ELG\nselection consists of a $g$-band magnitude cut and a $(g-r)$ vs.\\ $(r-z)$ color\nbox, while the SV1 selection explores extensions of the Main selection\nboundaries.\n  The Main ELG sample is composed of two disjoint subsamples, which have target\ndensities of about 1940 deg$^{-2}$ and 460 deg$^{-2}$, respectively. We first\ncharacterize their photometric properties and density variations across the\nfootprint. Then we analyze the DESI spectroscopic data obtained since December\n2020 during the Survey Validation and the Main Survey up to December 2021. We\nestablish a preliminary criterion to select reliable redshifts, based on the\n\\oii~flux measurement, and assess its performance. Using that criterion, we are\nable to present the spectroscopic efficiency of the Main ELG selection, along\nwith its redshift distribution. We thus demonstrate that the the main selection\nwith higher target density sample should provide more than 400 deg$^{-2}$\nreliable redshifts in both the $0.6<z<1.1$ and the $1.1<z<1.6$ ranges.\n", "  We investigate how the constraints on cosmological and astrophysical\nparameters ($\\Omega_{\\rm m}$, $\\sigma_{8}$, $A_{\\rm SN1}$, $A_{\\rm SN2}$) vary\nwhen exploiting information from multiple fields in cosmology. We make use of a\nconvolutional neural network to retrieve the salient features from different\ncombinations of field maps from IllustrisTNG in the CAMELS project. The fields\nconsidered are neutral hydrogen (HI), gas density (Mgas), magnetic fields (B)\nand gas metallicity (Z). We estimate the predictive uncertainty on the\npredictions of our model by using Monte Carlo dropout, a Bayesian\napproximation. Results show that overall, the performance of the model improves\non all parameters as the number of channels of its input is increased. As\ncompared to previous works, our model is able to predict the astrophysical\nparameters with up to $5\\%$ higher in accuracy. In the best setup which\nincludes all fields (four channel input, Mgas-HI-B-Z) the model achieves $R^{2}\n> 0.96$ on all parameters. Similarly, we find that the total uncertainty, which\nis dominated by the aleatoric uncertainty, decreases as more fields are used to\ntrain the model in general. The uncertainties obtained by dropout variational\ninference are overestimated on all parameters in our case, in that the\npredictive uncertainty is much larger than the actual squared error. After\ncalibration, which consists of a simple $\\sigma$ scaling method, the average\ndeviation of the total uncertainty from the actual error goes down to $25\\%$ at\nmost (on $A_{\\rm SN1}$).\n", "  Diverse astrophysical observations suggest the existence of cold dark matter\nthat interacts only gravitationally with radiation and ordinary baryonic\nmatter. Any nonzero coupling between dark matter and baryons would provide a\nsignificant step towards understanding the particle nature of dark matter.\nMeasurements of the cosmic microwave background (CMB) provide constraints on\nsuch a coupling that complement laboratory searches. In this work we place\nupper limits on a variety of models for dark matter elastic scattering with\nprotons and electrons by combining large-scale CMB data from the Planck\nsatellite with small-scale information from Atacama Cosmology Telescope (ACT)\nDR4 data. In the case of velocity-independent scattering, we obtain bounds on\nthe interaction cross section for protons that are 40\\% tighter than previous\nconstraints from the CMB anisotropy. For some models with velocity-dependent\nscattering we find best-fitting cross sections with a 2$\\sigma$ deviation from\nzero, but these scattering models are not statistically preferred over\n$\\Lambda$CDM in terms of model selection.\n", "  At times prior to Big Bang Nucleosynthesis, the universe could show a\nprimordial structure formation period if dominated by a fast oscillating\ninflaton field during reheating. In this context, we have postulated a new\nmechanism of primordial black hole formation [L. E. Padilla, J. C. Hidalgo, and\nK. A. Malik, Phys. Rev. D, vol. 106, p. 023519, Jul 2022], that draws the\nanalogy between an extended reheating era and the scalar field dark matter\nmodel, stipulating the gravitational collapse of inflaton halos and inflaton\nstars. In this paper we look at the requirements for the realization of this\nnew mechanism. We show that a generic primordial power spectrum with a peak at\nsmall scales is most suitable for the production of a considerable number of\nPBHs. When such requirement is met, and if reheating lasts long enough, large\npopulations of PBHs with $M_{\\rm PBH}\\sim 1~\\mathrm{gram}$ may be produced. We\nfind in particular, that the mass fraction of PBHs is orders of magnitude\nlarger than that obtained when PBHs form via direct collapse in a universe\ndominated by radiation or pressure-less dust. Looking at observable\nimplications of our findings, we explore the possibility that the PBHs\ncomponent may dominate the energy density of the universe at some point after\nthe end of reheating.\n", "  The Minkowski tensors (MTs) can be used to probe anisotropic signals in a\nfield, and are well suited for measuring the redshift space distortion (RSD)\nsignal in large scale structure catalogs. We consider how the linear RSD signal\ncan be extracted from a field without resorting to the plane parallel\napproximation. A spherically redshift space distorted field is both anisotropic\nand inhomogeneous. We derive expressions for the two point correlation\nfunctions that elucidate the inhomogeneity, and then explain how the breakdown\nof homogeneity impacts the volume and ensemble averages of the tensor Minkowski\nfunctionals. We construct the ensemble average of these quantities in\ncurvilinear coordinates and show that the ensemble and volume averages can be\napproximately equated, but this depends on our choice of definition of the\nvolume average of a tensor and the radial distance between the observer and\nfield. We then extract the tensor Minkowski functionals from spherically\nredshift space distorted, Gaussian random fields and gravitationally evolved\ndark matter density fields at $z=0$ to test if we can successfully measure the\nKaiser RSD signal. For the dark matter field we find a significant, $\\sim 10\\%$\nanomalous signal in the MT component parallel to the line of sight that is\npresent even on large scales $R_{\\rm G} \\gtrsim 15 \\, {\\rm Mpc}$, in addition\nto the Kaiser effect. This is due to the line of sight component of the MT\nbeing significantly contaminated by the Finger of God effect, which can be\napproximately modelled by an additional damping term in the cumulants.\n", "  We propose a novel method to measure the $E_G$ statistic from clustering\nalone. The $E_G$ statistic provides an elegant way of testing the consistency\nof General Relativity by comparing the geometry of the Universe, probed through\ngravitational lensing, with the motion of galaxies in that geometry. Current\n$E_G$ estimators combine galaxy clustering with gravitational lensing, measured\neither from cosmic shear or from CMB lensing. In this paper, we construct a\nnovel estimator for $E_G$, using only clustering information obtained from two\ntracers of the large-scale structure: intensity mapping and galaxy clustering.\nIn this estimator, both the velocity of galaxies and gravitational lensing are\nmeasured through their impact on clustering. We show that with this estimator,\nwe can suppress the contaminations that affect other $E_G$ estimators and\nconsequently test the validity of General Relativity robustly. We forecast that\nwith the coming generation of surveys like HIRAX and Euclid, we will measure\n$E_G$ with a precision of up to 7% (3.9% for the more futuristic SKA2).\n", "  Cosmological constraints from key probes of the Euclid imaging survey rely\ncritically on the accurate determination of the true redshift distributions,\n$n(z)$, of tomographic redshift bins. We determine whether the mean redshift,\n$<z>$, of ten Euclid tomographic redshift bins can be calibrated to the Euclid\ntarget uncertainties of $\\sigma(<z>)<0.002\\,(1+z)$ via cross-correlation, with\nspectroscopic samples akin to those from the Baryon Oscillation Spectroscopic\nSurvey (BOSS), Dark Energy Spectroscopic Instrument (DESI), and Euclid's NISP\nspectroscopic survey. We construct mock Euclid and spectroscopic galaxy samples\nfrom the Flagship simulation and measure small-scale clustering redshifts up to\nredshift $z<1.8$ with an algorithm that performs well on current galaxy survey\ndata. The clustering measurements are then fitted to two $n(z)$ models: one is\nthe true $n(z)$ with a free mean; the other a Gaussian Process modified to be\nrestricted to non-negative values. We show that $<z>$ is measured in each\ntomographic redshift bin to an accuracy of order 0.01 or better. By measuring\nthe clustering redshifts on subsets of the full Flagship area, we construct\nscaling relations that allow us to extrapolate the method performance to larger\nsky areas than are currently available in the mock. For the full expected\nEuclid, BOSS, and DESI overlap region of approximately 6000 deg$^{2}$, the\nuncertainties attainable by clustering redshifts exceeds the Euclid requirement\nby at least a factor of three for both $n(z)$ models considered, although\nsystematic biases limit the accuracy. Clustering redshifts are an extremely\neffective method for redshift calibration for Euclid if the sources of\nsystematic biases can be determined and removed, or calibrated-out with\nsufficiently realistic simulations. We outline possible future work, in\nparticular an extension to higher redshifts with quasar reference samples.\n", "  Relativistic and free-streaming particles like neutrinos leave imprints in\nlarge scale structures (LSS), providing probes of the effective number of\nneutrino species $N_{\\rm eff}$. In this paper, we use the Fisher formalism to\nforecast $N_{\\rm eff}$ constraints from the bispectrum (B) of LSS for current\nand future galaxy redshift surveys, specifically using information from the\nbaryon acoustic oscillations (BAOs). Modeling the galaxy bispectrum at the\ntree-level, we find that adding the bispectrum constraints to current CMB\nconstraints from Planck can improve upon the Planck-only constraints on $N_{\\rm\neff}$ by about 10\\% -- 40\\% depending on the survey. Compared to the Planck +\npower spectrum (P) constraints previously explored in the literature, using\nPlanck+P+B provides a further improvement of about 5\\% -- 30\\%. Besides using\nBAO wiggles alone, we also explore using the total information which includes\nboth the wiggles and the broadband information (which is subject to systematics\nchallenges), generally yielding better results. Finally, we exploit the\ninterference feature of the BAOs in the bispectrum to select a subset of\ntriangles with the most information on $N_{\\rm eff}$. This allows for the\nreduction of computational cost while keeping most of the information, as well\nas for circumventing some of the shortcomings of applying directly to the\nbispectrum the current wiggle extraction algorithm valid for the power\nspectrum. In sum, our study validates that the current Planck constraint on\n$N_{\\rm eff}$ can be significantly improved with the aid of galaxy surveys\nbefore the next-generation CMB experiments like CMB-Stage 4.\n", "  In this work, which is the first of a series to prepare a cosmological\nparameter analysis with third-order cosmic shear statistics, we model both the\nshear three-point correlation functions $\\Gamma^{(i)}$ and the third-order\naperture statistics $\\langle\\mathcal{M}_\\mathrm{ap}^3\\rangle$ from the\nBiHalofit bispectrum model and validate these statistics with a series of\nN-body simulations.\n  We then investigate how to bin the shear three-point correlation functions to\nachieve an unbiased estimate for third-order aperture statistics in real data.\n  Finally, we perform a cosmological parameter analysis on KiDS1000-like mock\ndata with second- and third-order statistics. We recover all cosmological\nparameters with very little bias. Furthermore, we find that a joint analysis\nalmost doubles the constraining power on $S_8$ and increases the\nfigure-of-merit in the $\\Omega_\\mathrm{m}$-$\\sigma_8$ plane by a factor of 5.9\nwith respect to an analysis with only second-order shear statistics.\n  Our modelling pipeline is publicly available at\nhttps://github.com/sheydenreich/threepoint/releases/.\n", "  Our view of the last-scattering surface in the cosmic microwave background\n(CMB) is obscured by secondary anisotropies, sourced by scattering,\nextragalactic emission and gravitational processes between recombination and\nobservation. Whilst it is established that non-Gaussianity from the correlation\nbetween the integrated-Sachs-Wolfe (ISW) effect and gravitational lensing can\nsignificantly bias primordial non-Gaussianity (PNG) searches, recent work by\nHill (2018) has suggested that other combinations of secondary anisotropies can\nalso produce significant biases. Building on that work, we use the WebSky and\nSehgal et al.(2010) simulations to perform an extensive examination of possible\nbiases to PNG measurements for the local, equilateral and orthogonal shapes.\nFor a Planck-like CMB experiment, without foreground cleaning, we find\nsignificant biases from cosmic infrared background (CIB)-lensing and thermal\nSunyaev-Zel'dovich (tSZ)-lensing bispectra for the local and orthogonal\ntemplates, and from CIB and tSZ bispectra for the equilateral template. For\nfuture experiments, such as the Simons Observatory, biases from correlations\nbetween the ISW effect and the tSZ and CIB will also become important. Finally\nwe investigate whether foreground-cleaning techniques are able to suppress\nthese biases sufficiently. We find that the majority of these biases are\neffectively suppressed by the internal-linear-combination method and the total\nbias to Planck-like and SO-like experiments is less than the $1\\,\\sigma$\nstatistical error. However, the small total bias arises from the cancellation\nof several $1\\,\\sigma$ biases for Planck-like experiments and $2\\,\\sigma$\nbiases for SO-like. As this cancellation is likely sensitive to the precise\nmodelling, to ensure robustness against these biases explicit removal methods\nshould be used, likely at the cost of decreased constraining power.\n", "  We constrain the deceleration-acceleration epoch, namely the transition\nredshift $z_{tr}$, adopting model-independent techniques that utilize a\ncalibrated $E_{\\rm p}$-$E_{\\rm iso}$ correlation for gamma-ray bursts (GRBs).\nTo do so, in addition to real data points, we employ up to $1000$ simulated\nobservational Hubble data (OHD) points. We then calibrate the $E_{\\rm\np}$-$E_{\\rm iso}$ correlation by means of the well-consolidate B\\'ezier\npolynomial technique, interpolating OHD up to the second order. Once GRB data\nhave been calibrated, we consider two strategies of cosmographic expansions,\ni.e., first we take a direct Hubble rate expansion around $z_{tr}$, and second\nthe expansion of the deceleration parameter around the same redshift, but with\na different order. Employing type Ia supernovae, baryonic acoustic oscillations\nand GRB data sets, from Monte Carlo analyses we infer tight constraints on\n$z_{tr}$ and the jerk parameters at $z=z_{tr}$, namely $j_{tr}$. Our results\nare extremely compatible with previous outcomes and confirm the $\\Lambda$CDM\npredictions, being slightly different in terms of the jerk parameter. In this\nrespect, we conjecture which extensions of the concordance paradigm are\npossible and we compare our findings with expectations provided by generic dark\nenergy models.\n", "  With the advent of the Square Kilometre Array Observatory (SKAO), scientists\nwill be able to directly observe the Epoch of Reionization by mapping the\ndistribution of neutral hydrogen at different redshifts. While physically\nmotivated results can be simulated with radiative transfer codes, these\nsimulations are computationally expensive and can not readily produce the\nrequired scale and resolution simultaneously. Here we introduce the\nPhysics-Informed neural Network for reIONization (PINION), which can accurately\nand swiftly predict the complete 4-D hydrogen fraction evolution from the\nsmoothed gas and mass density fields from pre-computed N-body simulation. We\ntrained PINION on the C$^2$-Ray simulation outputs and a physics constraint on\nthe reionization chemistry equation is enforced. With only five redshift\nsnapshots and a propagation mask as a simplistic approximation of the ionizing\nphoton mean free path, PINION can accurately predict the entire reionization\nhistory between $z=6$ and $12$. We evaluate the accuracy of our predictions by\nanalysing the dimensionless power spectra and morphology statistics estimations\nagainst C$^2$-Ray results. We show that while the network's predictions are in\ngood agreement with simulation to redshift $z>7$, the network's accuracy\nsuffers for $z<7$ primarily due to the oversimplified propagation mask. We\nmotivate how PINION performance can be drastically improved and potentially\ngeneralized to large-scale simulations.\n", "  The combination of multi-band imaging from HST with MUSE integral field\nspectroscopy, obtained at the VLT, has recently driven remarkable progress in\nstrong lensing (SL) modeling of galaxy clusters. From a few tens of multiple\nimages with photometric redshifts per cluster, a new generation of\nhigh-precision SL models have recently been developed, by exploiting in some\ncases over a hundred of spectroscopically confirmed multiple images and cluster\nmember galaxies. A further step forward is expected with JWST observations of\nSL clusters (from hundreds to possibly a thousand of multiple images). In this\ncontext, we present a new, state-of-the-art SL model of the galaxy cluster MACS\nJ0416.1-2403, utilizing 237 spectroscopically confirmed multiple images, which\nis the largest sample of secure multiply lensed sources utilized to date. This\nmodel incorporates stellar kinematics information of 64 cluster galaxies and\nthe hot-gas mass distribution of the cluster determined from Chandra X-ray\nobservations. The observed positions of the many multiple images are reproduced\nwith a remarkable accuracy of 0.43 arcsec. To further assess the reliability of\nthis lens model and to highlight the improvement over previously published\nmodels, we show the extended surface brightness reconstruction of several\nlensed galaxies through a newly developed forward modeling software. The\ncomparison with other SL models of the same cluster demonstrates that this new\nmodel is better suited to accurately reproduce the positions, shapes and fluxes\nof the observed multiple images. Besides a robust characterization of the total\nmass distribution of the cluster, our model can provide accurate and precise\nmagnification maps that are key to studying the intrinsic physical properties\nof faint, high-redshift lensed sources. The model is made publicly available\nthrough our newly developed Strong Lensing Online Tool (or SLOT).\n", "  We present posterior sample-based cosmic microwave background (CMB)\nconstraints from Planck LFI and WMAP observations derived through global\nend-to-end Bayesian processing. We use these samples to study correlations\nbetween CMB, foreground, and instrumental parameters, and we identify a\nparticularly strong degeneracy between CMB temperature fluctuations and\nfree-free emission on intermediate angular scales, which is mitigated through\nmodel reduction, masking, and resampling. We compare our posterior-based CMB\nresults with previous Planck products, and find generally good agreement, but\nwith higher noise due to exclusion of HFI data. We find a best-fit CMB dipole\namplitude of $3362.7\\pm1.4{\\mu}K$, in excellent agreement with previous Planck\nresults. The quoted uncertainty is derived directly from the sampled posterior\ndistribution, and does not involve any ad hoc contribution for systematic\neffects. Similarly, we find a temperature quadrupole amplitude of\n$\\sigma^{TT}_2=229\\pm97{\\mu}K^2$, in good agreement with previous results in\nterms of the amplitude, but the uncertainty is an order of magnitude larger\nthan the diagonal Fisher uncertainty. Relatedly, we find lower evidence for a\npossible alignment between $\\ell = 2$ and $\\ell = 3$ than previously reported\ndue to a much larger scatter in the individual quadrupole coefficients, caused\nboth by marginalizing over a more complete set of systematic effects, and by\nour more conservative analysis mask. For higher multipoles, we find that the\nangular temperature power spectrum is generally in good agreement with both\nPlanck and WMAP. This is the first time the sample-based asymptotically exact\nBlackwell-Rao estimator has been successfully established for multipoles up to\n$\\ell\\le600$, and it now accounts for the majority of the cosmologically\nimportant information. Cosmological parameter constraints are presented in a\ncompanion paper. (Abriged)\n", "  We present Planck LFI frequency sky maps derived within the BeyondPlanck\nframework. This framework draws samples from a global posterior distribution\nthat includes instrumental, astrophysical and cosmological parameters, and the\nmain product is an entire ensemble of frequency sky map samples. This ensemble\nallows for computationally convenient end-to-end propagation of low-level\ninstrumental uncertainties into higher-level science products. We show that the\ntwo dominant sources of LFI instrumental systematic uncertainties are\ncorrelated noise and gain fluctuations, and the products presented here support\n- for the first time - full Bayesian error propagation for these effects at\nfull angular resolution. We compare our posterior mean maps with traditional\nfrequency maps delivered by the Planck collaboration, and find generally good\nagreement. The most important quality improvement is due to significantly lower\ncalibration uncertainties in the new processing, as we find a fractional\nabsolute calibration uncertainty at 70 GHz of $\\delta g_{0}/g_{0} =5 \\cdot\n10^{-5}$, which is nominally 40 times smaller than that reported by Planck\n2018. However, the original Planck 2018 estimate has a non-trivial statistical\ninterpretation, and this further illustrates the advantage of the new framework\nin terms of producing self-consistent and well-defined error estimates of all\ninvolved quantities without the need of ad hoc uncertainty contributions. We\ndescribe how low-resolution data products, including dense pixel-pixel\ncovariance matrices, may be produced directly from the posterior samples\nwithout the need for computationally expensive analytic calculations or\nsimulations. We conclude that posterior-based frequency map sampling provides\nunique capabilities in terms of low-level systematics modelling and error\npropagation, and may play an important role for future CMB B-mode experiments.\n(Abridged.)\n", "  Reconstruction of gravitational lensing effects in the CMB from current and\nupcoming surveys is still dominated by temperature anisotropies. Extragalactic\nforegrounds in temperature maps can induce significant biases in the lensing\npower spectrum obtained with the standard quadratic estimators. Techniques such\nas masking cannot remove these foregrounds fully, and the residuals can still\nlead to large biases if unaccounted for. In this paper, we study the\n\"shear-only\" estimator, an example of a class of geometric methods that\nsuppress extragalactic foreground contamination while making only minimal\nassumptions about foreground properties. The shear-only estimator has only been\nformulated in the flat-sky limit and so is not easily applied to wide surveys.\nHere, we derive the full-sky version of the shear-only estimator and its\ngeneralisation to an $m=2$ multipole estimator that has improved performance\nfor lensing reconstruction on smaller scales. The multipole estimator is\ngenerally not separable, and so is expensive to compute. We explore separable\napproximations based on a singular-value decomposition, which allow efficient\nevaluation of the estimator with real-space methods. Finally, we apply these\nestimators to simulations that include extragalactic foregrounds and verify\ntheir efficacy in suppressing foreground biases.\n", "  We present a novel $n$EPT ($n$th-order Eulerian Perturbation Theory) scheme\nto model the nonlinear density field by the summation up to $n$th-order density\nfields in perturbation theory. The obtained analytical power spectrum shows\nexcellent agreement with the results from all 20 Dark-Quest suites of $N$-body\nsimulations spreading over a broad range of cosmologies. The agreement is much\nbetter than the conventional two-loop Standard Perturbation Theory and would\nreach out to $k_{\\rm max}\\simeq 0.4~h/{\\rm Mpc}$ at $z=3$ for the best-fitting\nPlanck cosmology, without any free parameters. The method can accelerate the\nforward modeling of the non-linear cosmological density field, an indispensable\nprobe of cosmic mysteries such as inflation, dark energy, and dark matter.\n", "  We study the minimum mass of dark compact objects formed in dissipative\ndark-matter halos and show that the simple atomic-dark-matter model consistent\nwith all current observations can create low-mass fragments that can evolve\ninto compact objects forbidden by stellar astrophysics. We model the collapse\nof the dark halo's dense core by tracing the thermo-chemical evolution of a\nuniform-density volume element under two extreme assumptions for density\nevolution: hydrostatic equilibrium and pressure-free collapse. We then compute\nthe opacity-limited minimum fragment mass from the minimum temperature achieved\nin these calculations.\n", "  The origin of dark energy driving the accelerated expansion of the universe\nis still mysterious. We explore the possibility that dark energy fluctuates,\nresulting in spatial correlations. Due to these fluctuations, the Hubble rate\nitself becomes a fluctuating quantity. We discuss the effect this has on\nmeasurements of type Ia supernovae, which are used to constrain the luminosity\ndistance. We show that the luminosity distance is affected by spatial\ncorrelations in several ways. First, the luminosity distance becomes dressed by\nthe fluctuations, thereby differing from standard $\\Lambda$CDM. Second, angular\ncorrelations become visible in the two-point correlation function of the\nluminosity distance. To investigate the latter we construct the angular power\nspectrum of luminosity distance fluctuations. We then perform a forecast for\ntwo supernova surveys, the ongoing Dark Energy Survey (DES) and the upcoming\nLegacy Survey of Space and Time (LSST), and compare this effect with\nrelativistic lensing effects from perturbed $\\Lambda$CDM. We find that the\nsignal can rise above the lensing effects and that LSST could test this effect\nfor a large part of the parameter space. As an example, a specific realisation\nof such a scenario is that quantum fluctuations of some field in the early\nuniverse imprint spatial correlations with a predictable form in the dark\nenergy density today. In this case, the Hubble rate fluctuates due to the\nintrinsic quantum nature of the dark energy density field. We study whether the\nsignal of this specific model would be measurable, and conclude that testing\nthis model with LSST would be challenging. However, taking into account a speed\nof sound $c_s<1$ of the dark energy fluid can make this model observable.\n", "  The Warm-Hot Intergalactic Medium (WHIM) is believed to host a significant\nfraction of the ``missing baryons'' in the nearby Universe. Its signature has\nbeen detected in the X-ray absorption spectra of distant quasars. However, its\ndetection in emission, that would allow us to study the WHIM in a systematic\nway, is still lacking. Motivated by the possibility to perform these studies\nwith next generation integral field spectrometers, and thanks to the\navailability of a large suite of state-of-the-art hydrodynamic simulations --\nthe CAMELS suite -- we study here in detail the emission properties of the WHIM\nand the possibility to infer its physical properties with upcoming X-ray\nmissions like Athena. We focused on the two most prominent WHIM emission lines,\nthe OVII triplet and the OVIII singlet, and build line surface brightness maps\nin a lightcone, mimicking a data cube generated through integral field\nspectroscopy. We confirm that detectable WHIM emission, even with next\ngeneration instruments, is largely associated to galaxy-size dark matter halos\nand that the WHIM properties evolve little from $z\\simeq0.5$ to now. Some\ncharacteristics of the WHIM, like the line number counts as a function of their\nbrightness, depend on the specific hydrodynamic simulation used, while others,\nlike the WHIM clustering properties, are robust to this aspect. The large\nnumber of simulations available in the CAMELS datasets allows us to assess the\nsensitivity of the WHIM properties to the background cosmology and to the\nenergy feedback mechanisms regulated by AGN and stellar activity. [ABRIDGED]\n", "  We study the contribution of subhalos to the 21 cm forest signal. The halos\ncan host the substructures and including the effects of those small scale\nclumps can potentially boost the 21 cm optical depth in favor of detecting the\n21 cm forest signals. We estimate the boost factor representing the ratio of\nthe optical depth due to the subhalo contribution and that due to the host halo\nalone (without subhalos). Even though the optical depth boost factor is\nnegligible for a small host halo with the mass of order $10^5 M_{\\odot}$, the\nsubhalo contribution can enhance the optical depth by an order of magnitude for\na host halo of order $10^7 M_{\\odot}$. The resultant 21 cm absorption line\nabundance which is obtained by integrating over the halo mass range relevant\nfor the 21 cm forest signal can be enhanced by up to of order $10\\%$ due to the\nsubstructures. The larger boost factor for a larger host halo would be of\nparticular interest for the 21 cm forest detection because the the contribution\nof the larger host halos to the 21 cm forest signals is smaller due to their\nhigher temperature and less abundance than the smaller host halos. The subhalos\nhence can well help the larger host halos more important for the signal\nestimation which, without considering the subhalos, may not give appreciable\ncontribution to 21 cm forest signals.\n", "  We introduce $\\texttt{Hi-COLA}$, a code designed to run fast, approximate\n$\\textit{N}$-body simulations of non-linear structure formation in reduced\nHorndeski gravity. Given an input Lagrangian, $\\texttt{Hi-COLA}$ dynamically\nconstructs the appropriate field equations and consistently solves for the\ncosmological background, linear growth, and screened fifth force of that\ntheory. Hence $\\texttt{Hi-COLA}$ is a general, adaptable, and useful tool that\nallows the mildly non-linear regime of many Horndeski theories to be\ninvestigated for the first time, at low computational cost. In this work, we\nfirst describe the screening approximations and simulation setup of\n$\\texttt{Hi-COLA}$ for theories with Vainshtein screening. We validate the code\nagainst traditional $\\textit{N}$-body simulations for cubic Galileon gravity,\nfinding $2.5\\%$ agreement up to $k_{\\rm max}=1.2~h/{\\rm Mpc}$. To demonstrate\nthe flexibility of $\\texttt{Hi-COLA}$, we additionally run the first\nsimulations of an extended shift-symmetric gravity theory. We use the\nconsistency and modularity of $\\texttt{Hi-COLA}$ to dissect how the modified\nbackground, linear growth, and screened fifth force all contribute to\ndepartures from $\\Lambda$CDM in the non-linear matter power spectrum.\n$\\texttt{Hi-COLA}$ can be found at https://github.com/Hi-COLACode/Hi-COLA .\n", "  We have analyzed the rate of capture of dark matter (DM) particles by the\ngalaxy in the case of the existence of two different types of DM or a bimodal\nvelocity distribution function for DM. It is shown that, in addition to the\nscenario considered in our previous work which is based on the assumption of an\nunimodal distribution, more complex scenarios are possible in which the\ntransition to the state of intense capture and/or exit from it can occur in two\nstages. A detailed description is given of the change in the curve describing\nthe rate of capture of dark matter particles as a function of the rate of\nincrease in the baryon mass of the galaxy for various values of the rate of\ndecrease of the DM density.\n", "  We present a measurement of the Hubble constant ($H_0$) using type Ia\nsupernova (SNe Ia) in the near-infrared (NIR) from the recently updated sample\nof SNe Ia in nearby galaxies with distances measured via Cepheid\nperiod-luminosity relations by the SHOES project. We collect public\nnear-infrared photometry of up to 19 calibrator SNe Ia and further 57 SNe Ia in\nthe Hubble flow ($z>0.01$), and directly measure their peak magnitudes in the\n$J$ and $H$ band by Gaussian processes and spline interpolation. Calibrator\npeak magnitudes together with Cepheid-based distances are used to estimate the\naverage absolute magnitude in each band, while Hubble-flow SNe are used to\nconstrain the zero-point intercept of the magnitude-redshift relation. Our\nbaseline result of $H_0$ is $72.3\\pm1.4$ (stat) $\\pm1.4$ (syst) km s$^{-1}$\nMpc$^{-1}$ in the $J$ band and $72.3\\pm1.3$ (stat) $\\pm1.4$ (syst) km s$^{-1}$\nMpc$^{-1}$ in the $H$ band, where the systematic uncertainties include the\nstandard deviation of up to 21 variations of the analysis, the 0.7\\% distance\nscale systematic from SHOES Cepheid anchors, a photometric zeropoint\nsystematic, and a cosmic variance systematic. Our final measurement represents\na measurement with a precision of 2.8\\% in both bands. The variant with the\nlargest change in $H_0$ is when limiting the sample to SNe from CSP and CfA\nprogrammes, noteworthy because these are the best calibrated, yielding\n$H_0\\sim75$ km s$^{-1}$ Mpc$^{-1}$ in both bands. We demonstrate stretch and\nreddening corrections are still useful in the NIR to standardize SN Ia NIR peak\nmagnitudes. Based on our results, in order to improve the precision of the\n$H_0$ measurement with SNe Ia in the NIR in the future, we would need to\nincrease the number of calibrator SNe Ia, be able to extend the\nHubble-Lema\\^itre diagram to higher-z, and include standardization procedures\nto help reducing the NIR intrinsic scatter.\n", "  If dark matter resides in a hidden sector minimally coupled to the Standard\nModel, another particle within the hidden sector might dominate the energy\ndensity of the early universe temporarily, causing an early matter-dominated\nera (EMDE). During an EMDE, matter perturbations grow more rapidly than they\nwould in a period of radiation domination, which leads to the formation of\nmicrohalos much earlier than they would form in standard cosmological\nscenarios. These microhalos boost the dark matter annihilation signal, but this\nboost is highly sensitive to the small-scale cut-off in the matter power\nspectrum. If the dark matter is sufficiently cold, this cut-off is set by the\nrelativistic pressure of the particle that dominates the hidden sector. We\ndetermine the evolution of dark matter density perturbations in this scenario,\nobtaining the power spectrum at the end of the EMDE. We analyze the suppression\nof perturbations due to the relativistic pressure of the dominant hidden sector\nparticle and express the cut-off scale and peak scale for which the matter\npower spectrum is maximized in terms of the properties of this particle. We\nalso supply transfer functions to relate the matter power spectrum with a\nsmall-scale cut-off resulting from the pressure of the dominant hidden sector\nparticle to the matter power spectrum that results from a cold hidden sector.\nThese transfer functions facilitate the quick computation of accurate matter\npower spectra in EMDE scenarios with initially hot hidden sectors and allow us\nto identify which models significantly enhance the microhalo abundance.\n", "  To use strong gravitational lenses as an astrophysical or cosmological probe,\nmodels of their mass distributions are often needed. We present a new,\ntime-efficient automation code for uniform modeling of strongly lensed quasars\nwith GLEE, a lens modeling software, for high-resolution multi-band data. By\nusing the observed positions of the lensed quasars and the spatially extended\nsurface brightness distribution of the lensed quasar host galaxy, we obtain a\nmodel of the mass distribution of the lens galaxy. We apply this uniform\nmodeling pipeline to a sample of nine strongly lensed quasars with HST WFC 3\nimages. The models show in most cases well reconstructed light components and a\ngood alignment between mass and light centroids. We find that the automated\nmodeling code significantly reduces the user input time during the modeling\nprocess. The preparation time of required input files is reduced significantly.\nThis automated modeling pipeline can efficiently produce uniform models of\nextensive lens system samples which can be used for further cosmological\nanalysis. A blind test through a comparison with the results of an independent\nautomated modeling pipeline based on the modeling software Lenstronomy reveals\nimportant lessons. Quantities such as Einstein radius, astrometry, mass\nflattening and position angle are generally robustly determined. Other\nquantities depend crucially on the quality of the data and the accuracy of the\nPSF reconstruction. Better data and/or more detailed analysis will be necessary\nto elevate our automated models to cosmography grade. Nevertheless, our\npipeline enables the quick selection of lenses for follow-up monitoring and\nfurther modeling, significantly speeding up the construction of\ncosmography-grade models. This is an important step forward to take advantage\nof the orders of magnitude increase in the number of lenses expected in the\ncoming decade.\n", "  The redshift space anisotropy of the bispectrum is generally quantified using\nmultipole moments. The possibility of measuring these multipoles in any survey\ndepends on the level of statistical fluctuations. We present a formalism to\ncompute the statistical fluctuations in the measurement of bispectrum\nmultipoles for galaxy surveys. We consider specifications of a {\\it Euclid}\nlike galaxy survey and present two quantities: the signal-to-noise ratio (SNR)\nwhich quantifies the detectability of a multipole, and the rank correlation\nwhich quantifies the correlation in measurement errors between any two\nmultipoles. Based on SNR values, we find that {\\it Euclid} can potentially\nmeasure the bispectrum multipoles up to $\\ell=4$ across various triangle\nshapes, formed by the three {\\bf k} vectors in Fourier space. In general, SNR\nis maximum for the linear triangles. SNR values also depend on the scales and\nredshifts of observation. While, $\\ell \\leq 2$ multipoles can be measured with\n${\\rm SNR}>5$ even at linear/quasi-linear ($k \\lesssim 0.1 \\,{\\rm Mpc}^{-1}$)\nscales, for $\\ell>2$ multipoles, we require to go to small scales or need to\nincrease bin sizes. For most multipole pairs, the errors are only weakly\ncorrelated across much of the triangle shapes barring a few in the vicinity of\nsqueezed and stretched triangles. This makes it possible to combine the\nmeasurements of different multipoles to increase the effective SNR.\n", "  In this paper, we discussed the multiple vector fields during the inflation\nera and the inflationary magnetogenesis with multiple vector fields. Instead of\na single coupling function in single vector field models, the coupling matrix\nbetween vector fields and scalar field which drive the inflation is introduced.\nThe dynamical equations for multiple vector fields are obtained and applied to\nthe inflation era. We discussed three cases for the double-field model. In no\nmutual-coupling case, one can find that both electric and magnetic spectrum can\nbe scale-invariant at the end of inflation, meanwhile, the strong coupling\nproblem can be avoided. The effect of mutual-coupling between different vector\nfields is also discussed. We found that weak mutual-coupling can lead to the\nslightly blue spectrum of the magnetic field. On the other hand, in the strong\nmutual-coupling case, the scale-invariant magnetic spectrum can also be\nobtained but the energy density of electromagnetic fields either lead to the\nbackreaction problem or is diluted by inflation.\n", "  We study the topology of the network of ionized and neutral regions that\ncharacterized the intergalactic medium during the Epoch of Reionization. Our\nanalysis uses the formalism of persistent homology, which offers a highly\nintuitive and comprehensive description of the ionization topology in terms of\nthe births and deaths of topological features. Features are identified as\n$k$-dimensional holes in the ionization bubble network, whose abundance is\ngiven by the $k$th Betti number: $\\beta_0$ for ionized bubbles, $\\beta_1$ for\ntunnels, and $\\beta_2$ for neutral islands. Using semi-numerical models of\nreionization, we investigate the dependence on the properties of sources and\nsinks of ionizing radiation. Of all topological features, we find that the\ntunnels dominate during reionization and that their number is easiest to\nobserve and most sensitive to the astrophysical parameters of interest, such as\nthe gas fraction and halo mass necessary for star formation. Seen as a phase\ntransition, the importance of the tunnels can be explained by the entanglement\nof two percolating clusters and the fact that higher-dimensional features arise\nwhen lower-dimensional features link together. We also study the relation\nbetween the morphological components of the bubble network (bubbles, tunnels,\nislands) and those of the cosmic web (clusters, filaments, voids), describing a\ncorrespondence between the $k$-dimensional features of both. Finally, we apply\nthe formalism to mock observations of the 21-cm signal. Assuming 1000\nobservation hours with HERA Phase II, we show that astrophysical models can be\ndifferentiated and confirm that persistent homology provides additional\ninformation beyond the power spectrum.\n", "  We measure the tidal alignment of the major axes of Luminous Red Galaxies\n(LRGs) from the Legacy Imaging Survey and use it to infer the artificial\nredshift-space distortion signature that will arise from an\norientation-dependent, surface-brightness selection in the Dark Energy\nSpectroscopic Instrument (DESI) survey. Using photometric redshifts to\ndown-weight the shape-density correlations due to weak lensing, we measure the\nintrinsic tidal alignment of LRGs. Separately, we estimate the net polarization\nof LRG orientations from DESI's fiber-magnitude target selection to be of order\n10^-2 along the line of sight. Using these measurements and a linear tidal\nmodel, we forecast a 0.5% fractional decrease on the quadrupole of the 2-point\ncorrelation function for projected separations of 40-80 Mpc/h. We also use a\nhalo catalog from the Abacus Summit cosmological simulation suite to reproduce\nthis false quadrupole.\n", "  Calibrating the redshift distributions of photometric galaxy samples is\nessential in weak lensing studies. The self-calibration method combines angular\nauto- and cross-correlations between galaxies in multiple photometric redshift\n(photo-$z$) bins to reconstruct the scattering rates matrix between redshift\nbins. In this paper, we test a recently proposed self-calibration algorithm\nusing the DECaLS Data Release 9 and investigate to what extent the scattering\nrates are determined. We first mitigate the spurious angular correlations due\nto imaging systematics by a machine learning based method. We then improve the\nalgorithm for $\\chi^2$ minimization and error estimation. Finally, we solve for\nthe scattering matrices, carry out a series of consistency tests and find\nreasonable agreements: (1) finer photo-$z$ bins return a high-resolution\nscattering matrix, and it is broadly consistent with the low-resolution matrix\nfrom wider bins; (2) the scattering matrix from the Northern Galactic Cap is\nalmost identical to that from Southern Galactic Cap; (3) the scattering\nmatrices are in reasonable agreement with those constructed from the power\nspectrum and the weighted spectroscopic subsample. We also evaluate the impact\nof cosmic magnification. Although it changes little the diagonal elements of\nthe scattering matrix, it affects the off-diagonals significantly. The\nscattering matrix also shows some dependence on scale cut of input\ncorrelations, which may be related to a known numerical degeneracy between\ncertain scattering pairs. This work demonstrates the feasibility of the\nself-calibration method in real data and provides a practical alternative to\ncalibrate the redshift distributions of photometric samples.\n", "  The kinetic Sunyaev-Zeldovich (kSZ) effect will be an important source of\ncosmological and astrophysical information in upcoming surveys of the cosmic\nmicrowave background (CMB). However, the kSZ effect will also act as the\ndominant source of noise for several other measurements that use small angular\nscales in CMB temperature maps, since its blackbody nature implies that\nstandard component separation techniques cannot be used to remove it from\nobserved maps. In this paper, we explore the idea of \"de-kSZing\": constructing\na template for the late-time kSZ effect using external surveys of large-scale\nstructure, and then subtracting this template from CMB temperature maps in\norder to remove some portion of the kSZ signal. After building intuition for\ngeneral aspects of the de-kSZing procedure, we perform forecasts for the\nde-kSZing efficiency of several large-scale structure surveys, including BOSS,\nDESI, Roman, MegaMapper, and PUMA. We also highlight potential applications of\nde-kSZing to cosmological constraints from the CMB temperature power spectrum,\nCMB lensing reconstruction, and the moving-lens effect. While our forecasts\npredict achievable de-kSZing efficiencies of 10-20% at best, these results are\nspecific to the de-kSZing formalism adopted in this work, and we expect that\nhigher efficiencies are possible using improved versions of this formalism.\n", "  Amongst the most popular explanations for dark energy are modified theories\nof gravity. The galaxy overdensity and peculiar velocity fields help us to\nconstrain the growth rate of structure and distinguish different models of\ngravity. We introduce an improved method for constraining the growth rate of\nstructure with the galaxy overdensity and peculiar velocity fields. This method\nreduces the modelling systematic error by accounting for the wide-angle effect\nand the zero-point calibration uncertainty during the modelling process. We\nalso speed up the posterior sampling by around 30 times by first calculating\nthe likelihood at a small number of fiducial points and then interpolating the\nlikelihood values during MCMC sampling. We test the new method on mocks and we\nfind it is able to recover the fiducial growth rate of structure. We applied\nour new method to the SDSS PV catalogue, which is the largest single peculiar\nvelocity catalogue to date. Our constraint on the growth rate of structure is\n\\(f\\sigma_8 = 0.405_{-0.071}^{+0.076}\\) (stat) \\(\\pm 0.009\\) (sys) at the\neffective redshift of 0.073. Our constraint is consistent with a Planck 2018\ncosmological model, \\(f\\sigma_8 = 0.448\\), within one standard deviation. Our\nimproved methodology will enable similar analysis on future data, with even\nlarger sample sizes and covering larger angular areas on the sky.\n", "  The dependence of galaxy clustering on local density provides an effective\nmethod for extracting non-Gaussian information from galaxy surveys. The\ntwo-point correlation function (2PCF) provides a complete statistical\ndescription of a Gaussian density field. However, the late-time density field\nbecomes non-Gaussian due to non-linear gravitational evolution and higher-order\nsummary statistics are required to capture all of its cosmological information.\nUsing a Fisher formalism based on halo catalogues from the Quijote simulations,\nwe explore the possibility of retrieving this information using the\ndensity-split clustering (DS) method, which combines clustering statistics from\nregions of different environmental density. We show that DS provides more\nprecise constraints on the parameters of the $\\nu \\Lambda$CDM model compared to\nthe 2PCF, and we provide suggestions for where the extra information may come\nfrom. DS improves the constraints on the sum of neutrino masses by a factor of\n$7$ and by factors of 4, 3, 3, 6, and 5 for $\\Omega_{\\rm m}$, $\\Omega_{\\rm b}$,\n$h$, $n_s$, and $\\sigma_8$, respectively. We compare DS statistics when the\nlocal density environment is estimated from the real or redshift-space\npositions of haloes. The inclusion of DS autocorrelation functions, in addition\nto the cross-correlation functions between DS environments and haloes, recovers\nmost of the information that is lost when using the redshift-space halo\npositions to estimate the environment. We discuss the possibility of\nconstructing simulation-based methods to model DS clustering statistics in\ndifferent scenarios.\n", "  End-to-end simulations play a key role in the analysis of any\nhigh-sensitivity CMB experiment, providing high-fidelity systematic error\npropagation capabilities unmatched by any other means. In this paper, we\naddress an important issue regarding such simulations, namely how to define the\ninputs in terms of sky model and instrument parameters. These may either be\ntaken as a constrained realization derived from the data, or as a random\nrealization independent from the data. We refer to these as Bayesian and\nfrequentist simulations, respectively. We show that the two options lead to\nsignificantly different correlation structures, as frequentist simulations,\ncontrary to Bayesian simulations, effectively include cosmic variance, but\nexclude realization-specific correlations from non-linear degeneracies.\nConsequently, they quantify fundamentally different types of uncertainties, and\nwe argue that they therefore also have different and complementary scientific\nuses, even if this dichotomy is not absolute. Before BeyondPlanck, most\npipelines have used a mix of constrained and random inputs, and used the same\nhybrid simulations for all applications, even though the statistical\njustification for this is not always evident. BeyondPlanck represents the first\nend-to-end CMB simulation framework that is able to generate both types of\nsimulations, and these new capabilities have brought this topic to the\nforefront. The Bayesian BeyondPlanck simulations and their uses are described\nextensively in a suite of companion papers. In this paper we consider one\nimportant applications of the corresponding frequentist simulations, namely\ncode validation. That is, we generate a set of 1-year LFI 30 GHz frequentist\nsimulations with known inputs, and use these to validate the core low-level\nBeyondPlanck algorithms; gain estimation, correlated noise estimation, and\nmapmaking.\n", "  We evaluate the performance of the Lyman-$\\alpha$ forest weak gravitational\nlensing estimator of Metcalf et al. on forest data from hydrodynamic\nsimulations and ray-traced simulated lensing potentials. We compare the results\nto those obtained from the Gaussian random field simulated Ly$\\alpha$ forest\ndata and lensing potentials used in previous work. We find that the estimator\nis able to reconstruct the lensing potentials from the more realistic data, and\ninvestigate dependence on spectrum signal to noise. The non-linearity and\nnon-Gaussianity in this forest data arising from gravitational instability and\nhydrodynamics causes a reduction in signal to noise by a factor of $\\sim2.7$\nfor noise free data and a factor of $\\sim 1.5$ for spectra with signal to noise\nof order unity (comparable to current observational data). Compared to Gaussian\nfield lensing potentials, using ray-traced potentials from N-body simulations\nincurs a further signal to noise reduction of a factor of $\\sim1.3$ at all\nnoise levels. The non-linearity in the forest data is also observed to increase\nbias in the reconstructed potentials by $5-25\\%$, and the ray-traced lensing\npotential further increases the bias by $20-30\\%$. We demonstrate methods for\nmitigating these issues including Gaussianization and bias correction which\ncould be used in real observations.\n", "  We present CosmoGridV1: a large set of lightcone simulations for map-level\ncosmological inference with probes of large scale structure. It is designed for\ncosmological parameter measurement based on Stage-III photometric surveys with\nnon-Gaussian statistics and machine learning. CosmoGridV1 spans the $w$CDM\nmodel by varying $\\Omega_m$, $\\sigma_8$, $w_0$, $H_0$, $n_s$, $\\Omega_b$, and\nassumes three degenerate neutrinos with $\\sum m_\\nu$ = 0.06 eV. This space is\ncovered by 2500 grid points on a Sobol sequence. At each grid point, we run 7\nsimulations with PkdGrav3 and store 69 particle maps at nside=2048 up to\n$z$=3.5, as well as halo catalog snapshots. The fiducial cosmology has 200\nindependent simulations, along with their stencil derivatives. An important\npart of CosmoGridV1 is the benchmark set of 28 simulations, which include\nlarger boxes, higher particle counts, and higher redshift resolution of shells.\nThey allow for testing if new types of analyses are sensitive to choices made\nin CosmoGridV1. We add baryon feedback effects on the map level, using\nshell-based baryon correction model. The shells are used to create maps of weak\ngravitational lensing, intrinsic alignment, and galaxy clustering, using the\nUFalcon code. The main part of CosmoGridV1 are the raw particle count shells\nthat can be used to create full-sky maps for a given $n(z)$. We also release\nprojected maps for a Stage-III forecast, as well as maps used previously in\nKiDS-1000 deep learning constraints with CosmoGridV1. The data is available at\nwww.cosmogrid.ai.\n", "  We consider the possibility of primordial black hole, PBH, formation sourced\nby a rise in the power spectrum. The power spectrum becomes large at late times\ndue to decay of the inflaton into vectors through a $\\phi F \\tilde{F}$\ncoupling. Two background inflaton models which are well supported by current\nPlanck data are considered, natural inflation and hilltop inflation. Many of\nthe papers considering formation of PBHs have considered a peaked power\nspectrum where $P_{\\zeta}$ gets small again at late times. This avoids\noverproducing miniature PBHs which would evaporate and could violate BBN and\nCMB bounds. This paper examines the other way of avoiding these bounds,\nproducing PBHs from perturbations formed closer to the end of inflation such\nthat the PBHs are too small to violate these bounds. This has the advantage of\nallowing for simpler models in that no additional feature is needed to be added\nto evade constraints. Although these black holes would have evaporated, they\ncan be close to without exceeding current BBN bounds, making it possible the\nsignature will be revealed in the future. We calculate how the various model\nparameters affect the mass and number of PBHs produced. Any evidence for PBHs\nsourced from an inflationary power spectrum would provide evidence for\ninflation on a drastically different energy scale from the CMB, and thus would\nbe highly valuable in answering what occurred during inflation.\n", "  We present an alternative calibration of the MagLim lens sample redshift\ndistributions from the Dark Energy Survey (DES) first three years of data (Y3).\nThe new calibration is based on a combination of a Self-Organising Maps based\nscheme and clustering redshifts to estimate redshift distributions and inherent\nuncertainties, which is expected to be more accurate than the original DES Y3\nredshift calibration of the lens sample. We describe in detail the methodology,\nwe validate it on simulations and discuss the main effects dominating our error\nbudget. The new calibration is in fair agreement with the fiducial DES Y3\nredshift distributions calibration, with only mild differences ($<3\\sigma$) in\nthe means and widths of the distributions. We study the impact of this new\ncalibration on cosmological constraints, analysing DES Y3 galaxy clustering and\ngalaxy-galaxy lensing measurements, assuming a $\\Lambda$CDM cosmology. We\nobtain $\\Omega_{\\rm m} = 0.30\\pm 0.04$, $\\sigma_8 = 0.81\\pm 0.07 $ and $S_8 =\n0.81\\pm 0.04$, which implies a $\\sim 0.4\\sigma$ shift in the $\\Omega_{\\rm}-S_8$\nplane compared to the fiducial DES Y3 results, highlighting the importance of\nthe redshift calibration of the lens sample in multi-probe cosmological\nanalyses.\n", "  We investigate impacts of long-wavelength gravitational waves (GWs) on\nnonlinear structure formation by utilizing the tidal separate universe\nsimulations. Based on the equivalence of a long-wavelength GW to a uniform\ntidal field in a local frame, we provide a way to incorporate a long-wavelength\nGW into the tidal separate universe simulation as an effective anisotropic\nexpansion. This methodology enables us to study effects of GWs on large-scale\nstructure efficiently. We measure the anisotropic imprint in the local power\nspectrum from the tidal separate universe simulations with GWs, which\ncorresponds to the scalar-scalar-tensor bispectrum in squeezed limit or the\nso-called power spectrum response to GWs. We also detect the halo tidal bias\ninduced by GWs from the response of the halo-matter cross-power spectrum to\nGWs, as well as the linear shape bias (or the linear alignment coefficient)\ninduced by GWs from the one-point function of the halo ellipticity. In contrast\nto the case of the tidal field induced by scalar perturbations, we discover\nthat the wavenumber dependence of the temporal evolution of GWs naturally\ncauses these biases to be scale-dependent. We also find that this scale\ndependence is well approximated by the second-order density induced by the\ncoupling between scalar and tensor perturbation. This highlights that the\nstructure formation, especially the process to determine the halo shape, is\nnonlocal in time. Our findings lay the foundation for predicting the impact of\nGWs on large-scale structure.\n", "  In this work we present the first results from a new ray-tracing tool to\ncalculate cosmological distances in the context of fully nonlinear general\nrelativity. We use this tool to study the ability of the general cosmographic\nrepresentation of luminosity distance, as truncated at third order in redshift,\nto accurately capture anisotropies in the \"true\" luminosity distance. We use\nnumerical relativity simulations of cosmological large-scale structure\nformation which are free from common simplifying assumptions in cosmology. We\nfind the general, third-order cosmography is accurate to within 1% for\nredshifts to z\\approx 0.034 when sampling scales strictly above 100 Mpc/h,\nwhich is in agreement with an earlier prediction. We find the inclusion of\nsmall-scale structure generally spoils the ability of the third-order\ncosmography to accurately reproduce the full luminosity distance for wide\nredshift intervals, as might be expected. For a simulation sampling small-scale\nstructures, we find a +/- 5% variance in the monopole of the ray-traced\nluminosity distance at z \\approx 0.02. Further, all 25 observers we study here\nsee a 9--20% variance in the luminosity distance across their sky at z \\approx\n0.03, which reduces to 2--5% by z \\approx 0.1. These calculations are based on\nsimulations and ray tracing which adopt fully nonlinear general relativity, and\nhighlight the potential importance of fair sky-sampling in low-redshift\nisotropic cosmological analysis.\n", "  We present new diagnostic metrics to probe the dynamical state of galaxy\nclusters. These novel metrics rely on the computation of the power spectra of\nthe matter and gas distributions and their cross-correlation derived from\ncluster observations. This analysis permits us to cross-correlate the\nfluctuations in the matter distribution, inferred from high-resolution lensing\nmass maps derived from Hubble Space Telescope (HST) data, with those derived\nfrom the emitted X-ray surface brightness distribution of the hot Intra-Cluster\nmedium (ICM) from the Chandra X-ray Observatory (CXO). These methodological\ntools allow us to quantify with unprecedented resolution the coherence with\nwhich the gas traces the mass and interrogate the assumption that the gas is in\nhydro-static equilibrium with the underlying gravitational potential. We\ncharacterize departures from equilibrium as a function of scale with a new\ngas-mass coherence parameter. The efficacy of these metrics is demonstrated by\napplying them to the analysis of two representative clusters known to be in\ndifferent dynamical states: the massive merging cluster Abell 2744, from the\nHST Frontier Fields (HSTFF) sample, and the dynamically relaxed cluster Abell\n383, from the Cluster Lensing And Supernova Survey with Hubble (CLASH) sample.\nUsing lensing mass maps in combination with archival Chandra data, and\nsimulated cluster analogs available from the OMEGA500 suite, we quantify the\nfluctuations in the mass and X-ray surface brightness and show that new\ninsights into the dynamical state of the clusters can be obtained from our\ngas-mass coherence analysis.\n", "  The amplitude of the metagalactic ultraviolet background (UVB) at\nlarge-scales is impacted by two factors. First, it naturally attenuates at\nscales larger than mean-free-path of UVB photons due to the absorption by\nneutral intergalactic medium. Second, there are discrete and rare ionizing\nsources distributing in the Universe, emitting the UVB photons, and thus\nenhancing the local UVB amplitude. Therefore, for cosmological probe that is\nsensitive to the UVB amplitude and capable of detecting the large scale like\nLyman-$\\alpha$ forest spectrum, the fluctuation due to the clustering of\nionizing sources becomes a significant factor for Lyman-$\\alpha$ flux\ntransmission and leave imprints on Lyman-$\\alpha$ flux power spectrum at these\nlarge scales. In this work, we make use of a radiative transfer model that\nparametrizes the UVB source distribution by its bias $b_{\\rm j}$ and shot noise\n$\\overline{n}_{\\rm j}$. We estimate the constraints on this model through the\ncross-correlation between Lyman-$\\alpha$ forest survey and galaxy survey, using\nthe DESI Lyman-$\\alpha$ forest survey and the Roman Space Telescope emission\nline galaxy survey as an example. We show the detection sensitivity improvement\nfor UVB parameters from disjoint to maximal overlap of DESI+Roman survey\nstrategy. We also show that the degeneracy of two ionizing source parameters\ncan be broken by increasing the overlapping survey area. Our results motivate\nsurvey strategies more dedicated to probe the UVB large-scale fluctuations.\n", "  Local primordial non-Gaussianity (PNG) is a promising observable of the\nunderlying physics of inflation, characterised by $f_{\\rm NL}^{\\rm loc}$. We\npresent the methodology to measure $f_{\\rm NL}^{\\rm loc}$ from the Dark Energy\nSurvey (DES) data using the 2-point angular correlation function (ACF) with\nscale-dependent bias. One of the focuses of the work is the integral\nconstraint. This condition appears when estimating the mean number density of\ngalaxies from the data and is key in obtaining unbiased $f_{\\rm NL}^{\\rm loc}$\nconstraints. The methods are analysed for two types of simulations: $\\sim 246$\nGOLIAT-PNG N-body small area simulations with $f_{\\rm NL}$ equal to -100 and\n100, and 1952 Gaussian ICE-COLA mocks with $f_{\\rm NL}=0$ that follow the DES\nangular and redshift distribution. We use the ensemble of GOLIAT-PNG mocks to\nshow the importance of the integral constraint when measuring PNG, where we\nrecover the fiducial values of $f_{\\rm NL}$ within the $1\\sigma$ when including\nthe integral constraint. In contrast, we found a bias of $\\Delta f_{\\rm NL}\\sim\n100$ when not including it. For a DES-like scenario, we forecast a bias of\n$\\Delta f_{\\rm NL} \\sim 23$, equivalent to $1.8\\sigma$, when not using the IC\nfor a fiducial value of $f_{\\rm NL}=100$. We use the ICE-COLA mocks to validate\nour analysis in a realistic DES-like setup finding it robust to different\nanalysis choices: best-fit estimator, the effect of IC, BAO damping,\ncovariance, and scale choices. We forecast a measurement of $f_{\\rm NL}$ within\n$\\sigma(f_{\\rm NL})=31$ when using the DES-Y3 BAO sample, with the ACF in the\n$1\\ {\\rm deg}<\\theta<20\\ {\\rm deg}$ range.\n", "  We use $N$-body simulations to study halo assembly bias (i.e., the dependence\nof halo clustering on properties beyond total mass) in the density and\nprimordial non-Gaussianity (PNG) linear bias parameters $b_1$ and $b_\\phi$,\nrespectively. We consider concentration, spin and sphericity as secondary halo\nproperties, for which we find a clear detection of assembly bias for $b_1$ and\n$b_\\phi$. At fixed total mass, halo spin and sphericity impact $b_1$ and\n$b_\\phi$ in a similar manner, roughly preserving the shape of the linear\n$b_\\phi(b_1)$ relation satisfied by the global halo population. Halo\nconcentration, however, drives $b_1$ and $b_\\phi$ in opposite directions. This\ninduces significant changes to the $b_\\phi(b_1)$ relation, with higher\nconcentration halos having higher amplitude of $b_\\phi(b_1)$. For $z=0.5$ and\n$b_1 \\approx 2$ in particular, the population comprising either all halos,\nthose with the $33\\%$ lowest or those with the $33\\%$ highest concentrations\nhave a PNG bias of $b_\\phi \\approx 3$, $b_\\phi \\approx -1$ and $b_\\phi \\approx\n9$, respectively. Varying the halo concentration can make $b_\\phi$ very small\nand even change its sign. These results have important ramifications for galaxy\nclustering constraints of the local PNG parameter $f_{\\rm NL}$ that assume\nfixed forms for the $b_\\phi(b_1)$ relation. We illustrate the significant\nimpact of halo assembly bias in actual data using the BOSS DR12 galaxy power\nspectrum: assuming that BOSS galaxies are representative of all halos, the\n$33\\%$ lowest or the $33\\%$ highest concentration halos yields $\\sigma_{f_{\\rm\nNL}} = 44, 165, 19$, respectively. Our results suggest taking host halo\nconcentration into account in galaxy selection strategies to maximize the\nsignal-to-noise on $f_{\\rm NL}$. They also motivate more simulation-based\nefforts to study the $b_\\phi(b_1)$ relation of halos and galaxies.\n", "  The precise estimation of the mass of galaxy clusters is a major issue for\ncosmology. Large galaxy cluster surveys rely on scaling laws that relate\ncluster observables to their masses. From the high resolution observations of ~\n45 galaxy clusters with NIKA2 and XMM-Newton instruments, the NIKA2 SZ Large\nProgram should provide an accurate scaling relation between the thermal\nSunyaev-Zel'dovich effect and the hydrostatic mass. In this paper, we present\nan exhaustive analysis of the hydrostatic mass of the well known galaxy cluster\nCL J1226.9+3332, the highest-redshift cluster in the NIKA2 SZ Large Program at\nz = 0.89. We combine the NIKA2 observations with thermal Sunyaev-Zel'dovich\ndata from NIKA, Bolocam and MUSTANG instruments and XMM-Newton X-ray\nobservations and test the impact of the systematic effects on the mass\nreconstruction. We conclude that slight differences in the shape of the mass\nprofile can be crucial when defining the integrated mass at R500, which\ndemonstrates the importance of the modeling in the mass determination. We prove\nthe robustness of our hydrostatic mass estimates by showing the agreement with\nall the results found in the literature. Another key information for cosmology\nis the bias of the masses estimated assuming hydrostatic equilibrium\nhypothesis. Based on the lensing convergence maps from the Cluster Lensing And\nSupernova survey with Hubble (CLASH) data, we obtain the lensing mass estimate\nfor CL J1226.9+3332. From this we are able to measure the\nhydrostatic-to-lensing mass bias for this cluster, that spans from 1 -\nbHSE/lens ~ 0.7 to 1, presenting the impact of data-sets and mass\nreconstruction models on the bias.\n", "  The measurement of the large scale distribution of neutral hydrogen in the\nlate Universe, obtained with radio telescopes through the hydrogen 21cm line\nemission, has the potential to become a key cosmological probe in the upcoming\nyears. We explore the constraining power of 21cm intensity mapping observations\non the full set of cosmological parameters that describe the $\\Lambda$CDM\nmodel. We assume a single-dish survey for the SKA Observatory and simulate the\n21cm linear power spectrum monopole and quadrupole within six redshift bins in\nthe range $z=0.25-3$. Forecasted constraints are computed numerically through\nMarkov Chain Monte Carlo techniques. We extend the sampler \\texttt{CosmoMC} by\nimplementing the likelihood function for the 21cm power spectrum multipoles. We\nassess the constraining power of the mock data set alone and combined with\nPlanck 2018 CMB observations. We include a discussion on the impact of\nextending measurements to non-linear scales in our analysis. We find that 21cm\nmultipoles observations alone are enough to obtain constraints on the\ncosmological parameters comparable with other probes. Combining the 21cm data\nset with CMB observations results in significantly reduced errors on all the\ncosmological parameters. The strongest effect is on $\\Omega_ch^2$ and $H_0$,\nfor which the error is reduced by almost a factor four. The percentage errors\nwe estimate are $\\sigma_{\\Omega_ch^2} = 0.25\\%$ and $\\sigma_{H_0} = 0.16\\%$, to\nbe compared with the Planck only results $\\sigma_{\\Omega_ch^2} = 0.99\\%$ and\n$\\sigma_{H_0} = 0.79\\%$. We conclude that 21cm SKAO observations will provide a\ncompetitive cosmological probe, complementary to CMB and, thus, pivotal for\ngaining statistical significance on the cosmological parameters constraints,\nallowing a stress test for the current cosmological model.\n", "  The power spectrum of cosmic microwave background lensing is a powerful tool\nfor constraining fundamental physics such as the sum of neutrino masses and the\ndark energy equation of state. Current lensing measurements primarily come from\ndistortions to the microwave background temperature field, but the polarization\nlensing signal will dominate upcoming experiments with greater sensitivity.\nCosmic birefringence refers to the rotation of the linear polarization\ndirection of microwave photons propagating from the last scattering surface to\nus, which can be induced by parity-violating physics such as axion-like dark\nmatter or primordial magnetic fields. We find that, for an upcoming CMB-S4-like\nexperiment, if there exists the scale-invariant anisotropic birefringence with\nan amplitude corresponding to the current $95\\%$ upper bound, the measured\nlensing power spectrum could be biased by up to a factor of few at small\nscales, $L\\gtrsim 1000$. We show that the bias scales linearly with the\namplitude of the scale-invariant birefringence spectrum. The signal-to-noise of\nthe contribution from anisotropic birefringence is larger than unity even if\nthe birefringence amplitude decreases to $\\sim 5\\%$ of the current upper bound.\nOur results indicate that a measurement and characterization of the anisotropic\nbirefringence is important for lensing analysis in future low-noise\npolarization experiments.\n", "  Galaxy surveys provide one of the best ways to constrain the theory of\ngravity at cosmological scales. They can be used to constrain the two\ngravitational potentials encoding time, $\\Psi$, and spatial, $\\Phi$,\ndistortions, which are exactly equal at late time within general relativity.\nHence, any small variation leading to a nonzero anisotropic stress, i.e. a\ndifference between these potentials, would be an indication for modified\ngravity. Current analyses usually consider gravitational lensing and\nredshift-space distortions to constrain the anisotropic stress, but these rely\non certain assumptions like the validity of the weak equivalence principle, and\na specific time evolution of the functions encoding deviations from general\nrelativity. In this work, we propose a reparametrization of the gravitational\nlensing observable, together with the use of the relativistic dipole of the\ncorrelation function of galaxies to directly measure the anisotropic stress\nwith a minimum amount of assumptions. We consider the future Legacy Survey of\nSpace and Time of the Vera C. Rubin Observatory and the future Square Kilometer\nArray, and show that combining gravitational lensing and gravitational redshift\nwith the proposed approach we will achieve model-independent constraints on the\nanisotropic stress at the level of $\\sim 20\\,\\%$.\n", "  Local measurements of the Hubble constant ($H_0$) based on Cepheids e Type Ia\nsupernova differ by $\\approx 5 \\sigma$ from the estimated value of $H_0$ from\nPlanck CMB observations under $\\Lambda$CDM assumptions. In order to better\nunderstand this $H_0$ tension, the comparison of different methods of analysis\nwill be fundamental to interpret the data sets provided by the next generation\nof surveys. In this paper, we deploy machine learning algorithms to measure the\n$H_0$ through a regression analysis on synthetic data of the expansion rate\nassuming different values of redshift and different levels of uncertainty. We\ncompare the performance of different regression algorithms as Extra-Trees,\nArtificial Neural Network, Gradient Boosting, Support Vector Machines, and we\nfind that the Support Vector Machine exhibits the best performance in terms of\nbias-variance tradeoff in most cases, showing itself a competitive cross-check\nto non-supervised regression methods such as Gaussian Processes.\n", "  We study the effect of magnification in the Dark Energy Survey Year 3\nanalysis of galaxy clustering and galaxy-galaxy lensing, using two different\nlens samples: a sample of Luminous red galaxies, redMaGiC, and a sample with a\nredshift-dependent magnitude limit, MagLim. We account for the effect of\nmagnification on both the flux and size selection of galaxies, accounting for\nsystematic effects using the Balrog image simulations. We estimate the impact\nof magnification on the galaxy clustering and galaxy-galaxy lensing cosmology\nanalysis, finding it to be a significant systematic for the MagLim sample. We\nshow cosmological constraints from the galaxy clustering auto-correlation and\ngalaxy-galaxy lensing signal with different magnifications priors, finding\nbroad consistency in cosmological parameters in $\\Lambda$CDM and $w$CDM.\nHowever, when magnification bias amplitude is allowed to be free, we find the\ntwo-point correlations functions prefer a different amplitude to the fiducial\ninput derived from the image simulations. We validate the magnification\nanalysis by comparing the cross-clustering between lens bins with the\nprediction from the baseline analysis, which uses only the auto-correlation of\nthe lens bins, indicating systematics other than magnification may be the cause\nof the discrepancy. We show adding the cross-clustering between lens redshift\nbins to the fit significantly improves the constraints on lens magnification\nparameters and allows uninformative priors to be used on magnification\ncoefficients, without any loss of constraining power or prior volume concerns.\n", "  Observations of the Lyman-$\\alpha$ (Ly$\\alpha$) forest from spectroscopic\nsurveys such as BOSS/eBOSS, or the ongoing DESI, offer a unique window to study\nthe growth of structure on megaparsec scales. Interpretation of these\nmeasurements is a complicated task, requiring hydrodynamical simulations to\nmodel and marginalise over the thermal and ionisation state of the\nintergalactic medium. This complexity has limited the use of Ly$\\alpha$\nclustering measurements in joint cosmological analyses. In this work we show\nthat the cosmological information content of the 1D power spectrum\n($P_\\mathrm{1D}$) of the Ly$\\alpha$ forest can be compressed into a simple\ntwo-parameter likelihood without any significant loss of constraining power. We\nsimulate $P_\\mathrm{1D}$ measurements from DESI using hydrodynamical\nsimulations and show that the compressed likelihood is model independent and\nlossless, recovering unbiased results even in the presence of massive neutrinos\nor running of the primordial power spectrum.\n", "  In the next decade, radio telescopes like the Square Kilometer Array (SKA)\nwill explore the Universe at high redshift, and particularly during the Epoch\nof Reionisation (EoR). The first structures emerged during this epoch, and\ntheir radiations have reionised the previously cold and neutral gas of the\nUniverse creating ionised bubbles that percolate at the end of the EoR (at a\nredshift of approximately 6). SKA will produce 2D images of the distribution of\nthe neutral gas at many redshifts, pushing us to develop tools and simulations\nto understand its properties. This paper aims at measuring topological\nstatistics of the EoR in the \"reionisation times\" fields from both cosmological\nand semi-analytical simulations. This field informs us about the time of\nreionisation of the gas at each position, is used to probe the inhomogeneities\nof reionisation histories and can possibly be extracted from 21 cm maps. We\nalso compare these measurements with analytical predictions from the gaussian\nrandom field (GRF) theory. The GRF theory allows us to compute many statistics\nof a field: PDFs of the field or its gradient, isocontour length, critical\npoint distributions, and skeleton length. We compare these theoretical\npredictions to measurements made on reionisation time fields extracted from an\nEMMA and a 21cmFAST simulations at 1 a cMpc/h resolution. We also compared our\nresults to GRFs generated from the fitted power spectra of the simulation maps.\nBoth EMMA and 21cmFAST reionisation time fields (treion(r)) are close to be\ngaussian fields, in contrast with the 21 cm, density or ionisation fraction\nthat are all proven to be non-gaussian. Only accelerating ionisation fronts at\nthe end of the EoR seem to be a cause of small non-gaussianities in treion(r).\nOverall our results indicate that an analytical description of the reionisation\npercolation can be reasonably made within the framework of GRF theory.\n", "  One of the open issues of the standard cosmological model is the value of the\ncosmic dipole measured from the Cosmic Microwave Background (CMB), as well as\nfrom the number count of quasars and radio sources. These measurements are\ncurrently in tension, with the number count dipole being 2-5 times larger than\nexpected from CMB measurements. This discrepancy has been pointed out as a\npossible indication that the cosmological principle is not valid. In this\npaper, we explore the possibility of detecting and estimating the cosmic dipole\nwith gravitational waves (GWs) from compact binary mergers detected by the\nfuture next-generation detectors Einstein Telescope and Cosmic Explorer. We\nmodel the expected signal and show that for binary black holes, the dipole\namplitude in the number count of detections is independent of the\ncharacteristics of the population and provides a systematic-free tool to\nestimate the observer velocity. We introduce techniques to detect the cosmic\ndipole from number counting of GW detections and estimate its significance. We\nshow that a GW dipole consistent with the amplitude of the dipole in radio\ngalaxies would be detectable with $>3\\sigma$ significance with a few years of\nobservation ($10^6$ GW detections) and estimated with a $16\\%$ precision, while\na GW dipole consistent with the CMB one would require at least $10^7$ GW events\nfor a confident detection. We also demonstrate that a total number $N_{\\rm\ntot}$ of GW detections would be able to detect a dipole with amplitude $v_o/c\n\\simeq1/\\sqrt{N_{\\rm tot}}$.\n", "  One of the major goals of future cosmic microwave background (CMB) $B$-mode\npolarization experiments is the detection of primordial gravitational waves\nthrough an unbiased measurement of the tensor-to-scalar ratio $r$. Robust\ndetection of this signal will require mitigating all possible contamination to\nthe $B$-mode polarization from astrophysical origins. One such extragalactic\ncontamination arises from the patchiness in the electron density during the\nreionization epoch. Along with the signature on CMB polarization, the patchy\nreionization can source secondary anisotropies on the CMB temperature through\nthe kinetic Sunyaev-Zeldovich (kSZ) effect. In order to study the impact of\nthis foreground for the upcoming CMB missions, we present a self-consistent\nframework to compute the CMB anisotropies based on a physically motivated model\nof reionization. We show that the value of $r$ can bias towards a higher value\nif the secondary contribution from reionization is neglected. However,\ncombining small-scale kSZ signal, large-scale $E$-mode polarization, and\n$B$-mode polarization measurements, we can put constraints on the patchiness in\nelectron density during reionization and can mitigate its impact on the value\nof $r$. CMB missions such as CMB-S4 and PICO may experience a bias of\n$>0.17\\sigma$ which can go as high as $\\sim 0.73\\sigma$ for extreme\nreionization models allowed by the Planck and SPT CMB measurements. As future\nexperiments target to measure $r$ at $5\\sigma$, this is likely to affect the\nmeasurement significance and hence possibly affect the claim of detection of\n$r$, if not mitigated properly by using joint estimations of different\nreionization observables.\n", "  The velocity of the Sun with respect to the cosmic microwave background (CMB)\ncan be extracted from the CMB dipole, provided its intrinsic dipole is assumed\nto be small in comparison. This interpretation is consistent, within fairly\nlarge error bars, with the measurement of the correlations between neighboring\nCMB multipoles induced by the velocity of the observer, which effectively\nbreaks isotropy. In contrast, the source number count dipole was reported to\nprivilege a velocity of the observer with an amplitude which is about twice as\nlarge as the one extracted from the entirely kinematic interpretation of the\nCMB dipole, with error bars which indicate a more and more significant tension.\nIn this work, we study the effect of the peculiar velocity of the observer on\ncorrelations of nearby multipoles in the source number counts. We provide an\nunbiased estimator for the kinetic dipole amplitude, which is proportional to\nthe peculiar velocity of the observer and we compute the expected signal to\nnoise ratio. Near future experiments can achieve better than 5$\\%$ constraints\non the velocity of the Sun with our estimator.\n", "  The three-dimensional distribution of the Ly$\\alpha$ forest has been\nextensively used to constrain cosmology through measurements of the baryon\nacoustic oscillations (BAO) scale. However, more cosmological information could\nbe extracted from the full shapes of the Ly$\\alpha$ forest correlations through\nthe Alcock-Paczy\\'nski (AP) effect. In this work, we prepare for a cosmological\nanalysis of the full shape of the Ly$\\alpha$ forest correlations by studying\nsynthetic data of the extended Baryon Oscillation Spectroscopic Survey (eBOSS).\nWe use a set of one hundred eBOSS synthetic data sets in order to validate such\nan analysis. These mocks undergo the same analysis process as the real data. We\nperform a full-shape analysis on the mean of the correlation functions measured\nfrom the one hundred eBOSS realizations, and find that our model of the\nLy$\\alpha$ correlations performs well on current data sets. We show that we are\nable to obtain an unbiased full-shape measurement of $D_M/D_H(z_\\mathrm{eff})$,\nwhere $D_M$ is the transverse comoving distance, $D_H$ is the Hubble distance,\nand $z_\\mathrm{eff}$ is the effective redshift of the measurement. We test the\nfit over a range of scales, and decide to use a minimum separation of\n$r_\\mathrm{min}=25\\ h^{-1}\\text{Mpc}$. We also study and discuss the impact of\nthe main contaminants affecting Ly$\\alpha$ forest correlations, and give\nrecommendations on how to perform such analysis with real data. While the final\neBOSS Ly$\\alpha$ BAO analysis measured $D_M/D_H(z_\\mathrm{eff}=2.33)$ with\n$4\\%$ statistical precision, a full-shape fit of the same correlations could\nprovide a $\\sim2\\%$ measurement.\n", "  We explore a re-parameterization of the lensing amplitude tension between\nweak lensing (WL) and cosmic microwave background (CMB) data and its\nimplications for a joint resolution with the Hubble tension. Specifically, we\nfocus on the lensing amplitude over a scale of 12 Mpc in absolute distance\nunits using a derived parameter $S_{12}$ and show its constraints from recent\nsurveys in comparison with Planck 2018. In WL alone, we find that the absolute\ndistance convention correlates $S_{12}$ with $H_0$. Accounting for this\ncorrelation in the 3D space $S_{12}\\times \\omega_m \\times h$ reproduces the\nusual levels of $2\\sim 3\\sigma$ tension inferred from $S_8\\times\\Omega_m$.\nAdditionally, we derive scaling relations in the $S_8\\times h$ and\n$S_{12}\\times h$ planes that are allowed by $\\Lambda$CDM and extrapolate target\nscalings needed to solve the $H_0$ and lensing-amplitude tensions jointly in a\nhypothetical beyond-$\\Lambda$CDM model. As a test example, we quantify how the\nearly dark energy scenario compares with these target scalings. Useful fitting\nformulae for $S_8$ and $S_{12}$ as a function of other cosmological parameters\nin $\\Lambda$CDM are provided, with 1% precision.\n", "  We determine the product of the expansion rate and angular-diameter distance\nat redshift $z=2.3$ from the anisotropy of Lyman-$\\alpha$ (Ly$\\alpha$) forest\ncorrelations measured by the Sloan Digital Sky Survey (SDSS). Our result is the\nmost precise from large-scale structure at $z>1$. In flat $\\Lambda$CDM we\ndetermine the matter density to be $\\Omega_\\mathrm{m}=0.36^{+0.03}_{-0.04}$\nfrom Ly$\\alpha$ alone. This is a factor of two tighter than baryon acoustic\noscillation results from the same data due to our use of a wide range of scales\n($25<r<180$ $h^{-1}\\text{Mpc}$). Using a nucleosynthesis prior, we measure the\nHubble constant to be $H_0=63.2\\pm2.5$ km/s/Mpc. In combination with other SDSS\ntracers, we find $H_0=67.2\\pm0.9$ km/s/Mpc and measure the dark energy\nequation-of-state parameter to be $w=-0.90\\pm0.12$. Our work opens a new avenue\nfor constraining cosmology at high redshift.\n", "  We study the global agreement between the most recent observations of the\nCosmic Microwave Background temperature and polarization anisotropies angular\npower spectra released by the Atacama Cosmology Telescope and the Planck\nsatellite in various cosmological models that differ by the inclusion of\ndifferent combinations of additional parameters. By using the Suspiciousness\nstatistic, we show that the global \"CMB tension\" between the two experiments,\nquantified at the Gaussian equivalent level of $\\sim 2.5\\,\\sigma$ within the\nbaseline $\\Lambda$CDM, is reduced at the level of $1.8\\sigma$ when the\neffective number of relativistic particles ($N_{\\rm eff}$) is significantly\nless than the standard value, while it ranges between $2.3\\,\\sigma$ and\n$3.5\\,\\sigma$ in all the other extended models.\n", "  We present a methodology for constructing modified gravity (MG) constrained\nsimulations of the local Universe using positions and peculiar velocities from\nthe CosmicFlows data set. Our analysis focuses on the following MG models: the\nnormal branch of the Dvali-Gabadadze-Porrati (nDGP) model and Hu-Sawicki $f(R)$\nmodel. We develop a model independent methodology for constructing constrained\nsimulations with any given power spectra and numerically calculated linear\ngrowth functions. Initial conditions (ICs) for a set of constrained simulations\nare constructed for the standard cosmological model $\\Lambda$CDM and the MG\nmodels. Differences between the model's reconstructed Wiener filtered density\nand the resultant simulation density are presented showing the importance for\nthe generation of MG constrained ICs to study the subtle effects of MG in the\nlocal Universe. These are the first MG constrained simulations ever produced.\nThe current work paves the way to improved approximate methods for models with\nscale-dependent growth functions, such as $f(R)$, and for high-resolution\nhydrodynamical MG zoom-in simulations of the local Universe.\n", "  Super-sample covariance (SSC) is an important effect for cosmological\nanalyses that use the deep structure of the cosmic web; it may, however, be\nnontrivial to include it practically in a pipeline. We solve this difficulty by\npresenting a formula for the precision (inverse covariance) matrix and show\napplications to update likelihood or Fisher forecast pipelines. The formula has\nseveral advantages in terms of speed, reliability, stability, and ease of\nimplementation. We present an analytical application to show the formal\nequivalence between three approaches to SSC: (i) at the usual covariance level,\n(ii) at the likelihood level, and (iii) with a quadratic estimator. We then\npresent an application of this computationally efficient framework for studying\nthe impact of inaccurate modelling of SSC responses for cosmological\nconstraints from stage IV surveys. We find that a weak-lensing-only analysis is\nvery sensitive to inaccurate modelling of the scale dependence of the response,\nwhich needs to be calibrated at the $\\sim15\\%$ level. The sensitivity to this\nscale dependence is less severe for the joint weak-lensing and galaxy\nclustering analysis (also known as 3x2pt). Nevertheless, we find that both the\namplitude and scale-dependence of the responses have to be calibrated at better\nthan 30\\%.\n", "  We embed linear and nonlinear parametrisations of beyond standard\ncosmological physics in the halo model reaction framework, providing a\nmodel-independent prescription for the nonlinear matter power spectrum. As an\napplication, we focus on Horndeski theories, using the Effective Field Theory\nof Dark Energy (EFTofDE) to parameterise linear and quasi-nonlinear\nperturbations. In the nonlinear regime we investigate both a nonlinear\nparameterised-post Friedmannian (nPPF) approach as well as a physically\nmotivated and approximate phenomenological model based on the error function\n(Erf). We compare the parameterised approaches' predictions of the nonlinear\nmatter power spectrum to the exact solutions, as well as state-of-the-art\nemulators, in an evolving dark energy scenario and two well studied modified\ngravity models, finding sub-percent agreement in the reaction using the Erf\nmodel at $z\\leq1$ and $k\\leq 5~h/{\\rm Mpc}$. This suggests only an additional 3\nfree constants, above the background and linear theory parameters, are\nsufficient to model nonlinear, non-standard cosmology in the matter power\nspectrum at scales down to $k \\leq 3h~/{\\rm Mpc}$ within $2\\%$ accuracy. We\nimplement the parametrisations into ver.2.0 of the ReACT code.\n", "  21 cm intensity mapping (IM) has the potential to be a strong and unique\nprobe of cosmology from redshift of order unity to redshift potentially as high\nas 30. For post-reionization 21 cm observations, the signal is modulated by the\nthermal and dynamical reaction of gas in the galaxies to the passage of\nionization fronts during the Epoch of Reionization. In this work, we\ninvestigate the impact of inhomogeneous reionization on the post-reionization\n21 cm power spectrum and the induced shifts of cosmological parameters at\nredshifts $3.5 \\lesssim z \\lesssim 5.5$. We make use of hydrodynamics\nsimulations that could resolve small-scale baryonic structure evolution to\nquantify HI abundance fluctuation, while semi-numerical large box 21cmFAST\nsimulations capable of displaying inhomogeneous reionization process are\ndeployed to track the inhomogeneous evolution of reionization bubbles. We\ndiscussed the prospects of capturing this effect in two post-reionization 21 cm\nintensity mapping experiments: SKA1-LOW and PUMA. We find the inhomogeneous\nreionization effect could impact the HI power spectrum up to tens of percent\nlevel and shift cosmological parameters estimation from sub-percent to tens\npercent in the observation of future post-reionization 21 cm intensity mapping\nexperiments such as PUMA, while SKA1-LOW is likely to miss this effect at the\nredshifts of interest given the considered configuration. In particular, the\nshift is up to 0.0206 in the spectral index $n_s$ and 0.0192 eV in the sum of\nthe neutrino masses $\\sum m_\\nu$ depending on the reionization model and the\nobservational parameters. We discuss strategies to mitigate and separate these\nbiases.\n", "  We use the Magneticum suite of state-of-the-art hydrodynamical simulations to\nidentify cosmic voids based on the watershed technique and investigate their\nmost fundamental properties across different resolutions in mass and scale.\nThis encompasses the distributions of void sizes, shapes, and content, as well\nas their radial density and velocity profiles traced by the distribution of\ncold dark matter particles and halos. We also study the impact of various\ntracer properties, such as their sparsity and mass, and the influence of void\nmerging on these summary statistics. Our results reveal that all of the\nanalyzed void properties are physically related to each other and describe\nuniversal characteristics that are largely independent of tracer type and\nresolution. Most notably, we find that the motion of tracers around void\ncenters is perfectly consistent with linear dynamics, both for individual, as\nwell as stacked voids. Despite the large range of scales accessible in our\nsimulations, we are unable to identify the occurrence of nonlinear dynamics\neven inside voids of only a few Mpc in size. This suggests voids to be among\nthe most pristine probes of cosmology down to scales that are commonly referred\nto as highly nonlinear in the field of large-scale structure.\n", "  Context. The physical state of most of the baryonic matter in the local\nuniverse is unknown, which is commonly referred to as the ``missing baryon\nproblem\". It is theorized that at least half of these missing baryons are in a\nwarm-hot, low-density phase outside of the virialized dark-matter halos.\n  Aims. We make an attempt to find the signature of this warm-hot intergalactic\nmedium (WHIM) phase in the filaments of the nearby Virgo cluster by using\noptical and Sunyaev-Zeldovich effect data.\n  Methods. Specifically, we use a filament-galaxy catalog created from the\nHyperLeda database and an all-sky Compton-y map extracted from the Planck\nsatellite data for 2-dimensional cross-correlation analysis by applying\nspherical harmonics transform. Significance test is based on the null-test\nsimulations which exploits advanced cut-sky analysis tools for a proper map\nreconstruction. To place upper limits on the WHIM density in the Virgo\nfilaments, realistic baryonic density modelling within the cosmic filaments is\ndone based on state-of-the-art hydro-simulations, and it's done within the\nsignal-boosting routine.\n  Results. The cross-correlation signal is found to be too dim compared to the\nnoise level in the Planck y-map. At 3$\\sigma$ confidence level, the upper limit\non volume-average WHIM density turns out to be $\\left\\langle n_e \\right\\rangle\n\\lt 4\\times10^{-4} cm^{-3}$, which is indeed consistent with the WHIM parameter\nspace as predicted from simulations.\n", "  We present the first clustering measurement of Strong Blended Lyman $\\alpha$\n(SBLA) absorption systems by measuring their cross-correlation with the Lyman\n$\\alpha$ forest. SBLAs are a new population of absorbers detected within the\nLyman $\\alpha$ forest. We find a bias of $2.329\\pm0.057$, consistent with that\nof Damped Lyman $\\alpha$ absorbers (DLAs). For DLAs, we recover a bias of\n$2.331\\pm0.057$ larger than previously reported (P\\'erez-R\\`afols et al.\n2018b). We also find a redshift space distortion parameter\n$\\beta=0.417\\pm0.010$, also consistent with the recovered value for DLAs\n($\\beta=0.416\\pm0.010$). This is consistent with SBLA and DLA systems tracing\ndifferent portions of the circumgalactic medium of a broadly common population\nof galaxies. Given these common clustering properties, we combined them to\nperform a cross-correlation of galaxies in absorption with the Ly$\\alpha$\nforest. We find that the BAO scale uncertainty of this new measurement is\n$1.75\\times$ that of Ly$\\alpha$ auto-correlation and $1.6\\times$ that of the\nquasar cross-correlation with the Ly$\\alpha$ forest. We note that the current\npreferred metal contamination model for fitting the correlation functions with\nrespect to the Ly$\\alpha$ forest is not realistic enough for SBLA systems,\nlikely due to their status as high redshift precision sites of high metal\nenrichment. Mock spectra including SBLA systems and their associated metal\nabsorption are required to understand this sample fully. We conclude that SBLAs\nhave the potential to complement the standard Ly$\\alpha$ cosmological analyses\nin future surveys.\n", "  We present a method for mapping variations between probability distribution\nfunctions and apply this method within the context of measuring galaxy redshift\ndistributions from imaging survey data. This method, which we name PITPZ for\nthe probability integral transformations it relies on, uses a difference in\ncurves between distribution functions in an ensemble as a transformation to\napply to another distribution function, thus transferring the variation in the\nensemble to the latter distribution function. This procedure is broadly\napplicable to the problem of uncertainty propagation. In the context of\nredshift distributions, for example, the uncertainty contribution due to\ncertain effects can be studied effectively only in simulations, thus\nnecessitating a transfer of variation measured in simulations to the redshift\ndistributions measured from data. We illustrate the use of PITPZ by using the\nmethod to propagate photometric calibration uncertainty to redshift\ndistributions of the Dark Energy Survey Year 3 weak lensing source galaxies.\nFor this test case, we find that PITPZ yields a lensing amplitude uncertainty\nestimate due to photometric calibration error within 1 per cent of the truth,\ncompared to as much as a 30 per cent underestimate when using traditional\nmethods.\n", "  Early dark energy (EDE) models have attracted attention in the context of the\nrecent problem of the Hubble tension. Here we extend these models by taking\ninto account the new density fluctuations generated by the EDE which decays\naround the recombination phase. We solve the evolution of the density\nperturbations in dark energy fluid generated at the phase transition of EDE as\nisocurvature perturbations. Assuming that the isocurvature mode is\ncharacterized by a power-law power spectrum and is uncorrelated with the\nstandard adiabatic mode, we calculate the CMB angular power spectra. By\ncomparing them to the Planck data using the Markov-Chain Monte Carlo method, we\nobtained zero-consistent values of the EDE parameters and\n$H_0=67.56^{+0.65}_{-0.66}~\\mathrm{km} \\, \\mathrm{s}^{-1} \\mathrm{Mpc}^{-1}$ at\n$68 \\%$ CL. This $H_0$ value is almost the same as the Planck value in the\n$\\Lambda$CDM model, $H_0=67.36 \\pm 0.54~\\mathrm{km} \\, \\mathrm{s}^{-1}\n\\mathrm{Mpc}^{-1}$, and there is still a $\\sim 3.5 \\sigma$ tension between the\nCMB and Type Ia supernovae observations. Including CMB lensing, BAO, supernovae\nand SH0ES data sets, we find $H_0=68.94^{+0.47}_{-0.57}~\\mathrm{km} \\,\n\\mathrm{s}^{-1} \\mathrm{Mpc}^{-1}$ at $68 \\%$ CL. The amplitude of the\nfluctuations induced by the phase transition of the EDE is constrained to be\nless than $1$--$2$ percent of the amplitude of the adiabatic mode. This is so\nsmall that such non-standard fluctuations cannot appear in the CMB angular\nspectra. In conclusion, the isocurvature fluctuations induced by our simplest\nEDE phase transition model do not explain the Hubble tension well.\n", "  We present the first systematic follow-up of Planck Sunyaev-Zeldovich effect\n(SZE) selected candidates down to signal-to-noise (S/N) of 3 over the 5000\ndeg$^2$ covered by the Dark Energy Survey. Using the MCMF cluster confirmation\nalgorithm, we identify optical counterparts, determine photometric redshifts\nand richnesses and assign a parameter, $f_{\\rm cont}$, that reflects the\nprobability that each SZE-optical pairing represents a random superposition of\nphysically unassociated systems rather than a real cluster. The new PSZ-MCMF\ncluster catalogue consists of 853 MCMF confirmed clusters and has a purity of\n90%. We present the properties of subsamples of the PSZ-MCMF catalogue that\nhave purities ranging from 90% to 97.5%, depending on the adopted $f_{\\rm\ncont}$ threshold. Halo mass estimates $M_{500}$, redshifts, richnesses, and\noptical centers are presented for all PSZ-MCMF clusters. The PSZ-MCMF catalogue\nadds 589 previously unknown Planck identified clusters over the DES footprint\nand provides redshifts for an additional 50 previously published Planck\nselected clusters with S/N>4.5. Using the subsample with spectroscopic\nredshifts, we demonstrate excellent cluster photo-$z$ performance with an RMS\nscatter in $\\Delta z/(1+z)$ of 0.47%. Our MCMF based analysis allows us to\ninfer the contamination fraction of the initial S/N>3 Planck selected candidate\nlist, which is ~50%. We present a method of estimating the completeness of the\nPSZ-MCMF cluster sample. In comparison to the previously published Planck\ncluster catalogues. this new S/N>3 MCMF confirmed cluster catalogue populates\nthe lower mass regime at all redshifts and includes clusters up to z$\\sim$1.3.\n", "  Upcoming large-scale-structure surveys can shed new light on the properties\nof dark energy. In particular, if dark energy is a dynamical component, it must\nhave spatial perturbations. Their behaviour is regulated by the speed of sound\nparameter, which is currently unconstrained. In this work we present the\nnumerical methods that will allow to perform cosmological simulations of\ninhomogeneous dark energy scenarios where the speed of sound is small and\nnon-vanishing. We treat the dark energy component as an effective fluid and\nbuild upon established numerical methods for hydrodynamics to construct a\nnumerical solution of the effective continuity and Euler equations. In\nparticular, we develop conservative finite volume schemes that rely on the\nsolution of the Riemann problem, which we provide here in both exact and\napproximate forms for the case of a dark energy fluid.\n", "  In astronomy and cosmology, significant effort is devoted to characterizing\nand understanding spatial cross-correlations between points - e.g. galaxy\npositions, high energy neutrino arrival directions, X-ray and AGN sources, and\ncontinuous field - e.g. weak lensing and Cosmic Microwave Background (CMB)\nmaps. Recently, we introduced the $k$-nearest neighbor formalism to better\ncharacterize the clustering of discrete (point) datasets. Here we extend it to\nthe point-field cross-correlation analysis. It combines $k$NN measurements of\nthe point data set with measurements of the field smoothed on many scales. The\nresulting statistics are sensitive to all orders in the joint clustering of the\npoints and the field. We demonstrate that this approach, unlike the 2-pt\ncross-correlation, can measure the statistical dependence of two datasets even\nwhen there are no linear (Gaussian) correlations. We further demonstrate that\nthis framework is far more effective than the two-point function in detecting\ncross-correlations when the continuous field is contaminated by high levels of\nnoise. For a particularly high level of noise, the cross-correlations between\nhalos and the underlying matter field in a cosmological simulation, between\n$10h^{-1}{\\rm Mpc}$ and $30h^{-1}{\\rm Mpc}$, is detected at $>5\\sigma$\nsignificance using the technique presented here, when the two-point\ncross-correlation significance is $\\sim 1\\sigma$. Finally, we show that the\n$k$NN cross-correlations of halos and the matter field can be well-modeled on\nquasilinear scales by the Hybrid Effective Field Theory (HEFT) framework, with\nthe same set of bias parameters as are used for the two-point\ncross-correlations. The substantial improvement in the statistical power of\ndetecting cross-correlations with this method makes it a promising tool for\nvarious cosmological applications.\n", "  We explore the bounds that can be placed on interactions between cold dark\nmatter and vacuum energy, with equation of state $w=-1$, using state-of-the-art\ncosmological observations. We consider linear perturbations about a simple\nbackground model where the energy transfer per Hubble time, $Q/H$, is a general\nlinear function of the dark matter density, $\\rho_c$, and vacuum energy, $V$.\nWe explain the parameter degeneracies found when fitting cosmic microwave\nbackground (CMB) anisotropies alone, and show how these are broken by the\naddition of supernovae data, baryon acoustic oscillations (BAO) and\nredshift-space distortions (RSD). In particular, care must be taken when\nrelating redshift-space distortions to the growth of structure in the presence\nof non-zero energy transfer. Interactions in the dark sector can alleviate the\ntensions between low-redshift measurements of the Hubble parameter, $H_0$, or\nweak-lensing, $S_8$, and the values inferred from CMB data. However these\ntensions return when we include constraints from supernova and BAO-RSD\ndatasets. In the general linear interaction model we show that, while it is\npossible to relax both the Hubble and weak-lensing tensions simultaneously, the\nreduction in these tensions is modest (reduced to less slightly than $4\\sigma$\nand $2\\sigma$ respectively).\n", "  I describe a method to estimate response matrices of Cosmic Microwave\nBackground (CMB) lensing power spectra estimators to the true sky power under\nrealistic conditions. Applicable to all lensing reconstruction pipelines based\non quadratic estimators (QE), it uses a small number of Gaussian CMB\nMonte-Carlos and specially designed QE's in order to obtain sufficiently\naccurate matrices with little computational effort. This method may be used to\nimprove the modelling of CMB lensing band-powers by incorporating at least some\nof the non-idealities encountered in CMB lensing reconstruction. These\nnon-idealities always include masking, and often inhomogeneous filtering,\neither in the harmonic domain or pixel space. I obtain these matrices for\nPlanck latest lensing reconstructions, and then show that the residual\ncouplings induced by masking explain very well the residual multiplicative bias\nseen on the Planck simulations, removing the need for an empirical correction.\n", "  The 2-m aperture Chinese Space Station Telescope (CSST), which observes at\nwavelengths ranging from 255 to 1000 nm, is expected to start science\noperations in 2024. An ultra-deep field observation program covering\napproximately 10 square degrees is proposed with supernovae (SNe) and other\ntransients as one of its primary science drivers. This paper presents the\nsimulated detection results of type Ia supernovae (SNe Ia) and explores the\nimpact of new datasets on the determinations of cosmological parameters. The\nsimulated observations are conducted with an exposure time of 150 s and\ncadences of 10, 20, and 30 days. The survey mode covering a total of 80\nobservations but with a random cadence in the range of 4 to 14 days is also\nexplored. Our simulation results indicate that the CSST can detect up to $\\sim\n1800$ SNe Ia at z $<$ 1.3. The simulated SNe Ia are then used to constrain the\ncosmological parameters. The constraint on $\\Omega_m$ can be improved by 37.5%\nusing the 10-day cadence sample in comparison with the Pantheon sample. A\ndeeper measurement simulation with a 300 s exposure time together with the\nPantheon sample improves the current constraints on $\\Omega_m$ by 58.3% and\n$\\omega$ by 47.7%. Taking future ground-based SNe Ia surveys into\nconsideration, the constraints on $\\omega$ can be improved by 59.1%. The CSST\nultra-deep field observation program is expected to discover large amounts of\nSNe Ia over a broad redshift span and enhance our understanding of the nature\nof dark energy.\n", "  We construct a family of simple single-field inflation models consistent with\nPlanck / BICEP Keck bounds which have a parametrically small tensor amplitude\nand no running of the scalar spectral index. The construction consists of a\nconstant-roll hilltop inflaton potential with the end of inflation left as a\nfree parameter induced by higher-order operators which become dominant late in\ninflation. This construction directly demonstrates that there is no lower bound\non the tensor/scalar ratio for simple single-field inflation models.\n", "  We investigate the synergy of upcoming galaxy surveys and gravitational wave\n(GW) experiments in constraining late-time cosmology, examining the\ncross-correlations between the weak lensing of gravitational waves (GW-WL) and\nthe galaxy fields. Without focusing on any specific GW detector configuration,\nwe benchmark the requirements for the high-precision measurement of\ncosmological parameters by considering several scenarios, varying the number of\ndetected GW events and the uncertainty on the inference of the source\nluminosity distance and redshift. We focus on $\\Lambda$CDM and scalar-tensor\ncosmologies, using the Effective Field Theory formalism as a unifying language.\nWe find that, in some of the explored setups, GW-WL contributes to the galaxy\nsignal by doubling the accuracy on non-$\\Lambda$CDM parameters, allowing in the\nmost favourable scenarios to reach even percent and sub-percent level bounds.\nThough the most extreme cases presented here are likely beyond the\nobservational capabilities of currently planned individual GW detectors, we\nshow nonetheless that - provided that enough statistics of events can be\naccumulated - GW-WL offers the potential to become a cosmological probe\ncomplementary to LSS surveys, particularly for those parameters that cannot be\nconstrained by other GW probes such as standard sirens.\n", "  Lyman-alpha emitters (LAEs) are excellent probes of the reionization process,\nas they must be surrounded by large ionized bubbles in order to be visible\nduring the reionization era. Large ionized regions are thought to correspond to\nover-dense regions and may be protoclusters, making them interesting test-beds\nfor early massive structures. Close associations containing several LAEs are\noften assumed to mark over-dense, ionized bubbles. Here, we develop the first\nframework to quantify the ionization and density fields of high-z galaxy\nassociations. We explore the interplay between (i) the large-scale density of a\nsurvey field, (ii) Poisson noise due to the small number density of bright\nsources at high redshifts (z~7), and (iii) the effects of the ionized fraction\non the observation of LAEs. We use Bayesian statistics, a simple model of\nreionization, and a Monte-Carlo simulation to construct a more comprehensive\nmethod for calculating the large-scale density of LAE regions than previous\nworks. We find that Poisson noise has a strong effect on the inferred density\nof a region and show how the ionized fraction can be inferred. We then apply\nour framework to the strongest association yet identified: Hu et al. (2021)\nfound 14 LAEs in a volume of ~50,000 cMpc^3 inside the COSMOS field at z~7. We\nshow that this is most likely a 2.5-sigma over-density inside of an ionized or\nnearly ionized bubble. We also show that this LAE association implies that the\nglobal ionized fraction is Q = 0.60 (+0.08,-0.09), within the context of a\nsimple reionization model.\n", "  The Hubble horizon at matter-radiation equality ($k^{-1}_{\\rm{eq}}$) and the\nsound horizon at the last scattering surface ($r_s(z_*)$) provides interesting\nconsistency check for the $\\Lambda$CDM model and its extensions. It is well\nknown that the reduction of $r_s$ can be compensated by the increase of $H_0$,\nwhile the same is true for the standard rulers $k_{\\rm{eq}}$. Adding extra\nradiational component to the early universe can reduce $k_{\\rm{eq}}$. The\naddition of early dark energy (EDE), however, tends to increase $k_{\\rm{eq}}$.\nWe perform $k_{\\rm{eq}}$- and $r_s$-based analyses in both the EDE model and\nthe Wess-Zumino Dark Radiation (WZDR) model. In the latter case we find $\\Delta\nH_0 = 0.4$ between the $r_s$- and $k_{\\rm{eq}}$-based datasets, while in the\nformer case we find $\\Delta H_0 = 1.2$. This result suggests that the dark\nradiation scenario is more consistent in the fit of the two standard rulers\n($k_{\\rm{eq}}$ and $r_s$). As a forecast analyses, we fit the two models with a\nmock $k_{\\rm{eq}}$ prior derived from \\emph{Planck} best-fit $\\Lambda$CDM\nmodel. Compared with the best-fit $H_0$ in baseline $\\Lambda$CDM model, we find\n$\\Delta H_0 = 1.1$ for WZDR model and $\\Delta H_0 = - 2.4$ for EDE model.\n", "  We present SKiLLS, a suite of multi-band image simulations for the weak\nlensing analysis of the complete Kilo-Degree Survey (KiDS), dubbed KiDS-Legacy\nanalysis. The resulting catalogues enable joint shear and redshift calibration,\nenhancing the realism and hence accuracy over previous efforts. To create a\nlarge volume of simulated galaxies with faithful properties and to a sufficient\ndepth, we integrated cosmological simulations with high-quality imaging\nobservations. We also improved the realism of simulated images by allowing the\npoint spread function (PSF) to differ between CCD images, including stellar\ndensity variations and varying noise levels between pointings. Using realistic\nvariable shear fields, we accounted for the impact of blended systems at\ndifferent redshifts. Although the overall correction is minor, we found a clear\nredshift-bias correlation in the blending-only variable shear simulations,\nindicating the non-trivial impact of this higher-order blending effect. We also\nexplored the impact of the PSF modelling errors and found a small yet\nnoticeable effect on the shear bias. Finally, we conducted a series of\nsensitivity tests, including changing the input galaxy properties. We conclude\nthat our fiducial shape measurement algorithm, lensfit, is robust within the\nrequirements of lensing analyses with KiDS. As for future weak lensing surveys\nwith tighter requirements, we suggest further investments in understanding the\nimpact of blends at different redshifts, improving the PSF modelling algorithm\nand developing the shape measurement method to be less sensitive to the galaxy\nproperties.\n", "  Line-of-sight effects in strong gravitational lensing have long been treated\nas a nuisance. However, it was recently proposed that the line-of-sight shear\ncould be a cosmological observable in its own right, if it is not degenerate\nwith lens model parameters. We firstly demonstrate that the line-of-sight shear\ncan be accurately measured from a simple simulated strong lensing image with\npercent precision. We then extend our analysis to more complex simulated images\nand stress test the recovery of the line-of-sight shear when using deficient\nfitting models, finding that it escapes from degeneracies with lens model\nparameters, albeit at the expense of the precision. Lastly, we check the\nvalidity of the tidal approximation by simulating and fitting an image\ngenerated in the presence of many line-of-sight dark matter haloes, finding\nthat an explicit violation of the tidal approximation does not necessarily\nprevent one from measuring the line-of-sight shear.\n", "  Galaxy clusters and cosmic voids, the most extreme objects of our Universe in\nterms of mass and size, trace two opposite sides of the large-scale matter\ndensity field. By studying their abundance as a function of their mass and\nradius, respectively, i.e. the halo mass function (HMF) and void size function\n(VSF), it is possible to achieve fundamental constraints on the cosmological\nmodel. While the HMF has already been extensively exploited providing robust\nconstraints on the main cosmological model parameters (e.g. $\\Omega_{\\rm m}$,\n$\\sigma_8$ and $S_8$), the VSF is still emerging as a viable and effective\ncosmological probe. Given the expected complementarity of these statistics, in\nthis work we aim at estimating the costraining power deriving from their\ncombination. To this end, we exploit realistic mock samples of galaxy clusters\nand voids extracted from state-of-the-art large hydrodynamical simulations, in\nthe redshift range $0.2 \\leq z \\leq 1$. We perform an accurate calibration of\nthe free parameters of the HMF and VSF models, needed to take into account the\ndifferences between the types of mass tracers used in this work and those\nconsidered in previous literature analyses. Then, we obtain constraints on\n$\\Omega_{\\rm m}$ and $\\sigma_8$ by performing a Bayesian analysis. We find that\ncluster and void counts represent powerful independent and complementary probes\nto test the cosmological framework. In particular, the constraining power of\nthe HMF on $\\Omega_{\\rm m}$ and $\\sigma_8$ improves drastically with the VSF\ncontribution, increasing the $S_8$ constraint precision by a factor of about\n60%.\n", "  We analyse the full shape of anisotropic clustering measurements from the\nextended Baryon Oscillation Spectroscopic survey (eBOSS) quasar sample together\nwith the combined galaxy sample from the Baryon Oscillation Spectroscopic\nSurvey (BOSS). We obtain constraints on the cosmological parameters independent\nof the Hubble parameter $h$ for the extensions of the $\\Lambda$CDM models,\nfocusing on cosmologies with free dark energy equation of state parameter $w$.\nWe combine the clustering constraints with those from the latest CMB data from\nPlanck to obtain joint constraints for these cosmologies for $w$ and the\nadditional extension parameters - its time evolution $w_{\\rm{a}}$, the physical\ncurvature density $\\omega_{K}$ and the neutrino mass sum $\\sum m_{\\nu}$. Our\njoint constraints are consistent with flat $\\Lambda$CDM cosmological model\nwithin 68\\% confidence limits. We demonstrate that the Planck data are able to\nplace tight constraints on the clustering amplitude today, $\\sigma_{12}$, in\ncosmologies with varying $w$ and present the first constraints for the\nclustering amplitude for such cosmologies, which is found to be slightly higher\nthan the $\\Lambda$CDM value. Additionally, we show that when we vary $w$ and\nallow for non-flat cosmologies and the physical curvature density is used,\nPlanck prefers a curved universe at $4\\sigma$ significance, which is\n$\\sim2\\sigma$ higher than when using the relative curvature density\n$\\Omega_{\\rm{K}}$. Finally, when $w$ is varied freely, clustering provides only\na modest improvement (of 0.021 eV) on the upper limit of $\\sum m_{\\nu}$.\n", "  An excess up-scattering mass bias on a weak lensing cluster mass estimate is\na statistical bias that an observed weak lensing mass ($M_{\\rm obs}$) of a\ncluster of galaxies is, in a statistical sense, larger than its true mass\n($M_{\\rm true}$) because of a higher chance of up-scattering than that of\ndown-scattering due to random noises in a weak lensing cluster shear profile.\nThis non-symmetric scattering probability is caused by a monotonically\ndecreasing cluster mass function with increasing mass. We examine this bias\n(defined by $b=M_{\\rm obs}/M_{\\rm true}$) in weak lensing shear-selected\nclusters, and present an empirical method for mitigating it. In so doing, we\nperform the standard weak lensing mass estimate of realistic mock clusters, and\nfind that the weak lensing mass estimate based on the standard $\\chi^2$\nanalysis gives a statistically correct confidence intervals, but resulting\nbest-fitting masses are biased high on average. Our correction method uses the\nframework of the standard Bayesian statistics with the prior of the probability\ndistribution of the cluster mass and concentration parameter from recent\nempirical models. We test our correction method using mock weak lensing\nclusters, and find that the method works well with resulting corrected $M_{\\rm\nobs}$-bin averaged mass biases being close to unity within $\\sim 10$ percent.\nWe applied the correction method to weak lensing shear-selected cluster sample\nof Hamana et al. (2020), and present bias-corrected weak lensing cluster\nmasses.\n", "  The polarization of the cosmic microwave background (CMB) can be used to\nsearch for parity-violating processes like that predicted by a Chern-Simons\ncoupling to a light pseudoscalar field. Such an interaction rotates $E$ modes\ninto $B$ modes in the observed CMB signal by an effect known as cosmic\nbirefringence. Even though isotropic birefringence can be confused with the\nrotation produced by a miscalibration of the detectors' polarization angles the\ndegeneracy between both effects is broken when Galactic foreground emission is\nused as a calibrator. In this work, we use realistic simulations of the\nHigh-Frequency Instrument of the Planck mission to test the impact that\nGalactic foreground emission and instrumental systematics have on the recent\nbirefringence measurements obtained through this technique. Our results\ndemonstrate the robustness of the methodology against the miscalibration of\npolarization angles and other systematic effects, like\nintensity-to-polarization leakage, beam leakage, or cross-polarization effects.\nHowever, our estimator is sensitive to the $EB$ correlation of polarized\nforeground emission. Here we propose to correct the bias induced by dust $EB$\nby modeling the foreground signal with templates produced in Bayesian\ncomponent-separation analyses that fit parametric models to CMB data.\nAcknowledging the limitations of currently available dust templates like that\nof the Commander sky model, high-precision CMB data and a characterization of\ndust beyond the modified blackbody paradigm are needed to obtain a definitive\nmeasurement of cosmic birefringence in the future.\n", "  One-point probability distribution functions (PDFs) of the cosmic matter\ndensity are powerful cosmological probes that extract non-Gaussian properties\nof the matter distribution and complement two-point statistics. Computing the\ncovariance of one-point PDFs is key for building a robust galaxy survey\nanalysis for upcoming surveys like Euclid and the Rubin Observatory LSST and\nrequires good models for the two-point PDFs characterising spatial\ncorrelations. In this work, we obtain accurate PDF covariances using effective\nshifted lognormal two-point PDF models for the mildly non-Gaussian weak lensing\nconvergence and validate our predictions against large sets of Gaussian and\nnon-Gaussian maps. We show how the dominant effects in the covariance matrix\ncapturing super-sample covariance arise from a large-separation expansion of\nthe two-point PDF and discuss differences between the covariances obtained from\nsmall patches and full sky maps. Finally, we describe how our formalism can be\nextended to characterise the PDF covariance for 3D-dimensional spectroscopic\nfields using the 3D matter PDF as an example. We describe how covariances from\nsimulated boxes with fixed overall density can be supplemented with the missing\nsuper-sample covariance effect by relying on theoretical predictions validated\nagainst separate-universe style simulations.\n", "  We present estimates of line-of-sight distortion fields derived from the 95\nGHz and 150 GHz data taken by BICEP2, BICEP3, and Keck Array up to the 2018\nobserving season, leading to cosmological constraints and a study of\ninstrumental and astrophysical systematics. Cosmological constraints are\nderived from three of the distortion fields concerning gravitational lensing\nfrom large-scale structure, polarization rotation from magnetic fields or an\naxion-like field, and the screening effect of patchy reionization. We measure\nan amplitude of the lensing power spectrum $A_L^{\\phi\\phi}=0.95 \\pm 0.20$. We\nconstrain polarization rotation, expressed as the coupling constant of a\nChern-Simons electromagnetic term $g_{a\\gamma} \\leq 2.6 \\times 10^{-2}/H_I$,\nwhere $H_I$ is the inflationary Hubble parameter, and an amplitude of\nprimordial magnetic fields smoothed over 1 Mpc $B_{1\\text{Mpc}} \\leq 6.6\n\\;\\text{nG}$ at 95 GHz. We constrain the root mean square of optical-depth\nfluctuations in a simple \"crinkly surface\" model of patchy reionization,\nfinding $A^\\tau<0.19$ ($2\\sigma$) for the coherence scale of $L_c=100$. We show\nthat all of the distortion fields of the 95 GHz and 150 GHz polarization maps\nare consistent with simulations including lensed-$\\Lambda$CDM, dust, and noise,\nwith no evidence for instrumental systematics. In some cases, the EB and TB\nquadratic estimators presented here are more sensitive than our previous\nmap-based null tests at identifying and rejecting spurious B-modes that might\narise from instrumental effects. Finally, we verify that the standard\ndeprojection filtering in the BICEP/Keck data processing is effective at\nremoving temperature to polarization leakage.\n", "  We cross-correlate positions of galaxies measured in data from the first\nthree years of the Dark Energy Survey with Compton-$y$-maps generated using\ndata from the South Pole Telescope (SPT) and the {\\it Planck} mission. We model\nthis cross-correlation measurement together with the galaxy auto-correlation to\nconstrain the distribution of gas in the Universe. We measure the hydrostatic\nmass bias or, equivalently, the mean halo bias-weighted electron pressure\n$\\langle b_{h}P_{e}\\rangle$, using large-scale information. We find $\\langle\nb_{h}P_{e}\\rangle$ to be\n$[0.16^{+0.03}_{-0.04},0.28^{+0.04}_{-0.05},0.45^{+0.06}_{-0.10},0.54^{+0.08}_{-0.07},0.61^{+0.08}_{-0.06},0.63^{+0.07}_{-0.08}]$\nmeV cm$^{-3}$ at redshifts $z \\sim [0.30, 0.46, 0.62,0.77, 0.89, 0.97]$. These\nvalues are consistent with previous work where measurements exist in the\nredshift range. We also constrain the mean gas profile using small-scale\ninformation, enabled by the high-resolution of the SPT data. We compare our\nmeasurements to different parametrized profiles based on the cosmo-OWLS\nhydrodynamical simulations. We find that our data are consistent with the\nsimulation that assumes an AGN heating temperature of $10^{8.5}$K but are\nincompatible with the model that assumes an AGN heating temperature of\n$10^{8.0}$K. These comparisons indicate that the data prefer a higher value of\nelectron pressure than the simulations within $r_{500c}$ of the galaxies'\nhalos.\n", "  In the realistic model of cosmic inflation the inflaton potential should be\nflat and stable under quantum corrections. It is natural to imagine that there\nis some symmetry behind and an idea of the inflaton as a Nambu-Goldstone boson\nof spontaneous breaking of some symmetry has been examined. We give a general\nformulation of this idea using the non-linear realization of Nambu-Goldstone\nboson in low-energy effective theory with some explicit symmetry breaking to\ngenerate non-trivial potential. The potential is naturally a simple function,\ntypically the mass term of inflaton, and the scenario of \"warm inflation\"\nshould necessarily be applied under the present observational constraints. We\ninvestigate the generation mechanism of necessary thermal dissipation term in\ninflaton field equation for \"warm inflation\" without large thermal corrections\nto inflaton potential. A simple numerical analysis is given to investigate the\nviability of this scenario.\n", "  We predict the 21-cm global signal and power spectra during the Epoch of\nReionisation using the MERAXES semi-analytic galaxy formation and reionisation\nmodel, updated to include X-ray heating and thermal evolution of the\nintergalactic medium. Studying the formation and evolution of galaxies together\nwith the reionisation of cosmic hydrogen using semi-analytic models (such as\nMERAXES) requires N-body simulations within large volumes and high mass\nresolutions. For this, we use a simulation of side-length $210~h^{-1}$ Mpc with\n$4320^3$ particles resolving dark matter haloes to masses of\n$5\\times10^8~h^{-1}~M_\\odot$. To reach the mass resolution of atomically cooled\ngalaxies, thought to be the dominant population contributing to reionisation,\nat $z=20$ of $\\sim 2\\times10^7~h^{-1}~M_\\odot$, we augment this simulation\nusing the DARKFOREST Monte-Carlo merger tree algorithm (achieving an effective\nparticle count of $\\sim10^{12}$). Using this augmented simulation we explore\nthe impact of mass resolution on the predicted reionisation history as well as\nthe impact of X-ray heating on the 21-cm global signal and the 21-cm power\nspectra. We also explore the cosmic variance of 21-cm statistics within\n$70^{3}$ $h^{-3}$ Mpc$^3$ sub-volumes. We find that the midpoint of\nreionisation varies by $\\Delta z\\sim0.8$ and that the cosmic variance on the\npower spectrum is underestimated by a factor of $2-4$ at $k\\sim 0.1-0.4$\nMpc$^{-1}$ due to the non-Gaussian nature of the 21-cm signal. To our\nknowledge, this work represents the first model of both reionisation and galaxy\nformation which resolves low-mass atomically cooled galaxies while\nsimultaneously sampling sufficiently large scales necessary for exploring the\neffects of X-rays in the early Universe.\n", "  The Data Release 4 of the Atacama Cosmology Telescope (ACT) shows an\nagreement with an Harrison-Zel'dovich primordial spectrum ($n_s=1.009 \\pm\n0.015$), introducing a tension with a significance of $99.3\\%$ CL with the\nresults from the Planck satellite. The discrepancy on the value of the scalar\nspectral index is neither alleviated with the addition of large scale structure\ninformation nor with the low multipole polarization data. We discuss possible\navenues to alleviate the tension relying on either neglecting polarization\nmeasurements from ACT or in extending different sectors of the theory.\n", "  Dark matter could comprise, at least in part, primordial black holes (PBH).\nTo test this hypothesis, we present an approach to constrain the PBH mass\n($M_{\\rm{PBH}}$) and mass fraction ($f_{\\rm{PBH}}$) from the flux ratios of\nquadruply imaged quasars. Our approach uses an approximate Bayesian computation\n(ABC) forward modeling technique to directly sample the posterior distribution\nof $M_{\\rm{PBH}}$ and $f_{\\rm{PBH}}$, while marginalizing over the subhalo mass\nfunction amplitude, spatial distribution, and the size of the lensed source. We\napply our method to 11 quadruply-imaged quasars and derive a new constraint on\nthe intermediate-mass area of PBH parameter space $10^4\n$M$_{\\odot}<M_{\\rm{PBH}}<10^6$M$_\\odot$. We obtain an upper limit\n$f_{\\mathrm{PBH}}<0.17$ (95\\% C.L.). This constraint is independent of all\nother previously published limits.\n", "  We present a data-driven technique to analyze multifrequency images from\nupcoming cosmological surveys mapping large sky area. Using full information\nfrom the data at the two-point level, our method can simultaneously constrain\nthe large-scale structure (LSS), the spectra and redshift distribution of\nemitting sources, and the noise in the observed data without any prior\nassumptions beyond the homogeneity and isotropy of cosmological perturbations.\nIn particular, the method does not rely on source detection or photometric or\nspectroscopic redshift estimates. Here, we present the formalism and\ndemonstrate our technique with a mock observation from nine optical and\nnear-infrared photometric bands. Our method can recover the input signal and\nnoise without bias, and quantify the uncertainty on the constraints. Our\ntechnique provides a flexible framework to analyze the LSS observation traced\nby different types of sources, which has potential for wide application to\ncurrent or future cosmological datasets such as SPHEREx, Rubin Observatory,\nEuclid, or the Nancy Grace Roman Space Telescope.\n", "  Cosmological inference with large galaxy surveys requires theoretical models\nthat combine precise predictions for large-scale structure with robust and\nflexible galaxy formation modelling throughout a sufficiently large cosmic\nvolume. Here, we introduce the MillenniumTNG (MTNG) project which combines the\nhydrodynamical galaxy formation model of IllustrisTNG with the large volume of\nthe Millennium simulation. Our largest hydrodynamic simulation, covering (500\nMpc/h)^3 = (740 Mpc)^3, is complemented by a suite of dark-matter-only\nsimulations with up to 4320^3 dark matter particles (a mass resolution of 1.32\nx 10^8 Msun/h) using the fixed-and-paired technique to reduce large-scale\ncosmic variance. The hydro simulation adds 4320^3 gas cells, achieving a\nbaryonic mass resolution of 2 x 10^7 Msun/h. High time-resolution merger trees\nand direct lightcone outputs facilitate the construction of a new generation of\nsemi-analytic galaxy formation models that can be calibrated against both the\nhydro simulation and observation, and then applied to even larger volumes -\nMTNG includes a flagship simulation with 1.1 trillion dark matter particles and\nmassive neutrinos in a volume of (3000 Mpc)^3. In this introductory analysis we\ncarry out convergence tests on basic measures of non-linear clustering such as\nthe matter power spectrum, the halo mass function and halo clustering, and we\ncompare simulation predictions to those from current cosmological emulators. We\nalso use our simulations to study matter and halo statistics, such as halo bias\nand clustering at the baryonic acoustic oscillation scale. Finally we measure\nthe impact of baryonic physics on the matter and halo distributions.\n", "  Modeling the 21cm global signal from the Cosmic Dawn is challenging due to\nthe many poorly constrained physical processes that come into play. We address\nthis problem using the semi-analytical code \"Cosmic Archaeology Tool\" (CAT).\nCAT follows the evolution of dark matter halos tracking their merger history\nand provides an ab initio description of their baryonic evolution, starting\nfrom the formation of the first (Pop III) stars and black holes (BHs) in\nmini-halos at z > 20. The model is anchored to observations of galaxies and AGN\nat z < 6 and predicts a reionization history consistent with constraints. In\nthis work we compute the evolution of the mean global 21cm signal between\n$4\\leq z \\leq 40$ based on the rate of formation and emission properties of\nstars and accreting black holes. We obtain an absorption profile with a maximum\ndepth $\\delta {\\rm T_b} = -95$ mK at $z \\sim 26.5$ (54 MHz). This feature is\nquickly suppressed turning into an emission signal at $z = 20$ due to the\ncontribution of accreting BHs that efficiently heat the IGM at $z < 27$. The\nhigh-$z$ absorption feature is caused by the early coupling between the spin\nand kinetic temperature of the IGM induced by Pop III star formation episodes\nin mini-halos. Once we account for an additional radio background from early\nBHs, we are able to reproduce the timing and the depth of the EDGES signal only\nif we consider a smaller X-ray background from accreting BHs, but not the\nshape.\n", "  When Type Ia supernovae are used to infer cosmological parameters, their\nluminosities are compared to those from a homogeneous cosmology. In this note\nwe propose a test to examine to what degree SN Ia have been observed on lines\nof sight where the average matter density is \\textit{not} representative of the\nhomogeneous background. We apply our test to the Pantheon SN Ia compilation,\nand find two redshift bins which indicate a moderate bias to over-density at\n$\\sim 2\\sigma$. We modify the Tripp estimator to explicitly de-lens SN Ia\nmagnitudes, and show that this reduces scatter of Hubble diagram residuals.\nUsing our revised Tripp estimator, the effect on cosmological parameters from\nPantheon in $\\Lambda$CDM is however small with a change in mean value from\n$\\Omega_{\\rm m} = 0.317 \\pm 0.027$ (baseline) to $\\Omega_{\\rm m} = 0.312 \\pm\n0.025$ (de-lensed). For the Flat $w$CDM case it is $\\Omega_{\\rm m} = 0.332 \\pm\n0.049$ and $w = -1.16 \\pm 0.16$ (baseline) versus $\\Omega_{\\rm m} = 0.316 \\pm\n0.048$ and $w = -1.12 \\pm 0.15$ (de-lensed). We note that the effect of lensing\non cosmological parameters may be larger for future high-z surveys.\n", "  We develop an optimal Bayesian solution for jointly inferring secondary\nsignals in the Cosmic Microwave Background (CMB) originating from gravitational\nlensing and from patchy screening during the epoch of reionization. This method\nis able to extract full information content from the data, improving upon\npreviously considered quadratic estimators for lensing and screening. We\nforecast constraints using the Marginal Unbiased Score Expansion (MUSE) method,\nand show that they are largely dominated by CMB polarization, and depend on the\nexact details of reionization. For models consistent with current data which\nproduce the largest screening signals, a detection (3\\,$\\sigma$) of the\ncross-correlation between lensing and screening is possible with SPT-3G, and a\ndetection of the auto-correlation is possible with CMB-S4. Models with the\nlowest screening signals evade the sensitivity of SPT-3G, but are still\npossible to detect with CMB-S4 via their lensing cross-correlation.\n", "  The abundance of galaxy clusters is a sensitive probe to the amplitude of\nmatter density fluctuations, the total amount of matter in the Universe as well\nas its expansion history. Inferring correct values and accurate uncertainties\nof cosmological parameters requires accurate knowledge of cluster abundance\nstatistics, encoded in the likelihood function. In this paper, we test the\naccuracy of cluster abundance likelihoods used in the literature, namely the\nPoisson and Gaussian likelihoods as well as the more complete description of\nthe Gauss-Poisson Compound likelihood. This is repeated for a variety of\nbinning choices and analysis setups. In order to evaluate the accuracy of a\ngiven likelihood, this work compares individual posterior covariances to the\ncovariance of estimators over the 1000 simulated dark matter halo catalogs\nobtained from PINOCCHIO algorithm. We find that for Rubin/LSST or Euclid-like\nsurveys the Gaussian likelihood gives robust constraints over a large range of\nbinning choices. The Poisson likelihood, that does not account for sample\ncovariance, always underestimates the errors on the parameters, even when the\nsample volume is reduced or only high-mass clusters are considered. We find no\nbenefit in using the more complex Gauss-Poisson Compound likelihood as it gives\nessentially the same results as the Gaussian likelihood, but at a greater\ncomputational cost. Finally, in this ideal setup, we note only a small gain on\nthe parameter error bars when using a large number of bins in the mass-redshift\nplane.\n", "  We design a new observable, the expansion rate fluctuation $\\eta$, to\ncharacterize deviations from the linear relation between redshift and distance\nin the local universe. We also show how to compress the resulting signal into\nspherical harmonic coefficients in order to better decipher the structure and\nsymmetries of the anisotropies in the local expansion rate. We apply this\nanalysis scheme to several public catalogs of redshift-independent distances,\nthe Cosmicflows-3 and Pantheon data sets, covering the redshift range\n$0.01<z<0.05$.\n  The leading anisotropic signal is stored in the dipole. Within the standard\ncosmological model, it is interpreted as a bulk motion ($307 \\pm 23$ km/s) of\nthe entire local volume in a direction aligned at better than $4$ degrees with\nthe bulk component of the Local Group velocity with respect to the CMB. This\nterm alone, however, provides an overly simplistic and inaccurate description\nof the angular anisotropies of the expansion rate. We find that the quadrupole\ncontribution is non-negligible ($\\sim 50\\%$ of the anisotropic signal), in\nfact, statistically significant, and signaling a substantial shearing of\ngravity in the volume covered by the data. In addition, the 3D structure of the\nquadrupole is axisymmetric, with the expansion axis aligned along the axis of\nthe dipole.\n  Implications for the determination of the $H_0$ parameter are also discussed.\n", "  Halo Models of large scale structure provide powerful and indispensable tools\nfor phenomenological understanding of the clustering of matter in the Universe.\nWhile the halo model builds structures out of the superposition of haloes,\ndefining halo profiles in their outskirts - beyond their virial radii - becomes\nincreasingly ambiguous, as one cannot assign matter to individual haloes in a\nclear way. In this paper, we tackle this question by using numerical N-body\nsimulations to find a systematic definition of mean halo profile that can be\nextended to large radii. These profiles must be compensated and are the key\ningredients for the computation of cosmological correlation functions in the\nAmended Halo Model. The latter, introduced in our earlier work\n(arXiv:1912.04872), provides a more physically accurate phenomenological\ndescription of nonlinear structure formation, which respects conservation laws\non large scales. Here, we extend this model from the matter auto-power spectrum\nto the halo-matter cross-power spectra, using N-body simulations. We find that\nthe (dimensionless) compensated halo profile, $r^3 \\times \\rho(r)/M_{200c}$ has\na near-universal maximum in the small range $0.03-0.04$ around the virial\nradius, $r \\simeq r_{\\rm 200c}$, independent of the halo mass. The profiles\ncross zero into negative values in the halo outskirts, beyond 2-3$\\times r_{\\rm\n200c}$, consistent with our previous results. We provide preliminary fitting\nfunctions for compensated Navarro-Frenk-White (NFW) profiles, and this can be\nused to compute more physical observables in the Amended Halo Model of large\nscale structure.\n", "  In this review article, we briefly outline our current understanding of the\nphysics associated with the HI 21-cm signal from cosmic dawn. We discuss\ndifferent phases of cosmic dawn as the ambient gas and the background\nradiations evolve with the redshift. We address the consequences of several\npossible heating sources and radiation background on the global 21-cm signal.\nWe further review our present perspective of other important aspects of the HI\n21-cm signal such as the power spectrum and imaging. Finally, we highlight the\nfuture key measurements of the Square Kilometre Array and other\nongoing/upcoming experiments that will enlighten our understanding of the early\nUniverse.\n", "  AI super-resolution, combining deep learning and N-body simulations has been\nshown to successfully reproduce the large scale structure and halo abundances\nin the Lambda Cold Dark Matter cosmological model. Here, we extend its use to\nmodels with a different dark matter content, in this case Fuzzy Dark Matter\n(FDM), in the approximation that the difference is encoded in the initial power\nspectrum. We focus on redshift z = 2, with simulations that model smaller\nscales and lower masses, the latter by two orders of magnitude, than has been\ndone in previous AI super-resolution work. We find that the super-resolution\ntechnique can reproduce the power spectrum and halo mass function to within a\nfew percent of full high resolution calculations. We also find that halo\nartifacts, caused by spurious numerical fragmentation of filaments, are equally\npresent in the super-resolution outputs. Although we have not trained the\nsuper-resolution algorithm using full quantum pressure FDM simulations, the\nfact that it performs well at the relevant length and mass scales means that it\nhas promise as technique which could avoid the very high computational cost of\nthe latter, in some contexts. We conclude that AI super-resolution can become a\nuseful tool to extend the range of dark matter models covered in mock catalogs.\n", "  We present a field-based signal extraction of weak lensing from noisy\nobservations on the curved and masked sky. We test the analysis on a simulated\nEuclid-like survey, using a Euclid-like mask and noise level. To make optimal\nuse of the information available in such a galaxy survey, we present a Bayesian\nmethod for inferring the angular power spectra of the weak lensing fields,\ntogether with an inference of the noise-cleaned tomographic weak lensing shear\nand convergence (projected mass) maps. The latter can be used for field-level\ninference with the aim of extracting cosmological parameter information\nincluding non-gaussianity of cosmic fields. We jointly infer all-sky $E$-mode\nand $B$-mode tomographic auto- and cross-power spectra from the masked sky, and\npotentially parity-violating $EB$-mode power spectra, up to a maximum multipole\nof $\\ell_{\\rm max}=2048$. We use Hamiltonian Monte Carlo sampling, inferring\nsimultaneously the power spectra and denoised maps with a total of $\\sim 16.8$\nmillion free parameters. The main output and natural outcome is the set of\nsamples of the posterior, which does not suffer from leakage of power from $E$\nto $B$ unless reduced to point estimates. However, such point estimates of the\npower spectra, the mean and most likely maps, and their variances and\ncovariances, can be computed if desired.\n", "  Interesting discrepancies in cosmological parameters are challenging the\nsuccess of the $\\Lambda$CDM model. Direct measurements of the Hubble constant\n$H_0$ using Cepheid variables and supernovae turn out to be higher than\ninferred from the Cosmic Microwave Background (CMB). Weak galaxy lensing\nsurveys consistently report values of the strength of matter clustering\n$\\sigma_8$ lower than values derived from the CMB in the context of\n$\\Lambda$CDM. In this paper we address these discrepancies in cosmological\nparameters by considering Dark Energy (DE) as a fluid with evolving equation of\nstate $w_{\\mathrm{de}}(z)$, constant sound speed squared\n$\\hat{c}_{\\mathrm{s}}^{2}$, and vanishing anisotropic stress $\\sigma$. Our\n$w_{\\mathrm{de}}(z)$ is derived from the Holographic Principle and can\nconsecutively exhibit radiation-like, matter-like, and DE-like behaviour, thus\naffecting the sound horizon and the comoving angular diameter distance, hence\n$H_0$. Here we show DE sound speed plays a part in the matter clustering\nbehaviour through its effect on the evolution of the gravitational potential.\nWe compute cosmological constraints using several data set combinations\nincluding primary CMB, CMB lensing, redshift-space-distortions, local\ndistance-ladder, supernovae, and baryon acoustic oscillations. In our analysis\nwe marginalise over $\\hat{c}_{\\mathrm{s}}^{2}$ and find\n$\\hat{c}_{\\mathrm{s}}^{2}=1$ is excluded at $\\gtrsim 3\\sigma$. For our baseline\nresult including the whole data set we found $H_0$ and $\\sigma_8$ in good\nagreement (within $\\approx 2\\sigma$) with low redshift probes. Our constraint\nfor the baryon energy density $\\omega_{\\rm{b}}$ is however in $\\approx 3\\sigma$\ntension with BBN constraints. We conclude evolving DE also having non-standard\nclustering properties [e.g., $\\hat{c}_{\\mathrm{s}}^{2}(z,k)$] might be relevant\nfor the solution of current discrepancies in cosmological parameters.\n", "  This paper analyse the properties of minimal solutions for the reconstruction\nof the lens potential in the singular perturbative approach. These minimal\nsolutions corresponds to an expansion with a minimal degree in Fourier\nexpansion of the perturbative fields. Using these minimal solutions prevent\nspurious physically meaningless terms in the reconstruction of the fields. In\neffect a perturbative analysis indicates that a small change in the source\nmodel will corresponds to the higher order terms in the expansion of the\nfields. The results of the perturbative analysis are valid not only for\nslightly non-circular sources but also for more distorted sources to order two.\nIt is thus of crucial importance to minimize the number of terms used in the\nmodelling of the lens. Another important asset of the minimal solutions is that\nthey offers a de-coupling between the source and lens model and thus help to\nbreak the source lens degeneracy issue. The possible drawback of minimal\nsolutions is to under-estimate the higher order terms in the solution. However\nthis bias has its merit since the detection of higher order terms using this\nmethod will ensure that these terms are real. This type of analysis using\nminimal solutions will be of particular interest when considering the\nstatistical analysis of a large number of lenses, especially in light of the\nincoming satellite surveys.\n", "  An accurate calibration of the source redshift distribution $p(z)$ is a key\naspect in the analysis of cosmic shear data. This, one way or another, requires\nthe use of spectroscopic or high-quality photometric samples. However, the\ndifficulty to obtain colour-complete spectroscopic samples matching the depth\nof weak lensing catalogs means that the analyses of different cosmic shear\ndatasets often use the same samples for redshift calibration. This introduces a\nsource of statistical and systematic uncertainty that is highly correlated\nacross different weak lensing datasets, and which must be accurately\ncharacterised and propagated in order to obtain robust cosmological constraints\nfrom their combination. In this paper we introduce a method to quantify and\npropagate the uncertainties on the source redshift distribution in two\ndifferent surveys sharing the same calibrating sample. The method is based on\nan approximate analytical marginalisation of the $p(z)$ statistical\nuncertainties and the correlated marginalisation of residual systematics. We\napply this method to the combined analysis of cosmic shear data from the DESY1\ndata release and the HSC-DR1 data, using the COSMOS 30-band catalog as a common\nredshift calibration sample. We find that, although there is significant\ncorrelation in the uncertainties on the redshift distributions of both samples,\nthis does not change the final constraints on cosmological parameters\nsignificantly. The same is true also for the impact of residual systematic\nuncertainties from the errors in the COSMOS 30-band photometric redshifts.\nAdditionally, we show that these effects will still be negligible in Stage-IV\ndatasets. Finally, the combination of DESY1 and HSC-DR1 allows us to constrain\nthe ``clumpiness'' parameter to $S_8 = 0.768^{+0.021}_{-0.017}$. This\ncorresponds to a $\\sim\\sqrt{2}$ improvement in uncertainties with respect to\neither DES or HSC alone.\n", "  We investigate whether the shapes of galaxy clusters inferred from weak\ngravitational lensing can be used as a test of the nature of dark matter. We\nanalyse mock weak lensing data, with gravitational lenses extracted from\ncosmological simulations run with two different dark matter models (CDM and\nSIDM). We fit elliptical NFW profiles to the shear fields of the simulated\nclusters. Despite large differences in the distribution of 3D shapes between\nCDM and SIDM, we find that the distributions of weak-lensing-inferred cluster\nshapes are almost indistinguishable. We trace this information loss to two\ncauses. Firstly, weak lensing measures the shape of the projected mass\ndistribution, not the underlying 3D shape, and projection effects wash out some\nof the difference. Secondly, weak lensing is most sensitive to the projected\nshape of clusters, on a scale approaching the virial radius (~ 1.5 Mpc),\nwhereas SIDM shapes differ most from CDM in the inner halo. We introduce a\nmodel for the mass distribution of galaxy clusters where the ellipticity of the\nmass distribution can vary with distance to the centre of the cluster. While\nthis mass distribution does not enable weak lensing data to distinguish between\nCDM and SIDM with cluster shapes (the ellipticity at small radii is poorly\nconstrained by weak lensing), it could be useful when modelling combined strong\nand weak gravitational lensing of clusters.\n", "  In certain cases of astronomical data analysis, the meaningful physical\nquantity to extract is the ratio $R$ between two data sets. Examples include\nthe lensing ratio, the interloper rate in spectroscopic redshift samples, the\ndecay rate of gravitational potential and $E_G$ to test gravity. However,\nsimply taking the ratio of the two data sets is biased, since it renders (even\nstatistical) errors in the denominator into systematic errors in $R$.\nFurthermore, it is not optimal in minimizing statistical errors of $R$. Based\non Bayesian analysis and the usual assumption of Gaussian error in the data, we\nderive an analytical expression of the posterior PDF $P(R)$. This result\nenables fast and unbiased $R$ measurement, with minimal statistical errors.\nFurthermore, it relies on no underlying model other than the proportionality\nrelation between the two data sets. Even more generally, it applies to the\ncases where the proportionality relation holds for the underlying\nphysics/statistics instead of the two data sets directly. It also applies to\nthe case of multiple ratios ($R\\rightarrow {\\bf R}=(R_1,R_2,\\cdots)$). We take\nthe lensing ratio as an example to demonstrate our method. We take lenses as\nDESI imaging survey galaxies, and sources as DECaLS cosmic shear and\n\\emph{Planck} CMB lensing. We restrict the analysis to the ratio between CMB\nlensing and cosmic shear. The resulting $P(R)$, for multiple lens-shear pairs,\nare all nearly Gaussian. The S/N of measured $R$ ranges from $4.9$ to $8.4$. We\nperform several tests to verify the robustness of the above result.\n", "  Inflationary gravitational waves, behaving as additional radiation in the\nEarly Universe, can increase the effective number of relativistic species\n($N_{\\rm eff}$) by a further correction that depends on the integrated\nenergy-density in gravitational waves over all scales. This effect is typically\nused to constrain (blue-tilted) models of inflation in light of the bounds\nresulting from the Big Bang Nucleosynthesis. In this paper, we recompute this\ncontribution, discussing some caveats of the state-of-the-art analyses. Through\na parametric investigation, we first demonstrate that the calculation is\ndominated by the ultraviolet frequencies of the integral and therefore by the\nbehavior of the tensor spectrum on scales corresponding to modes that cross the\nhorizon very close to the end of inflation, when the slow-roll dynamics breaks\ndown and the production of gravitational waves becomes strongly model\ndependent. Motivated by these results, we realize a theoretical Monte Carlo\nand, working within the framework of the Effective Field Theory of inflation,\nwe investigate the observable predictions of a very broad class of models. For\neach model, we solve a system of coupled differential equations whose solution\ncompletely specifies the evolution of the spectrum up to the end of inflation.\nWe prove the calculation of $\\Delta N_{\\rm eff}^{\\rm GW}$ to be remarkably\nmodel-dependent and therefore conclude that accurate analyses are needed to\ninfer reliable information on the inflationary Universe.\n", "  The density profiles of dark matter haloes contain rich information about\ntheir growth history and physical properties. One particularly interesting\nregion is the splashback radius, $R_{\\rm sp}$, which marks the transition\nbetween particles orbiting in the halo and particles undergoing first infall.\nWhile the dependence of $R_{\\rm sp}$ on the recent accretion rate is well\nestablished and theoretically expected, it is not clear exactly what parts of\nthe accretion history $R_{\\rm sp}$ responds to, and what other halo properties\nmight additionally influence its position. We comprehensively investigate these\nquestions by correlating the dynamically measured splashback radii of a large\nset of simulated haloes with their individual growth histories as well as their\nstructural, dynamical, and environmental properties. We find that $R_{\\rm sp}$\nis sensitive to the accretion over one crossing time but largely insensitive to\nthe prior history (in contrast to concentration, which probes earlier epochs).\nAll secondary correlations are much weaker, but we discern a relatively higher\n$R_{\\rm sp}$ in less massive, older, more elliptical, and more tidally deformed\nhaloes. Despite these minor influences, we conclude that the splashback radius\nis a clean indicator of a halo's growth over the past dynamical time. We\npredict that the magnitude gap should be a promising observable indicator of a\nhalo's accretion rate and splashback radius.\n", "  Tensions between cosmological parameters (in particular the local expansion\nrate $H_0$ and the amplitude of matter clustering $S_8$) inferred from\nlow-redshift data and data from the cosmic microwave background (CMB) and\nlarge-scale structure (LSS) experiments have inspired many extensions to the\nstandard cosmological model, $\\Lambda$CDM. Models which simultaneously lessen\nboth tensions are of particular interest. We consider one scenario with the\npotential for such a resolution, in which some fraction of the dark matter has\nconverted into dark radiation since the release of the CMB. Such a scenario\nencompasses and generalizes the more standard \"decaying dark matter\" model,\nallowing additional flexibility in the rate and time at which the dark matter\nconverts into dark radiation. In this paper, we constrain this scenario with a\nfocus on exploring whether it can solve (or reduce) these tensions. We find\nthat such a model is effectively ruled out by low-$\\ell$ CMB data, in\nparticular by the reduced peak-smearing due to CMB lensing and the excess\nIntegrated Sachs--Wolfe (ISW) signal caused by the additional dark energy\ndensity required to preserve flatness after dark matter conversion into dark\nradiation. Thus, such a model does not have the power to reduce these tensions\nwithout further modifications. This conclusion extends and generalizes related\nconclusions derived for the standard decaying dark matter model.\n", "  The change of physical conditions across the turbulent and magnetized\ninterstellar medium (ISM) induces a 3D spatial variation of the properties of\nGalactic polarized emission. The observed signal results from the averaging of\ndifferent spectral energy distributions (SED) and polarization angles, along\nand between lines of sight. As a consequence, the total Stokes parameters $Q$\nand $U$ will have different distorted SEDs, so that the polarization angle\nbecomes frequency dependent. In the present work, we show how this phenomenon\nsimilarly induces a different distorted SED for the three polarized angular\npower spectra $EE$, $BB$ and $EB$, implying a variation of the $EE/BB$ ratio\nwith frequency. We demonstrate how the previously introduced spin-moment\nformalism provides a natural framework to grasp these effects, allowing us to\nderive analytical predictions for the spectral behaviors of the polarized\nspectra, focusing here on the example of thermal dust polarized emission. After\na quantitative discussion based on a model combining emission from a filament\nwith its background, we further reveal that the spectral complexity implemented\nin the dust models commonly used by the cosmic microwave background (CMB)\ncommunity produce such effects. This new understanding is crucial for CMB\ncomponent separation, in which an extreme accuracy is required in the modeling\nof the dust signal to allow for the search of the primordial imprints of\ninflation or cosmic birefringence. For the latter, as long as the dust $EB$\nsignal is not measured accurately, great caution is required about the\nassumptions made to model its spectral behavior, as it may not simply follow\nfrom the other dust angular power spectra.\n", "  We introduce a novel unbiased, cross-correlation estimator for the one-point\nstatistics of cosmological random fields. One-point statistics are a useful\ntool for analysis of highly non-Gaussian density fields, while\ncross-correlations provide a powerful method for combining information from\npairs of fields and separating them from noise and systematics. We derive a new\nDeconvolved Distribution Estimator that combines the useful properties of these\ntwo methods into one statistic. Using two example models of a toy Gaussian\nrandom field and a line intensity mapping survey, we demonstrate these\nproperties quantitatively and show that the DDE can be used for inference. This\nnew estimator can be applied to any pair of overlapping, non-Gaussian\ncosmological observations, including large-scale structure, the\nSunyaev-Zeldovich effect, weak lensing, and many others.\n", "  Cosmic variance limits the accuracy of cosmological N-body simulations,\nintroducing bias in statistics such as the power spectrum, halo mass function,\nor the cosmic shear. We provide new methods to measure and reduce the effect of\ncosmic variance in existing and new simulations. We ran pairs of simulations\nusing phase-shifted initial conditions with matching amplitudes. We set the\ninitial amplitudes of the Fourier modes to ensure that the average power\nspectrum of the pair is equal to the cosmic mean power spectrum from linear\ntheory. The average power spectrum of a pair of such simulations remains\nconsistent with the estimated nonlinear spectra of the state-of-the-art methods\neven at late times. We also show that the effect of cosmic variance on any\nanalysis involving a cosmological simulation can be estimated using the\ncomplementary pair of the original simulation. To demonstrate the effectiveness\nof our novel technique, we simulated a complementary pair of the original\nMillennium run and quantified the degree to which cosmic variance affected its\nthe power spectrum. The average power spectrum of the original and\ncomplementary Millennium simulation was able to directly resolve the baryon\nacoustic oscillation features.\n", "  We study the effect of super-sample covariance (SSC) on the power spectrum\nand higher-order statistics: bispectrum, halo mass function, and void size\nfunction. We also investigate the effect of SSC on the cross covariance between\nthe statistics. We consider both the matter and halo fields. Higher-order\nstatistics of the large-scale structure contain additional cosmological\ninformation beyond the power spectrum and are a powerful tool to constrain\ncosmology. They are a promising probe for ongoing and upcoming high precision\ncosmological surveys such as DESI, PFS, Rubin Observatory LSST, Euclid,\nSPHEREx, SKA, and Roman Space Telescope. Cosmological simulations used in\nmodeling and validating these statistics often have sizes that are much smaller\nthan the observed Universe. Density fluctuations on scales larger than the\nsimulation box, known as super-sample modes, are not captured by the\nsimulations and in turn can lead to inaccuracies in the covariance matrix. We\ncompare the covariance measured using simulation boxes containing super-sample\nmodes to those without. We also compare with the Separate Universe approach. We\nfind that while the power spectrum, bispectrum and halo mass function show\nsignificant scale- or mass-dependent SSC, the void size function shows\nrelatively small SSC. We also find significant SSC contributions to the cross\ncovariances between the different statistics, implying that future\njoint-analyses will need to carefully take into consideration the effect of\nSSC. To enable further study of SSC, our simulations have been made publicly\navailable at https://github.com/HalfDomeSims/ssc.\n", "  Reconstructing the initial conditions of the Universe from late-time\nobservations has the potential to optimally extract cosmological information.\nDue to the high dimensionality of the parameter space, a differentiable forward\nmodel is needed for convergence, and recent advances have made it possible to\nperform reconstruction with nonlinear models based on galaxy (or halo)\npositions. In addition to positions, future surveys will provide measurements\nof galaxies' peculiar velocities through the kinematic Sunyaev-Zel'dovich\neffect (kSZ), type Ia supernovae, and the fundamental plane or Tully-Fisher\nrelations. Here we develop the formalism for including halo velocities, in\naddition to halo positions, to enhance the reconstruction of the initial\nconditions. We show that using velocity information can significantly improve\nthe reconstruction accuracy compared to using only the halo density field. We\nstudy this improvement as a function of shot noise, velocity measurement noise,\nand angle to the line of sight. We also show how halo velocity data can be used\nto improve the reconstruction of the final nonlinear matter overdensity and\nvelocity fields. We have built our pipeline into the differentiable\nParticle-Mesh FlowPM package, paving the way to perform field-level\ncosmological inference with joint velocity and density reconstruction. This is\nespecially useful given the increased ability to measure peculiar velocities in\nthe near future.\n", "  A numerical detection of the radius-dependent spin transition of dark matter\nhalos is reported. Analyzing the data from the IllustrisTNG simulations, we\nmeasure the halo spin vectors at several inner radii within the virial\nboundaries and investigate their orientations in the principal frames of the\ntidal and velocity shear fields, called the Tweb and Vweb, respectively. The\nhalo spin vectors in the high-mass section exhibit a transition from the Tweb\nintermediate to major principal axes as they are measured at more inner radii,\nwhich holds for both of the dark matter and baryonic components. The radius\nthreshold at which the transition occurs depends on the smoothing scale,\n$R_{f}$, becoming larger as $R_{f}$ decreases. For the case of the Vweb, the\noccurrence of the radius-dependent spin transition is witnessed only when\n$R_{f}\\ge 1\\, h^{-1}$Mpc. Repeating the same analysis but with the vorticity\nvectors, we reveal a critical difference from the spins. The vorticity vectors\nare always perpendicular to the Tweb (Vweb) major principal axes, regardless of\n$R_{f}$, which indicates that the halo inner spins are not strongly affected by\nthe generation of vorticity. It is also shown that the halo spins, as well as\nthe Tweb (Vweb) principal axes, have more directional coherence over a wide\nrange of radial distances in the regions where the vorticity vectors have\nhigher magnitudes. The physical interpretations and implications of our results\nare discussed.\n", "  Non-linear cosmic structures contain valuable information on the expansion\nhistory of the background space-time, the nature of dark matter, and the\ngravitational interaction. The recently developed kinetic field theory of\ncosmic structure formation (KFT) allows to accurately calculate the non-linear\npower spectrum of cosmic density fluctuations up to wave numbers of\n$k\\lesssim10\\,h\\,\\mathrm{Mpc}^{-1}$ at redshift zero. Cosmology and gravity\nenter this calculation via two functions, viz. the background expansion\nfunction and possibly a time-dependent modification of the gravitational\ncoupling strength.\n  The success of the cosmological standard model based on general relativity\nsuggests that cosmological models in generalized theories of gravity should\nhave observable effects differing only weakly from those in standard cosmology.\nBased on this assumption, we derive the functional, first-order Taylor\nexpansion of the non-linear power spectrum of cosmic density fluctuations\nobtained from the mean-field approximation in KFT in terms of the expansion\nfunction and the gravitational coupling strength. This allows us to study\nnon-linear power spectra expected in large classes of generalized gravity\ntheories. To give one example, we apply our formalism to generalized Proca\ntheories.\n", "  Velocity dispersion of the massive neutrinos presents a daunting challenge\nfor non-linear cosmological perturbation theory. We consider the neutrino\npopulation as a collection of non-linear fluids, each with uniform initial\nmomentum, through an extension of the Time Renormalization Group perturbation\ntheory. Employing recently-developed Fast Fourier Transform techniques, we\naccelerate our non-linear perturbation theory by more than two orders of\nmagnitude, making it quick enough for practical use. After verifying that the\nneutrino mode-coupling integrals and power spectra converge, we show that our\nperturbation theory agrees with N-body neutrino simulations to within 10% for\nneutrino fractions $\\Omega_{\\nu,0} h^2 \\leq 0.005$ up to wave numbers of k = 1\nh/Mpc, an accuracy consistent with 2.5% errors in the neutrino mass\ndetermination. Non-linear growth represents a >10% correction to the neutrino\npower spectrum even for density fractions as low as $\\Omega_{\\nu,0} h^2 =\n0.001$, demonstrating the limits of linear theory for accurate neutrino power\nspectrum predictions. Our code FlowsForTheMasses is avaliable online at\ngithub.com/upadhye/FlowsForTheMasses .\n", "  Weak gravitational lensing by the intervening large-scale structure (LSS) of\nthe Universe is the leading non-linear effect on the anisotropies of the cosmic\nmicrowave background (CMB). The integrated line-of-sight mass that causes the\ndistortion -- known as lensing convergence -- can be reconstructed from the\nlensed temperature and polarization anisotropies via estimators quadratic in\nthe CMB modes, and its power spectrum has been measured from multiple CMB\nexperiments. Sourced by the non-linear evolution of structure, the bispectrum\nof the lensing convergence provides additional information on late-time\ncosmological evolution complementary to the power spectrum. However, when\ntrying to estimate the summary statistics of the reconstructed lensing\nconvergence, a number of noise-biases are introduced, as previous studies have\nshown for the power spectrum. Here, we explore for the first time the\nnoise-biases in measuring the bispectrum of the reconstructed lensing\nconvergence. We compute the leading noise-biases in the flat-sky limit and\ncompare our analytical results against simulations, finding excellent\nagreement. Our results are critical for future attempts to reconstruct the\nlensing convergence bispectrum with real CMB data.\n", "  The clustering signals of galaxy clusters are known to be powerful tools for\nself-calibrating the mass-observable relation and are complementary to cluster\nabundance and lensing. In this work, we explore the possibility of combining\nthree correlation functions -- cluster lensing, the cluster-galaxy\ncross-correlation function, and the galaxy auto-correlation function -- to\nself-calibrate optical cluster selection bias, the boosted clustering and\nlensing signals in a richness-selected sample mainly caused by projection\neffects. We develop mock catalogues of redMaGiC-like galaxies and\nredMaPPer-like clusters by applying Halo Occupation Distribution (HOD) models\nto N-body simulations and using counts-in-cylinders around massive haloes as a\nrichness proxy. In addition to the previously known small-scale boost in\nprojected correlation functions, we find that the projection effects also\nsignificantly boost 3D correlation functions out to scales 100 $h^{-1}\n\\mathrm{Mpc}$. We perform a likelihood analysis assuming survey conditions\nsimilar to that of the Dark Energy Survey (DES) and show that the selection\nbias can be self-consistently constrained at the 10% level. We discuss\nstrategies for applying this approach to real data. We expect that expanding\nthe analysis to smaller scales and using deeper lensing data would further\nimprove the constraints on cluster selection bias.\n", "  Aims. With the next generation of large surveys coming to the stage of\nobservational cosmology soon, it is important to explore their potential\nsynergies and to maximise their scientific outcomes. In this study, we aim to\ninvestigate the complementarity of the two upcoming space missions Euclid and\nthe China Space Station Telescope (CSST), focusing on weak lensing (WL)\ncosmology. In particular, we analyse the photometric redshifts (photo-zs) and\nthe galaxy blending effects. For Euclid, WL measurements suffer from chromatic\nPSF effects. For this, CSST can provide valuable information for Euclid to\nobtain more accurate PSF, and to calibrate the color and color-gradient biases\nfor WL measurements.\n  Methods. We create image simulations for different surveys, and quantify the\nphoto-z performance. For blending analyses, we employ high-resolution\nHST/CANDELS data to mock Euclid, CSST, and an LSST-like survey. We analyse the\nblending fraction for different cases, and the blending effects on galaxy\nphotometry. Furthermore, we demonstrate that CSST can provide a large enough\nnumber of high SNR multi-band galaxy images to calibrate the color-gradient\nbiases for Euclid.\n  Results. The sky coverage of Euclid lies entirely within the CSST footprint.\nThe combination of Euclid with CSST data can be done more uniformly than with\nthe various ground-based data. Our studies show that by combining Euclid and\nCSST, we can reach a photo-z precision of $\\sigma_{\\rm NMAD} \\approx 0.04$, and\nan outlier fraction of $\\eta\\approx 2.4\\%$. Because of the similarly high\nresolutions, the data combination of Euclid and CSST can be relatively\nstraightforward for photometry. To include ground-based data, however,\nsophisticated deblending utilizing priors from high-resolution space data is\ndemanded. The color-gradient biases for Euclid can be well calibrated to the\nlevel of 0.1% using galaxies from CSST deep survey.\n", "  The motion of cosmic strings in the universe leads to the generation of wakes\nbehind them. We study magnetized wakes of cosmic strings moving in the post\nrecombination plasma. We show that magnetic reconnection can occur in the post\nshock region. Since the width of the cosmic string wake is very small, the\nreconnection occurs over a very short lengthscale. The reconnection leads to a\nlarge amount of kinetic energy being released in the post shock region of the\ncosmic string wake. This enhances the kinetic energy released during the\nreconnection. We make a rudimentary estimate of the kinetic energy released by\nthe magnetic reconnection in cosmic strings wakes and show that it can account\nfor low energy Gamma Ray Bursts (GRB) in the post recombination era.\n", "  Sheth-Tormen mass function has been widely used to quantify the abundance of\ndark matter halos. It is a significant improvement over the Press-Schechter\nmass function as it uses ellipsoidal collapse in place of spherical collapse.\nBoth of these mass functions can be written in a form that is universal, i.e.,\nindependent of cosmology and power spectrum when scaled in suitable variables.\nHowever, cosmological simulations have shown that this universality is\napproximate. In this paper, we investigate the power spectrum dependence of\nhalo mass function through a suite of dark-matter-only N-body simulations of\nseven power-law models in an Einstein-de Sitter cosmology. This choice of\ncosmology and a power-law power spectrum ensures the self-similar evolution of\ndark matter distribution, allowing us to isolate the power spectrum dependence\nof mass function. We find that the mass function shows a clear\nnon-universality. We present fits for the parameters of the Sheth-Tormen mass\nfunction for a range of power-law power-spectrum indices. We find a mild\nevolution in the overall shape of the mass function with the epoch. Finally, we\nextend our result to LCDM cosmology. We show that the Sheth-Tormen mass\nfunction with parameter values derived from a matched power-law EdS cosmology\nprovides a better fit to the LCDM mass function than the standard Sheth-Tormen\nmass function. Our results indicate that an improved analytical theory is\nrequired to provide better fits to the mass function.\n", "  Upcoming advances in galaxy surveys and cosmic microwave background data will\nenable measurements of the anisotropic distribution of diffuse gas in filaments\nand superclusters at redshift $z=1$ and beyond, observed through the thermal\nSunyaev-Zel'dovich (tSZ) effect. These measurements will help distinguish\nbetween different astrophysical feedback models, account for baryons that\nappear to be 'missing' from the cosmic census, and present opportunities for\nusing locally-anisotropic tSZ statistics as cosmological probes. This study\nseeks to guide such future measurements by analysing whether diffuse\nintergalactic gas is a major contributor to anisotropic tSZ signal in The Three\nHundred Gizmo-Simba hydrodynamic simulations. We apply multiple different halo\nboundary and temperature criteria to divide concentrated from diffuse gas at\n$z=1$, then create mock Compton-$y$ maps for the separated components. The maps\nfrom 98 simulation snapshots are centred on massive galaxy clusters, oriented\nby the most prominent galaxy filament axis, and stacked. Results vary\nsignificantly depending on the definition used for diffuse gas, indicating that\nassumptions should be clearly defined when claiming observations of the\nwarm-hot intergalactic medium. In all cases, the diffuse gas is important,\ncontributing 25-60% of the tSZ signal in the far field ($>4 h^{-1}$ comoving\nMpc) from the stacked clusters. The gas 1-2 virial radii from halo centres is\nespecially key. Oriented stacking and environmental selections help to amplify\nthe signal from the warm-hot intergalactic medium, which is aligned but less\nconcentrated along the filament axis than the hot halo gas.\n", "  Recent observations of Type Ia supernovae (SNe) by SH0ES collaboration (R11\nand R16) diverge from the value reported by recent CMBR observations utilising\nthe Planck satellite and application of the $\\Lambda CDM$ cosmological model by\nat least $3 \\sigma$. It is among the most challenging problems in contemporary\ncosmology and is known as the Hubble tension. The SNe Ia in R11 and R16 were\ncalibrated through cepheid variables in three distinct galaxies: Milky Way,\nLMC, and NGC4258. Carnegie Hubble Program (CHP) observations of type Ia SNe\ncalibrated using the tip of the red giant approach yielded a somewhat different\nestimate for the Hubble constant. This decreased the Hubble tension from over\n3$\\sigma$ to below 2$\\sigma$. It is a legitimate question to answer whether\nthere are any issues with SNe Ia calibration and to investigate whether the\nHubble tension is real or not. We use statistical techniques namely, ANOVA, K-S\ntest, and t-test to examine whether the cepheid calibration is host-dependent.\nOur analysis shows that (i) both R11 and R16 data suffer from non-Gaussian\nsystematic effects, (ii) $H_0$ values in the sub-samples (different\nanchor-based) in both R11 and R16 groups are significantly different at a 99\\%\nconfidence level, and (iii) neglecting the metal-rich MW sample does not reduce\nthe $H_0$ value significantly, and thus Hubble tension persists. A small\nreduction in the Hubble constant could be linked to the differences in the host\nenvironment. Hence instead of using a single universal relation environment\nbased slope and zero point should be preferred.\n", "  Detecting gravitationally lensed supernovae is among the biggest challenges\nin astronomy. It involves a combination of two very rare phenomena: catching\nthe transient signal of a stellar explosion in a distant galaxy and observing\nit through a nearly perfectly aligned foreground galaxy that deflects light\ntowards the observer. High-cadence optical observations with the Zwicky\nTransient Facility, with an unparalleled large field of view, led to the\ndetection of a multiply-imaged Type Ia supernova (SN Ia), ``SN Zwicky\", a.k.a.\nSN 2022qmx. Magnified nearly twenty-five times, the system was found thanks to\nthe ``standard candle\" nature of SNe Ia. High-spatial resolution imaging with\nthe Keck telescope resolved four images of the supernova with very small\nangular separation, corresponding to an Einstein radius of only $\\theta_E\n=0.167\"$ and almost identical arrival times. The small $\\theta_E$ and faintness\nof the lensing galaxy is very unusual, highlighting the importance of\nsupernovae to fully characterise the properties of galaxy-scale gravitational\nlenses, including the impact of galaxy substructures.\n", "  Simulation-Based Inference of Galaxies (${\\rm S{\\scriptsize IM}BIG}$) is a\nforward modeling framework for analyzing galaxy clustering using\nsimulation-based inference. In this work, we present the ${\\rm S{\\scriptsize\nIM}BIG}$ forward model, which is designed to match the observed SDSS-III BOSS\nCMASS galaxy sample. The forward model is based on high-resolution ${\\rm\nQ{\\scriptsize UIJOTE}}$ $N$-body simulations and a flexible halo occupation\nmodel. It includes full survey realism and models observational systematics\nsuch as angular masking and fiber collisions. We present the \"mock challenge\"\nfor validating the accuracy of posteriors inferred from ${\\rm S{\\scriptsize\nIM}BIG}$ using a suite of 1,500 test simulations constructed using forward\nmodels with a different $N$-body simulation, halo finder, and halo occupation\nprescription. As a demonstration of ${\\rm S{\\scriptsize IM}BIG}$, we analyze\nthe power spectrum multipoles out to $k_{\\rm max} = 0.5\\,h/{\\rm Mpc}$ and infer\nthe posterior of $\\Lambda$CDM cosmological and halo occupation parameters.\nBased on the mock challenge, we find that our constraints on $\\Omega_m$ and\n$\\sigma_8$ are unbiased, but conservative. Hence, the mock challenge\ndemonstrates that ${\\rm S{\\scriptsize IM}BIG}$ provides a robust framework for\ninferring cosmological parameters from galaxy clustering on non-linear scales\nand a complete framework for handling observational systematics. In subsequent\nwork, we will use ${\\rm S{\\scriptsize IM}BIG}$ to analyze summary statistics\nbeyond the power spectrum including the bispectrum, marked power spectrum, skew\nspectrum, wavelet statistics, and field-level statistics.\n", "  The $Euclid$ mission will provide first-of-its-kind coverage in the\nnear-infrared over deep (three fields, $\\sim$10-20 square degrees each) and\nwide ($\\sim$10000 square degrees) fields. While the survey is not designed to\ndiscover transients, the deep fields will have repeated observations over a\ntwo-week span, followed by a gap of roughly six months. In this analysis, we\nexplore how useful the deep field observations will be for measuring properties\nof Type Ia supernovae (SNe Ia). Using simulations that include $Euclid$'s\nplanned depth, area and cadence in the deep fields, we calculate that more than\n3700 SNe between $0.0<z<1.5$ will have at least five $Euclid$ detections around\npeak with signal-to-noise ratio larger than 3. While on their own, $Euclid$\nlight curves are not good enough to directly constrain distances, when combined\nwith LSST deep field observations, we find that uncertainties on SN distances\nare reduced by 20-30% for $z<0.8$ and by 40-50% for $z>0.8$. Furthermore, we\npredict how well additional $Euclid$ mock data can be used to constrain a key\nsystematic in SN Ia studies - the size of the luminosity 'step' found between\nSNe hosted in high mass ($>10^{10} M_{\\odot}$) and low mass ($>10^{10}\nM_{\\odot}$) galaxies. This measurement has unique information in the rest-frame\nNIR. We predict that if the step is caused by dust, we will be able to measure\nits reduction in the NIR compared to optical at the 4$\\sigma$ level. We\nhighlight that the LSST and $Euclid$ observing strategies used in this work are\nstill provisional and some level of joint processing is required. Still, these\nfirst results are promising, and assuming $Euclid$ begins observations well\nbefore the Nancy Roman Space Telescope (Roman), we expect this dataset to be\nextremely helpful for preparation for Roman itself.\n", "  We use the MACSIS hydrodynamical simulations to estimate the extent of gas\nclumping in the intracluster medium of massive galaxy clusters and how it\naffects the hydrostatic mass bias. By comparing the clumping to the azimuthal\nscatter in the emission measure, an observational proxy, we find that they both\nincrease with radius and are larger in higher-mass and dynamically perturbed\nsystems. Similar trends are also seen for the azimuthal temperature scatter and\nnon-thermal pressure fraction, both of which correlate with density\nfluctuations, with these values also increasing with redshift. However, in\nagreement with recent work, we find only a weak correlation between the\nclumping, or its proxies, and the hydrostatic mass bias. To reduce the effect\nof clumping in the projected profiles, we compute the azimuthal median\nfollowing recent observational studies, and find this reduces the scatter in\nthe bias. We also attempt to correct the cluster masses by using a non-thermal\npressure term and find over-corrected mass estimates ($1-b=0.86$ to $1-b=1.15$)\nfrom 3D gas profiles but improved mass estimates ($1-b=0.75$ to $1-b=0.85$)\nfrom projected gas profiles, with the caveat of systematically increased\nscatter. We conclude that the cluster-averaged mass bias is minimised from\napplying a non-thermal pressure correction ($1-b=0.85$) with more modest\nreductions from selecting clusters that have low clumping ($1-b=0.79$) or are\ndynamically relaxed ($1-b=0.80$). However, the latter selection is most\neffective at minimising the scatter for individual objects. Such results can be\ntested with next generation X-ray missions equipped with high-resolution\nspectrometers such as Athena.\n", "  We report the discovery of a transient seen in a strongly lensed arc at\nredshift $z_{\\rm s}=1.2567$ in \\emph{Hubble Space Telescope} imaging of the\nAbell 370 galaxy cluster. The transient is detected at $29.51\\pm0.14$ AB mag in\na WFC3/UVIS F200LP difference image made using observations from two different\nepochs, obtained in the framework of the \\emph{Flashlights} program, and is\nalso visible in the F350LP band ($m_{\\rm F350LP} \\approx 30.53\\pm0.76$ AB mag).\nThe transient is observed on the negative-parity side of the critical curve at\na distance of $\\sim 0.6\"$ from it, greater than previous examples of lensed\nstars. The large distance from the critical curve yields a significantly\nsmaller macromagnification, but our simulations show that bright, O/B-type\nsupergiants can reach sufficiently high magnifications to be seen at the\nobserved position and magnitude. In addition, the observed transient image is a\ntrailing image with an observer-frame time delay of $\\sim+0.8$ days from its\nexpected counterpart, so that any transient lasting for longer than that should\nhave also been seen on the minima side and is thus excluded. This, together\nwith the blue colour we measure for the transient ($m_{\\rm F200LP} - m_{\\rm\nF350LP} \\approx [-0.3,-1.6]$ AB), rules out most other transient candidates\nsuch as (kilo)novae, for example, and makes a lensed star the prime candidate.\nAssuming the transient is indeed a lensed star as suggested, many more such\nevents should be detected in the near future in cluster surveys with the\n\\emph{Hubble Space Telescope} and \\emph{James Webb Space Telescope}.\n", "  We investigate nonlinear structure formation in the fuzzy dark matter (FDM)\nmodel in comparison to cold dark matter (CDM) models from a weak lensing\nperspective using perturbative methods. We use Eulerian perturbation theory\n(PT) up to fourth order to compute the tree-level matter trispectrum and the\none-loop matter spectrum and bispectrum from consistently chosen initial\nconditions. In addition, we predict the non-linear matter power spectra using\n$N$-body simulations with CDM and FDM initial conditions. We go on to derive\nthe respective lensing spectra, bispectra and trispectra in CDM and FDM in the\ncontext of a Euclid-like weak lensing survey. Finally, we compute the\nattainable cumulative signal-to-noise ratios and an estimate of the attainable\n$\\chi^2$-functionals for distinguishing FDM from CDM at particle masses\n$m=10^{-21}$ eV, $m = 10^{-22}$ eV and $m = 10^{-23}$ eV. We find that PT\npredictions cannot be used to reliably distinguish the three models in a weak\nlensing survey. Assuming that $N$-body simulations overestimate the late-time\nsmall-scale power in the FDM model, future weak lensing survey might be used to\ndistinguish between the FDM and CDM cases up to a mass of $m = 10^{-23}$ eV.\nHowever, observations probing the local high-$z$ universe are probably more\nsuited to constrain the FDM mass.\n", "  Cosmological perturbation theory is known to converge poorly for predicting\nthe spherical collapse and void evolution of collisionless matter. Using the\nexact parametric solution as a testing ground, we develop two asymptotic\nmethods in spherical symmetry that resolve the gravitational evolution to much\nhigher accuracy than Lagrangian perturbation theory (LPT), which is the current\ngold standard in the literature. One of the methods selects a stable\nfixed-point solution of the renormalization-group flow equation, thereby\npredicting already at the leading order the critical exponent of the phase\ntransition to collapsed structures. The other method completes the truncated\nLPT series far into the UV regime, by adding a non-analytic term that captures\nthe critical nature of the gravitational collapse. We find that the UV method\nmost accurately resolves the evolution of the nonlinear density as well as its\none-point probability distribution function. Similarly accurate predictions are\nachieved with the renormalization-group method, especially when paired with\nPad\\'e approximants. Further, our results yield new, very accurate, formulas to\nrelate linear and nonlinear density contrasts. Finally, we chart possible ways\non how to adapt our methods to the case of cosmological random field initial\nconditions.\n", "  Novel summary statistics beyond the standard 2-point correlation function\n(2PCF) are necessary to capture the full astrophysical and cosmological\ninformation from the small-scale (r < 30Mpc/h) galaxy clustering. However, the\nanalysis of beyond-2PCF statistics on small scales is challenging because we\nlack the appropriate treatment of observational systematics for arbitrary\nsummary statistics of the galaxy field. In this paper, we develop a full\nforward modeling pipeline for a wide range of summary statistics using the\nlarge high-fidelity AbacusSummit lightcones that accounts for many systematic\neffects but also remains flexible and computationally efficient to enable\nposterior sampling. We apply our forward model approach to a fully realistic\nmock galaxy catalog and demonstrate that we can recover unbiased constraints on\nthe underlying galaxy-halo connection model using two separate summary\nstatistics: the standard 2PCF and the novel k-th nearest neighbor (kNN)\nstatistics, which are sensitive to correlation functions of all orders. We will\nextend this method to a full cosmology emulator in a follow up paper. We expect\nthis to become a powerful approach when applying to upcoming surveys such as\nDESI where we can leverage a multitude of summary statistics across a wide\nredshift range to maximally extract information from the non-linear scales.\n", "  In cosmology, we routinely choose between models to describe our data, and\ncan incur biases due to insufficient models or lose constraining power with\noverly complex models. In this paper we propose an empirical approach to model\nselection that explicitly balances parameter bias against model complexity. Our\nmethod uses synthetic data to calibrate the relation between bias and the\n$\\chi^2$ difference between models. This allows us to interpret $\\chi^2$ values\nobtained from real data (even if catalogues are blinded) and choose a model\naccordingly. We apply our method to the problem of intrinsic alignments -- one\nof the most significant weak lensing systematics, and a major contributor to\nthe error budget in modern lensing surveys. Specifically, we consider the\nexample of the Dark Energy Survey Year 3 (DES Y3), and compare the commonly\nused nonlinear alignment (NLA) and tidal alignment & tidal torque (TATT)\nmodels. The models are calibrated against bias in the $\\Omega_m - S_8$ plane.\nOnce noise is accounted for, we find that it is possible to set a threshold\n$\\Delta \\chi^2$ that guarantees an analysis using NLA is unbiased at some\nspecified level $N\\sigma$ and confidence level. By contrast, we find that\ntheoretically defined thresholds (based on, e.g., $p-$values for $\\chi^2$) tend\nto be overly optimistic, and do not reliably rule out cosmological biases up to\n$\\sim 1-2\\sigma$. Considering the real DES Y3 cosmic shear results, based on\nthe reported difference in $\\chi^2$ from NLA and TATT analyses, we find a\nroughly $30\\%$ chance that were NLA to be the fiducial model, the results would\nbe biased (in the $\\Omega_m - S_8$ plane) by more than $0.3\\sigma$. More\nbroadly, the method we propose here is simple and general, and requires a\nrelatively low level of resources. We foresee applications to future analyses\nas a model selection tool in many contexts.\n", "  In the self-similar scenario for galaxy cluster formation and evolution, the\nthermodynamic properties of the X-ray emitting plasma can be predicted in their\ndependencies on the halo mass and redshift only. However, several departures\nfrom this simple self-similar scenario have been observed. We show how our\nsemi-analytic model $i(cm)z$, which modifies the self-similar predictions\nthrough two temperature-dependent quantities, the gas mass fraction $f_g=f_0\nT^{f_1} E_z^{f_z}$ and the temperature variation $f_T=t_0 T^{t_1} E_z^{t_z}$,\ncan be calibrated to incorporate the mass and redshift dependencies. We used a\npublished set of 17 scaling relations to constrain the parameters of the model.\nWe were subsequently able to make predictions as to the slope of any observed\nscaling relation within a few percent of the central value and about one\n$\\sigma$ of the nominal error. Contextually, the evolution of these scaling\nlaws was also determined, with predictions within $1.5 \\sigma$ and within 10\npercent of the observational constraints. Relying on this calibration, we have\nalso evaluated the consistency of the predictions on the radial profiles with\nsome observational datasets. For a sample of high-quality data (X-COP), we were\nable to constrain a further parameter of the model, the hydrostatic bias $b$.\nBy calibrating the model, we have determined that (i) the slopes of the\ntemperature dependence are $f_1=0.403 (\\pm0.009)$ and $t_1=0.144 (\\pm0.017)$;\nand that (ii) the dependence upon $E_z$ are constrained to be $f_z=-0.004 (\\pm\n0.023)$ and $t_z=0.349 (\\pm 0.059)$. These values permit one to estimate\ndirectly how the normalizations of a given quantity $Q_{\\Delta}$ changes as a\nfunction of the mass (or temperature) and redshift halo in the form $Q_{\\Delta}\n\\sim M^{a_M} E_z^{a_z} \\sim T^{a_T} E_z^{a_{Tz}}$, in very good agreement with\nthe current observational constraints.\n", "  We explore a model introduced by Cyr-Racine, Ge, and Knox\n(arXiv:2107.13000(2)) that resolves the Hubble tension by invoking a ``mirror\nworld\" dark sector with energy density a fixed fraction of the ``ordinary\"\nsector of Lambda-CDM. Although it reconciles cosmic microwave background and\nlarge-scale structure observations with local measurements of the Hubble\nconstant, the model requires a value of the primordial Helium mass fraction\nthat is discrepant with observations and with the predictions of Big Bang\nNucleosynthesis (BBN). We consider a variant of the model with standard Helium\nmass fraction but with the value of the electromagnetic fine-structure constant\nslightly different during photon decoupling from its present value. If $\\alpha$\nat that epoch is lower than its current value by $\\Delta \\alpha \\simeq -2\\times\n10^{-5}$, then we can achieve the same Hubble tension resolution as in\nCyr-Racine, et al. but with consistent Helium abundance. As an example of such\ntime-evolution, we consider a toy model of an ultra-light scalar field, with\nmass $m <4\\times 10^{-29}$ eV, coupled to electromagnetism, which evolves after\nphoton decoupling and that appears to be consistent with late-time constraints\non $\\alpha$ variation and the weak equivalence principle.\n", "  Extragalactic foregrounds are known to generate significant biases in\ntemperature-based CMB lensing reconstruction. Several techniques, which include\n``source hardening'' and ``shear-only estimators'' have been proposed to\nmitigate contamination and have been shown to be very effective at reducing\nforeground-induced biases. Here we extend both techniques to polarization,\nwhich will be an essential component of CMB lensing reconstruction for future\nexperiments, and investigate the ``large-lens'' limit analytically to gain\ninsight on the origin and scaling of foreground biases, as well as the\nsensitivity to their profiles.Using simulations of polarized point sources, we\nestimate the expected bias to both Simons Observatory and CMB-S4 like\n(polarization-based) lensing reconstruction, finding that biases to the former\nare minuscule while those to the latter are potentially non-negligible at small\nscales ($L\\sim1000-2000$). In particular, we show that for a CMB-S4 like\nexperiment, an optimal linear combination of point-source hardened estimators\ncan reduce the (point-source induced) bias to the CMB lensing power spectrum by\nup to two orders of magnitude, at a $\\sim4\\%$ noise cost relative to the global\nminimum variance estimator.\n", "  Although weak lensing (WL) is a powerful method to estimate a galaxy cluster\nmass without any dynamical assumptions, a model bias can arise when the cluster\ndensity profile departs from the assumed model profile. In a merging system,\nthe bias is expected to become most severe because the constituent halos\nundergo significant structural changes. In this study, we investigate WL mass\nbias in binary cluster mergers using a suite of idealized hydrodynamical\nsimulations. Realistic WL shear catalogs are generated by matching the source\ngalaxy properties, such as intrinsic shape dispersion, measurement noise,\nsource densities, etc., to those from Subaru and {\\it Hubble Space Telescope}\nobservations. We find that, with the typical mass-concentration ($M$-$c$)\nrelation and the Navarro-Frenk-White (NFW) profile, the halo mass bias depends\non the time since the first pericenter passage and increases with the mass of\nthe companion cluster. The time evolution of the mass bias is similar to that\nof the concentration, indicating that, to first order, the mass bias is\nmodulated by the concentration change. For a collision between two\n$\\sim10^{15}~M_{\\odot}$ clusters, the maximum bias amounts to $\\sim60\\%$. This\nsuggests that previous WL studies may have significantly overestimated the mass\nof the clusters in some of the most massive mergers. Finally, we apply our\nresults to three merger cases: Abell 2034, MACS J1752.0+4440, and ZwCl\n1856.8+6616, and report their mass biases at the observed epoch, as well as\ntheir pre-merger masses, utilizing their merger shock locations as tracers of\nthe merger phases.\n", "  Baryonic Acoustic Oscillations (BAOs) studies based on the clustering of\nvoids and matter tracers provide important constraints on cosmological\nparameters related to the expansion of the Universe. However, modelling the\nvoid exclusion effect is an important challenge for fully exploiting the\npotential of this kind of analyses. We thus develop two numerical methods to\ndescribe the clustering of cosmic voids. Neither model requires additional\ncosmological information beyond that assumed within the galaxy de-wiggled\nmodel. The models consist in power spectra whose performance we assess in\ncomparison to a parabolic model on Patchy cubic and light-cone mocks. Moreover,\nwe test their robustness against systematic effects and the reconstruction\ntechnique. The void model power spectra and the parabolic model with a fixed\nparameter provide strongly correlated values for the Alcock-Paczynski\n($\\alpha$) parameter, for boxes and light-cones likewise. The resulting\n$\\alpha$ values -- for all three models -- are unbiased and their uncertainties\nare correctly estimated. However, the numerical models show less variation with\nthe fitting range compared to the parabolic one. The Bayesian evidence suggests\nthat the numerical techniques are often favoured compared to the parabolic\nmodel. Moreover, the void model power spectra computed on boxes can describe\nthe void clustering from light-cones as well as from boxes. The same void model\npower spectra can be used for the study of pre- and post-reconstructed\ndata-sets. Lastly, the two numerical techniques are resilient against the\nstudied systematic effects. Consequently, using either of the two new void\nmodels, one can more robustly measure cosmological parameters.\n", "  In the procedure of constraining the cosmological parameters with the\nobservational Hubble data and the type Ia supernova data, the combination of\nMasked Autoregressive Flow and Denoising Autoencoder can perform a good result.\nThe above combination extracts the features from OHD with DAE, and estimates\nthe posterior distribution of cosmological parameters with MAF. We ask whether\nwe can find a better tool to compress large data in order to gain better\nresults while constraining the cosmological parameters. Information maximising\nneural networks, a kind of simulation-based machine learning technique, was\nproposed at an earlier time. In a series of numerical examples, the results\nshow that IMNN can find optimal, non-linear summaries robustly. In this work,\nwe mainly compare the dimensionality reduction capabilities of IMNN and DAE. We\nuse IMNN and DAE to compress the data into different dimensions and set\ndifferent learning rates for MAF to calculate the posterior. Meanwhile, the\ntraining data and mock OHD are generated with a simple Gaussian likelihood, the\nspatially flat {\\Lambda}CDM model and the real OHD data. To avoid the complex\ncalculation in comparing the posterior directly, we set different criteria to\ncompare IMNN and DAE.\n", "  Polarization of the cosmic microwave background (CMB) can probe new\nparity-violating physics such as cosmic birefringence (CB), which requires\nexquisite control over instrumental systematics. The non-idealities of the\nhalf-wave plate (HWP) represent a source of systematics when used as a\npolarization modulator. We study their impact on the CMB angular power spectra,\nwhich is partially degenerate with CB and miscalibration of the polarization\nangle. We use full-sky beam convolution simulations including HWP to generate\nmock noiseless time-ordered data, process them through a bin averaging\nmap-maker, and calculate the power spectra including $TB$ and $EB$\ncorrelations. We also derive analytical formulae which accurately model the\nobserved spectra. For our choice of HWP parameters, the HWP-induced angle\namounts to a few degrees, which could be misinterpreted as CB. Accurate\nknowledge of the HWP is required to mitigate this. Our simulation and\nanalytical formulae will be useful for deriving requirements for the accuracy\nof HWP calibration.\n", "  We quantify the cosmological constraining power of the `lensing PDF' - the\none-point probability density of weak lensing convergence maps - by modelling\nthis statistic numerically with an emulator trained on $w$CDM cosmic shear\nsimulations. After validating our methods on Gaussian and lognormal fields, we\nshow that `multi-scale' PDFs - measured from maps with multiple levels of\nsmoothing - offer considerable gains over two-point statistics, owing to their\nability to extract non-Gaussian information: for a mock Stage-III survey,\nlensing PDFs yield 33\\% tighter constraints on the clustering parameter\n$S_8=\\sigma_8\\sqrt{\\Omega_{\\rm m}/0.3}$ than the two-point shear correlation\nfunctions. For Stage-IV surveys, we achieve $>$90\\% tighter constraints on\n$S_8$, but also on the Hubble and dark energy equation of state parameters.\nInterestingly, we find improvements when combining these two probes only in our\nStage-III setup; in the Stage-IV scenario the lensing PDFs contain all\ninformation from the standard two-point statistics and more. This suggests that\nwhile these two probes are currently complementary, the lower noise levels of\nupcoming surveys will unleash the constraining power of the PDF.\n", "  We present a further observational analysis of the $\\Lambda_{\\rm s}$CDM model\nproposed in Akarsu et al. [Phys. Rev. D 104, 123512 (2021)]. This model is\nbased on the recent conjecture suggesting the Universe has transitioned from\nanti-de Sitter vacua to de Sitter vacua (viz., the cosmological constant\nswitches sign from negative to positive), at redshift ${z_\\dagger\\sim2}$,\ninspired by the graduated dark energy model proposed in Akarsu et al. [Phys.\nRev. D 101, 063528 (2020)]. $\\Lambda_{\\rm s}$CDM was previously claimed to\nsimultaneously relax five cosmological discrepancies, namely, the $H_0$, $S_8$,\nand $M_B$ tensions along with the Ly-$\\alpha$ and $\\omega_{\\rm b}$ anomalies,\nwhich prevail within the standard $\\Lambda$CDM model as well as its\ncanonical/simple extensions. In the present work, we extend the previous\nanalysis by constraining the model using the Pantheon data (with and without\nthe SH0ES $M_B$ prior) and/or the completed BAO data along with the full Planck\nCMB data. We find that $\\Lambda_{\\rm s}$CDM exhibits a better fit to the data\ncompared to $\\Lambda$CDM, and simultaneously relaxes the six discrepancies of\n$\\Lambda$CDM, viz., the $H_0$, $M_B$, $S_8$, Ly-$\\alpha$, $t_0$, and\n$\\omega_{\\rm b}$ discrepancies, all of which are discussed in detail. When the\n$M_B$ prior is included in the analyses, $\\Lambda_{\\rm s}$CDM performs\nsignificantly better in relaxing the $H_0$, $M_B$, and $S_8$ tensions with the\nconstraint ${z_\\dagger\\sim1.8}$ even when the Ly-$\\alpha$ data (which imposed\nthe $z_\\dagger\\sim2$ constraint in the previous studies) are excluded. In\ncontrast, the presence of the $M_B$ prior causes only negligible improvements\nfor $\\Lambda$CDM. Thus, the $\\Lambda_{\\rm s}$CDM model provides remedy to\nvarious cosmological tensions simultaneously, only that the galaxy BAO data\nhinder its success to some extent.\n", "  We provide a correlation analysis of signatures associated with traces of the\ndark matter decay and the galaxy spatial distribution according to the 2MRS\ncatalog of galaxies. Signature data analysis plays an important role in the\ncontext of current and future observations and cosmological constraints.\nAttention is paid to the constraints that can be obtained for decaying sterile\nneutrinos when analyzing observations in the context of the\nSpectr-Roentegn-Gamma (SRG) mission. We study the correlation spectra of dark\nmatter and galaxies, which can be obtained both for the eROSITA telescope and\nfor the first time for the ART-XC telescope. The analysis is carried out both\nwithin the framework of the Limber approximation and within the framework of\nthe extended Limber approximation, which makes it possible to more accurately\nstudy the power spectra in the region of small multipoles. We calculate the\npower spectra in both approaches and examine the contribution of different\nranges of multipoles to the resulting constraints on sterile neutrino\nparameters.\n", "  Cosmic birefringence is the in-vacuo rotation of the linear polarization\nplane experienced by photons of the Cosmic Microwave Background (CMB) radiation\nwhen theoretically well-motivated parity-violating extensions of Maxwell\nelectromagnetism are considered. If the angle, parametrizing such a rotation is\ndependent on the photon's direction, then this phenomenon is called Anisotropic\nCosmic Birefringence (ACB). In this paper, we perform for the first time a\ntomographic treatment of the ACB, by considering photons emitted both at the\nrecombination and reionization epoch. This allows one to extract additional and\ncomplementary information about the physical source of cosmic birefringence\nwith respect to the isotropic case. We focus here on the case of an axion-like\nfield $\\chi$, whose coupling with the electromagnetic sector induces such a\nphenomenon, by using an analytical and numerical approach (which involves a\nmodification of the CLASS code). We find that the anisotropic component of\ncosmic birefringence exhibits a peculiar behavior: an increase of the axion\nmass implies an enhancement of the anisotropic amplitude, allowing to probe a\nwider range of masses with respect to the purely isotropic case. Moreover, we\nshow that at large angular scales, the interplay between the reionization and\nrecombination contributions to ACB is sensitive to the axion mass, so that at\nsufficiently low multipoles, for sufficiently light masses, the reionization\ncontribution overtakes the recombination one, making the tomographic approach\nto cosmic birefringence a promising tool for investigating the properties of\nthis axion-like field.\n", "  The theoretical basis of dark energy remains unknown and could signify a need\nto modify the laws of gravity on cosmological scales. In this study we\ninvestigate how the clustering and motions of galaxies can be used as probes of\nmodified gravity theories, using galaxy and direct peculiar velocity auto- and\ncross-correlation functions. We measure and fit these correlation functions in\nsimulations of $\\Lambda$CDM, DGP, and $f(R)$ cosmologies and, by extracting the\ncharacteristic parameters of each model, we show that these theories can be\ndistinguished from General Relativity using these measurements. We present\nforecasts showing that with sufficiently large data samples, this analysis\ntechnique is a competitive probe that can help place limits on allowed\ndeviations from GR. For example, a peculiar velocity survey reaching to $z=0.5$\nwith $20\\%$ distance accuracy would constrain model parameters to 3-$\\sigma$\nconfidence limits $\\log_{10}|f_{R0}| < -6.45$ for $f(R)$ gravity and $r_c >\n2.88 \\, c/H_0$ for nDGP, assuming a fiducial GR model.\n", "  Galaxies, diffuse gas, and dark matter make up the cosmic web that defines\nthe large-scale structure of the Universe. We constrained the joint\ndistribution of these constituents by cross-correlating galaxy samples binned\nby stellar mass from the Sloan Digital Sky Survey CMASS catalog with maps of\nlensing convergence and the thermal Sunyaev-Zeldovich (tSZ) effect from the\nPlanck mission. Fitting a halo-based model to our measured angular power\nspectra (galaxy-galaxy, galaxy-lensing convergence, and galaxy-tSZ) at a median\nredshift of $z=0.53$, we detected variation with stellar mass of the galaxy\nsatellite fraction and galaxy spatial distribution within host halos. We find a\ntSZ-halo hydrostatic mass bias, $b_h$, such that $(1-b_h)=0.6\\pm0.05$, with a\nhint of a larger bias, $b_h$, at the high stellar mass end. The normalization\nof the galaxy-cosmic microwave background lensing convergence cross-power\nspectrum shows that galaxies trace the matter distribution without an\nindication of stochasticity ($A=0.98\\pm 0.09$). We forecast that\nnext-generation cosmic microwave background experiments will improve the\nconstraints on the hydrostatic bias by a factor of two and will be able to\nconstrain the small-scale distribution of dark matter, hence informing the\ntheory of feedback processes.\n", "  We study primordial non-Gaussian signatures in the redshift-space halo field\non non-linear scales, using a quasi-maximum likelihood estimator based on\noptimally compressed power spectrum and modal bispectrum statistics. We train\nand validate the estimator on a suite of halo catalogues constructed from the\nQuijote-PNG N-body simulations, which we release to accompany this paper. We\nverify its unbiasedness and near optimality, for the three main types of\nprimordial non-Gaussianity (PNG): local, equilateral, and orthogonal. We\ncompare the modal bispectrum expansion with a $k$-binning approach, showing\nthat the former allows for faster convergence of numerical derivatives in the\ncomputation of the score-function, thus leading to better final constraints. We\nfind, in agreement with previous studies, that the local PNG signal in the\nhalo-field is dominated by the scale-dependent bias signature on large scales\nand saturates at $k \\sim 0.2~h\\,\\mathrm{Mpc}^{-1}$, whereas the small-scale\nbispectrum is the main source of information for equilateral and orthogonal\nPNG. Combining power spectrum and bispectrum on non-linear scales plays an\nimportant role in breaking degeneracies between cosmological and PNG\nparameters; such degeneracies remain however strong for equilateral PNG. We\nforecast that PNG parameters can be constrained with $\\Delta\nf_\\mathrm{NL}^\\mathrm{local} = 45$, $\\Delta f_\\mathrm{NL}^\\mathrm{equil} =\n570$, $\\Delta f_\\mathrm{NL}^\\mathrm{ortho} = 110$, on a cubic volume of $1\n\\left({ {\\rm Gpc}/{ {\\rm h}}} \\right)^3$, at $z = 1$, considering scales up to\n$k_\\mathrm{max} = 0.5~h\\,\\mathrm{Mpc}^{-1}$.\n", "  We present a continuation of an analysis that aims to quantify resolution of\n$N$-body simulations by exploiting large (up to $N=4096^3$) simulations of\nscale-free cosmologies run using Abacus. Here we focus on radial pairwise\nvelocities of the matter field, both by direct estimation and through the\ncumulative-2PCF (using the pair conservation equation). We find that\nconvergence at the $1\\%$ level of the mean relative pairwise velocity can be\ndemonstrated over a range of scales, evolving from a few times the grid spacing\nat early times to slightly below this scale at late times. We show the analysis\nof two different box sizes as well as from averaging results from the smaller\nboxes, and compare the power of the two aforementioned estimators in\nconstraining accuracy at each scale. Down to scales of order of the smoothing\nparameter, convergence is obtained at $\\sim5\\%$ precision, and shows a\nbehaviour indicating asymptotic stable clustering. We also infer for LCDM\nsimulations conservative estimates on the evolution of the lower cut-off to\nresolution (at $1\\%$ and $5\\%$ precision) as a function of redshift.\n", "  It has been theorized that Dynamical Dark Energy (DDE) could be a possible\nsolution to the Hubble tension. To avoid the degeneracy between the Hubble\nparameter $H_0$ and the sound horizon scale $r_d$, in this article we use their\nmultiplication as one parameter $c/\\left(H_0 r_d\\right)$ and we use it to infer\ncosmological parameters for 6 different models - $\\Lambda$CDM and 5 DDE\nparametrizations -- the Chevallier-Polarski-Linder (CPL), the Barboza-Alcaniz\n(BA), the Low correlation (LC), the Jassal-Bagla-Padmanabhan (JBP) and the\nFeng-Shen-Li-Li model. We choose a dataset that treats this combination as one\nparameter, that includes the Baryon Acoustic Oscillation (BAO) data $0.11 \\le z\n\\le 2.40$ and additional points from the Cosmic Microwave Background (CMB)\nPeaks ($z \\approx 1090$). To them, we add the marginalized Pantehon dataset and\nGRB dataset. We see that the tension is moved from $H_0$ and $r_d$ to\n$c/\\left(H_0 r_d\\right)$ and $\\Omega_m$. There is only one model that satisfies\nthe Planck 2018 constraints on both parameters and this is LC with a huge\nerror. The rest cannot fit into both constraints. $\\Lambda$CDM is preferred\nwith respect to the statistical measures.\n", "  Incomplete sky analysis of cosmic microwave background (CMB) polarization\nspectra poses a major problem of leakage between $E$- and $B$-modes. We present\na machine learning approach to remove this $E$-to-$B$ leakage using a\nconvolutional neural network (CNN) in presence of detector noise. The CNN\npredicts the full sky $E$- and $B$-modes spectra for multipoles $2 \\leq \\ell\n\\leq 384$ from the partial sky spectra for $N_{\\rm{side}} = 256$. We use\ntensor-to-scalar ratio $r=0.001$ to simulate the CMB polarization maps. We\ntrain our CNN using $10^5$ full sky target spectra and an equal number of noise\ncontaminated partial sky spectra obtained from the simulated maps. The CNN\nworks well for two masks covering the sky area of $\\sim 80\\%$ and $\\sim 10\\%$\nrespectively after training separately for each mask. For the assumed\ntheoretical $E$- and $B$-modes spectra, predicted full sky $E$- and $B$-modes\nspectra agree well with the corresponding target spectra and their means agree\nwith theoretical spectra. The CNN preserves the cosmic variances at each\nmultipole, effectively removes correlations of the partial sky $E$- and\n$B$-modes spectra, and retains the entire statistical properties of the targets\navoiding the problem of so-called $E$-to-$B$ leakage for the chosen theoretical\nmodel.\n", "  Galaxy formation theories predict that galaxy shapes and angular momenta have\nnon-random alignments with the cosmic web. This leads to so-called intrinsic\nalignment between pairs of galaxies, which is important to quantify as a\nnuisance parameter for weak lensing. We study galaxy-cosmic web alignment in\nthe IllustrisTNG suite of hydrodynamical simulations at redshifts 1 and 2,\nfinding that alignment trends are consistent with previous studies. However, we\nfind that the magnitude of the spin alignment signal is $\\sim 2.4 \\times$\nweaker than seen in previous studies of the Horizon-AGN simulation, suggesting\nthat this signal may have significant dependence on subgrid physics. Based on\nIllustrisTNG, we then construct mock observational spectroscopic surveys that\ncan probe shape-cosmic web alignment at $z \\sim 1-2$, modeled on the low-$z$\ngalaxy redshift and IGM tomography surveys on the upcoming Subaru Prime Focus\nSpectrograph Galaxy Evolution (PFS GE) survey. However, even over box sizes of\n$L=205\\,h^{-1}\\,\\mathrm{Mpc}$, we find that global anisotropies induce a sample\nvariance in the 2D projected alignment signal that depend on the projected\ndirection -- this induces significant errors in the observed alignment. We\npredict a $5.3\\sigma$ detection of IllustrisTNG's shape alignment signal at $z\n\\sim 1$ from Subaru PFS GE, although a detection would be challenging at $z\n\\sim 2$. However, a rough rescaling of the relative alignment signal strengths\nbetween the TNG and HorizonAGN simulations suggests that PFS GE should be able\nto more easily constrain the latter's stronger signal.\n", "  While the probability density function (PDF) of the cosmic microwave\nbackground (CMB) convergence field approximately follows a Gaussian\ndistribution, primordial non-Gaussianities and small contributions from\nstructures at low redshifts make the overall distribution slightly\nnon-Gaussian. Some of the late-time component can be modelled using the\ndistribution of galaxies and subtracted off from the original CMB lensing map\nto produce a map of matter distribution at high redshifts. Using this\nhigh-redshift mass map, we are able to directly study the early phases of\nstructure formation. In this work, we forecast the detectability of signatures\nof non-Gaussianity due to nonlinear structure formation at $z>1.2$. Assuming\nthe optimal case of no systematics, we find that it is challenging to detect\nsuch signatures in current surveys, but future experiments such as the deep\nfield of CMB-S4 will be able to make detections of $\\sim7\\sigma$.\n", "  Weak lensing studies via cosmic voids are a promising probe of Modified\nGravity (MG). Excess surface mass density (ESD) is widely used as a lensing\nstatistic in weak lensing research. In this paper, we use the ray-tracing\nmethod to study the ESD around voids in simulations based on Cubic Galileon\n(CG) gravity. With the compilation of N-body simulation and ray-tracing method,\nchanges in structure formation and deflection angle resulting from MG can both\nbe considered, making the extraction of lensing signals more realistic. We find\ngood agreements between the measurement and theoretical prediction of ESD for\nCG gravity. Meanwhile, the lensing signals are much less affected by the change\nof the deflection angle than the change of the structure formation, indicating\na good approximation of regarding ESD (statistics) as the projection of 3D dark\nmatter density field. Finally, we demonstrate that it is impossible to\ndistinguish CG and General Relativity in our simulation, however, in the\nnext-generation survey, thanks to the large survey area and the increased\ngalaxy number density, detecting the differences between these two models is\npossible. The methodology employed in this paper that combines N-body\nsimulation and ray-tracing method can be a robust way to measure the lensing\nsignals from simulations based on the MGs, and especially on that which\nsignificantly modifies the deflection angle.\n", "  We present a first application to photometric galaxy clustering and weak\nlensing of wavelet based multi-scale higher order summary statistics: starlet\npeak counts and starlet $\\ell_1$-norm. Peak counts are the local maxima in the\nmap and the $\\ell_1$-norm is computed via the sum of the absolute values of the\nstarlet (wavelet) decomposition coefficients of a map, providing a fast\nmulti-scale calculation of the pixel distribution, encoding the information of\nall pixels in the map. We employ the cosmo-SLICS simulations sources and lenses\ncatalogues and we compute wavelet based higher order statistics in the context\nof combined probes and their potential when applied to the weak lensing\nconvergence maps and galaxy maps. We get forecasts on the matter density\nparameter $\\Omega_{\\rm m}$, the reduced Hubble constant $h$, the matter\nfluctuation amplitude $\\sigma_8$, and the dark energy equation of state\nparameter $w_0$. We find that, in our setting for this first application,\nconsidering the two probes as independent, starlet peaks and the $\\ell_1$-norm\nrepresent interesting summary statistics that can improve the constraints with\nrespect to the power spectrum also in the case of photometric galaxy clustering\nand when the two probes are combined.\n", "  We present a novel approach to the construction of mock galaxy catalogues for\nlarge-scale structure analysis based on the distribution of dark matter halos\nobtained with effective bias models at the field level. We aim to produce mock\ngalaxy catalogues capable of generating accurate covariance matrices for a\nnumber of cosmological probes that are expected to be measured in current and\nforthcoming galaxy redshift surveys (e.g. two- and three-point statistics). We\nuse the bias assignment method (BAM) to model the statistics of halo\ndistribution through a learning algorithm using a few detailed $N$-body\nsimulations, and approximated gravity solvers based on Lagrangian perturbation\ntheory. Using specific models of halo occupation distributions, we generate\ngalaxy mocks with the expected number density and central-satellite fraction of\nemission-line galaxies, which are a key target of the DESI experiment. BAM\ngenerates mock catalogues with per cent accuracy in a number of summary\nstatistics, such as the abundance, the two- and three-point statistics of halo\ndistributions, both in real and redshift space. In particular, the mock galaxy\ncatalogues display $\\sim 3\\%-10\\%$ accuracy in the multipoles of the power\nspectrum up to scales of $k\\sim 0.4\\,h^{-1}{\\rm Mpc}$. We show that covariance\nmatrices of two- and three-point statistics obtained with BAM display a similar\nstructure to the reference simulation. BAM offers an efficient way to produce\nmock halo catalogues with accurate two- and three-point statistics, and is able\nto generate a variety of multi-tracer catalogues with precise covariance\nmatrices of several cosmological probes. We discuss future developments of the\nalgorithm towards mock production in DESI and other galaxy-redshift surveys.\n(Abridged)\n", "  Following results presented in Spallicci et al. (Eur Phys J Plus 137, 2022)\nby the same authors, we investigate the observed red shift $z$, working under\nthe hypothesis that it might be composed by the expansion red shift $z_{\\rm C}$\nand an additional frequency shift $z_{\\rm S}$, towards the red or the blue, due\nto Extended Theories of Electromagnetism (ETE). We have tested this prediction\nconsidering the novel Pantheon+ Catalogue, composed by 1701 light curves\ncollected by 1550 SNe Ia, and 16 BAO data, for different cosmological models\ncharacterised by the absence of a dark energy component. In particular, we\nshall derive which values of $z_{\\rm S}$ match the observations, comparing the\nnew results with the ones obtained considering the older Pantheon Catalogue. We\nfind interesting differences in the resulting $z_{\\rm S}$ distributions,\nhighlighted in the text. Later, we also add a discussion regarding Extended\nTheories of Gravity and how to incorporate them in our methodology.\n", "  In this work, we propose a string-inspired two fields inflation model to\naddress the fine-tuning problem that the standard inflation model suffers. The\nfast-rolling tachyon $\\mathcal{T}$ originated from the D-brane and anti-D-brane\npair annihilation locks the inflaton $\\varphi$ slowly rolling on a Higgs-like\npotential $V(\\varphi)=-m_\\varphi^2\\varphi^2+\\lambda \\varphi^4$ and drives a\nkinetically stabilized (KS) inflation. Our numerical simulation confirms such a\nsolution is a dynamic attractor. In particular, for $\\lambda< 0.8\\times\n10^{-3}$, the e-folding number contributed by the KS inflation phase can be\nlarger than $62$ to solve the horizon and flatness problems of Big Bang theory.\nNotably, this KS inflation generates a nearly scale-invariant primordial\ncurvature perturbations spectrum consistent with current cosmic microwave\nbackground (CMB) observations. It predicts a low tensor-to-scalar ratio, which\nthe current primordial gravitational wave background (the B-modes in CMB)\nsearches favor.\n", "  To assume hydrostatic equilibrium between the intracluster medium and the\ngravitational potential of galaxy clusters is an extensively used method to\ninvestigate their total masses. We want to test hydrostatic masses obtained\nwith an observational code in the context of the SRG/eROSITA survey. We use the\nhydrostatic modeling code MBProj2 to fit surface-brightness profiles to\nsimulated clusters with idealized properties as well as to a sample of 93\nclusters taken from the Magneticum Pathfinder simulations. We investigate the\nlatter under the assumption of idealized observational conditions and also for\nrealistic eROSITA data quality. The comparison of the fitted cumulative total\nmass profiles and the true mass profiles provided by the simulations allows to\ngain knowledge about the reliability of our approach. Furthermore, we use the\ntrue profiles for gas density and pressure to compute hydrostatic mass profiles\nbased on theory for every cluster. For an idealized cluster that was simulated\nto fulfill perfect hydrostatic equilibrium, we find that the cumulative total\nmass at the true $r_{500}$ and $r_{200}$ can be reproduced with deviations of\nless than 7%. For the clusters from the Magneticum Pathfinder simulations under\nidealized observational conditions, the median values of the fitted cumulative\ntotal masses at the true $r_{500}$ and $r_{200}$ are in agreement with our\nexpectations, taking into account the hydrostatic mass bias. Nevertheless, we\nfind a tendency towards a too high steepness of the cumulative total mass\nprofiles in the outskirts. For realistic eROSITA data quality, this steepness\nproblem intensifies for clusters with high redshifts and thus leads to too high\ncumulative total masses at $r_{200}$. For the hydrostatic masses based on the\ntrue profiles known from the simulations, we find a good agreement with our\nexpectations concerning the hydrostatic mass.\n", "  The measurement of the absolute neutrino mass scale from cosmological\nlarge-scale clustering data is one of the key science goals of the Euclid\nmission. Such a measurement relies on precise modelling of the impact of\nneutrinos on structure formation, which can be studied with $N$-body\nsimulations. Here we present the results from a major code comparison effort to\nestablish the maturity and reliability of numerical methods for treating\nmassive neutrinos. The comparison includes eleven full $N$-body implementations\n(not all of them independent), two $N$-body schemes with approximate time\nintegration, and four additional codes that directly predict or emulate the\nmatter power spectrum. Using a common set of initial data we quantify the\nrelative agreement on the nonlinear power spectrum of cold dark matter and\nbaryons and, for the $N$-body codes, also the relative agreement on the\nbispectrum, halo mass function, and halo bias. We find that the different\nnumerical implementations produce fully consistent results. We can therefore be\nconfident that we can model the impact of massive neutrinos at the sub-percent\nlevel in the most common summary statistics. We also provide a code validation\npipeline for future reference.\n", "  We develop a pipeline to set new constraints on scale-independent modified\ngravity, from the galaxy power spectrum in redshift space of BOSS DR12. The\nlatter is modelled using the effective field theory of large-scale structure up\nto 1-loop order in perturbation theory. We test our pipeline on synthetic and\nsimulated data, to assess systematic biases on the inferred cosmological\nparameters due to marginalization and theoretical errors, and we apply it to\nthe normal branch of the DGP model with a $\\Lambda$CDM background. When applied\nto synthetic data and cosmological simulations, we observe biased posteriors\ndue to the strong degeneracy between the nDGP parameter $\\Omega_{\\rm rc}$ and\nthe primordial amplitude of fluctuations $A_s$. Fixing the latter to the Planck\ncentral value, we obtain a posterior distribution with $\\Omega_{\\rm rc}\\lesssim\n0.65$ at 95$\\%$ C.L., under the assumption of a flat prior on $\\log_{10}\n\\Omega_{\\rm rc}$. This upper bound, however, depends strongly on the prior on\n$\\Omega_{\\rm rc}$. To alleviate this effect, we provide an upper bound based on\nthe Bayes factor between the nDGP model and $\\Lambda$CDM model, which gives\n$\\Omega_{\\rm rc}\\lesssim 0.2$ at 95$\\%$ C.L..\n", "  One of the most promising probes to constrain the reionization history of the\nuniverse is the power spectrum of neutral hydrogen 21 cm emission fluctuations.\nThe corresponding analyses require computationally efficient modelling of\nreionization, usually achieved through semi-numerical simulations. We\ninvestigate the capability of one such semi-numerical code, SCRIPT, to\nconstrain the reionization parameters. Our study involves creating a mock data\nset corresponding to the upcoming SKA-Low, followed by a Bayesian inference\nmethod to constrain the model parameters. In particular, we explore in detail\nwhether the inferred parameters are unbiased with respect to the inputs used\nfor the mock, and also if the inferences are insensitive to the resolution of\nthe simulation. We find that the model is successful on both fronts. We also\ndevelop a simple template model of reionization which can mimic the complex\nphysical processes like inhomogeneous recombinations and radiative feedback and\nshow that it can recover the global reionization history reliably with moderate\ncomputational cost. However, such simple models are not suitable for\nconstraining the properties of the ionizing sources. Our results are relevant\nfor constraining reionization using high-quality data expected in future\ntelescopes.\n", "  We consider coupled dark energy (CDE) cosmologies, where dark matter\nparticles feel a force stronger than gravity, due to the fifth force mediated\nby a scalar field which plays the role of dark energy. We perform for the first\ntime a tomographic analysis of coupled dark energy, where the coupling strength\nis parametrized and constrained in different redshift bins. This allows us to\nverify which data can better constrain the strength of the coupling and how\nlarge the coupling can be at different epochs. First, we employ cosmic\nmicrowave background data from Planck, the Atacama Cosmology Telescope (ACT)\nand South Pole Telescope (SPT), showing the impact of different choices that\ncan be done in combining these datasets. Then, we use a range of low redshift\nprobes to test CDE cosmologies, both for a constant and for a tomographic\ncoupling. In particular, we use for the first time data from weak lensing (the\nKiDS-1000 survey), galaxy clustering (BOSS survey), and their combination,\nincluding 3x2pt galaxy-galaxy lensing cross-correlation data. We do not find\nevidence for nonzero coupling, either for a constant or tomographic case. A\nnonzero coupling is however still in agreement with current data. For CMB and\nbackground datasets, a tomographic coupling allows for $\\beta$ values up to one\norder of magnitude larger than in previous works, in particular at $z<1$. The\nuse of 3x2pt analysis then becomes important to constrain $\\beta$ at low\nredshifts, even when coupling is allowed to vary: for 3x2pt we find, at $0.5 <\nz < 1$, $\\beta=0.0180_{-0.011}^{+0.007}$, comparable to what CMB and background\ndatasets would give for a constant coupling. This makes upcoming galaxy surveys\npotentially powerful probes to test CDE models at low redshifts. (abridged)\n", "  We validate the COVMOS method introduced in Baratta et al. (2019) allowing\nfor the fast simulation of catalogues of different cosmological field tracers\n(e.g. dark matter particles, halos, galaxies, etc.). The power spectrum and\none-point probability distribution function of the underlying tracer density\nfield are set as inputs of the method and are arbitrarily chosen by the user.\nIn order to evaluate the validity domain of COVMOS at the level of the produced\ntwo-point statistics covariance matrix, we choose to target these two input\nstatistical quantities from realistic $N$-body simulation outputs. In\nparticular, we perform this cloning procedure in a $\\Lambda$CDM and in a\nmassive neutrino cosmologies, for five redshifts in the range $z\\in[0,2]$.\nFirst, we validate the output real-space two-point statistics (both in\nconfiguration and Fourier space) estimated over $5,000$ COVMOS realisations per\nredshift and per cosmology, with a volume of $1\\ [\\mathrm{Gpc}/h]^3$ and $10^8$\nparticles each. Such a validation is performed against the corresponding\n$N$-body measurements, estimated from 50 simulations. We find the method to be\nvalid up to $k\\sim 0.2h/$Mpc for the power spectrum and down to $r~\\sim 20$\nMpc$/h$ for the correlation function. Then, we extend the method by proposing a\nnew modelling of the peculiar velocity distribution, aiming at reproducing the\nredshift-space distortions both in the linear and mildly non-linear regimes.\nAfter validating this prescription, we finally compare and validate the\nproduced redshift-space two-point statistics covariance matrices in the same\nrange of scales. We release on a public repository the Python code associated\nwith this method, allowing the production of tens of thousands of realisations\nin record time. COVMOS is intended for any user involved in large galaxy-survey\nscience requiring a large number of mock realisations.\n", "  From observations at low and high redshifts, it is well known that the bulk\nof dark matter (DM) has to be stable or at least very long-lived. However, the\npossibility that a small fraction of DM is unstable or that all DM decays with\na half-life time ($\\tau$) significantly longer than the age of the Universe is\nnot ruled out. One-body decaying dark matter (DDM) consists of a minimal\nextension to the $\\Lambda$CDM model. It causes a modification of the cosmic\ngrowth history as well as a suppression of the small-scale clustering signal,\nproviding interesting consequences regarding the $S_8$ tension, which is the\nobserved difference in the clustering amplitude between weak-lensing (WL) and\ncosmic microwave background (CMB) observations. In this paper, we investigate\nmodels in which a fraction or all DM decays into radiation, focusing on the\nlong-lived regime, that is, $\\tau \\gtrsim H_0^{-1}$ ( $H_0^{-1}$ being the\nHubble time). We used WL data from the Kilo-Degree Survey (KiDS) and CMB data\nfrom Planck. First, we confirm that this DDM model cannot alleviate the $S_8$\ndifference. We then show that the most constraining power for DM decay does not\ncome from the nonlinear WL data, but from CMB via the integrated Sachs-Wolfe\neffect. From the CMB data alone, we obtain constraints of $\\tau \\geq 288$~Gyr\nif all DM is assumed to be unstable, and we show that a maximum fraction of\n$f=0.07$ is allowed to decay assuming the half-life time to be comparable to\n(or shorter than) one Hubble time. The constraints from the KiDS-1000 WL data\nare significantly weaker, $\\tau \\geq 60$~Gyr and $f<0.34$. Combining the CMB\nand WL data does not yield tighter constraints than the CMB alone, except for\nshort half-life times, for which the maximum allowed fraction becomes $f=0.03$.\nAll limits are provided at the 95% confidence level.\n", "  While the simplest inflationary models predict the primordial perturbations\nto be near scale-invariant, the primordial power spectrum (PPS) can exhibit\noscillatory features in many physically well-motivated models. We search for\nhints of such features via free-form reconstructions of the PPS based on\n\\textit{Planck} 2018 CMB temperature and polarization anisotropies. In order to\nrobustly invert the oscillatory integrals and handle noisy unbinned data, we\ndraw inspiration from image analysis techniques. In previous works, the\nRichardson-Lucy deconvolution algorithm for deblurring images has been modified\nfor reconstructing PPS from the CMB temperature angular power spectrum. We\nextensively develop the methodology by including CMB polarization and\nintroducing two new regularization techniques, also inspired by image analysis\nand adapted for our cosmological context. Regularization is essential for\nimproving the fit to the temperature and polarization channels (TT, TE and EE)\nsimultaneously without sacrificing one for another. The reconstructions we\nobtain are consistent with previous findings from temperature-only analyses. We\nevaluate the statistical significance of the oscillatory features in our\nreconstructions using mock data and find the observations to be consistent with\nhaving a featureless PPS. The machinery developed here will be a complimentary\ntool in the search for features with upcoming CMB surveys. Our methodology also\nshows competitive performance in image deconvolution tasks, which have various\napplications from microscopy to medical imaging.\n", "  The mergers of supermassive black hole binaries (SMBHBs) can serve as\nstandard sirens: the gravitational wave (GW) analog of standard candles. The\nupcoming space-borne GW detectors will be able to discover such systems and\nestimate their luminosity distances precisely. Unfortunately, weak\ngravitational lensing can induce significant errors in the measured distance of\nthese standard sirens at high redshift, severely limiting their usefulness as\nprecise distance probes. The uncertainty due to weak lensing can be reduced if\nthe lensing magnification of the siren can be estimated independently, a\nprocedure called 'delensing'. With the help of up-to-date numerical\nsimulations, here we investigate how much the weak-lensing errors can be\nreduced using convergence maps reconstructed from shear measurements. We also\nevaluate the impact of delensing on cosmological parameter estimation with\nbright standard sirens. We find that the weak-lensing errors for sirens at $z_s\n= 2.9$ can be reduced by about a factor of two on average, but to achieve this\nwould require expensive ultra-deep field observations for every siren. Such an\napproach is likely to be practical in only limited cases, and the reduction in\nthe weak-lensing error is therefore likely to be insufficient to significantly\nimprove the cosmological parameter estimation. We conclude that performing\ndelensing corrections is unlikely to be worthwhile, in contrast to the more\npositive expectations presented in previous studies. For delensing to become\nmore practicable and useful in the future will require significant improvements\nin the resolution/depth of weak-lensing surveys and/or the methods to\nreconstruct convergence maps from these surveys.\n", "  Known as the \"Missing Baryon Problem\", about one-third of baryons in the\nlocal universe remain unaccounted for. The missing baryons are thought to\nreside in the warm-hot intergalactic medium (WHIM) of the cosmic web filaments,\nwhich are challenging to detect. Recent Chandra X-ray observations used a novel\nstacking analysis and detected an OVII absorption line toward the sightline of\na luminous quasar, hinting that the missing baryons may reside in the WHIM. To\nexplore how the properties of the OVII absorption line depend on feedback\nphysics, we compare the observational results with predictions obtained from\nthe Cosmology and Astrophysics with MachinE Learning (CAMEL) Simulation suite.\nCAMELS consists of cosmological simulations with state-of-the-art supernova\n(SN) and active galactic nuclei (AGN) feedback models from the IllustrisTNG and\nSIMBA simulations, with varying strengths. We find that the simulated OVII\ncolumn densities are higher in the outskirts of galaxies than in the\nlarge-scale WHIM, but they are consistently lower than those obtained in the\nChandra observations, for all feedback runs. We establish that the OVII\ndistribution is primarily sensitive to changes in the SN feedback prescription,\nwhereas changes in the AGN feedback prescription have minimal impact. We also\nfind significant differences in the OVII column densities between the\nIllustrisTNG and SIMBA runs. We conclude that the tension between the observed\nand simulated OVII column densities cannot be explained by the wide range of\nfeedback models implemented in CAMELS.\n", "  The Cosmic Microwave Background (CMB) anisotropies are thought to be\nstatistically isotropic and Gaussian. However, several anomalies are observed,\nincluding the CMB Cold Spot, an unexpected cold $\\sim 10^{\\circ}$ region with\n$p$-value $\\lesssim 0.01$ in standard $\\Lambda$CDM. One of the proposed origins\nof the Cold Spot is an unusually large void on the line of sight, that would\ngenerate a cold region through the combination of integrated Sachs-Wolfe and\nRees-Sciama effects. In the past decade extensive searches were conducted in\nlarge scale structure surveys, both in optical and infrared, in the same area\nfor $z \\lesssim 1$ and did find evidence of large voids, but of depth and size\nable to account for only a fraction of the anomaly. Here we analyze the lensing\nsignal in the Planck CMB data and rule out the hypothesis that the Cold Spot\ncould be due to a large void located anywhere between us and the surface of\nlast scattering. In particular, computing the evidence ratio we find that a\nmodel with a large void is disfavored compared to $\\Lambda$CDM, with odds 1 :\n13 (1 : 20) for SMICA (NILC) maps, compared to the original odds 56 : 1 (21 :\n1) using temperature data alone.\n", "  We establish constraints on $f(T)$ gravity by considering the possibility of\na scenario that supports a phantom crossing of the equation of state parameter\n$\\omega_{DE}$. After determining the viable parameter space of the model, while\nchecking the impact on the background dynamics, we perform an analysis to\nobtain constraints on cosmological parameters and determine the viability of\nthis scenario. To this end, we use combined data sets from cosmic chronometers\n(CC), baryonic acoustic oscillations (BAO), redshift space distortion (RSD) and\nType Ia supernovae (SN) measurements from the latest Pantheon$+$ set, in which\nthe impact on the absolute magnitude due to the change of the effective\ngravitational constant is also considered. It is found that a state where a\nphantom crossing of $\\omega_{DE}$ happens is favored by data, and the $f(T)$\nmodel is competitive with the $\\Lambda$CDM one by statistical criteria, such as\nAIC and BIC. Additionally, we find evidence of the Hubble tension being\nalleviated within the $f(T)$ model, at the same time that it does not worsen\nthe growth one, indicating a possibility of the present scenario as an option\nto address the current cosmic tensions.\n", "  Context. The present study addresses a key question related to our\nunderstanding of the relation between void galaxies and their environment: the\nrelationship between luminous and dark matter in and around voids. Aims. To\nexplore the extent to which local Universe voids are empty of matter, we study\nthe full (dark+luminous) matter content of seven nearby cosmic voids that are\nfully contained within the CosmicFlows-3 volume. Methods. We obtained the\nmatter-density profiles of seven cosmic voids using two independent methods.\nThese were built from the galaxy redshift space two-point correlation function\nin conjunction with peculiar velocity gradients from the CosmicFlows-3 dataset.\nResults. The results are striking, because when the redshift survey is used,\nall voids show a radial positive gradient of galaxies, while based on the\ndynamical analysis, only three of these voids display a clear underdensity of\nmatter in their center. Conclusions. This work constitutes the most detailed\nobservational analysis of voids conducted so far, and shows that void emptiness\nshould be derived from dynamical information. From this limited study, the\nHercules void appears to be the best candidate for a local Universe pure\n\"pristine volume\", expanding in three directions with no dark matter located in\nthat void.\n", "  This article publicly releases three-dimensional reconstructions of the local\nUniverse gravitational field below z=0.8 that were computed using the\nCosmicFlows-4 catalog of 56,000 galaxy distances and its sub-sample of 1,008\ntype Ia supernovae distances. The article also provides measurements of the\ngrowth rate of structure using the pairwise correlation of radial peculiar\nvelocities f sigma8 = 0.38(+/-0.04) (ungrouped CF4), f sigma8 = 0.36(+/-0.05)\n(grouped CF4), f sigma8 = 0.30(+/-0.06) (SNIa) and of the bulk flow in the 3D\nreconstructed Local Universe of 230 +/- 136 km s-1 at 300 Mpc of distance from\nthe observer. The exploration of 10,000 reconstructions gives that the\ndistances delivered by the Cosmicflows-4 catalog are compatible with a Hubble\nconstant of H0 = 74.5 +/- 0.1 (grouped CF4), H0 = 75.0 +/- 0.35 (ungrouped CF4)\nand H0 = 75.5 +/- 0.95 (CF4 SNIa subsample).\n", "  We summarize the second radio synchrotron background workshop, which took\nplace June 15-17, 2022 in Barolo, Italy. This meeting was convened because\navailable measurements of the diffuse radio zero level continue to suggest that\nit is several times higher than can be attributed to known Galactic and\nextragalactic sources and processes, rendering it the least well understood\nelectromagnetic background at present and a major outstanding question in\nastrophysics. The workshop agreed on the next priorities for investigations of\nthis phenomenon, which include searching for evidence of the Radio\nSunyaev-Zel'dovich effect, carrying out cross-correlation analyses of radio\nemission with other tracers, and supporting the completion of the 310 MHz\nabsolutely calibrated sky map project.\n", "  We present growth of structure constraints from the cosmological analysis of\nthe power spectrum multipoles of SDSS-III BOSS DR12 galaxies. We use the galaxy\npower spectrum model of Hand et al. (2017), which decomposes the galaxies into\nhalo mass bins, each of which is modeled separately using the relations between\nhalo biases and halo mass. The model combines Eulerian perturbation theory and\nhalo model calibrated on $N$-body simulations to model the halo clustering. In\nthis work, we also generate the covariance matrix by combining the analytic\ndisconnected part with the empirical connected part: we smooth the connected\ncomponent by selecting a few principal components and show that it achieves\ngood agreement with the mock covariance. Our analysis differs from recent\nanalyses in that we constrain a single parameter $f\\sigma_8$ fixing everything\nelse to Planck+BAO prior, thereby reducing the effects of prior volume and\nmismodeling. We find tight constraints on $f\\sigma_8$:\n$f\\sigma_8(z_{\\mathrm{eff}}=0.38)=0.489 \\pm 0.038$ and\n$f\\sigma_8(z_{\\mathrm{eff}}=0.61)=0.455 \\pm 0.028$ at $k_{\\mathrm{max}} = 0.2\\\nh$Mpc$^{-1}$, with an overall amplitude error of 5%, and in good agreement\n(within 0.3 sigma) of Planck amplitude. We discuss the sensitivity of\ncosmological parameter estimation to the choice of scale cuts, covariance\nmatrix, and the inclusion of hexadecapole $P_4(k)$. We show that with\n$k_{\\mathrm{max}} = 0.4\\ h$Mpc$^{-1}$ the constraints improve considerably to\nan overall 3.2% amplitude error, but there is some evidence of model\nmisspecification on MultiDark-PATCHY mocks. Choosing $k_{\\mathrm{max}}$\nconsistently and reliably remains the main challenge of RSD analysis methods.\n", "  In this paper, we use electromagnetic wave data (H0LiCOW, $H(z)$, SNe) and\ngravitational wave data (Tianqin) to constrain the interacting dark energy\n(IDE) model and investigate the Hubble tension problem and coincidences\nproblem. By combining these four kinds of data (Tianqin+H0LiCOW+SNe+$H(z)$), we\nobtained the parameter values at the confidence interval of $1\\sigma$:\n$\\Omega_m=0.36\\pm0.18$, $\\omega_x=-1.29^{+0.61}_{-0.23}$,\n$\\xi=3.15^{+0.36}_{-1.1}$, and $H_0=70.04\\pm0.42$ $kms^{-1}Mpc^{-1}$. According\nto our results, the best valve of $H_0$ show that the Hubble tension problem\ncan be alleviated to some extent. In addition, the $\\xi+3\\omega_x =\n-0.72^{+2.19}_{-1.19}(1\\sigma)$ of which the center value indicates the\ncoincidence problem is slightly alleviated. However, the $\\xi+3\\omega_x = 0$ is\nstill within the $1\\sigma$ error range which indicates the $\\Lambda$CDM model\nis still the model which is in best agreement with the observational data at\npresent. Finally, we compare the constraint results of electromagnetic wave and\ngravitational wave on the model parameters and find that the constraint effect\nof electromagnetic wave data on model parameters is better than that of\nsimulated Tianqin gravitational wave data.\n", "  Double source lensing provides a dimensionless ratio of distance ratios, a\n\"remote viewing\" of cosmology through distances relative to the gravitational\nlens, beyond the observer. We use this to test the cosmological framework,\nparticularly with respect to spatial curvature and the distance duality\nrelation. We derive a consistency equation for constant spatial curvature,\nallowing not only the investigation of flat vs curved but of the\nFriedmann-Lema\\^itre-Robertson-Walker framework itself. For distance duality,\nwe demonstrate that the evolution of the lens mass profile slope must be\ncontrolled to $\\gtrsim5$ times tighter fractional precision than a claimed\ndistance duality violation. Using LENSPOP forecasts of double source lensing\nsystems in Euclid and LSST surveys we also explore constraints on dark energy\nequation of state parameters and any evolution of the lens mass profile slope.\n", "  It is known that Primordial Black Holes (PBHs) can leave an imprint on Cosmic\nMicrowave Background (CMB) anisotropy power spectra, due to their\naccretion-powered injection of energy into the recombining plasma. Here we\nstudy a qualitatively new CMB observable sourced by accreting PBHs: the\ntemperature trispectrum or connected 4-point function. This non-Gaussian\nsignature is due to the strong spatial modulation of the PBH accretion\nluminosity, thus ionization perturbations, by large-scale supersonic relative\nvelocities between PBHs and the accreted baryons. We first derive a\nfactorizable quadratic transfer function for free-electron fraction\ninhomogeneities induced by accreting PBHs. We then compute the perturbation to\nthe CMB temperature anisotropy due to a general modification of recombination,\nand apply our results to accreting PBHs. We calculate a new contribution to the\ntemperature power spectrum due to the spatial fluctuations of the ionization\nperturbation induced by accreting PBHs, going beyond past studies which only\naccounted for its homogeneous part. While these contributions are formally\ncomparable, we find the new part to be subdominant, due to the poor correlation\nof the perturbed temperature field with the standard CMB anisotropy. For the\nfirst time, we compute the temperature trispectrum due to accreting PBHs. This\ntrispectrum is weakly correlated with the local-type primordial non-Gaussianity\ntrispectrum, hence constraints on the latter do not lead to competitive bounds\non accreting PBHs. We also forecast Planck's sensitivity to the temperature\ntrispectrum sourced by accreting PBHs. Excitingly, we find it to be more\nsensitive to PBHs under $\\sim 10^3 M_{\\odot}$ than current temperature-only\npower spectrum constraints. This result motivates our future work extending\nthis study to temperature and polarization trispectra induced by\ninhomogeneously-accreting PBHs.\n", "  The current discrepancy between the Hubble constant $H_0$ derived from the\nlocal distance ladder and from the cosmic microwave background is one of the\nmost crucial issues in cosmology, as it possibly indicates unknown systematics\nor new physics. Here we present a novel non-parametric method to estimate\nHubble constant as a function of redshift. We establish independent estimates\nof the evolution of Hubble constant by diagonalizing the covariance matrix.\nFrom type Ia supernovae and the observed Hubble parameter data, a decreasing\ntrend of Hubble constant with a significance of 5.6$\\sigma$ confidence level is\nfound. At low redshift, its value is dramatically consistent with that measured\nfrom the local distance ladder, and it drops to the value measured from the\ncosmic microwave background at high redshift. Our results can relieve the\nHubble tension, and prefer the late-time solutions of it, especially the new\nphysics.\n", "  Numerical simulations indicate that cosmological halos display power-law\nradial profiles of pseudo phase-space density (PPSD), Q=rho/sigma^3, where rho\nis mass density and sigma velocity dispersion. We test these predictions using\nthe parameters derived from the Markov Chain Monte Carlo (MCMC) analysis\nperformed with the MAMPOSSt code on the observed kinematics of a velocity\ndispersion based stack (sigmav) of 54 nearby regular clusters of galaxies from\nthe WINGS dataset. In the definition of PPSD, the density is either in total\nmass rho (Q_rho) or in galaxy number density nu (Q_nu) of three morphological\nclasses of galaxies (ellipticals, lenticulars, and spirals), while the velocity\ndispersion (obtained by inversion of the Jeans equation) is either the total\n(Q_rho and Q_nu) or its radial component (Q_r,rho and Q_r,nu). We find that the\nPPSD profiles are power-law relations for nearly all MCMC parameters. The\nlogarithmic slopes of our observed Q_rho(r) and Q_r,rho(r) for ellipticals and\nspirals are in excellent agreement with the predictions for particles in\nsimulations, but slightly shallower for S0s. For Q_nu(r) and Q_r,nu(r), only\nthe ellipticals have a PPSD slope matching that of particles in simulations,\nwhile the slope for spirals is much shallower, similar to that of subhalos. But\nfor cluster stacks based on richness or gas temperature, the fraction of\npower-law PPSDs is lower (esp. Q_nu) and the Q_rho slopes are shallower, except\nfor S0s. The observed PPSD profiles, defined using rho rather than nu, appear\nto be a fundamental property of galaxy clusters. They would be imprinted during\nan early phase of violent relaxation for dark matter and ellipticals, and later\nfor spirals as they move towards dynamical equilibrium in the cluster\ngravitational potential, while S0s are either intermediate (richness and\ntemperature-based stacks) or a mixed class (sigmav stack).\n", "  A variety of scenarios for early-universe cosmology give rise to a population\nof primordial black holes (PBHs) with a broad spectrum of masses. The\nevaporation of PBHs in such scenarios has the potential to place the universe\ninto an extended period of \"stasis\" during which the abundances of matter and\nradiation remain absolutely constant despite cosmological expansion. This\nsurprising phenomenon can give rise to new possibilities for early-universe\ndynamics and lead to distinctive signatures of the evaporation of such PBHs. In\nthis paper, we discuss how this stasis epoch arises and explore a number of its\nphenomenological consequences, including implications for inflationary\nobservables, the stochastic gravitational-wave background, baryogenesis, and\nthe production of dark matter and dark radiation.\n", "  In order to extract information about inflationary gravitational waves using\n$B$-mode patterns of cosmic microwave polarization anisotropy, we need to\nremove the foreground radiation from the Milky Way. In our previous delta-map\nmethod for foreground removal, the number of observation bands was limited to\nthe number of parameters of the assumed foreground model, and therefore it was\ndifficult to improve the sensitivity by increasing the number of observation\nbands. Here, we extend the previous method so that it can be adapted to an\narbitrary number of observation bands. Using parametric likelihood and\nrealistic foreground and CMB simulations, we show that our method can increase\nthe sensitivity to the tensor-to-scalar ratio $r$ without inducing any\nsignificant bias.\n", "  The interacting dark energy (IDE) model is a promising alternative\ncosmological model which has the potential to solve the fine-tuning and\ncoincidence problems by considering the interaction between dark matter and\ndark energy. Previous studies have shown that the energy exchange between the\ndark sectors in this model can significantly affect the dark matter halo\nproperties. In this study, utilising a large set of cosmological $N$-body\nsimulations, we analyse the redshift evolution of the halo concentration - mass\n($c$ - $M$) relation in the IDE model, and show that the $c$ - $M$ relation is\na sensitive proxy of the interaction strength parameter $\\xi_2$, especially at\nlower redshifts. Furthermore, we construct parametrized formulae to quantify\nthe dependence of the $c$ - $M$ relation on $\\xi_2$ at redshifts ranging from\n$z=0$ to $0.6$. Our parametrized formulae provide a useful tool in constraining\n$\\xi_2$ with the observational $c$ - $M$ relation. As a first attempt, we use\nthe data from X-ray, gravitational lensing, and galaxy rotational curve\nobservations and obtain a tight constraint on $\\xi_2$, i.e. $\\xi_2 = 0.071 \\pm\n0.034$. Our work demonstrates that the halo $c$ - $M$ relation, which reflects\nthe halo assembly history, is a powerful probe to constrain the IDE model.\n", "  In the submm regime, spectral line scans and line intensity mapping (LIM) are\nnew promising probes for the cold gas content and star formation rate of\ngalaxies across cosmic time. However, both of these two measurements suffer\nfrom field-to-field variance. We study the effect of field-to-field variance on\nthe predicted CO and [CII] power spectra from future LIM experiments such as\nCONCERTO, as well as on the line luminosity functions (LFs) and the cosmic\nmolecular gas mass density that are currently derived from spectral line scans.\nWe combined a 117 $\\rm deg^2$ dark matter lightcone from the Uchuu cosmological\nsimulation with the simulated infrared dusty extragalactic sky (SIDES)\napproach. We find that in order to constrain the CO LF with an uncertainty\nbelow 20%, we need survey sizes of at least 0.1 $\\rm deg^2$. Furthermore,\naccounting for the field-to-field variance using only the Poisson variance can\nunderestimate the total variance by up to 80%. The lower the luminosity is and\nthe larger the survey size is, the higher the level of underestimate. At $z$<3,\nthe impact of field-to-field variance on the cosmic molecular gas density can\nbe as high as 40% for the 4.6 arcmin$^2$ field, but drops below 10% for areas\nlarger than 0.2 deg$^2$. However, at $z>3$ the variance decreases more slowly\nwith survey size and for example drops below 10% for 1 deg$^2$ fields. Finally,\nwe find that the CO and [CII] LIM power spectra can vary by up to 50% in $\\rm 1\ndeg^2$ fields. This limits the accuracy of the constraints provided by the\nfirst 1 deg$^2$ surveys. The level of the shot noise power is always dominated\nby the sources that are just below the detection thresholds. We provide an\nanalytical formula to estimate the field-to-field variance of current or future\nLIM experiments. The code and the full SIDES-Uchuu products (catalogs, cubes,\nand maps) are publicly available.\n", "  We search for a linearity in the ratio of dark matter to baryonic matter as a\nfunction of radius for galaxy clusters, motivated by a recent result by Lovas\n(arXiv:2206.11431), who has discovered such a linearity for a diverse suite of\ngalaxies in the SPARC sample. For our analysis, we used a sample of 54 non-cool\ncore clusters from the HIFLUGCS sample. We do not find any evidence for a\nlinear trend in the aforementioned ratio as a function of radius for individual\nclusters. We then repeat this analysis for the stacked sample, which also does\nnot show this linearity. Therefore, the linear scaling found by Lovas is not a\nuniversal property of dark matter haloes at all scales.\n", "  We compare void size and clustering statistics for nDGP and $f(R)$ gravity\nmodels and GR using N-body simulations. We show how it is critical to consider\nthe statistics derived from mock galaxy catalogs rather than the dark matter\nhalos alone. Marked differences between the void size functions for GR and\n$f(R)$ models which present when voids are identified using dark matter halos\nare removed when voids are identified, more realistically, from mock galaxy\ntracers of the halos. The void radial velocities and velocity dispersions in\nthe $f(R)$ and nDGP models are enhanced relative to GR in both halos and mock\ngalaxy identified voids. Despite this, we find that the redshift space void\nquadrupole moments derived from the mock galaxy tracers are strikingly similar\nacross the three gravity models. The Gaussian Streaming Model (GSM) is shown to\naccurately reconstruct $\\xi_2$ in modified gravity models and we employ the\nGSM, using a functional derivative approach, to analyze the insensitivity of\n$\\xi_2$ to the gravity model. Assuming linear theory, we show the void\nquadrupole to be an unbiased estimator of the redshift space growth rate\nparameter $\\beta=f/b$ in the modified gravity theories.\n", "  The Indian Consortium of Cosmologists has proposed a cosmic microwave\nbackground (CMB) space mission, Exploring Cosmic History and Origin (ECHO). A\nmajor scientific goal of the mission is to detect the primordial B-mode signal\nof CMB polarization. The detection of the targeted signal is very challenging\nas it is deeply buried under the dominant astrophysical foreground emissions of\nthe thermal dust and the Galactic synchrotron. To facilitate the adequate\nsubtraction of thermal dust, the instrument design of ECHO has included nine\ndust-dominated high-frequency bands over the frequency range of 220-850 GHz. In\nthis work, we closely reexamine the utility of the high-frequency ECHO bands in\nforeground subtraction using the Needlet Internal Linear Combination component\nseparation method. We consider three dust models: a physical dust model, a dust\nspectral energy distribution (SED) with a single modified black body (MBB)\nemission law and a multilayer dust model with frequency-frequency\ndecorrelation. We consider eleven ECHO bands in the 28-190 GHz range as our\nbaseline configuration and investigate the changes in the level foreground and\nnoise residuals as subsequent dust-dominated high-frequency bands are added. We\nfind that adding the high-frequency bands leads to a consistent decrease in the\nlevel of residual foreground and noise, and the sensitivity of r measurement\nimproves. Most of the reduction in both residual levels and enhancement in the\nsensitivity is achieved in the 28-600 GHz frequency range. Negligible change in\nresidual levels is seen by extending the frequency range from 600 GHz to 850\nGHz.\n", "  Context. Galaxy cluster masses are usually defined as the mass within a\nspherical region enclosing a given matter overdensity (in units of the critical\ndensity). Converting masses from one overdensity definition to another can have\nseveral useful applications. Aims. In this article we present a generic\nnon-parametric formalism that allows one to accurately map the halo mass\nfunction between two different mass overdensity definitions using the\ndistribution of halo sparsities defined as the ratio of the two masses. We show\nthat changing mass definitions reduces to modelling the distribution of halo\nsparsities. Methods. Using standard transformation rules of random variates, we\nderive relations between the halo mass function at different overdensities and\nthe distribution of halo sparsities. Results. We show that these relations\nreproduce the N-body halo mass functions from the Uchuu simulation within the\nstatistical errors at a few percent level. Furthermore, these relations allow\nthe halo mass functions at different overdensities to be related to parametric\ndescriptions of the halo density profile. In particular, we discuss the case of\nthe concentration-mass relation of the Navarro-Frenk-White profile. Finally, we\nshow that the use of such relations allows us to predict the distribution of\nsparsities of a sample of haloes of a given mass, thus opening the way to\ninferring cosmological constraints from individual galaxy cluster sparsity\nmeasurements.\n", "  Cosmological weak lensing measurements rely on a precise measurement of the\nshear two-point correlation function (2PCF) along with a deep understanding of\nsystematics that affect it. In this work, we demonstrate a general framework\nfor detecting and modeling the impact of PSF systematics on the cosmic shear\n2PCF, and mitigating its impact on cosmological analysis. Our framework can\ndescribe leakage and modeling error from all spin-2 quantities contributed by\nthe PSF second and higher moments, rather than just the second moments, using\nthe cross-correlations between galaxy shapes and PSF moments. We interpret null\ntests using the HSC Year 3 (Y3) catalogs with this formalism, and find that\nleakage from the spin-2 combination of PSF fourth moments is the leading\ncontributor to additive shear systematics, with total contamination that is an\norder of magnitude higher than that contributed by PSF second moments alone. We\nconducted a mock cosmic shear analysis for HSC Y3, and find that, if\nuncorrected, PSF systematics can bias the cosmological parameters $\\Omega_m$\nand $S_8$ by $\\sim$0.3$\\sigma$. The traditional second moment-based model can\nonly correct for a 0.1$\\sigma$ bias, leaving the contamination largely\nuncorrected. We conclude it is necessary to model both PSF second and fourth\nmoment contamination for HSC Y3 cosmic shear analysis. We also reanalyze the\nHSC Y1 cosmic shear analysis with our updated systematics model, and identify a\n0.07$\\sigma$ bias on $\\Omega_m$ when using the more restricted second moment\nmodel from the original analysis. We demonstrate how to self-consistently use\nthe method in both real space and Fourier space, assess shear systematics in\ntomographic bins, and test for PSF model overfitting.\n", "  Recent cosmological analyses with large-scale structure and weak lensing\nmeasurements, usually referred to as 3$\\times$2pt, had to discard a lot of\nsignal-to-noise from small scales due to our inability to accurately model\nnon-linearities and baryonic effects. Galaxy-galaxy lensing, or the\nposition-shear correlation between lens and source galaxies, is one of the\nthree two-point correlation functions that are included in such analyses,\nusually estimated with the mean tangential shear. However, tangential shear\nmeasurements at a given angular scale $\\theta$ or physical scale $R$ carry\ninformation from all scales below that, forcing the scale cuts applied in real\ndata to be significantly larger than the scale at which theoretical\nuncertainties become problematic. Recently there have been a few independent\nefforts that aim to mitigate the non-locality of the galaxy-galaxy lensing\nsignal. Here we perform a comparison of the different methods, including the\nY-transformation, the Point-Mass marginalization methodology and the Annular\nDifferential Surface Density statistic. We do the comparison at the\ncosmological constraints level in a combined galaxy clustering and\ngalaxy-galaxy lensing analysis. We find that all the estimators yield\nequivalent cosmological results assuming a simulated Rubin Observatory Legacy\nSurvey of Space and Time (LSST) Year 1 like setup and also when applied to DES\nY3 data. With the LSST Y1 setup, we find that the mitigation schemes yield\n$\\sim$1.3 times more constraining $S_8$ results than applying larger scale cuts\nwithout using any mitigation scheme.\n", "  We present the first cosmological constraints derived from the analysis of\nthe void size function. This work relies on the final BOSS DR12 data set, a\nlarge spectroscopic galaxy catalog, ideal for the identification of cosmic\nvoids. We extract a sample of voids from the distribution of galaxies and we\napply a cleaning procedure aimed at reaching high levels of purity and\ncompleteness. We model the void size function by means of an extension of the\npopular volume-conserving model, based on two additional nuisance parameters.\nRelying on mock catalogs specifically designed to reproduce the BOSS DR12\ngalaxy sample, we calibrate the extended size function model parameters and\nvalidate the methodology. We then apply a Bayesian analysis to constrain the\n$\\Lambda$CDM model and one of its simplest extensions, featuring a constant\ndark energy equation of state parameter, $w$. Following a conservative\napproach, we put constraints on the total matter density parameter and the\namplitude of density fluctuations, finding $\\Omega_{\\rm m}=0.29 \\pm 0.06$ and\n$\\sigma_8=0.79^{+0.09}_{-0.08}$. Testing the alternative scenario, we derive\n$w=-1.1\\pm 0.2$, in agreement with the $\\Lambda$CDM model. These results are\nindependent and complementary to those derived from standard cosmological\nprobes, opening up new ways to identify the origin of potential tensions in the\ncurrent cosmological paradigm.\n", "  The ability to test and constrain theories of cosmic inflation will advance\nsubstantially over the next decade. Key data sources include cosmic microwave\nbackground (CMB) measurements and observations of the distribution of matter at\nlow-redshift from optical, near-infrared, and 21cm intensity surveys. A\npositive detection of a CMB B-mode consistent with a primordial stochastic\ngravitational wave background (SGWB) is widely viewed as a smoking gun for an\ninflationary phase. Still, a null result does not exclude inflation. However,\nin a significant class of inflationary scenarios, a low SGWB amplitude is\ncorrelated with a more significant running, $\\alpha_s$, in the primordial\ndensity perturbations than is seen with the simplest inflationary potentials.\nWith this motivation, we forecast the precision with which the spectral index\n$n_{\\rm{s}}$ and $\\alpha_{\\rm{s}}$ can be constrained by currently envisaged\nobservations, including CMB (Simons Observatory, CMB-S4 and LiteBIRD),\noptical/near infra-red (DESI and SPHEREx), and 21cm intensity mapping (Tianlai\nand CHIME) surveys. We identify optimal combinations of datasets for\nconstraining the running and show that they may yield additional and\ninformative constraints on the overall inflationary parameter space if the SGWB\nremains undetected.\n", "  The rapidly increasing statistical power of cosmological imaging surveys\nrequires us to reassess the regime of validity for various approximations that\naccelerate the calculation of relevant theoretical predictions. In this paper,\nwe present the results of the 'N5K non-Limber integration challenge', the goal\nof which was to quantify the performance of different approaches to calculating\nthe angular power spectrum of galaxy number counts and cosmic shear data\nwithout invoking the so-called 'Limber approximation', in the context of the\nRubin Observatory Legacy Survey of Space and Time (LSST). We quantify the\nperformance, in terms of accuracy and speed, of three non-Limber\nimplementations: ${\\tt FKEM (CosmoLike)}$, ${\\tt Levin}$, and ${\\tt matter}$,\nthemselves based on different integration schemes and approximations. We find\nthat in the challenge's fiducial 3x2pt LSST Year 10 scenario, ${\\tt FKEM\n(CosmoLike)}$ produces the fastest run time within the required accuracy by a\nconsiderable margin, positioning it favourably for use in Bayesian parameter\ninference. This method, however, requires further development and testing to\nextend its use to certain analysis scenarios, particularly those involving a\nscale-dependent growth rate. For this and other reasons discussed herein,\nalternative approaches such as ${\\tt matter}$ and ${\\tt Levin}$ may be\nnecessary for a full exploration of parameter space. We also find that the\nusual first-order Limber approximation is insufficiently accurate for LSST Year\n10 3x2pt analysis on $\\ell=200-1000$, whereas invoking the second-order Limber\napproximation on these scales (with a full non-Limber method at smaller $\\ell$)\ndoes suffice.\n", "  Breakdown of rotational invariance of the primordial power spectrum manifests\nin the statistical anisotropy of the observed Cosmic Microwave Background (CMB)\nradiation. Hemispherical power asymmetry in the CMB may be caused due to a\ndipolar modulation, indicating the presence of a preferred direction.\nAppropriately re-scaled local variance maps of the CMB temperature anisotropy\ndata effectively encapsulate this dipolar pattern. As a first-of-its-kind\nmethod, we train Artificial Neural Networks (ANNs) with such local variances as\ninput features to distinguish statistically isotropic CMB maps from dipole\nmodulated ones. Our trained ANNs are able to predict components of the\namplitude times the unit vector of the preferred direction for mixed sets of\nmodulated and unmodulated maps, with goodness of fit ($R^2$) scores $>0.97$ for\nfull sky, and $>0.96$ for partial sky coverage. On all observed\nforeground-cleaned CMB maps, the ANNs detect the dipolar modulation signal with\noverall consistent values of amplitudes and directions. This detection is\nsignificant at $97.21\\%-99.38\\%$ C.L. for all full sky maps, and at\n$98.34\\%-100\\%$ C.L. for all partial sky maps. Robustness of the signal holds\nacross full and partial skies, various foreground cleaning methods, inpainting\nalgorithms, instruments and all the different periods of observation for Planck\nand WMAP satellites. The significant and robust detection of the signal, in\naddition to the consistency of values of amplitude and directions, as found\nindependent of any pre-existing methods, further mitigates the criticisms of\nlook-elsewhere effects and a posteriori inferences for the preferred dipole\ndirection in the CMB.\n", "  Third-order weak lensing statistics are a promising tool for cosmological\nanalyses since they extract cosmological information in the non-Gaussianity of\nthe cosmic large-scale structure. However, such analyses require precise and\naccurate models for the covariance. In this second paper of a series on\nthird-order weak lensing statistics, we derive and validate an analytic model\nfor the covariance of the third-order aperture statistics $\\langle\nM_\\mathrm{ap}^3\\rangle$. We derive the covariance model from a real-space\nestimator for $\\langle M_\\mathrm{ap}^3\\rangle$. We validate the model by\ncomparing it to estimates from simulated Gaussian random fields (GRF) and two\nsets of N-body simulations. Finally, we perform mock cosmological analyses with\nthe model covariance and the simulation estimate to compare the resulting\nparameter constraints. We find good agreement between the model and the\nsimulations, both for the GRF and the $N$-body simulations. The figure-of-merit\nin the $S_8$-$\\Omega_\\mathrm{m}$ plane from our covariance model is within 3\\%\nof the one obtained from the simulated covariances. We also show that our\nmodel, which is based on an estimator using convergence maps, can be used to\nobtain upper and lower bounds for the covariance of an estimator based on\nthree-point shear correlation functions. This second estimator is required for\nrealistic survey data. In our derivation, we find that the $\\langle\nM_\\mathrm{ap}^3\\rangle$ covariance cannot be obtained from the bispectrum\ncovariance and that it includes several `finite-field terms' that do not scale\nwith the inverse survey area. Our covariance model is sufficiently accurate for\nanalysing stage III surveys. Covariances for statistics in Fourier space cannot\nalways be straightforwardly converted into covariance for real-space\nstatistics. The modelling code is available at\nhttps://github.com/sheydenreich/threepoint/releases/ .\n", "  We construct data-driven solutions to the Hubble tension which are\nperturbative modifications to the fiducial $\\Lambda$CDM cosmology, using the\nFisher bias formalism. Taking as proof of principle the case of a time-varying\nelectron mass and fine structure constant, and focusing first on Planck CMB\ndata, we demonstrate that a modified recombination can solve the Hubble tension\nand lower $S_8$ to match weak lensing measurements. Once baryonic acoustic\noscillation and uncalibrated supernovae data are included, however, it is not\npossible to fully solve the tension with perturbative modifications to\nrecombination.\n", "  The standard approach to inference from cosmic large-scale structure data\nemploys summary statistics that are compared to analytic models in a Gaussian\nlikelihood with pre-computed covariance. To overcome the idealising assumptions\nabout the form of the likelihood and the complexity of the data inherent to the\nstandard approach, we investigate simulation-based inference (SBI), which\nlearns the likelihood as a probability density parameterised by a neural\nnetwork. We construct suites of simulated, exactly Gaussian-distributed data\nvectors for the most recent Kilo-Degree Survey (KiDS) weak gravitational\nlensing analysis and demonstrate that SBI recovers the full 12-dimensional KiDS\nposterior distribution with just under $10^4$ simulations. We optimise the\nsimulation strategy by initially covering the parameter space by a hypercube,\nfollowed by batches of actively learnt additional points. The data compression\nin our SBI implementation is robust to suboptimal choices of fiducial parameter\nvalues and of data covariance. Together with a fast simulator, SBI is therefore\na competitive and more versatile alternative to standard inference.\n", "  We use the large-scale structure galaxy data (LSS) from the BOSS and eBOSS\nsurveys, in combination with abundances information from Big Bang\nNucleosynthesis (BBN) to measure two values of the Hubble expansion rate,\n$H_0=100h\\,[{\\rm km}\\, {\\rm s}^{-1}\\,{\\rm Mpc}^{-1}]$, each of them based on\nvery different physical processes. One is a (traditional) late-time-background\nmeasurement based on determining the BAO scale and using BBN abundances on\nbaryons for calibrating its absolute size (BAO+BBN). This method anchors $H_0$\nto the (standard) physics of the sound horizon scale at pre-recombination\ntimes. The other is a newer early-time based measurement associated with the\nbroadband shape of the power spectrum. This second method anchors $H_0$ to the\nphysics of the matter-radiation equality scale, which also needs BBN\ninformation for determining the suppression of baryons in the power spectrum\nshape (shape+BBN). Within the $\\Lambda$CDM model, we find very good consistency\namong these two $H_0$'s: BAO+BBN (+growth) delivers $H_0=67.42_{-0.94}^{+0.88}$\n$(67.37_{-0.95}^{+0.86})$ km s$^{-1}$Mpc$^{-1}$ , whereas the shape+BBN\n(+growth) delivers $H_0 = 70.1_{-2.1}^{+2.1}$ $(70.1_{-2.1}^{+1.9})$ km\ns$^{-1}$ Mpc$^{-1}$, where \"growth\" stands for information from the\nlate-time-perturbations captured by the growth of structure parameter. These\nare the tightest sound-horizon free $H_0$ constraints from LSS data to date. As\na consequence to be viable, any $\\Lambda$CDM extension proposed to address the\nso-called \"Hubble tension\" needs to modify consistently not only the sound\nhorizon scale physics, but also the matter-radiation equality scale, in such a\nway that both late- and early-based $H_0$'s return results mutually consistent\nand consistent with the high $H_0$ value recovered by the standard cosmic\ndistance ladder (distance-redshift relation) determinations.\n", "  We revisit the epoch of cosmic speed-up characterized by the redshift of\ntransition from a decelerated to an accelerated phase. This redshift is termed\nthe transition redshift ($z_t$). We use the spatially Flat and Non-Flat\nvariants of the most common $\\Lambda$CDM and XCDM models to put constraints on\nthe transition redshift along with the other model parameters. The data for\nthis analysis comes from the recent and updated Pantheon+ Supernova dataset and\nthe Hubble parameter measurements obtained from Cosmic Chronometers. We\nconsider both datasets with their respective covariance matrices incorporating\nall kinds of statistical and systematic uncertainties. We observe that using\nthe combined datasets of H(z) and SNe, the best fit value of transition\nredshift lies in the range $0.61 < z_t < 0.82$ for all four dark energy models.\nIncidentally, we observe a positive curvature for the Non-Flat models and\ncorrelations between several model parameters.\n", "  The Cosmological Principle is part of the foundation that underpins the\nstandard model of the Universe. In the era of precision cosmology, when stress\ntests of the standard model are uncovering various tensions and possible\nanomalies, it is critical to check the viability of this principle. A key test\nis the consistency between the kinematic dipoles of the cosmic microwave\nbackground and of the large-scale matter distribution. Results using radio\ncontinuum and quasar samples indicate a rough agreement in the directions of\nthe two dipoles, but a larger than expected amplitude of the matter dipole. The\nresulting tension with the radiation dipole has been estimated at $\\sim\n5\\sigma$ for some cases, suggesting a potential new cosmological tension and a\npossible violation of the CP. However, the standard formalism for predicting\nthe dipole in the two-dimensional projection of sources overlooks possible\nevolution effects in the luminosity function. In fact, radial information from\nthe luminosity function is necessary for a correct projection of the\nthree-dimensional source distribution. Using a variety of current models of the\nquasar luminosity function, we show that neglecting redshift evolution can\nsignificantly overestimate the relative velocity amplitude. While the models we\ninvestigate are consistent with each other and with current data, the dipole\nderived from these, which depends on derivatives of the luminosity function,\ncan disagree by more than $3\\sigma$. This theoretical systematic bias needs to\nbe resolved before robust conclusions can be made about a new cosmic tension.\n", "  Entropy is an advantageous diagnostics to study the thermodynamic history of\nthe intracluster plasma of galaxy clusters. We present the entropy profile of\nthe Abell 2244 galaxy cluster derived both exclusively using X-ray data from\nthe low-background Swift XRT telescope and also using Planck y data. The\nentropy profile derivation using X-rays only is robust at least to the virial\nradius because the cluster brightness is large compared to the X-ray background\nat low energies, temperature is strongly bounded by the lack of cluster X-ray\nphotons at energies kT>3 keV, and the XRT background is low, stable and\nunderstood. In the observed solid angle, about one quadrant, the entropy radial\nprofile deviates from a power-law at the virial radius, mainly because of a\nsharp drop of the cluster temperature. This bending of the entropy profile is\nconfirmed when X-ray spectral information is replaced by the Compton map.\nClumping and non-thermal pressure support are insufficient to restore a power\nlaw entropy profile because they are bound to be small by: a) the agreement\nbetween mass estimates from different tracers (gas and galaxies), b) the\nagreement between entropy profile determinations based on combinations of\nobservables with different sensitivities and systematics, and c) the low value\nof clumping as estimated using the azimuthal scatter and the gas fraction.\nBased on numerical simulations, ion-electron equilibration is also insufficient\nto restore a linear entropy profile. Therefore, the bending of the entropy\nprofiles seems to be robustly derived and witnesses the teoretically-predicted\ndecrease in the inflow through the virial boundary.\n", "  The splashback radius of a dark matter halo, which corresponds to the first\napocenter radius reached by infalling matter and substructures, has been\ndetected around galaxy clusters using a multitude of observational methods,\nincluding weak lensing measurements. In this manuscript, we present how the\nsplashback feature in the halo density profile affects galaxy cluster masses\nderived through weak lensing measurements if it is not accounted for. We find\nthat the splashback radius has an increasingly large effect on group-sized\nhalos towards $M_{200m} \\sim 10^{13.5} \\mathrm{M_\\odot}$. Depending on the\nmodel and the radial scale used, the cluster/group masses can be biased low by\nmore than 0.1 dex. This bias, in turn, would result in a slightly lower\n$\\Omega_m$ value if propagated into a cluster cosmology analysis. The\nsplashback effect with group-sized dark matter halos may become important to\nconsider, given the increasingly stringent cosmological constraints coming from\noptical wide-field surveys.\n", "  We present a sample-variance-limited measurement of the temperature power\nspectrum ($TT$) of the cosmic microwave background (CMB) using observations of\na $\\sim\\! 1500 \\,\\mathrm{deg}^2$ field made by SPT-3G in 2018. We report\nmultifrequency power spectrum measurements at 95, 150, and 220GHz covering the\nangular multipole range $750 \\leq \\ell < 3000$. We combine this $TT$\nmeasurement with the published polarization power spectrum measurements from\nthe 2018 observing season and update their associated covariance matrix to\ncomplete the SPT-3G 2018 $TT/TE/EE$ data set. This is the first analysis to\npresent cosmological constraints from SPT $TT$, $TE$, and $EE$ power spectrum\nmeasurements jointly. We blind the cosmological results and subject the data\nset to a series of consistency tests at the power spectrum and parameter level.\nWe find excellent agreement between frequencies and spectrum types and our\nresults are robust to the modeling of astrophysical foregrounds. We report\nresults for $\\Lambda$CDM and a series of extensions, drawing on the following\nparameters: the amplitude of the gravitational lensing effect on primary power\nspectra $A_\\mathrm{L}$, the effective number of neutrino species\n$N_{\\mathrm{eff}}$, the primordial helium abundance $Y_{\\mathrm{P}}$, and the\nbaryon clumping factor due to primordial magnetic fields $b$. We find that the\nSPT-3G 2018 $T/TE/EE$ data are well fit by $\\Lambda$CDM with a\nprobability-to-exceed of $15\\%$. For $\\Lambda$CDM, we constrain the expansion\nrate today to $H_0 = 68.3 \\pm 1.5\\,\\mathrm{km\\,s^{-1}\\,Mpc^{-1}}$ and the\ncombined structure growth parameter to $S_8 = 0.797 \\pm 0.042$. The SPT-based\nresults are effectively independent of Planck, and the cosmological parameter\nconstraints from either data set are within $<1\\,\\sigma$ of each other.\n(abridged)\n", "  In this work, our focus is on exploring the potential of current GRB\nmeasurements to provide reliable constraints on cosmological model parameters\nat high redshift. This work is divided into two parts. First, we calibrate the\nAmati relation in a model-independent way by using Hubble parameter\nmeasurements obtained from the differential ages of the galaxies. We further\ncheck if the Amati relation parameters evolve with the GRBs' redshift or not,\nusing the data of Old Astrophysical Objects. The results indicate that GRBs do\nseem to evolve with redshift. In the second part, we test different\ncosmological models with the calibrated GRB data obtained by using constant and\ndynamical Amati relation. Our results indicate that the present quality of GRB\ndata is not good enough to put tight constraints on the cosmological\nparameters. Hence we perform a joint analysis with the combined data of GRBs\nand Type Ia Supernovae (SNe) and find that this can considerably enhance\ncosmological constraints in contrast to solely relying on GRBs.\n", "  We study the effect of baryons on the cosmic web -- halos, filaments, walls,\nand voids. To do so, we apply a modified version of NEXUS, a cosmic web\nmorphological analysis algorithm, to the IllustrisTNG simulations. We find that\nhalos lose more than $10\\%$ of their mass due to baryons, mostly to filaments\nand a small portion to walls and voids. However, the mass transfer does not\nsignificantly shift the boundaries of structures, leaving the volume fractions\nof the cosmic structures largely unaffected. We quantify the effects of\nbaryonic feedback on the power spectrum and the probability density function\n(PDF) of the density field for individual cosmic structures. For the power\nspectrum, most suppression due to feedback can be accounted for by including\n$M\\ge10^{12}~M_\\odot/h$ halos, without considering other cosmic structures.\nHowever, when examining the PDF of the density field, we find nearly $100\\%$\nsuppression of the emptiest regions and $10\\%$-level effects (boost or\nsuppression) in the remaining regions of filaments, walls, and voids. Our\nresults indicate the importance of modeling the effects of baryons in the whole\ncosmic web, not just halos, for cosmological analysis beyond two-point\nstatistics or field-based inferences.\n", "  In this paper, we forecast the expected detection rates and redshift\ndistributions of gravitationally lensed gravitational waves (GWs) from three\ndifferent mass distributions of primordial black holes (PBHs) and two stellar\nformation models of astrophysical black holes (ABHs) in the context of\nDECi-hertz Interferometer Gravitational wave Observatory (DECIGO) and it's\nsmaller scale version B-DECIGO. It suggests that DECIGO will be able to detect\n$10^4-10^5$ GW signals from such binary black holes (BBHs) each year and the\nevent rate distributions for PBHs will differ from those for ABHs due to their\ndifferent merger rate with respect to redshift. The large number of event rates\nmake $5-100$ detections of lensed GW signals being possible. After considering\nthe gravitational lensing effect, the difference between the detection rates\nand distributions for PBHs and ABHs will be more significant. Therefore, this\ncan be served as a complementary method to distinguish PBHs from ABHs.\n", "  Large imaging surveys, such as the Legacy Survey of Space and Time, rely on\nphotometric redshifts and tomographic binning for 3x2pt analyses that combine\ngalaxy clustering and weak lensing. In this paper, we propose a method for\noptimizing the tomographic binning choice for the lens sample of galaxies. We\ndivide the CosmoDC2 and Buzzard simulated galaxy catalogs into a training set\nand an application set, where the training set is nonrepresentative in a\nrealistic way, and then estimate photometric redshifts for the application\nsets. The galaxies are sorted into redshift bins covering equal intervals of\nredshift or comoving distance, or with an equal number of galaxies in each bin,\nand we consider a generalized extension of these approaches. We find that bins\nof equal comoving distance produce the highest dark energy figure of merit of\nthe initial binning choices, but that the choice of bin edges can be further\noptimized. We then train a neural network classifier to identify galaxies that\nare either highly likely to have accurate photometric redshift estimates or\nhighly likely to be sorted into the correct redshift bin. The neural network\nclassifier is used to remove poor redshift estimates from the sample, and the\nresults are compared to the case when none of the sample is removed. We find\nthat the neural network classifiers are able to improve the figure of merit by\n~13% and are able to recover ~25% of the loss in the figure of merit that\noccurs when a nonrepresentative training sample is used.\n", "  Degeneracies among parameters of the cosmological model are known to\ndrastically limit the information contained in the matter distribution. In the\nfirst paper of this series, we shown that the cosmic web environments; namely\nthe voids, walls, filaments and nodes; can be used as a leverage to improve the\nreal-space constraints on a set of six cosmological parameters, including the\nsummed neutrino mass.\n  Following-upon these results, we propose to study the achievable constraints\nof environment-dependent power spectra in redshift space where the velocities\nadd up information to the standard two-point statistics by breaking the\nisotropy of the matter density field. A Fisher analysis based on a set of\nthousands of Quijote simulations allows us to conclude that the combination of\npower spectra computed in the several cosmic web environments is able to break\nsome degeneracies. Compared to the matter monopole and quadrupole information\nalone, the combination of environment-dependent spectra tightens down the\nconstraints on key parameters like the matter density or the summed neutrino\nmass by up to a factor of $5.5$. Additionally, while the information contained\nin the matter statistic quickly saturates at mildly non-linear scales in\nredshift space, the combination of power spectra in the environments appears as\na goldmine of information able to improve the constraints at all the studied\nscales from $0.1$ to $0.5$ $h$/Mpc and suggests that further improvements are\nreachable at even finer scales.\n", "  We present a new definition of cosmic void and a publicly available code with\nthe algorithm that implements it. Underdense regions are defined as free-form\nobjects, called popcorn voids, made from the union of spheres of maximum volume\nwith a given joint integrated underdensity contrast.The method is inspired by\nthe excursion-set theory and consequently no rescaling processing is needed,\nthe removal of overlapping voids and objects with sizes below the shot noise\nthreshold is inherent in the algorithm. The abundance of popcorn voids in the\nmatter field can be fitted using the excursion-set theory provided the\nrelationship between the linear density contrast of the barrier and the\nthreshold used in void identification is modified relative to the spherical\nevolution model. We also analysed the abundance of voids in biased tracer\nsamples in redshift space. We show how the void abundance can be used to\nmeasure the geometric distortions due to the assumed fiducial cosmology, in a\ntest similar to an Alcock-Paczy\\'nski test. Using the formalism derived from\nprevious works, we show how to correct the abundance of popcorn voids for\nredshift-space distortion effects. Using this treatment, in combination with\nthe excursion-set theory, we demonstrate the feasibility of void abundance\nmeasurements as cosmological probes. We obtain unbiased estimates of the target\nparameters, albeit with large degeneracies in the parameter space. Therefore,\nwe conclude that the proposed test in combination with other cosmological\nprobes has potential to improve current cosmological parameter constraints.\n", "  The study of higher-order statistics, particularly three-point statistics, of\nthe Large Scale Structure (LSS) of the Universe provides us with unique\ninformation on the biasing relation between luminous and dark matter and on\ndeviations from primordial Gaussianity. As a result, much effort has been put\ninto improving measurement techniques as well as theoretical modelling,\nespecially in Fourier space. Comparatively, little progress has been made,\ninstead, in configuration space analyses. This work represents a first step\ntowards filling this gap by proposing a new strategy for modelling 3-point\nstatistics at higher perturbative orders in configuration space. Starting from\nthe next-to-leading order model for the matter bispectrum, we use 2D- FFTLog to\ngenerate its counterpart in configuration space. We calibrate the procedure\nusing the leading order predictions for which an analytic model for the\nthree-point correlation function (3PCF) already exists. Then we assess the\ngoodness of the 3PCF model by comparing its predictions with measurements\nperformed on the matter distribution in collisionless cosmological N-body\nsimulations (DEMNUni). We focus on two redshifts (z = 0.49 and z = 1.05) in the\nrange spanned by current and future galaxy redshift surveys. The chi-square\nanalysis reveals that the next-to-leading order 3PCF models significantly\nimprove over the leading order one for all triangle configurations in both\nredshifts, increasing the number of matched configurations at redshift z = 1.05\nand z = 0.49, respectively. In particular, a significant improvement is also\nseen on the Baryonic Acoustic Oscillations (BAO) scale for triangle\nconfigurations whose smallest side length is well into the nonlinear regime.\nThe computational cost of the model proposed here is high but not prohibitively\nlarge and represents the first step towards a complete 3PC model for the\ngalaxies.\n", "  Galaxy clusters detected through the thermal Sunyaev-Zeldovich (tSZ) effect\nare a powerful cosmological probe from which constraints on cosmological\nparameters such as $\\Omega_{\\mathrm{m}}$ and $\\sigma_8$ can be derived. The\nmeasured cluster tSZ signal can be, however, contaminated by Cosmic Infrared\nBackground (CIB) emission, as the CIB is spatially correlated with the cluster\ntSZ field. We quantify the extent of this contamination by applying the\niterative multi-frequency matched filter (iMMF) cluster-finding method to mock\nPlanck-like data from the Websky simulation. We find a significant bias in the\nretrieved cluster tSZ observables (signal-to-noise and Compton-$y$ amplitude),\nat the level of about $0.5\\, \\sigma$ per cluster. This CIB-induced bias\ntranslates into about $20$% fewer detections than expected if all the Planck\nHFI channels are used in the analysis, which can potentially bias derived\ncosmological constraints. We introduce a spectrally constrained iMMF, or\nsciMMF, which proves to be highly effective at suppressing this CIB-induced\nbias from the tSZ cluster observables by spectrally deprojecting the\ncluster-correlated CIB at the expense of a small signal-to-noise penalty. Our\nsciMMF is also robust to modelling uncertainties, namely to the choice of\ndeprojection spectral energy distribution. With it, CIB-free cluster catalogues\ncan be constructed and used for cosmological inference. We provide a publicly\navailable implementation of our sciMMF as part of the SZiFi package.\n", "  In a sky-averaged 21-cm signal experiment, the uncertainty on the extracted\nsignal depends mainly on the covariance between the foreground and 21-cm signal\nmodels. In this paper, we construct these models using the modes of variation\nobtained from the Singular Value Decomposition of a set of simulated foreground\nand 21-cm signals. We present a strategy to reduce this overlap between the\n21-cm and foreground modes by simultaneously fitting the spectra from multiple\ndifferent antennas, which can be used in combination with the method of\nutilizing the time dependence of foregrounds while fitting multiple drift scan\nspectra. To demonstrate this idea, we consider two different foreground models\n(i) a simple foreground model, where we assume a constant spectral index over\nthe sky, and (ii) a more realistic foreground model, with a spatial variation\nof the spectral index. For the simple foreground model, with just a single\nantenna design, we are able to extract the signal with good accuracy if we\nsimultaneously fit the data from multiple time slices. The 21-cm signal\nextraction is further improved when we simultaneously fit the data from\ndifferent antennas as well. This improvement becomes more pronounced while\nusing the more realistic mock observations generated from the detailed\nforeground model. We find that even if we fit multiple time slices, the\nrecovered signal is biased and inaccurate for a single antenna. However,\nsimultaneously fitting the data from different antennas reduces the bias and\nthe uncertainty by a factor of 2-3 on the extracted 21-cm signal.\n", "  We study a possibility of constraining isotropic cosmic birefringence with\nhelp of cosmic microwave background polarisation data in the presence of\npolarisation angle miscalibration without relying on any assumptions about the\nGalactic foreground angular power spectra and in particular on their EB\ncorrelation. We propose a new analysis framework based on a generalised\nparametric component separation approach, which accounts simultaneously on the\npresence of galactic foregrounds, relevant instrumental effects and external\npriors. We find that upcoming multi-frequency CMB data with appropriate\ncalibration priors will allow producing an instrumental-effect-corrected and\nforeground-cleaned CMB map, which can be used to estimate the isotropic\nbirefringence angle and the tensor-to-scalar ratio, accounting on statistical\nand systematic uncertainties incurred during the entire procedure. In\nparticular, in the case of a Simons Observatory-like, three Small Aperture\nTelescopes, we derive an uncertainty on the birefringence angle of\n$\\sigma(\\beta_{b}) = 0.07^\\circ$ (0.1$^\\circ$), assuming the standard cosmology\nand calibration priors for all (single) frequency channels with the precision\nof $\\sigma(\\alpha_i)= 0.1^\\circ$ as aimed at by the near future ground-based\nexperiments. This implies that these experiments could confirm or disprove the\nrecently detected value of $\\beta_b=0.35^\\circ$ with a significance between $3$\nand $5 \\sigma$. [abridged version]\n", "  We present a Lagrangian model of galaxy clustering bias in which we train a\nneural net using the local properties of the smoothed initial density field to\npredict the late-time mass-weighted halo field. By fitting the mass-weighted\nhalo field in the AbacusSummit simulations at z=0.5, we find that including\nthree coarsely spaced smoothing scales gives the best recovery of the halo\npower spectrum. Adding more smoothing scales may lead to 2-5% underestimation\nof the large-scale power and can cause the neural net to overfit. We find that\nthe fitted halo-to-mass ratio can be well described by two directions in the\noriginal high-dimension feature space. Projecting the original features into\nthese two principal components and re-training the neural net either reproduces\nthe original training result, or outperforms it with a better match of the halo\npower spectrum. The elements of the principal components are unlikely to be\nassigned physical meanings, partly owing to the features being highly\ncorrelated between different smoothing scales. Our work illustrates a potential\nneed to include multiple smoothing scales when studying galaxy bias, and this\ncan be done easily with machine-learning methods that can take in high\ndimensional input feature space.\n", "  The High Latitude Spectroscopic Survey (HLSS) is the reference baseline\nspectroscopic survey for NASA's Nancy Grace Roman space telescope, measuring\nredshifts of $\\sim 10$M H$\\alpha$ emission line galaxies over a $2000$ deg$^2$\nfootprint at $z=1-2$. In this work, we use a realistic Roman galaxy mock\ncatalogue to explore optimal phenomenological modeling of the measured power\nspectrum. We consider two methods for modeling the redshift-space distortions\n(Kaiser squashing and another with a window function on $\\beta$ that selects\nout the coherent radial infall pairwise velocities, $M_A$ and $M_B$,\nrespectively), two models for the nonlinear impact of baryons that smears the\nBAO signal (a fixed ratio between the smearing scales in the perpendicular and\nparallel dimensions and another where these smearing scales are kept as a free\nparameters, P$_{dw}(k|k_*)$ and P$_{dw}(k|\\Sigma_\\perp,\\Sigma_\\parallel)$,\nrespectively), and two analytical emulations of nonlinear growth (one employing\nthe halo model and another formulated from simulated galaxy clustering of a\nsemi-analytical model, $F_{HM}$ and $F_{SAM}$, respectively). We find that the\nbest model combination employing $F_{HM}$ is $P_{dw}(k|k_*)*F_{HM}*M_B$, while\nthe best combination employing $F_{SAM}$ is $P_{dw}(k|k_*)*F_{SAM}*M_B$, which\nleads to unbiased measurements of cosmological parameters. We compare these to\nthe Effective Field Theory of Large-Scale Structure perturbation theory model\n$P_{EFT}(k|\\Theta)$, and find that our simple phenomenological models are\ncomparable across the entire redshift range for $k_{max}=0.25$ and $0.3$\n$h$/Mpc. We expect the tools that we have developed to be useful in probing\ndark energy and testing gravity using Roman in an accurate and robust manner.\n", "  We present TXPipe, a modular, automated and reproducible pipeline for\ningesting catalog data and performing all the calculations required to obtain\nquality-assured two-point measurements of lensing and clustering, and their\ncovariances, with the metadata necessary for parameter estimation. The pipeline\nis developed within the Rubin Observatory Legacy Survey of Space and Time\n(LSST) Dark Energy Science Collaboration (DESC), and designed for cosmology\nanalyses using LSST data. In this paper, we present the pipeline for the\nso-called 3x2pt analysis -- a combination of three two-point functions that\nmeasure the auto- and cross-correlation between galaxy density and shapes. We\nperform the analysis both in real and harmonic space using TXPipe and other\nLSST-DESC tools. We validate the pipeline using Gaussian simulations and show\nthat it accurately measures data vectors and recovers the input cosmology to\nthe accuracy level required for the first year of LSST data under this\nsimplified scenario. We also apply the pipeline to a realistic mock galaxy\nsample extracted from the CosmoDC2 simulation suite (Korytov et al. 2019).\nTXPipe establishes a baseline framework that can be built upon as the LSST\nsurvey proceeds. Furthermore, the pipeline is designed to be easily extended to\nscience probes beyond the 3x2pt analysis.\n", "  UltraLight Dark Matter (ULDM) is an axion-like dark matter candidate with an\nextremely small particle mass. ULDM halos consist of a spherically symmetric\nsolitonic core and an NFW-like skirt. We simulate halo creation via soliton\nmergers and use these results to explore the core-halo mass relation. We\ncalculate the eigenstates of the merged halos and use these to isolate the\nsolitonic core and calculate its relative contribution to the halo mass. We\ncompare this approach to using a fitting function to isolate the core and find\na difference in masses up to 30%. We analyze three families of simulations:\nequal-mass mergers, unequal-mass mergers, and halos with a two-step merger\nhistory. Setting the halo mass to the initial mass in the simulation does not\nyield a consistent core-halo relationship. Excluding material \"ejected\" by the\ncollision yields a core-halo relationship with a slope of 1/3 for simultaneous\nmergers and roughly 0.4 for two-step mergers. Our findings suggest there is no\nuniversal core-halo mass relationship for ULDM and shed light on the differing\nresults for the core-halo relationship previously reported in the literature.\n", "  Cosmic voids, the underdense regions in the Universe, are impacted by dark\nenergy and massive neutrinos. In this work, relying on the DEMNUni suite of\ncosmological simulations, we explore the void size function in cosmologies with\nboth dynamical dark energy and massive neutrinos. We investigate the impact of\ndifferent choices of dark matter tracers on the void size function and study\nits sensitivity to the joint effect of modifying the dark energy equation of\nstate and the sum of neutrino masses. We show that dark energy and massive\nneutrinos produce separable effects on the void size function. This statistic\ntherefore allows us to distinguish among a wide range of combinations of dark\nenergy equations of state and total neutrino masses, and its exploitation in\nforthcoming large galaxy surveys will be extremely useful in breaking\ndegeneracies among these cosmological parameters.\n", "  Spatial curvature is one of the most fundamental parameters in our current\nconcordance flat $\\Lambda$CDM model of the Universe. The goal of this work is\nto investigate how the constraint on the spatial curvature is affected by an\nassumption on the sound horizon scale. The sound horizon is an essential\nquantity to use the standard ruler from the Cosmic Microwave Background (CMB)\nand Baryon Acoustic Oscillations (BAOs). As an example, we study the curvature\nconstraint in an axion-like Early Dark Energy (EDE) model in light of recent\ncosmological datasets from Planck, the South Pole Telescope (SPT), and the\nAtacama Cosmology Telescope (ACT), as well as BAO data compiled in Sloan\nDigital Sky Survey Data Release 16. We find that, independent of the CMB\ndatasets, the EDE model parameters are constrained only by the CMB power\nspectra as precisely and consistently as the flat case in previous work, even\nwith the spatial curvature. We also demonstrate that combining CMB with BAO is\nextremely powerful to constrain the curvature parameter even with a reduction\nof the sound-horizon scale in an EDE model, resulting in $\\Omega_K=-0.0056\\pm\n0.0031$ in the case of ACT+BAO after marginalizing over the parameters of the\nEDE model. This constraint is as competitive as the Planck+BAO result in a\n$\\Lambda$CDM model, $\\Omega_{K}=-0.0001\\pm 0.0018$.\n", "  One of the fundamental questions in inflation is how to characterize the\nstructure of different types of models in the field theoretic landscape.\nProposals in this direction include attempts to directly characterize the\nformal structure of the theory by considering complexity measures of the\npotentials. An alternative intrinsic approach is to focus on the behavior of\nthe observables that result from different models and to ask whether their\nbehavior differs among models. This type of analysis can be applied even to\nnontrivial multifield theories where a natural measure of the complexity of the\nmodel is not obvious and the analytical evaluation of the observables is often\nimpossible. In such cases one may still compute these observables numerically\nand investigate their behavior. One interesting case is when observables show a\nscaling behavior, in which case theories can be characterized in terms of their\nscaling amplitudes and exponents. Generically, models have nontrivial parameter\nspaces, leading to exponents that are functions of these parameters. In such\ncases we consider an iterative procedure to determine whether the exponent\nfunctions in turn lead to a scaling behavior. We show that modular inflation\nmodels can be characterized by families of simple scaling laws and that the\nscaling exponents that arise in this way in turn show a scaling law in\ndependence of these varying energy scales.\n", "  The characterization of the dynamical state of clusters is key to study their\nevolution, their selection, and use them as a cosmological probe. The offsets\nbetween different definitions of the center have been used to estimate the\ncluster disturbance. Our goal is to study the distribution of the offset\nbetween the X-ray and optical centers in clusters of galaxies. We study the\noffset for eROSITA clusters. We aim to connect observations to hydrodynamical\nsimulations and N-body models. We assess the astrophysical effects affecting\nthe displacements. We measure the offset for clusters observed in eFEDS and\neRASS1. We focus on a subsample of 87 massive eFEDS clusters at low redshift.\nWe link the observations to the offset parameter Xoff measured on dark matter\nhalos in N-body simulations, using the hydrodynamical simulations as a bridge.\neFEDS clusters show a smaller offset compared to eRASS1, because the latter\ncontains a larger fraction of massive and disturbed structures. We measure an\naverage offset of 76.3+30.1-27.1 kpc on the subsample of 87 eFEDS clusters.\nThis is in agreement with the predictions from TNG and Magneticum, and the\ndistribution of Xoff from DMO simulations. The tails of the distributions are\ndifferent. Using the offset to classify relaxed and disturbed clusters, we\nmeasure a relaxed fraction of 31% in the eFEDS subsample. Finally, we find a\ncorrelation between the offset in hydrodynamical simulations and Xoff measured\non their parent DMO run and calibrate a relation between them. There is good\nagreement between eROSITA data and simulations. Baryons cause a decrement\n(increment) in the low (high) offset regime compared to the Xoff distribution.\nThe offset-Xoff relation provides an accurate prediction of the true Xoff\ndistribution in Magneticum and TNG. It allows introducing the offsets in\ncosmology, marginalizing on dynamical selection effects.\n", "  In this paper we determine the dipole in the distance redshift relation from\nthe Pantheon+ data. We find that, while its amplitude roughly agrees with the\ndipole found in the cosmic microwave background which is attributed to the\nmotion of the solar system with respect to the cosmic rest frame, the direction\nis different with a significance of slightly more than $3\\si$. While the\namplitude depends on the lower redshift cutoff, the direction is quite stable.\nFor redshift cuts of order $z_{\\rm cut} \\simeq 0.05$ and higher, the dipole is\nno longer detected with high statistical significance. An important r\\^ole\nseems to be played by the redshift corrections for peculiar velocities.\n", "  Key non-Gaussian properties of cosmological fields can be captured by their\none-point statistics, providing a complement to two-point statistical\nmeasurements from power spectra or correlation functions. Large deviation\ntheory can robustly predict the one-point statistics of cosmological density\nfields on mildly non-linear scales from first principles. It provides a direct\nprediction for the cumulant generating function (CGF) of such fields, from\nwhich a prediction for the more commonly used probability density function\n(PDF) is extracted through an inverse Laplace transform. For joint one-point\nstatistics of multiple fields, the inverse Laplace transform rapidly becomes\nmore cumbersome and computationally expensive. In this work, we demonstrate for\nthe first time that the weak lensing CGF itself can be used as an observable\nthat captures an equal amount of cosmological information to the PDF. While we\nuse the weak-lensing convergence field as a simplistic and instructive example,\nthis work is intended as a first step towards a cosmological analysis based on\nlarge deviation theory in the context of a nulling framework, which excludes\ncontributions from small scales to facilitate highly accurate theoretical\npredictions. In this context, the method should be generally applicable for a\nmulti-scale tomographic analysis of weak lensing and galaxy clustering.\n", "  The number density of galaxy clusters as a function of mass and redshift is a\nsensitive function of the cosmological parameters. To use clusters for\ncosmological parameter studies, it is necessary to determine their masses as\naccurately as possible, which is typically done via mass-observable scaling\nrelations. X-ray observables can be biased by multiphase gas and projection\neffects, especially in the case where cluster temperatures and luminosities are\nestimated from single-model fits to all of the emission with a given radius.\nUsing simulated galaxy clusters from a realistic cosmological simulation, we\nseek to determine the importance of these biases in the context of\nSpectrum-Roentgen-Gamma/eROSITA observations of clusters. We extract clusters\nfrom the Magneticum suite, and simulate eROSITA observations of these clusters\nusing PHOX and SIXTE. We compare the fitted observables from these observations\nto those derived from the simulations. We fitted an intrinsically scattered\n$L_{\\rm X}-T$ scaling relation to these measurements following a Bayesian\napproach with which we fully took into account the selection effects and the\nmass function. The largest biases on the cluster observables come from the\ninadequacy of single-temperature model fits to represent emission from\nmultiphase gas, as well as a bias arising from cluster emission within the\nprojected $r_{500c}$ along the line of sight but outside of the spherical\n$r_{500c}$. We find that the biases on temperature and luminosity due to the\nprojection of emission from other clusters within $r_{500c}$ is small. We find\nthat our simulated clusters follow a $L_{\\rm X}-T$ scaling relation that has a\nbroadly consistent but slightly shallower slope compared to the literature, and\nthat the intrinsic scatter of $L_{\\rm X}$ at given T is lower compared to the\nrecent observational results where the selection effects are fully considered.\n", "  We present direct constraints on galaxy intrinsic alignments using the Dark\nEnergy Survey Year 3 (DES Y3), the Extended Baryon Oscillation Spectroscopic\nSurvey (eBOSS) and its precursor, the Baryon Oscillation Spectroscopic Survey\n(BOSS). Our measurements incorporate photometric red sequence (redMaGiC)\ngalaxies from DES with median redshift $z\\sim0.2-1.0$, luminous red galaxies\n(LRGs) from eBOSS at $z\\sim0.8$, and also a SDSS-III BOSS CMASS sample at\n$z\\sim0.5$. We measure two point intrinsic alignment correlations, which we fit\nusing a model that includes lensing, magnification and photometric redshift\nerror. Fitting on scales $6<r_{\\rm p} < 70$ Mpc$/h$, we make a detection of\nintrinsic alignments in each sample, at $5\\sigma-22\\sigma$ (assuming a simple\none parameter model for IAs). Using these red samples, we measure the\nIA-luminosity relation. Our results are statistically consistent with previous\nresults, but offer a significant improvement in constraining power,\nparticularly at low luminosity. With this improved precision, we see detectable\ndependence on colour between broadly defined red samples. It is likely that a\nmore sophisticated approach than a binary red/blue split, which jointly\nconsiders colour and luminosity dependence in the IA signal, will be needed in\nfuture. We also compare the various signal components at the best fitting point\nin parameter space for each sample, and find that magnification and lensing\ncontribute $\\sim2-18\\%$ of the total signal. As precision continues to improve,\nit will certainly be necessary to account for these effects in future direct IA\nmeasurements. Finally, we make equivalent measurements on a sample of Emission\nLine Galaxies (ELGs) from eBOSS at $z\\sim 0.8$. We report a null detection,\nconstraining the IA amplitude (assuming the nonlinear alignment model) to be\n$A_1=0.07^{+0.32}_{-0.42}$ ($|A_1|<0.78$ at $95\\%$ CL).\n", "  We present a model for the squeezed dark matter bispectrum, where the short\nmodes are deep in the non-linear regime. We exploit the consistency relations\nfor large-scale structures combined with a response function approach to write\nthe squeezed bispectrum in terms of a few unknown functions of the short modes.\nWe provide an ansatz for a fitting function for these response functions,\nchecking that the resulting model is reliable when compared to the one-loop\nsqueezed bispectrum. We then test the model against measured bispectra from\nnumerical simulations for short modes ranging between $k \\sim 0.1 \\, h/$Mpc,\nand $k \\sim 0.7 \\, h/$Mpc at redshift $z=0$. To evaluate the goodness of the\nfit of our model we implement a non-Gaussian covariance and find agreement\nwithin $1$-$\\sigma$ standard deviation of the simulated data.\n", "  We present limits on the spin-independent interaction cross section of dark\nmatter particles with silicon nuclei, derived from data taken with a cryogenic\ncalorimeter with 0.35 g target mass operated in the CRESST-III experiment. A\nbaseline nuclear recoil energy resolution of $(1.36\\pm 0.05)$ eV$_{\\text{nr}}$,\ncurrently the lowest reported for macroscopic particle detectors, and a\ncorresponding energy threshold of $(10.0\\pm 0.2)$ eV$_{\\text{nr}}$ have been\nachieved, improving the sensitivity to light dark matter particles with masses\nbelow 160 MeV/c$^2$ by a factor of up to 20 compared to previous results. We\ncharacterize the observed low energy excess, and we exclude noise triggers and\nradioactive contaminations on the crystal surfaces as dominant contributions.\n", "  We perform a Bayesian study of a generalization of the basic\n$\\alpha$-attractor T model given by the potential\n$V(\\phi)=V_0\\left[1-\\text{sech}^{p}\\left(\\phi/\\sqrt{6\\alpha}M_{pl}\\right)\\right]$\nwhere $\\phi$ is the inflaton field and the parameter $\\alpha$ corresponds to\nthe inverse curvature of the scalar manifold in the conformal or superconformal\nrealizations of the attractor models. Such generalization is characterized by\nthe power $p$ which includes the basic or base model for $p=2$. Once the priors\nfor the parameters of the $\\alpha$-attractor potential are set by numerical\nexploration, we perform the corresponding statistical analysis for the cases\n$p=1\\, , 2\\, , 3\\, ,4$, and derive posteriors. Considering the original\n$\\alpha$-attractor potential as the base model, we calculate the evidence for\nour generalization, and conclude that the $p=4$ model is preferred by the CMB\ndata. We also present constraints for the parameter $\\alpha$. Interestingly,\nall the cases studied prefer a specific value for the tensor-to-scalar ratio\ngiven by $r\\simeq 0.0025$.\n", "  Wave (fuzzy) dark matter ($\\psi$DM) consists of ultralight bosons, featuring\na solitonic core within a granular halo. Here we extend $\\psi$DM to two\ncomponents, with distinct particle masses $m$ and coupled only through gravity,\nand investigate the resulting soliton-halo structure via cosmological\nsimulations. Specifically, we assume $\\psi$DM contains $75$ per cent major\ncomponent and $25$ per cent minor component, fix the major-component particle\nmass to $m_{\\rm major}=1\\times10^{-22}\\,{\\rm eV}$, and explore two different\nminor-component particle masses with $m_{\\rm major}:m_{\\rm minor}=3:1$ and\n$1:3$, respectively. For $m_{\\rm major}:m_{\\rm minor}=3:1$, we find that (i)\nthe major- and minor-component solitons coexist, have comparable masses, and\nare roughly concentric. (ii) The soliton peak density is significantly lower\nthan the single-component counterpart, leading to a smoother soliton-to-halo\ntransition and rotation curve. (iii) The combined soliton mass of both\ncomponents follows the same single-component core-halo mass relation. In\ndramatic contrast, for $m_{\\rm major}:m_{\\rm minor}=1:3$, a minor-component\nsoliton cannot form with the presence of a stable major-component soliton; the\ntotal density profile, for both halo and soliton, is thus dominated by the\nmajor component and closely follows the single-component case. To support this\nfinding, we propose a toy model illustrating that it is difficult to form a\nsoliton in a hot environment associated with a deep gravitational potential.\nThe work demonstrates the extra flexibility added to the multi-component\n$\\psi$DM model can resolve observational tensions over the single-component\nmodel while retaining its key features.\n", "  We use a cosmology-independent method to calibrate gamma-ray burst (GRB) from\nthe observational Hubble data (OHD) with the cosmic chronometers method. By\nusing Gaussian Process to reconstruct OHD, we calibrate the Amati relation\n($E_{\\rm p}$--$E_{\\rm iso}$) to construct a GRB Hubble diagram with the A118\ndata set, and constrain Dark Energy models in a flat space with the Markov\nChain Monte Carlo numerical method. With the cosmology-independent GRBs at\n$1.4<z\\leq8.2$ in the A118 data set and the Pantheon sample of type Ia\nsupernovae (SNe Ia) at $0.01<z\\leq2.3$, we obtained $\\Omega_{\\rm m}$ =\n$0.379^{+0.033}_{-0.024}$, $h$ = $0.701^{+0.0035}_{-0.0035}$, $w$ =\n$-1.25^{+0.14}_{-0.12}$, $w_a$ = $-0.84^{+0.81}_{-0.38}$ for the flat\nChevallier-Polarski-Linder model at the 1$\\sigma$ confidence level. We find no\nsignificant evidence supporting deviations from the standard $\\Lambda$CDM\nmodel.\n", "  We present cosmological constraints from the Subaru Hyper Suprime-Cam (HSC)\nfirst-year weak lensing shear catalogue using convolutional neural networks\n(CNNs) and conventional summary statistics. We crop 19\n$3\\times3\\,\\mathrm{{deg}^2}$ sub-fields from the first-year area, divide the\ngalaxies with redshift $0.3\\le z\\le1.5$ into four equally-spaced redshift bins,\nand perform tomographic analyses. We develop a pipeline to generate simulated\nconvergence maps from cosmological $N$-body simulations, where we account for\neffects such as intrinsic alignments (IAs), baryons, photometric redshift\nerrors, and point spread function errors, to match characteristics of the real\ncatalogue. We train CNNs that can predict the underlying parameters from the\nsimulated maps, and we use them to construct likelihood functions for Bayesian\nanalyses. In the $\\Lambda$ cold dark matter model with two free cosmological\nparameters $\\Omega_\\mathrm{m}$ and $\\sigma_8$, we find\n$\\Omega_\\mathrm{m}=0.278_{-0.035}^{+0.037}$,\n$S_8\\equiv(\\Omega_\\mathrm{m}/0.3)^{0.5}\\sigma_8=0.793_{-0.018}^{+0.017}$, and\nthe IA amplitude $A_\\mathrm{IA}=0.20_{-0.58}^{+0.55}$. In a model with four\nadditional free baryonic parameters, we find\n$\\Omega_\\mathrm{m}=0.268_{-0.036}^{+0.040}$, $S_8=0.819_{-0.024}^{+0.034}$, and\n$A_\\mathrm{IA}=-0.16_{-0.58}^{+0.59}$, with the baryonic parameters not being\nwell-constrained. We also find that statistical uncertainties of the parameters\nby the CNNs are smaller than those from the power spectrum (5--24 percent\nsmaller for $S_8$ and a factor of 2.5--3.0 smaller for $\\Omega_\\mathrm{m}$),\nshowing the effectiveness of CNNs for uncovering additional cosmological\ninformation from the HSC data. With baryons, the $S_8$ discrepancy between HSC\nfirst-year data and Planck 2018 is reduced from $\\sim2.2\\,\\sigma$ to\n$0.3\\text{--}0.5\\,\\sigma$.\n", "  It is argued that the data presented by Hubble Space Telescope and James Webb\nSpace Telescope, that seem to be at odds with the canonical big bang cosmology,\nfind simple explanation if galaxy formation is seeded by massive primordial\nblack holes (PBH), as anticipated in 1993 (A. Dolgov and J. Silk, later DS).\nThe statement that the galaxy formation might be seeded by PBH is now\nrediscovered in several works. The predicted by DS log-normal mass spectrum of\nPBHs very well agrees with astronomical data. Abundant BH population of the\nGalaxy with masses of the order of tens solar masses is predicted. Extended\nmass spectrum of PBH together with their possible clustering allows them to\nmake 100\\% contribution into the cosmological dark matter. Another prediction\nof DS mechanism on noticeable amount of antimatter in the Milky Way also seems\nto be confirmed by the data.\n", "  Cross-correlating the data of neutral hydrogen (HI) 21cm intensity mapping\nwith galaxy surveys is an effective method to extract astrophysical and\ncosmological information. In this work, we investigate the cross-correlation of\nMeerKAT single-dish mode HI intensity mapping and China Space Station Telescope\n(CSST) spectroscopic galaxy surveys. We simulate a survey area of $\\sim 300$\n$\\mathrm{deg}^2$ of MeerKAT and CSST surveys at $z=0.5$ using Multi-Dark N-body\nsimulation. The PCA algorithm is applied to remove the foregrounds of HI\nintensity mapping, and signal compensation is considered to solve the signal\nloss problem in the HI-galaxy cross power spectrum caused by the foreground\nremoval process. We find that from CSST galaxy auto and MeerKAT-CSST cross\npower spectra, the constraint accuracy of the parameter product $\\Omega_{\\rm\nHI}b_{\\rm HI}r_{{\\rm HI},g}$ can reach to $\\sim1\\%$, which is about one order\nof magnitude higher than the current results. After performing the full MeerKAT\nHI intensity mapping survey with 5000 deg$^2$ survey area, the accuracy can be\nenhanced to $<0.3\\%$. This implies that the MeerKAT-CSST cross-correlation can\nbe a powerful tool to probe the cosmic HI property and the evolution of\ngalaxies and the Universe.\n", "  Filament finders are limited, among other things, by the abundance of\nspectroscopic redshift data. As there are proportionally more photometric\nredshift data than spectroscopic, we aim to use photometric data to improve and\nexpand the areas where we can detect the large-scale structure of the Universe.\nWe present a proof of concept, showing that the Bisous filament finder can\nimprove the detected filamentary network with photometric redshift data. We\ncreated mock data from the MultiDark-Galaxies catalogue. Galaxies with\nspectroscopic redshifts were given exact positions from the simulation.\nGalaxies with photometric redshifts were given uncertainties along one\ncoordinate. The errors were generated with different Gaussian distributions for\ndifferent samples. There are three different types of samples: spectroscopic\nonly, photometric only, and mixed samples of galaxies with photometric and\nspectroscopic redshifts. In photometric-only samples, the larger the\nuncertainty for photometric redshifts, the fewer filaments are detected, and\nthe filaments strongly align along the line of sight. Using mixed samples\nimproves the number of filaments detected and decreases the alignment bias of\nthose filaments. The results are compared against the full spectroscopic\nsample. The recall for photometric-only samples depends heavily on the size of\nuncertainty and dropped close to 20%; for mixed samples, the recall stayed\nbetween 40% and 80%. The false discovery rate stayed below 5% in every sample\ntested in this work. Mixed samples showed better results than corresponding\nphotometric-only or spectroscopic-only samples for every uncertainty size and\nnumber of spectroscopic galaxies in mixed samples. Mixed samples of galaxies\nwith photometric and spectroscopic redshifts help us to improve and extend the\nlarge-scale structure further than possible with only spectroscopic samples.\n", "  In this series of papers we present an emulator-based halo model for the\nnon-linear clustering of galaxies in modified gravity cosmologies. In the first\npaper, we present emulators for the following halo properties: the halo mass\nfunction, concentration-mass relation and halo-matter cross-correlation\nfunction. The emulators are trained on data extracted from the \\textsc{FORGE}\nand \\textsc{BRIDGE} suites of $N$-body simulations, respectively for two\nmodified gravity (MG) theories: $f(R)$ gravity and the DGP model, varying three\nstandard cosmological parameters $\\Omega_{\\mathrm{m0}}, H_0, \\sigma_8$, and one\nMG parameter, either $\\bar{f}_{R0}$ or $r_{\\mathrm{c}}$. Our halo property\nemulators achieve an accuracy of $\\lesssim 1\\%$ on independent test data sets.\nWe demonstrate that the emulators can be combined with a galaxy-halo connection\nprescription to accurately predict the galaxy-galaxy and galaxy-matter\ncorrelation functions using the halo model framework.\n", "  Recent work has shown that searches for diffuse radio emission by MeerKAT -\nand eventually the SKA - are well suited to provide some of the strongest\nconstraints yet on dark matter annihilations. To make full use of the\nobservations by these facilities, accurate simulations of the expected dark\nmatter abundance and diffusion mechanisms in these astrophysical objects are\nrequired. However, because of the computational costs involved, various\nmathematical and numerical techniques have been developed to perform the\ncalculations in a feasible manner. Here we provide the first quantitative\ncomparison between methods that are commonly used in the literature, and\noutline the applicability of each one in various simulation scenarios. These\nconsiderations are becoming ever more important as the hunt for dark matter\ncontinues into a new era of precision radio observations.\n", "  The large-scale structure is a major source of cosmological information.\nHowever, next-generation photometric galaxy surveys will only provide a\ndistorted view of cosmic structures due to large redshift uncertainties. To\naddress the need for accurate reconstructions of the large-scale structure in\npresence of photometric uncertainties, we present a framework that constrains\nthe three-dimensional dark matter density jointly with galaxy photometric\nredshift probability density functions (PDFs), exploiting information from\ngalaxy clustering. Our forward model provides Markov Chain Monte Carlo\nrealizations of the primordial and present-day dark matter density, inferred\njointly from data. Our method goes beyond 2-point statistics via field-level\ninference. It accounts for all observational uncertainties and the survey\ngeometry. We showcase our method using mock catalogs that emulate\nnext-generation surveys with a worst-case redshift uncertainty, equivalent to\n${\\sim}300$ Mpc. On scales $150$ Mpc, we improve the cross-correlation of the\nphotometric galaxy positions with the ground truth from $28\\%$ to $86\\%$. The\nimprovement is significant down to $13$ Mpc. On scales $150$ Mpc, we achieve a\ncross-correlation of $80-90\\%$ with the ground truth for the dark matter\ndensity, radial peculiar velocities, tidal shear and gravitational potential.\n", "  We test the smooth dark energy paradigm using Dark Energy Survey (DES) Year 1\nand Year 3 weak lensing and galaxy clustering data. Within the $\\Lambda$CDM and\n$w$CDM model we separate the expansion and structure growth history by\nsplitting $\\Omega_\\mathrm{m}$ (and $w$) into two meta-parameters that allow for\ndifferent evolution of growth and geometry in the Universe. We consider three\ndifferent combinations of priors on geometry from CMB, SNIa, BAO, BBN that\ndiffer in constraining power but have been designed such that the growth\ninformation comes solely from the DES weak lensing and galaxy clustering. For\nthe DES-Y1 data we find no detectable tension between growth and geometry\nmeta-parameters in both the $\\Lambda$CDM and $w$CDM parameter space. This\nstatement also holds for DES-Y3 cosmic shear and 3x2pt analyses. For the\ncombination of DES-Y3 galaxy-galaxy lensing and galaxy clustering (2x2pt) we\nmeasure a tension between our growth and geometry meta-parameters of\n2.6$\\sigma$ in the $\\Lambda$CDM and 4.48$\\sigma$ in the $w$CDM model space,\nrespectively. We attribute this tension to residual systematics in the DES-Y3\nRedMagic galaxy sample rather than to new physics. We plan to investigate our\nfindings further using alternative lens samples in DES-Y3 and future weak\nlensing and galaxy clustering datasets.\n", "  Considering possible solutions to the $S_8$ tension between the Planck cosmic\nmicrowave background (CMB) measurement and low-redshift probes, we extended the\nstandard $\\Lambda$CDM cosmological model by including decay of dark matter\n(DDM). We first tested the DDM model in which dark matter decays into a form of\nnoninteracting dark radiation. Under this DDM model, we investigated the\nimpacts of DDM on the Sunyaev Zel'dovich (SZ) effect by varying the decay\nlifetime, $\\Gamma^{-1}$, including the background evolution in cosmology and\nthe nonlinear prescription in the halo mass function. We performed a\ncosmological analysis under the assumption of this extended cosmological model\nby combining the latest high-redshift Planck CMB measurement and low-redshift\nmeasurements of the SZ power spectrum as well as the baryonic acoustic\noscillations (BAO) and luminosity distances to type Ia supernovae (SNIa). Our\nresult shows a preference for $\\Gamma^{-1} \\sim 220$ Gyr with a lower bound on\nthe decay lifetime of $\\sim$ 38 Gyr at 95\\% confidence level. Additionally, we\ntested the other DDM model in which dark matter decays into warm dark matter\nand dark radiation. This model supports $\\Gamma^{-1} \\sim 137$ Gyr to resolve\nthe $S_8$ tension with a lower bound on the decay lifetime of $\\sim$ 24 Gyr at\n95\\% confidence level. Comparing these two models, we find that the second\nleads to slightly better reconciliation of the $S_8$ tension.\n", "  Photometric redshifts are a key ingredient in the analysis and interpretation\nof large-scale structure (LSS) surveys. The accuracy and precision of these\nredshift estimates are directly linked to the constraining power of photometric\nsurveys. It is hence necessary to define precision and accuracy requirements\nfor the redshift calibration \\revision{to not} infer biased results in the\nfinal analysis. For weak gravitational lensing of the LSS, the photometry\nculminates in the estimation of the source redshift distribution (SRD) in each\nof the tomographic bins used in the analysis. The focus has been on shifts of\nthe mean of the SRDs and how well the calibration must be able to recover\nthose. Since the estimated SRDs are usually given as a normalized histogram\nwith corresponding errors, it would be advantageous to propagate these\nuncertainties accordingly to see whether the requirements of the given survey\nare indeed fulfilled. Here we propose the use of functional derivatives to\ncalculate the sensitivity of the final observables, e.g. the lensing angular\npower spectrum, with respect to the SRD at a specific redshift. This allows the\npropagation of arbitrarily shaped small perturbations to the SRD, without\nhaving to run the whole analysis pipeline for each realization again. We apply\nour method to an EUCLID survey and demonstrate it with SRDs of the KV450 data\nset, recovering previous results. Lastly, we note that the moments of the SRD\nof order larger than two will probably not be relevant when propagating\nredshift uncertainties in cosmic shear analysis.\n", "  The reported detection of the global 21-cm signal by the EDGES collaboration\nis significantly stronger than standard astrophysical predictions. One possible\nexplanation is an early radio excess above the cosmic microwave background.\nSuch a radio background could have been produced by high redshift galaxies, if\nthey were especially efficient in producing low-frequency synchrotron\nradiation. We have previously studied the effects of such an inhomogeneous\nradio background on the 21-cm signal; however, we made a simplifying assumption\nof isotropy of the background seen by each hydrogen cloud. Here we perform a\ncomplete calculation that accounts for the fact that the 21-cm absorption\noccurs along the line of sight, and is therefore sensitive to radio sources\nlying behind each absorbing cloud. We find that the complete calculation\nstrongly enhances the 21-cm power spectrum during cosmic dawn, by up to two\norders of magnitude; on the other hand, the effect on the global 21-cm signal\nis only at the $5\\%$ level. In addition to making the high-redshift 21-cm\nfluctuations potentially more easily observable, the line of sight radio effect\ninduces a new anisotropy in the 21-cm power spectrum. While these effects are\nparticularly large for the case of an extremely-enhanced radio efficiency, they\nmake it more feasible to detect even a moderately-enhanced radio efficiency in\nearly galaxies. This is especially relevant since the EDGES signal has been\ncontested by the SARAS experiment.\n", "  Massive elliptical galaxies align pointing their major axis towards each\nother in the structure of the Universe. Such alignments are well-described at\nlarge scales through a linear relation with respect to the tidal field of the\nlarge-scale structure. At such scales, galaxy alignments are sensitive to the\npresence of baryon acoustic oscillations (BAO). The shape of the BAO feature in\ngalaxy alignment correlations differs from the traditional peak in the\nclustering correlation function. Instead, it appears as a trough feature at the\nBAO scale. In this work, we show that this feature can be explained by a simple\ntoy model of tidal fields from a spherical shell of matter. This helps give a\nphysical insight for the feature and highlights the need for tailored\ntemplate-based identification methods for the BAO in alignment statistics. We\nalso discuss the impact of projection baselines and photometric redshift\nuncertainties for identifying the BAO in intrinsic alignment measurements.\n", "  Gravitational wave (GW) standard sirens may resolve the Hubble tension,\nprovided that standard siren inference of $H_0$ is free from systematic biases.\nHowever, standard sirens from binary neutron star (BNS) mergers suffer from two\nsources of systematic bias, one arising from the anisotropy of GW emission, and\nthe other from the anisotropy of electromagnetic (EM) emission from the\nkilonova. For an observed sample of BNS mergers, the traditional Bayesian\napproach to debiasing involves the direct computation of the detection\nlikelihood. This is infeasible for large samples of detected BNS merger due to\nthe high dimensionality of the parameter space governing merger detection. In\nthis study, we bypass this computation by fitting the Hubble constant to\nforward simulations of the observed GW and EM data under a simulation-based\ninference (SBI) framework using marginal neural ratio estimation. A key\ninnovation of our method is the inclusion of BNS mergers which were only\ndetected in GW, which allows for estimation of the bias introduced by EM\nanisotropy. Our method corrects for $\\sim$90$\\%$ of the bias in the inferred\nvalue of $H_0$ when telescope follow-up observations of BNS mergers have\nextensive tiling of the merger localization region, using known telescope\nsensitivities and assuming a model of kilonova emission. Our SBI-based method\nthus enables a debiased inference of the Hubble constant of BNS mergers,\nincluding both mergers with detected EM counterparts and those without.\n", "  We present a smoothed density-corrected $V_{\\rm max}$ technique for building\na random catalog for property-dependent galaxy clustering estimation. This\napproach is essentially based on the density-corrected $V_{\\rm max}$ method of\nCole(2011), with three improvements to the original method. To validate the\nimproved method, we generate two sets of flux-limited samples from two\nindependent mock catalogs with different $k+e$ corrections. By comparing the\ntwo-point correlation functions, our results demonstrate that the random\ncatalog created by the smoothed density-corrected $V_{\\rm max}$ approach\nprovides a more accurate and precise measurement for both sets of mock samples\nthan the commonly used $V_{\\rm max}$ method and redshift shuffled method. For\nflux-limited samples and color-dependent subsamples, the accuracy for the\nprojected correlation function is well constrained within $1\\%$ on the scale\n$0.07 h^{-1}\\rm Mpc - 30 h^{-1}\\rm Mpc$. The accuracy of the redshift-space\ncorrelation function is less than $2\\%$ as well. Currently, it is the only\napproach that holds promise for achieving the goal of high-accuracy clustering\nmeasures for next-generation surveys.\n", "  Two major challenges of contemporary cosmology are the Hubble tension and the\ncosmic dipole tension. At the crossroad of these, we investigate the impact of\npeculiar velocities on estimations of the Hubble constant from time-delay\ncosmography. We quantify the bias on the inference of the Hubble constant due\nto peculiar velocities of the lens, the source and of the observer. The former\ntwo, which may cancel from one system to another, affect the determination of\nthe angular diameter distances in the time-delay formula, and reconstructed\nquantities like the angle to the source, via a lens model. On the other hand,\nthe peculiar velocity of the observer, which is a debated quantity in the\ncontext of the cosmic dipole tension, systematically affects observed angles\nthrough aberration, redshifts, angular diameter distance and reconstructed\nquantities. We compute in detail the effect of these peculiar velocities on the\ninference of the Hubble constant to linear order in the peculiar velocities for\nthe seven lenses of the H0LiCOW/TDCOSMO collaboration. The bias generated by\nthe observer's peculiar velocity alone can reach $1.15\\%$ for the lenses which\nare well aligned with it. This results in a $0.25 \\%$ bias for the seven\ncombined lenses. Assuming a typical peculiar velocity of $300$ km s$^{-1}$ for\nthe lens and the source galaxies, these add an additional random uncertainty,\nwhich can reach $1\\%$ for an individual lens, but reduces to $0.24\\%$ for the\nfull TDCOSMO sample. The picture may change if peculiar velocities turn out to\nbe larger than expected. Any time-delay cosmography program which aims for\npercent precision on the Hubble constant may need to take this source of\nsystematic bias into account. This is especially so for future ground-based\nsurveys which cover a fraction of the celestial sphere that is well aligned\nwith the observer's peculiar velocity.\n", "  Euclid will survey most of the accessible extragalactic sky with imaging and\nslitless spectroscopy observations, creating a unique spectroscopic catalog of\ngalaxies with H$\\alpha$ line in emission that will map the Universe from\n$z=0.9$ to $1.8$. With low expected statistical errors, the error budget will\nlikely be dominated by systematic errors related to uncertainties in the data\nand modelling. I will discuss the strategy that has been proposed to mitigate\nthe expected systematic effects and propagate the uncertainty of mitigation to\ncosmological parameter errobars.\n", "  The Hubble constant ($H_0$), which represents the expansion rate of the\nUniverse, is one of the most important cosmological parameters. The recent\nmeasurements of $H_0$ using the distance ladder methods such as Type Ia\nSupernovae (SNe Ia) are significantly greater than the CMB measurements by\nPlanck. The difference points to a crisis in the standard model of cosmology\ntermed as Hubble tension.\n  In this work we compare different cosmological models, determine the Hubble\nconstant and comment on the Hubble tension using the data from differential\nages of galaxies. The data we use is free from the systematic effects as the\nabsolute age estimation of the galaxies is not needed. We have used the\nBayesian approach along with the commonly used maximum likelihood method to\nestimate $H_0$ and have calculated the AIC scores to compare the different\ncosmological models.The non-flat cosmological model provides a higher value for\nmatter density as well as the Hubble constant compared to the flat $\\Lambda$CDM\nmodel. The AIC score is smaller for the flat $\\Lambda$CDM cosmology compared to\nthe non-flat model indicating the flat model a better choice. The best-fit\nvalue of $H_0$ for both these models are $68.7\\pm3.1$ km/s/Mpc and $72.2\\pm4$\nkm/s/Mpc, respectively. Our results are consistent with the CCHP measurements.\nHowever, flat model result does not agree with the SH0ES result, while the\nnon-flat result is inconsistent with the Planck value.\n", "  We describe a simulation for the distribution of galaxies focusing on the\natomic Hydrogen content. We aim to make predictions for surveys of galaxies\nusing the redshifted 21 cm line emission. We take the expected distribution of\nHI masses, circular velocities, sizes of galaxies and orientations into account\nfor this simulation. We use the sensitivity of ASKAP and MeeKAT radio\ntelescopes to estimate the number of detections of HI galaxies in upcoming\nsurveys. We validate our simulation with earlier estimates carried out by using\nsome of these considerations. We show that unlike earlier simulations that take\nsome of the factors into account, the predicted number of galaxies and their\ndistribution across masses changes significantly when all of these are\naccounted for. We describe our predictions for the MIGHTEE-HI and WALLABY\nsurveys for blind detection of galaxies using the redshifted 21 cm radiation.\nWe study the dependence of the predicted number of detections on the HI mass\nfunction. We also describe our future plans for improving the simulation.\n", "  Neutral hydrogen ($\\rm{HI}$) $21$-cm intensity mapping (IM) offers an\nefficient technique for mapping the large-scale structures in the universe. We\nintroduce the 'Cross' Tapered Gridded Estimator (Cross TGE), which\ncross-correlates two cross-polarizations (RR and LL) to estimate the\nmulti-frequency angular power spectrum (MAPS) $C_{\\ell}(\\Delta\\nu)$. We expect\nthis to mitigate several effects like noise bias, calibration errors etc.,\nwhich affect the 'Total' TGE which combines the two polarizations. Here we\napply the Cross TGE on a $24.4 \\,\\rm{MHz}$ bandwidth uGMRT Band $3$ data\ncentred at $432.8 \\,\\rm{MHz}$ aiming $\\rm{HI}$ IM at $z=2.28$. The measured\n$C_{\\ell}(\\Delta\\nu)$ is modelled to yield maximum likelihood estimates of the\nforegrounds and the spherical power spectrum $P(k)$ in several $k$ bins.\nConsidering the mean squared brightness temperature fluctuations, we report a\n$2\\sigma$ upper limit $\\Delta_{UL}^{2}(k) \\le (58.67)^{2} \\, {\\rm mK}^{2}$ at\n$k=0.804 \\, {\\rm Mpc}^{-1}$ which is a factor of $5.2$ improvement on our\nprevious estimate based on the Total TGE. Assuming that the $\\rm{HI}$ traces\nthe underlying matter distribution, we have modelled $C_{\\ell}(\\Delta\\nu)$ to\nsimultaneously estimate the foregrounds and $[\\Omega_{\\rm{HI}} b_{\\rm{HI}}] $\nwhere $\\Omega_{\\rm{HI}}$ and $b_{\\rm{HI}}$ are the $\\rm{HI}$ density and linear\nbias parameters respectively. We obtain a best fit value of\n$[\\Omega_{\\rm{HI}}b_{\\rm{HI}}]^2 = 7.51\\times 10^{-4} \\pm 1.47\\times 10^{-3}$\nwhich is consistent with noise. Although the $2\\sigma$ upper limit\n$[\\Omega_{\\rm{HI}}b_{\\rm{HI}}]_{UL} \\leq 0.061$ is $\\sim 50$ times larger than\nthe expected value, this is a considerable improvement over earlier works at\nthis redshift.\n", "  Ultralight dark matter (ULDM) is usually taken to be a single scalar field.\nHere we explore the possibility that ULDM consists of $N$ light scalar fields\nwith only gravitational interactions. This configuration is more consistent\nwith the underlying particle physics motivations for these scenarios than a\nsingle ultralight field. ULDM halos have a characteristic granular structure\nthat increases stellar velocity dispersion and can be used as observational\nconstraints on ULDM models. In multifield simulations, we find that inside a\nhalo the amplitude of the total density fluctuations decreases as $1/\\sqrt{N}$\nand that the fields do not become significantly correlated over cosmological\ntimescales. Smoother halos heat stellar orbits less efficiently, reducing the\nvelocity dispersion relative to the single field case and thus weakening the\nobservational constraints on the field mass. Analytically, we show that for $N$\nequal-mass fields with mass $m$ the ULDM contribution to the stellar velocity\ndispersion scales as $1/(N m^3)$. Lighter fields heat the most efficiently and\nif the smallest mass $m_L$ is significantly below the other field masses the\ndispersion scales as $1/(N^2 m_L^3)$.\n", "  The evolution of the luminosity function (LF) of Active Galactic Nuclei\n(AGNs) at $z \\gtrsim 5$ represents a key constraint to understand their\ncontribution to the ionizing photon budget necessary to trigger the last phase\ntransition in the Universe, i.e. the epoch of Reionization. Recent searches for\nbright high-z AGNs suggest that the space densities of this population at $z>4$\nhas to be revised upwards, and sparks new questions about their evolutionary\npaths. Gas accretion is the key physical mechanism to understand both the\ndistribution of luminous sources and the growth of central Super-Massive Black\nHoles (SMBHs). In this work, we model the high-z AGN-LF assuming that high-z\nluminous AGN shine at their Eddington limit: we derive the expected evolution\nas a function of the ``duty-cycle'' ($f_{\\rm dc}$), i.e. the fraction of\nlife-time that a given SMBH spends accreting at the Eddington rate. Our results\nshow that intermediate values ($f_{\\rm dc} \\simeq 0.1$) predict the best\nagreement with the ionizing background and photoionization rate, but do not\nprovide enough ionizing photons to account for the observed evolution of the\nhydrogen neutral fraction. Smaller values ($f_{\\rm\n  dc} \\lesssim 0.05$) are required for AGNs to be the dominant population\nresponsible for Hydrogen reionization in the Early Universe. We then show that\nthis low-$f_{\\rm dc}$ evolution can be reconciled with the current constraints\non Helium reionization, although it implies a relatively large number of\ninactive SMBHs at $z\\gtrsim5$, in tension with SMBH growth models based on\nheavy seeding.\n", "  We study the statistical properties of the eigenvalues of the primordial\ntidal and deformation tensor for random Gaussian cosmic density fields. With\nthe tidal and deformation tensors, Hessians of the gravitational and velocity\npotential, being Gaussian, the corresponding eigenvalue fields are distinctly\nnon-Gaussian. Following the extension of the Doroshkevich formula for the\njoined distribution of eigenvalues to two-dimensional fields, we evaluate the\ntwo- and three-point correlation functions of the eigenvalue fields. In\naddition, we assess the number densities of singular points of the eigenvalue\nfields and find their corresponding two- and three-point correlation functions.\n  The role of tidal forces and the resulting mass element deformation in\nshaping the prominent anisotropic wall-like and filamentary components of the\ncosmic web has since long been recognized based on the Zel'dovich\napproximation. Less well-known is that the weblike spatial pattern is already\nrecognizable in the primordial tidal and deformation eigenvalue field, even\nwhile the corresponding Gaussian density and the potential field appear merely\nas a spatially incoherent and unstructured random field. Furthermore, against\nthe background of a full phase-space assessment of structure formation in the\nUniverse, the caustic skeleton theory entails a fully analytical framework for\nthe nonlinear evolution of the cosmic web. It describes the folding of the dark\nmatter sheet and the emerging caustic singularities, fully specified by the\ndeformation eigenvalues and eigenvectors. Finally, tidal tensor eigenvalues are\nof central importance, and understanding their distribution is critical in\npredicting the resulting rotation and orientation.\n  The current study applies to two-dimensional Gaussian random fields and will\nbe generalized to a three-dimensional analysis in an upcoming study.\n", "  We investigate spherical domain walls~(DWs) nucleated via quantum tunneling\nin multifield inflationary models and curvature perturbations induced by the\ninhomogeneous distribution of those DWs. We consider the case that the\nEuclidean action $S_{E}$ of DWs changes with time during inflation so that most\nof DWs nucleate when $S_{E}$ reaches the minimum value and the radii of DWs are\nalmost the same. When the Hubble horizon scale exceeds the DW radius after\ninflation, DWs begin to annihilate and release their energy into background\nradiation. Because of the random nature of the nucleation process, the\nstatistics of DWs is of the Poisson type and the power spectrum of curvature\nperturbations has a characteristic slope ${\\cal P}_{\\cal R}(k)\\propto k^{3}$.\nThe amplitude of ${\\cal P}_{\\cal R}(k)$ depends on the tension and abundance of\nDWs at the annihilation time while the peak mode depends on the mean separation\nof DWs. We also numerically obtain the energy spectra of scalar-induced\ngravitational waves from predicted curvature perturbations which are expected\nto be observed in multiband gravitational-wave detectors.\n", "  The next generation of galaxy surveys will provide highly accurate\nmeasurements of the large-scale structure of the Universe, allowing for more\nstringent tests of gravity on cosmological scales. Higher order statistics are\na valuable tool to study the non-Gaussianities in the matter field and to break\ndegeneracies between modified gravity and other physical or nuisance\nparameters. However, understanding from first principles the behaviour of these\ncorrelations is essential to characterise deviations from General Relativity\n(GR), and the purpose of this work. This work uses contemporary ideas of\nStandard Perturbation Theory on biased tracers to characterize the three point\ncorrelation function (3PCF) at tree level for Modified Gravity models with a\nscale-dependent gravitational strength, and applies the theory to two specific\nmodels ($f(R)$ and DGP) that are representative for Chameleon and Vainshtein\nscreening mechanisms. Additionally, we use a multipole decomposition, which\napart from speeding up the algorithm to extract the signal from data, also\nhelps to visualize and characterize GR deviations.\n", "  One of the frontiers for advancing what is known about dark matter lies in\nusing strong gravitational lenses to characterize the population of the\nsmallest dark matter halos. There is a large volume of information in strong\ngravitational lens images -- the question we seek to answer is to what extent\nwe can refine this information. To this end, we forecast the detectability of a\nmixed warm and cold dark matter scenario using the anomalous flux ratio method\nfrom strong gravitational lensed images. The halo mass function of the mixed\ndark matter scenario is suppressed relative to cold dark matter but still\npredicts numerous low-mass dark matter halos relative to warm dark matter.\nSince the strong lens signal is a convolution over a range of dark matter halo\nmasses and since the signal is sensitive to the specific configuration of dark\nmatter halos, not just the halo mass function, degeneracies between different\nforms of suppression in the halo mass function, relative to cold dark matter,\ncan arise. We find that, with a set of lenses with different configurations of\nthe main deflector and hence different sensitivities to different mass ranges\nof the halo mass function, the different forms of suppression of the halo mass\nfunction between the warm dark matter model and the mixed dark matter model can\nbe distinguished with $40$ lenses with Bayesian odds of 29.4:1.\n", "  We study the generation of helical magnetic fields during inflation by\nconsidering a model which does not suffer from strong coupling or large\nback-reaction. Electromagnetic conformal invariance is broken only during\ninflation by coupling the gauge-invariants $F_{\\mu\\nu}F^{\\mu\\nu}$ and\n$F_{\\mu\\nu}{\\tilde{F}}^{\\mu\\nu}$ to a time-dependent function $I$ with a sharp\ntransition during inflation. The magnetic power spectrum is scale-invariant up\nto the transition and very blue-shifted after that. The subsequent evolution of\nthe helical magnetic field is subjected to magneto-hydrodynamical processes,\nresulting in far larger coherence lengths than those occurring after adiabatic\ndecay. Scale-invariant quadratic gravity is a suitable framework to test the\nmodel, providing a natural physical interpretation. We show that fully helical\nmagnetic fields are generated with values in agreement with the lower bounds on\nfields in the Intergalactic Medium derived from blazar observations. This model\nholds even at large/intermediate energy scales of inflation, contrary to what\nhas been found in previous works.\n", "  The current observational status of the hot (log T(K) > 5.5) warm-hot\nintergalactic medium (WHIM) remains incomplete. While recent observations from\nstacking large numbers of Cosmic Web filaments have yielded statistically\nsignificant detections, direct measurements of single objects remain scarce.\nThe lack of such a sample currently prevents a robust analysis of the cosmic\nbaryon content composed of the hot WHIM, which could help solve the\ncosmological missing baryons problem. To improve the search for the missing\nbaryons, we used the EAGLE simulation. Our aim is to understand the metal\nenrichment and distribution of highly ionised metals in the Cosmic Web. We\ndetected the filaments by applying the Bisous formalism to the simulated\ngalaxies, and characterised the spatial distributions as well as mass and\nvolume fractions of the filamentary oxygen and OVII. We then constructed OVII\ncolumn density maps and determined their detectability with Athena X-IFU.\nHowever, the oxygen and OVII number densities drop fast beyond the virial radii\nof haloes, falling below detectable levels at 700 kpc. Thus, only ~1% of the\nfilament volumes are filled with OVII at detectable densities. This\nnon-homogeneous distribution of the OVII complicates its usage for tracing the\nmissing baryons. Instead, OVII forms narrow envelopes around haloes. This\nlocalised nature results in a low chance (10-20% per sight line) of detecting\nintergalactic OVII with Athena X-IFU within the SDSS catalogue of filaments.\nWith future filament samples from the 4MOST survey, the chances increase up to\na level of ~50%. Nonetheless, based on EAGLE results, this would not be enough\nto conclusively solve the missing baryon problem, as it would be limited to a\nfew times the virial radii of haloes. Fortunately, the volumes around haloes\nare dense in hot WHIM, and tracing it could reduce the content of baryons still\nmissing by ~25%.\n", "  Diffuse cluster-scale synchrotron radio emission is discovered in an\nincreasing number of galaxy clusters in the form of radio halos (RHs), probing\nthe presence of relativistic electrons and magnetic fields in the intra-cluster\nmedium. The favoured scenario to explain their origin is that they trace\nturbulent regions generated during cluster mergers where particles are\nre-accelerated. In this framework, RHs are expected to probe cluster dynamics\nand are predicted to be more frequent in massive systems. Statistical studies\nare important to study the connection of RHs with cluster dynamics and to\nconstrain theoretical models. Furthermore, low-frequency surveys can shed light\non the existence of RHs with very steep radio-spectra, a key prediction of\nturbulent models. We study the properties of RHs from clusters of the second\ncatalog of Planck Sunyaev Zel'dovich detected sources that lie within the 5634\ndeg^2 covered by the second Data Release (DR2) of the LOFAR Two-meter Sky\nSurvey. We find that the number of observed RHs, their radio flux density and\nredshift distributions are in line with what is expected in the framework of\nthe re-acceleration scenario. In addition, the fraction of clusters with RHs\nincreases with the cluster mass, confirming the leading role of the\ngravitational process of cluster formation in the generation of RHs. These\nmodels predict a large fraction of RHs with very steep spectrum in the DR2\nPlanck sample, this will be tested in future studies, yet a comparison of the\noccurrence of halos in GMRT and LOFAR samples indeed shows a larger occurrence\nof RHs at lower frequencies suggesting the presence of a number of very steep\nspectrum RH that is preferentially detected by LOFAR. Using morphological\ninformation we confirm that RHs are preferentially located in merging systems\nand that the fraction of newly LOFAR discovered RHs is larger in less disturbed\nsystems.\n", "  An intervening galaxy acts as a gravitational lens and produces multiple\nimages of a single source such as a remote galaxy. Galaxies have peculiar\nspeeds in addition to the bulk motion arising due to the expansion of the\nuniverse. There is a difference in light arrival times between lensed images.\nWe calculate more realistic time delays between lensed images when galaxy\npeculiar motions, that is the motion of the Lens, the Source and the Observer\nare taken into consideration neglecting the gravitomagnetic effects.\n", "  We present a novel simulation-based cosmological analysis of galaxy-galaxy\nlensing and galaxy redshift-space clustering. Compared to analysis methods\nbased on perturbation theory, our simulation-based approach allows us to probe\na much wider range of scales, $0.4 \\, h^{-1} \\, \\mathrm{Mpc}$ to $63 \\, h^{-1}\n\\, \\mathrm{Mpc}$, including highly non-linear scales, and marginalises over\nastrophysical effects such as assembly bias. We apply this framework to data\nfrom the Baryon Oscillation Spectroscopic Survey LOWZ sample cross-correlated\nwith state-of-the-art gravitational lensing catalogues from the Kilo Degree\nSurvey and the Dark Energy Survey. We show that gravitational lensing and\nredshift-space clustering when analysed over a large range of scales place\ntight constraints on the growth-of-structure parameter $S_8 = \\sigma_8\n\\sqrt{\\Omega_{\\rm m} / 0.3}$. Overall, we infer $S_8 = 0.792 \\pm 0.022$ when\nanalysing the combination of galaxy-galaxy lensing and projected galaxy\nclustering and $S_8 = 0.771 \\pm 0.027$ for galaxy redshift-space clustering.\nThese findings highlight the potential constraining power of full-scale studies\nover studies analysing only large scales, and also showcase the benefits of\nanalysing multiple large-scale structure surveys jointly. Our inferred values\nfor $S_8$ fall below the value inferred from the CMB, $S_8 = 0.834 \\pm 0.016$.\nWhile this difference is not statistically significant by itself, our results\nmirror other findings in the literature whereby low-redshift large scale\nstructure probes infer lower values for $S_8$ than the CMB, the so-called\n$S_8$-tension.\n", "  Structure formation in the Universe has been well-studied within the Eulerian\nand Lagrangian perturbation theories, where the latter performs substantially\nbetter in comparison with N-body simulations. Standing out is the celebrated\nZel'dovich approximation for dust matter. In this work, we recall the\ndescription of gravitational noncollisional systems and extend both the\nEulerian and Lagrangian approaches by including, possibly anisotropic, velocity\ndispersion. A simple case with plane symmetry is then studied with an exact,\nnonperturbative approach, and various approximations of the derived model are\nthen compared numerically. A striking result is that linearized Lagrangian\nsolutions outperform models based on Burgers' equation in the multistream\nregime in comparison with the exact solution. These results are finally\nextended to a 3D case without symmetries, and master equations for the\nevolution of all parts of the perturbations are derived. The particular 3D case\nstudied corresponds to a maximally anisotropic collapse, which involves an\napproximation based on the estimation of importance of the different levels of\nspatial derivatives of the local deformation field.\n", "  We use the state-of-the-art data on cosmic chronometers (CCH) and the\nPantheon+ compilation of supernovae of Type Ia (SNIa) to test the constancy of\nthe SNIa absolute magnitude, $M$, and the robustness of the cosmological\nprinciple (CP) at $z\\lesssim 2$ with a model-agnostic approach. We do so by\nreconstructing $M(z)$ and the curvature parameter $\\Omega_{k}(z)$ using\nGaussian Processes. Moreover, we use CCH in combination with data on baryon\nacoustic oscillations (BAO) from various galaxy surveys (6dFGS, BOSS, eBOSS,\nWiggleZ, DES Y3) to measure the sound horizon at the baryon-drag epoch, $r_d$,\nfrom each BAO data point and check their consistency. Given the precision\nallowed by the CCH, we find that $M(z)$, $\\Omega_k(z)$ and $r_d(z)$ are fully\ncompatible (at $<68\\%$ C.L.) with constant values. This justifies our final\nanalyses, in which we put constraints on these constant parameters under the\nvalidity of the CP, the metric description of gravity and standard physics in\nthe vicinity of the stellar objects, but otherwise in a model-independent way.\nIf we exclude the SNIa contained in the host galaxies employed by SH0ES, our\nresults read $M=(-19.314^{+0.086}_{-0.108})$ mag, $r_d=(142.3\\pm 5.3)$ Mpc and\n$\\Omega_k=-0.07^{+0.12}_{-0.15}$, with $H_0=(71.5\\pm 3.1)$ km/s/Mpc ($68\\%$\nC.L.). These values are independent from the main data sets involved in the\n$H_0$ tension, namely, the cosmic microwave background and the first two rungs\nof the cosmic distance ladder. If, instead, we also consider the SNIa in the\nhost galaxies, calibrated with Cepheids, we measure\n$M=(-19.252^{+0.024}_{-0.036})$ mag, $r_d=(141.9^{+5.6}_{-4.9})$ Mpc,\n$\\Omega_k=-0.10^{+0.12}_{-0.15}$ and $H_0=(74.0^{+0.9}_{-1.0})$ km/s/Mpc.\n", "  The Hubble constant $H_0$ is the value of the cosmic expansion rate at one\ntime (the present), and cannot be adjusted successfully without taking into\naccount the entire expansion history and cosmology. We outline some conditions,\nthat if not quite ``no go'' are ``no thanks'', showing that changing the\nexpansion history, e.g. employing dynamical dark energy, cannot reconcile\ndisparate deductions of $H_0$ without upsetting some other cosmological\nmeasurement.\n", "  On large cosmological scales, anisotropic gravitational collapse is manifest\nin the dark cosmic web. Its statistical properties are little known for\nalternative dark matter models such as fuzzy dark matter (FDM). In this work,\nwe assess for the first time the relative importance of cosmic nodes,\nfilaments, walls and voids in a cosmology with primordial small-scale\nsuppression of power. We post-process $N$-body simulations of FDM-like\ncosmologies with varying axion mass $m$ at redshifts $z\\sim 1.0-5.6$ using the\nNEXUS+ Multiscale Morphology Filter technique at smoothing scale $\\Delta x =\n0.04 \\ h^{-1}$Mpc. The formation of wall and void halos is more suppressed than\nnaively expected from the half-mode mass $M_{1/2}$. Also, we quantify the mass\nand volume filling fraction of cosmic environments and find that 2D cosmic\nsheets host a larger share of the matter content of the Universe as $m$ is\nreduced, with an $\\sim 8-12$\\% increase for the $m=7 \\times 10^{-22}$ eV model\ncompared to CDM. We show that in FDM-like cosmologies, filaments, walls and\nvoids are cleaner and more pronounced structures than in CDM, revealed by a\nstrong mid-range peak in the conditioned overdensity PDFs $P(\\delta)$. At high\nredshift, low-density regions are more suppressed than high-density regions.\nFurthermore, skewness estimates $S_3$ of the total overdensity PDF in FDM-like\ncosmologies are consistently higher than in CDM, especially at high redshift\n$z\\sim 5.6$ where the $m=10^{-22}$ eV model differs from CDM by $\\sim 6\n\\sigma$. Accordingly, we advocate for the usage of $P(\\delta)$ as a testbed for\nconstraining FDM and other alternative dark matter models.\n", "  It is possible to explain the discrepancy (tension) between the local\nmeasurement of the cosmological parameter $H_0$ (the Hubble constant) and its\nvalue derived from the Planck-mission measurements of the Cosmic Microwave\nBackground (CMB) by considering contamination of the CMB by emission from some\nmedium surrounding distant extragalactic sources (a distant foreground), such\nas extremely cold coarse-grain (grey) dust. As any other foreground, it would\nalter the CMB power spectrum and contribute to the dispersion of CMB\ntemperature fluctuations. By generating random samples of CMB with different\ndispersions, we have checked that the increased dispersion leads to a smaller\nestimated value of $H_0$, the rest of the cosmological model parameters\nremaining fixed. This might explain the reduced value of the {\\it\nPlanck}-derived parameter $H_0$ with respect to the local measurements. The\ncold grey dust for some time has been suspected to populate intergalactic space\nand it is known to be almost undetectable, except for the effect of dimming\nremote extragalactic sources.\n", "  Large scale primordial magnetic fields (PMFs) threading the intergalactic\nmedium are observed ubiquitously in the Universe playing a key role in the\ncosmic evolution. Their origin is still debated constituting a very active\nfield of research. In the present article, we propose a novel natural ab initio\nmechanism for the origin of such PMFs through the portal of supermassive\nprimordial black holes (PBHs) forming between the Big Bang Nucleosynthesis and\nthe recombination era. In particular, by considering PBHs furnished with a\nlocally isothermal disk we study the generation of a Biermann battery induced\nseed magnetic field (MF) due to the vortexlike motion of the primordial plasma\naround the black hole. Finally, by considering monochromatic PBH mass\ndistributions and deriving the relevant MF power spectrum we make a\nconservative estimate for the seed PMF in intergalactic scales and at redshift\n$z=30$, when typical galaxies are considered to form, which reads as $B\\simeq\n10^{-30}\\mathrm{G}\\left(\\frac{\\ell_\\mathrm{R}}{10^6}\\right)^2\\left(\\frac{M_\\mathrm{PBH}}{10^{14}M_\\odot}\\right)^{5/2}$,\nwhere $M_\\mathrm{PBH}$ is the PBH mass and $\\ell_\\mathrm{R}\\equiv\nR_\\mathrm{d}/R_\\mathrm{ISCO}$, is the ratio of the radius of the disk,\n$R_\\mathrm{d}$ over the radius of the innermost stable circular orbit,\n$R_\\mathrm{ISCO}$. Interestingly enough, by requiring to seed a PMF of the\norder of $10^{-30}\\mathrm{G}$ necessary to give rise to a present day\n$10^{-18}\\mathrm{G}$ in intergalactic scales, we find a lower bound on the PBH\nmass within the range $[10^{10}- 10^{16}]M_\\odot$ depending on the radius of\nthe PBH disk.\n", "  Cross-correlations of CMB lensing reconstructions with other tracers of\nmatter constrain primordial non-Gaussianity, neutrino masses and structure\ngrowth as a function of cosmic time. We formalize a method to improve the\nprecision of these measurements by using a third tracer to remove structure\nfrom the lensing reconstructions. Crucially, our method enjoys the variance\nreduction benefits of a joint-modelling approach without the need to model the\ncosmological dependence of the ancillary tracer. We present a first\ndemonstration of variance cancellation using data from Planck and the DESI\nLegacy Surveys, showing a 10-20% reduction in both lensing power and\ncross-correlation variance using the Cosmic Infrared Background (CIB) or DESI\nLegacy Survey Luminous Red Galaxies (LRGs) as matter tracers.\n", "  We investigate cosmological structure formation in Fuzzy Dark Matter (FDM)\nwith an attractive self-interaction (SI) with numerical simulations. Such a SI\nwould arise if the FDM boson were an ultra-light axion, which has a strong CP\nsymmetry-breaking scale (decay constant). Although weak, the attractive SI may\nbe strong enough to counteract the quantum 'pressure' and alter structure\nformation. We find in our simulations that the SI can enhance small-scale\nstructure formation, and soliton cores above a critical mass undergo a phase\ntransition, transforming from dilute to dense solitons.\n", "  We present a novel method for reconstructing weak lensing mass or convergence\nmaps as a probe to study non-Gaussianities in the cosmic density field. While\nprevious surveys have relied on a flat-sky approximation, the forthcoming stage\nIV survey will cover such large areas with a large field of view (FOV) to\nmotivate mass reconstruction on the sphere. Here, we present an improved\nKaiser-Squires (KS+) mass inversion method using a HEALPix pixelisation of the\nsphere while controlling systematic effects. As in the KS+ methodology, the\nconvergence maps were reconstructed without noise regularisation to preserve\nthe Information content and allow for non-Gaussain studies. The results of this\nnew method were compared with those of the Kaiser-Squires (KS) estimator\nimplemented on the curved sky using high-resolution realistic N-body\nsimulations. The quality of the method was evaluated by estimating the\ntwo-point correlation functions, third- and fourth-order moments, and peak\ncounts of the reconstructed convergence maps. The effects of masking, sampling,\nand noise were tested. We also examined the systematic errors introduced by the\nflat-sky approximation. We show that the improved Kaiser-Squires on the sphere\n(SKS+) method systematically improves inferred correlation errors by 10 times\nand provide on average a 20-30 % better maximum signal-to-noise peak estimation\ncompared to Kaiser-Squires on the sphere (SKS). We also show that the SKS+\nmethod is nearly unbiased and reduces errors by a factor of about 2 and 4 in\nthe third and fourth-order moments, respectively. Finally, we show how the\nreconstruction of the convergence field directly on the celestial sphere\neliminates the projection effects and allows the exclusion or consideration of\na specific region of the sphere in the processing.\n", "  The Hubble constant ($H_0$) tension is one of the major open problems in\nmodern cosmology. This tension is the discrepancy, ranging from 4 to 6\n$\\sigma$, between the $H_0$ value estimated locally with the combination of\nSupernovae Ia (SNe Ia) + Cepheids and the cosmological $H_0$ obtained through\nthe study of the Cosmic Microwave Background (CMB) radiation. The approaches\nadopted in Dainotti et al. 2021 (ApJ) and Dainotti et al. 2022 (Galaxies) are\nintroduced. Through a binning division of the Pantheon sample of SNe Ia\n(Scolnic et al. 2018), the value of $H_0$ has been estimated in each of the\nredshift-ordered bins and fitted with a function lowering with the redshift.\nThe results show a decreasing trend of $H_0$ with redshift. If this is not due\nto astrophysical biases or residual redshift evolution of the SNe Ia\nparameters, it can be explained in light of modified gravity theories, e.g.,\nthe $f(R)$ scenarios. We also briefly describe the possible impact of high-$z$\nprobes on the Hubble constant tension, such as Gamma-ray bursts (GRBs) and\nQuasars (QSOs), reported in Dainotti et al. 2022 (Galaxies) and Lenart et al.\n2022 (ApJ), respectively.\n", "  We present a new method to simultaneously/self-consistently model the mass\ndistribution of galaxy clusters that combines constraints from strong lensing\nfeatures, X-ray emission and galaxy kinematics measurements. We are able to\nsuccessfully decompose clusters into their collisionless and collisional mass\ncomponents thanks to the X-ray surface brightness, as well as using the\ndynamics of cluster members to obtain more accurate masses with the fundamental\nplane of elliptical galaxies. Knowledge from all observables is included\nthrough a consistent Bayesian approach in the likelihood or in physically\nmotivated priors. We apply this method to the galaxy cluster Abell S1063 and\nproduce a mass model that we publicly release with this paper. The resulting\nmass distribution presents a different ellipticities for the intra-cluster gas\nand the other large-scale mass components; and deviation from elliptical\nsymmetry in the main halo. We assess the ability of our method to recover the\nmasses of the different elements of the cluster using a mock cluster based on a\nsimplified version of our Abell S1063 model. Thanks to the wealth of\ninformation provided by the mass model and the X-ray emission, we also found\nevidence for an on-going merger event with gas sloshing from a smaller\ninfalling structure into the main cluster. In agreement with previous findings,\nthe total mass, gas profile and gas mass fraction are consistent with small\ndeviations from the hydrostatic equilibrium. This new mass model for Abell\nS1063 is publicly available as is the software used to construct it through the\n\\textsc{Lenstool} package.\n", "  The Hubble tension, revealed by a $\\sim 5\\sigma$ discrepancy between\nmeasurements of the Hubble-Lemaitre constant from early- and local-Universe\nobservations, is one of the most significant problems in modern cosmology. In\norder to better understand the origin of this mismatch, independent techniques\nto measure $H_0$, such as strong lensing time delays, are required. Notably,\nthe sample size of such systems is key to minimising statistical uncertainties\nand cosmic variance, which can be improved by exploring the datasets of\nlarge-scale sky surveys like DESI (Dark Energy Spectroscopic Instrument). We\nidentify possible strong lensing time-delay systems within DESI by selecting\ncandidate multiply imaged lensed quasars from a catalogue of 24,440,816\ncandidate QSOs contained in the 9th data release of the DESI Legacy Imaging\nSurveys (DESI-LS). Using a friend-of-friends-like algorithm on spatial\nco-ordinates, our method generates an initial list of compact quasar groups.\nThis list is subsequently filtered using a measure of the similarity of colours\nof a group's members and the likelihood that they are quasars. A visual\ninspection finally selects candidate strong lensing systems based on the\nspatial configuration of the group members. We identify 620 new candidate\nmultiply imaged lensed quasars (101 Grade-A, 214 Grade-B, 305 Grade-C). This\nnumber excludes 53 known spectroscopically confirmed systems and existing\ncandidate systems identified in other similar catalogues. When available, these\nnew candidates will be further checked by combining the spectroscopic and\nphotometric data from DESI. The catalogues and images of the candidates in this\nwork are available online\n(https://github.com/EigenHermit/lensed_qso_cand_catalogue_He-22/).\n", "  Tension between cosmic microwave background-based and distance ladder-based\ndeterminations of the Hubble constant ${\\rm H}_{\\rm 0}$ motivates pursuit of\nindependent methods that are not subject to the same systematic effects. A\npromising alternative, proposed by Refsdal in 1964, relies on the inverse\nscaling of ${\\rm H}_{\\rm 0}$ with the delay between the arrival times of at\nleast two images of a strongly-lensed variable source such as a quasar. To\ndate, Refsdal's method has mostly been applied to quasars lensed by individual\ngalaxies rather than by galaxy clusters. Using the three quasars strongly\nlensed by galaxy clusters (SDSS J1004+4112, SDSS J1029+2623, and SDSS\nJ2222+2745) that have both multiband Hubble Space Telescope data and published\ntime delay measurements, we derive ${\\rm H}_{\\rm 0}$, accounting for the\nsystematic and statistical sources of uncertainty. While a single time delay\nmeasurement does not yield a well-constrained ${\\rm H}_{\\rm 0}$ value,\nanalyzing the systems together tightens the constraint. Combining the six time\ndelays measured in the three cluster-lensed quasars gives ${\\rm H}_{\\rm 0}$ =\n74.1 $\\pm$ 8.0 km s$^{-1}$ Mpc$^{-1}$. To reach 1$\\%$ uncertainty in ${\\rm\nH}_{\\rm 0}$, we estimate that a sample size of order of 620 time delay\nmeasurements of similar quality as those from SDSS J1004+4112, SDSS J1029+2623,\nand SDSS J2222+2745 would be needed. Improving the lens modeling uncertainties\nby a factor of two and a half may reduce the needed sample size to 100 time\ndelays, potentially reachable in the next decade.\n", "  We characterize the peculiar velocity field of the local large-scale\nstructure reconstructed from the $2M++$ survey, by treating it as a fluid,\nextracting the divergence via different approximations over a range pf averaged\nscales. This reconstructed field is important for cosmology, since it was used\nto correct the peculiar redshifts of the last SNIA compilation Pantheon+. The\nresults have intriguing implications for the LLSS fluid dynamics and\nparticularly for the ``Tilted Cosmology'' model, although those results have to\nbe taken carefully as the velocity field could contain significant bias due to\nthe reconstruction procedure. Those possible bias and its influence in our\nresults are discussed. Representative values of the apparent deceleration\nparameter ($\\Tilde{q}$) are computed, in order to compare our results with the\ntheoretical predictions of the tilted-universe scenario. We conclude that\nbetter velocity field reconstructions are necessary in order to constrain the\nparameters implied in LLSS research and alternative cosmologies.\n", "  Observational searches for large-scale vorticity modes in the late time\nUniverse are underexplored. Within the standard $\\Lambda$CDM model, this is\nwell motivated given the observed properties of the cosmic microwave background\n(CMB). However, this means that searches for cosmic vorticity modes can serve\nas a powerful consistency test of our cosmological model. We show that through\ncombining CMB measurements of the kinetic Sunyaev-Zel'dovich and the moving\nlens effects with galaxy survey data we can constrain vorticity fields\nindependently from the large scale cosmic velocity field. This approach can\nprovide stringent constraints on the largest scale modes and can be achieved by\na simple change in the standard estimators. Alternatively if one assumes there\nare no cosmic vorticity modes, this estimator can be used to test for\nsystematic biases in existing analyses of kinetic Sunyaev-Zel'dovich effect in\na manner analogous to curl-lensing.\n", "  We present the merging of the Particle-Mesh (PM) relativistic Gevolution code\nwith the TreePM Gadget-4 code, with the aim of studying general relativity\neffects in cosmology. Our code, called GrGadget, is able to track the evolution\nof metric perturbations in the weak field limit by using Gevolution's\nimplementation of a relativistic PM in the Poisson gauge. To achieve this,\nstarting from Gevolution we have written a C++ library called libgevolution,\nthat allows a code to access and use the same abstractions and resources that\nGevolution uses for its PM-only N-body simulations. The code works under the\nassumption that particle interactions at short distances can be approximated as\nNewtonian, so that we can combine the forces computed with a Newtonian Tree\nwith those computed with a relativistic PM. The result is a TreePM simulation\ncode that represents metric perturbations at the scales where they are\nrelevant, while resolving non-linear structures. We validate our code by\nclosely matching Gadget-4 forces, computed with the Tree switched off, with\nthose computed with libgevolution in the Newtonian limit. With GrGadget we\nobtain a matter power spectrum that is compatible with Newtonian Gadget at\nsmall scales and contains GR features at large scales that are consistent with\nresults obtained with Gevolution. We demonstrate that, due to the better\nresolution of the highly non-linear regime, the representation of the\nrelativistic fields sampled on the mesh improves with respect to the PM-only\nsimulations.\n", "  While the sample of optical Type Ia Supernova (SN Ia) light curves (LCs)\nusable for cosmological parameter measurements surpasses 2000, the sample of\npublished, cosmologically viable near-infrared (NIR) SN Ia LCs, which have been\nshown to be good \"standard candles,\" is still $\\lesssim$ 200. Here, we present\nhigh-quality NIR LCs for 83 SNe Ia ranging from $0.002 < z < 0.09$ as a part of\nthe Dark Energy, H$_0$, and peculiar Velocities using Infrared Light from\nSupernovae (DEHVILS) survey. Observations are taken using UKIRT's WFCAM, where\nthe median depth of the images is 20.7, 20.1, and 19.3 mag (Vega) for $Y$, $J$,\nand $H$-bands, respectively. The median number of epochs per SN Ia is 18 for\nall three bands ($YJH$) combined and 6 for each band individually. We fit 47 SN\nIa LCs that pass strict quality cuts using three LC models, SALT3, SNooPy, and\nBayeSN and find scatter on the Hubble diagram to be comparable to or better\nthan scatter from optical-only fits in the literature. Fitting NIR-only LCs, we\nobtain standard deviations ranging from 0.128-0.135 mag. Additionally, we\npresent a refined calibration method for transforming 2MASS magnitudes to WFCAM\nmagnitudes using HST CALSPEC stars that results in a 0.03 mag shift in the\nWFCAM $Y$-band magnitudes.\n", "  As the statistical power of imaging surveys grows, it is crucial to account\nfor all systematic uncertainties. This is normally done by constructing a model\nof these uncertainties and then marginalizing over the additional model\nparameters. The resulting high dimensionality of the total parameter spaces\nmakes inferring the cosmological parameters significantly more costly using\ntraditional Monte-Carlo sampling methods. A particularly relevant example is\nthe redshift distribution, $p(z)$, of the source samples, which may require\ntens of parameters to describe fully. However, relatively tight priors can be\nusually placed on these parameters through calibration of the associated\nsystematics. In this paper we show, quantitatively, that a linearisation of the\ntheoretical prediction with respect to these calibratable systematic parameters\nallows us to analytically marginalise over these extra parameters, leading to a\nfactor $\\sim30$ reduction in the time needed for parameter inference, while\naccurately recovering the same posterior distributions for the cosmological\nparameters that would be obtained through a full numerical marginalisation over\n160 $p(z)$ parameters. We demonstrate that this is feasible not only with\ncurrent data and current achievable calibration priors but also for future\nStage-IV datasets.\n", "  Reliable analytical modeling of the non-linear power spectrum (PS) of matter\nperturbations is among the chief pre-requisites for cosmological analyses from\nthe largest sky surveys. This is especially true for the models that extend the\nstandard general-relativity paradigm by adding the fifth force, where numerical\nsimulations can be prohibitively expensive. Here we present a method for\nbuilding accurate PS models for two modified gravity (MG) variants: namely the\nHu-Sawicki $f(R)$, and the normal branch of the Dvali-Gabadadze-Porrati (nDGP)\nbraneworld. We start by modifying the standard halo model (HM) with respect to\nthe baseline Lambda-Cold-Dark-Matter ($\\Lambda$CDM) scenario, by using the HM\ncomponents with specific MG extensions. We find that our $P(k)_{\\text{HM}}$\nretains 5% accuracy only up to mildly non-linear scales ($k \\lesssim 0.3$\n$h/\\,\\mbox{Mpc}$) when compared to PS from numerical simulations. At the same\ntime, our HM prescription much more accurately captures the ratio $\\Upsilon(k)\n= P(k)_{\\text{MG}}/P(k)_{\\Lambda \\text{CDM}}$ up to non-linear scales. We show\nthat using HM-derived $\\Upsilon(k)$ together with a viable non-linear\n$\\Lambda$CDM $P(k)$ prescription (such as HALOFIT), we render a much better and\nmore accurate PS predictions in MG. The new approach yields considerably\nimproved performance, with modeled $P(k)_{\\text{MG}}$ being now accurate to\nwithin 5% all the way to non-linear scales of $k \\lesssim 2.5-3$\n$h/\\,\\mbox{Mpc}$. The magnitude of deviations from GR as fostered by these MG\nmodels is typically $\\mathcal{O}(10\\%)$ in these regimes. Therefore reaching 5%\nPS modeling is enough for forecasting constraints on modern-era cosmological\nobservables.\n", "  We theoretically investigate the recovery of global spectrum (monopole) from\nvisibilities (cross-correlation only) measured by the interferometer array and\nthe feasibility of extracting 21 cm signal of cosmic dawn. In our approach, the\nglobal spectrum is obtained by solving the monopole and higher-order components\nsimultaneously from the visibilities measured with up to thousands of\nbaselines. Using this algorithm, the monopole of both foreground and the 21 cm\nsignal can be correctly recovered in a broad range of conditions. We find that\na 3D baseline distribution can have much better performance than a 2D (planar)\nbaseline distribution, particularly when there is a lack of shorter baselines.\nWe simulate for ground-based 2D and 3D array configurations, and a cross-shaped\nspace array located at the Sun-Earth L2 point that can form 3D baselines\nthrough orbital precession. In all simulations we obtain good recovered global\nspectrum, and successfully extract the 21 cm signal from it, with reasonable\nnumber of antennas and observation time.\n", "  Recent cosmic shear studies have shown that higher-order statistics (HOS)\ndeveloped by independent teams now outperform standard two-point estimators in\nterms of statistical precision thanks to their sensitivity to the non-Gaussian\nfeatures of large-scale structure. The aim of the Higher-Order Weak Lensing\nStatistics (HOWLS) project is to assess, compare, and combine the constraining\npower of ten different HOS on a common set of $Euclid$-like mocks, derived from\nN-body simulations. In this first paper of the HOWLS series, we computed the\nnontomographic ($\\Omega_{\\rm m}$, $\\sigma_8$) Fisher information for the\none-point probability distribution function, peak counts, Minkowski\nfunctionals, Betti numbers, persistent homology Betti numbers and heatmap, and\nscattering transform coefficients, and we compare them to the shear and\nconvergence two-point correlation functions in the absence of any systematic\nbias. We also include forecasts for three implementations of higher-order\nmoments, but these cannot be robustly interpreted as the Gaussian likelihood\nassumption breaks down for these statistics. Taken individually, we find that\neach HOS outperforms the two-point statistics by a factor of around two in the\nprecision of the forecasts with some variations across statistics and\ncosmological parameters. When combining all the HOS, this increases to a $4.5$\ntimes improvement, highlighting the immense potential of HOS for cosmic shear\ncosmological analyses with $Euclid$. The data used in this analysis are\npublicly released with the paper.\n", "  The measurement of the $21$ cm signal from the Cosmic Dawn is a major goal\nfor several existing and upcoming radio interferometers such as NenuFAR and the\nSKA. During this era before the beginning of the Epoch of Reionization, the\nsignal is more difficult to observe due to brighter foregrounds but reveals\nadditional information on the underlying astrophysical processes encoded in the\nspatial fluctuations of the spin temperature of hydrogen. To interpret future\nmeasurements, controlling the level of accuracy of the Lyman-$\\alpha$ flux\nmodelling is mandatory. In this work, we evaluate the impact of various\napproximations that exist in the main fast modelling approach compared to the\nresults of a costly full radiative transfer simulation. The fast SPINTER code,\npresented in this work, computes the Lyman-$\\alpha$ flux including the effect\nof wing scatterings for an inhomogeneous emissivity field, but assuming an\notherwise homogeneous expanding universe. The LICORICE code computes the full\nradiative transfer in the Lyman-$\\alpha$ line without any substantial\napproximation. We find that the difference between homogeneous and\ninhomogeneous gas density and temperature is very small for the computed flux.\nOn the contrary, neglecting the effect of gas velocities produces a significant\nchange in the computed flux. We identify the causes (mainly Doppler shifts due\nto velocity gradients) and quantify the magnitude of the effect in both an\nidealised setup and a realistic cosmological situation. We find that the\namplitude of the effect, up to a factor of $\\sim 2$ on the $21$ cm signal power\nspectrum on some scales (depending on both other model parameters and the\nredshift), can be easily discriminated with an SKA-like survey and already be\napproached, particularly for exotic signals, by the ongoing NenuFAR Cosmic Dawn\nKey Science Program.\n", "  The study of the angular power spectrum of Cosmic Microwave Background (CMB)\nanisotropies, both in intensity and in polarisation, has led to the tightest\nconstraints on cosmological parameters. However, this statistical quantity is\nnot sensitive to any deviation from Gaussianity and statistical isotropy in the\nCMB data. Minkowski Functionals (MFs) have been adopted as one of the most\npowerful statistical tools to study such deviations, since they characterise\nthe topology and geometry of the field of interest. In this paper, we extend\nthe application of MFs to CMB polarisation data by introducing a new formalism,\nwhere we lift the spin $2$ polarisation field to a scalar function in a\nhigher-dimensional manifold: the group of rotations of the sphere, $SO(3)$.\nSuch a function is defined as $f = Q \\cos(2\\psi) - U \\sin(2\\psi)$. We\nanalytically obtain the expected values for the MFs of $f$ in the case of\nGaussian isotropic polarisation maps. Furthermore, we present a new pipeline\nwhich estimates these MFs from input HEALPix polarisation maps. We apply it to\nCMB simulations in order to validate the theoretical results and the\nmethodology. The pipeline is to be included in the publicly available Python\npackage $\\texttt{Pynkowski}$ available at\nhttps://github.com/javicarron/pynkowski.\n", "  The shear measurement from DECaLS (Dark Energy Camera Legacy Survey) provides\nan excellent opportunity for galaxy-galaxy lensing study with DESI (Dark Energy\nSpectroscopic Instrument) galaxies, given the large ($\\sim 9000$ deg$^2$) sky\noverlap. We explore this potential by combining the DESI 1\\% survey and DECaLS\nDR8. With $\\sim 106$ deg$^2$ sky overlap, we achieve significant detection of\ngalaxy-galaxy lensing for BGS and LRG as lenses. Scaled to the full BGS sample,\nwe expect the statistical errors to improve from $18(12)\\%$ to a promising\nlevel of $2(1.3)\\%$ at $\\theta>8^{'}(<8^{'})$. This brings stronger\nrequirements for future systematics control. To fully realize such potential,\nwe need to control the residual multiplicative shear bias $|m|<0.01$ and the\nbias in the mean redshift $|\\Delta z|<0.015$. We also expect significant\ndetection of galaxy-galaxy lensing with DESI LRG/ELG full samples as lenses,\nand cosmic magnification of ELG through cross-correlation with low-redshift\nDECaLS shear. {If such systematical error control can be achieved,} we find the\nadvantages of DECaLS, comparing with KiDS (Kilo Degree Survey) and HSC\n(Hyper-Suprime Cam), are at low redshift, large-scale, and in measuring the\nshear-ratio (to $\\sigma_R\\sim 0.04$) and cosmic magnification.\n", "  Galaxy shear - cosmic microwave background (CMB) lensing convergence\ncross-correlations contain additional information on cosmology to\nauto-correlations. While being immune to certain systematic effects, they are\naffected by the galaxy intrinsic alignments (IA). This may be responsible for\nthe reported low lensing amplitude of the galaxy shear $\\times$ CMB convergence\ncross-correlations, compared to the standard Planck $\\Lambda$CDM (cosmological\nconstant and cold dark matter) cosmology prediction. In this work, we\ninvestigate how IA affects the Kilo-Degree Survey (KiDS) galaxy lensing shear -\nPlanck CMB lensing convergence cross-correlation and compare it to previous\ntreatments with or without IA taken into consideration. More specifically, we\ncompare marginalization over IA parameters and the IA self-calibration (SC)\nmethod (with additional observables defined only from the source galaxies) and\nprove that SC can efficiently break the degeneracy between the CMB lensing\namplitude $A_{\\rm lens}$ and the IA amplitude $A_{\\rm IA}$. We further\ninvestigate how different systematics affect the resulting $A_{\\rm IA}$ and\n$A_{\\rm lens}$, and validate our results with the MICE2 simulation. We find\nthat by including the SC method to constrain IA, the information loss due to\nthe degeneracy between CMB lensing and IA is strongly reduced. The best-fit\nvalues are $A_{\\rm lens}=0.84^{+0.22}_{-0.22}$ and $A_{\\rm\nIA}=0.60^{+1.03}_{-1.03}$, while different angular scale cuts can affect\n$A_{\\rm lens}$ by $\\sim10\\%$. We show that appropriate treatment of the boost\nfactor, cosmic magnification, and photometric redshift modeling is important\nfor obtaining the correct IA and cosmological results.\n", "  The tomography of the polarized Sunyaev-Zeldvich effect due to free electrons\nof galaxy clusters can be used to constrain the nature of dark energy because\nCMB quadrupoles at different redshifts as the polarization source are sensitive\nto the integrated Sachs-Wolfe effect. Here we show that the low multipoles of\nthe temperature and E-mode polarization anisotropies from the all-sky CMB can\nimprove the constraint further through the correlation between them and the CMB\nquadrupoles viewed from the galaxy clusters. Using a Monte-Carlo simulation, we\nfind that low multipoles of the temperature and E-mode polarization\nanisotropies potentially improve the constraint on the equation of state of\ndark energy parameter by $\\sim 17$ percent.\n", "  In this work, we reconstruct the cosmological unified dark fluid model\nproposed previously by Elkhateeb \\cite{Elkhateeb:2017oqy} in the framework of\n$f(R)$ gravity. Utilizing the equivalence between the scalar-tensor theory and\nthe $f(R)$ gravity theory, the scalar field for the dark fluid is obtained,\nwhence the $f(R)$ function is extracted and its viability is discussed. The\n$f(R)$ functions and the scalar field potentials have then been extracted in\nthe early and late times of asymptotically de Sitter spacetime. The ability of\nour function to describe early time inflation is also tested. The early time\nscalar field potential is used to derive the slow roll inflation parameters.\nOur results of the tensor-to-scalar ratio $r$ and the scalar spectral index\n$n_s$ are in good agreement with results from Planck-2018 TT+TE+EE+lowE data\nfor the model parameter $m > 2$.\n", "  Precision antenna calibration is required for mitigating the impact of\nforeground contamination in 21 cm cosmological radio surveys. One widely\nstudied source of error is the effect of missing point sources in the\ncalibration sky model; however, poorly understood diffuse galactic emission\nalso creates a calibration bias that can complicate the clean separation of\nforegrounds from the 21 cm signal. In this work, we present a technique for\nsuppressing this bias with temporal filtering of radio interferometric\nvisibilities observed in a drift-scan mode. We demonstrate this technique on\nmock simulations of the Hydrogen Epoch of Reionization Array (HERA) experiment.\nInspecting the recovered calibration solutions, we find that our technique\nreduces spurious errors by over an order of magnitude. This improved accuracy\napproaches the required accuracy needed to make a fiducial detection of the 21\ncm signal with HERA, but is dependent on a number of external factors that we\ndiscuss. We also explore different types of temporal filtering techniques and\ndiscuss their relative performance and tradeoffs.\n", "  The discrepancy between the weak lensing (WL) and the {\\it Planck}\nmeasurements of $S_8$ has been a subject of several studies. These studies tend\nto show that a suppression of the amplitude of the mass power spectrum $P(k)$\nat high $k$ could resolve it. The WL signal at small-scale is sensitive to\nvarious effects, such as baryonic effects and intrinsic alignment. The accuracy\nof $P(k)$ depends on the modelling precision of these effects. A common\napproach for calculating $P(k)$ relies on a halo model. Amongst the various\ncomponents necessary for the construction of $P(k)$, the halo mass function\n(HMF) is an important one. Traditionally, the HMF has been assumed to follow a\nfixed model. Recent literature shows that baryonic physics, amongst several\nother factors, could affect the HMF. In this study, we investigate the impact\nof allowing the HMF to vary. This provides a way of testing the validity of the\nhalo model-HMF calibration using data. We find that the {\\it Planck} cosmology\nis not compatible with the vanilla HMF for both the DES-y3 and the KiDS-1000\ndata. When the cosmology and the HMF parameters are allowed to vary, the {\\it\nPlanck} cosmology is no longer in tension. The modified HMF predicts a matter\npower spectrum with a $\\sim 25\\%$ power loss at $k\\sim 1~{\\rm h/Mpc}$, in\nagreement with the recent studies. We show that Stage IV surveys will be able\nto measure the HMF parameters with a few percent accuracy.\n", "  Models that connect galaxy and halo properties often summarize a halo's mass\naccretion history (MAH) with a single value, and use this value as the basis\nfor predictions. However, a single-value summary fails to capture the\ncomplexity of MAHs and information can be lost in the process. We present\nMultiCAM, a generalization of traditional abundance matching frameworks, which\ncan simultaneously connect the full MAH of a halo with multiple halo and/or\ngalaxy properties. As a first case study, we apply MultiCAM to the problem of\nconnecting dark matter halo properties to their MAHs in the context of a dark\nmatter-only simulation. While some halo properties, such as concentration, are\nmore strongly correlated to the early-time mass growth of a halo, others, like\nthe virial ratio, have stronger correlations with late-time mass growth. This\nhighlights the necessity of considering the impact of the entire MAH on halo\nproperties. For most of the halo properties we consider, we find that MultiCAM\nmodels that use the full MAH achieve higher accuracy than conditional abundance\nmatching models which use a single epoch. We also demonstrate an extension of\nMultiCAM that captures the covariance between predicted halo properties. This\nextension provides a baseline model for applications where the covariance\nbetween predicted properties is important.\n", "  We use topological summaries based on Betti curves to characterize the\nlarge-scale spatial distribution of simulated dark matter haloes and galaxies.\nUsing the IllustrisTNG and CAMELS-SAM simulations, we show that the topology of\nthe galaxy distribution is significantly different from the topology of the\ndark matter halo distribution. Further, there are significant differences\nbetween the distributions of star-forming and quiescent galaxies. These\ntopological differences are broadly consistent across all simulations, while at\nthe same time there are noticeable differences when comparing between different\nmodels. Finally, using the CAMELS-SAM simulations, we show that the topology of\nthe quiescent galaxies in particular depends strongly on the amount of\nsupernova feedback. These results suggest that topological summary statistics\ncould be used to help better understand the processes of galaxy formation and\nevolution.\n", "  Virialized halos of cold dark matter generically exhibit multi-stream\nstructures of accreted dark matter within an outermost radial caustic known as\nthe splashback radius. By tracking the particle trajectories that accrete onto\nthe halos in cosmological $N$-body simulations, we count their number of\napocenter passages ($p$), and use them to characterize the multi-stream\nstructure of dark matter particles. We find that the radial density profile for\neach stream, classified by the number of apocenter passages, exhibits universal\nfeatures, and can be described by a double power-law function comprising inner\nshallow and outer steep slopes of indices of $-1$ and $-8$, respectively.\nSurprisingly, these properties hold over a wide range of halo masses. The\ndouble-power law feature is persistent when dividing the sample by\nconcentration or accretion rate. The dependence of the characteristic scale and\namplitude of the profile on $p$ cannot be replicated by known self-similar\nsolutions, requiring consideration of complexities such as the distribution of\nangular momentum or mergers.\n", "  We use the BOSS DR12 galaxy power spectrum to constrain compensated\nisocurvature perturbations (CIP), which are opposite-sign primordial baryon and\ndark matter perturbations that leave the total matter density unchanged.\nLong-wavelength CIP $\\sigma(\\vec{x})$ enter the galaxy density contrast as\n$\\delta_g(\\vec{x}) \\supset b_\\sigma\\sigma(\\vec{x})$, with $b_\\sigma$ the linear\nCIP galaxy bias parameter. We parameterize the CIP spectra as $P_{\\sigma\\sigma}\n= A^2P_{\\mathcal{R}\\mathcal{R}}$ and $P_{\\sigma\\mathcal{R}} =\n\\xi\\sqrt{P_{\\sigma\\sigma}P_{\\mathcal{R}\\mathcal{R}}}$, where $A$ is the CIP\namplitude and $\\xi$ is the correlation with the curvature perturbations\n$\\mathcal{R}$. We find a significance of detection of $Ab_\\sigma \\neq 0$ of\n$1.8\\sigma$ for correlated ($\\xi = 1$) and $3.7\\sigma$ for uncorrelated ($\\xi =\n0$) CIP. Large-scale data systematics have a bigger impact for uncorrelated\nCIP, which may explain the large significance of detection. The constraints on\n$A$ depend on the assumed priors for the $b_\\sigma$ parameter, which we\nestimate using separate universe simulations. Assuming $b_\\sigma$ values\nrepresentative of all halos we find $\\sigma_A = 145$ for correlated CIP and\n$\\sigma_{|A|} = 475$ for uncorrelated CIP. Our strongest uncorrelated CIP\nconstraint is for $b_\\sigma$ representative of the $33\\%$ most concentrated\nhalos, $\\sigma_{|A|} = 197$, which is better than the current CMB bounds $|A|\n\\lesssim 360$. We also discuss the impact of the local primordial\nnon-Gaussianity parameter $f_{\\rm NL}$ in CIP constraints. Our results\ndemonstrate the power of galaxy data to place tight constraints on CIP, and\nmotivate works to understand better the impact of data systematics, as well as\nto determine theory priors for $b_\\sigma$.\n", "  We present GLASS, the Generator for Large Scale Structure, a new code for the\nsimulation of galaxy surveys for cosmology, which iteratively builds a light\ncone with matter, galaxies, and weak gravitational lensing signals as a\nsequence of nested shells. This allows us to create deep and realistic\nsimulations of galaxy surveys at high angular resolution on standard computer\nhardware and with low resource consumption. GLASS also introduces a new\ntechnique to generate transformations of Gaussian random fields (including\nlognormal) to essentially arbitrary precision, an iterative line-of-sight\nintegration over matter shells to obtain weak lensing fields, and flexible\nmodelling of the galaxies sector. We demonstrate that GLASS readily produces\nsimulated data sets with per cent-level accurate two-point statistics of galaxy\nclustering and weak lensing, thus enabling simulation-based validation and\ninference that is limited only by our current knowledge of the input matter and\ngalaxy properties.\n", "  We present an estimate of the bulk flow in a volume of radii\n$150-200h^{-1}$Mpc using the minimum variance (MV) method with data from the\nCosmicFlows-4 (CF4) catalog. The addition of new data in the CF4 has resulted\nin an increase in the estimate of the bulk flow in a sphere of radius\n$150h^{-1}$Mpc relative to the CosmicFlows-3 (CF3). This bulk flow has less\nthan a $0.03\\%$ chance of occurring in the Standard Cosmological Model\n($\\Lambda$CDM) with cosmic microwave background derived parameters. Given that\nthe CF4 is deeper than the CF3, we were able to use the CF4 to accurately\nestimate the bulk flow on scales of $200h^{-1}$Mpc (equivalent to 266 Mpc for\nHubble constant $H_o=75$ km/s/Mpc) for the first time. This bulk flow is in\neven greater tension with the Standard Model, having less than $0.003\\%$\nprobability of occurring. To estimate the bulk flow accurately, we introduce a\nnovel method to calculate distances and velocities from distance moduli that is\nunbiased and accurate at all distances. Our results are completely independent\nof the value of $H_o$.\n", "  The distribution of matter that is measured through galaxy redshift and\npeculiar velocity surveys can be harnessed to learn about the physics of dark\nmatter, dark energy, and the nature of gravity. To improve our understanding of\nthe matter of the Universe, we can reconstruct the full density and velocity\nfields from the galaxies that act as tracer particles. In this paper, we use\nthe simulated halos as proxies for the galaxies. We use a convolutional neural\nnetwork, a V-net, trained on numerical simulations of structure formation to\nreconstruct the density and velocity fields. We find that, with detailed tuning\nof the loss function, the V-net could produce better fits to the density field\nin the high-density and low-density regions, and improved predictions for the\nprobability distribution of the amplitudes of the velocities. However, the\nweights will reduce the precision of the estimated $\\beta$ parameter. We also\nfind that the redshift-space distortions of the halo catalogue do not\nsignificantly contaminate the reconstructed real-space density and velocity\nfield. We estimate the velocity field $\\beta$ parameter by comparing the\npeculiar velocities of halo catalogues to the reconstructed velocity fields,\nand find the estimated $\\beta$ values agree with the fiducial value at the 68\\%\nconfidence level.\n", "  In this paper, we firstly calibrate the Amati relation (the $E_{\\rm p}-E_{\\rm\niso}$ correlation) of gamma ray bursts (GRBs) at low redshifts ($z<0.8$) via\nGaussian process by using the type Ia supernovae samples from Pantheon+ under\nthe philosophy that objects at the same redshift should have the same\nluminosity distance in any cosmology. As a result, this calibration derives the\ndistance moduli of GRBs at high redshifts ($z>0.8$). For an application of\nthese derived distance modulus of GRBs to cosmology, via Gaussian process\nagain, a series of cosmography parameters, which describe kinematics of our\nUniverse, up to the fifth oder and the redshift $z\\sim 5$, i.e. the Hubble\nparameter $H(z)$, the deceleration parameter $q(z)$, the jerk parameter $j(z)$,\nthe snap parameter $s(z)$ and the lerk parameter $l(z)$, are reconstructed from\nthe cosmic observations. The reconstructed cosmography parameters show a\ntransition singularity at $z\\sim 6$, it may resort to two possible\nexplanations: one is that the GRBs data points at high redshift $z>5$ are still\nreliable, it means that new physics beyond the $\\Lambda$CDM model happens;\nanother one is that the quality and quantity of GRBs data points at high\nredshift $z>5$ are not good enough to give any viable prediction of the\nkinematics of our Universe. To pin down this problem, more high redshifts $z>5$\ncosmic observational are still needed.\n", "  Based on a new HI survey using the Five-hundred-meter Aperture Spherical\nradio Telescope (FAST), combined with the Pan-STARRS1 images, we identified an\nisolated HI cloud without any optical counterpart, named FAST J0139+4328. The\nnewly discovered HI cloud appears to be a typical disk galaxy since it has a\ndouble-peak shape in the global HI profile and an S-like rotation structure in\nthe velocity-position diagram. Moreover, this disk galaxy has an extremely low\nabsolute magnitude (M_B>-10.0 mag) and stellar mass (<6.9*10^5 Msun).\nFurthermore, we obtained that the HI mass of this galaxy is 8.3*10^7 Msun, and\nthe dynamical mass to total baryonic mass ratio is 47+-27, implying that dark\nmatter dominates over baryons in FAST J0139+4328. These findings provide\nobservational evidence that FAST J0139+4328 is an isolated dark dwarf galaxy\nwith a redshift of z=0.0083. This is the first time that an isolated dark\ngalaxy has been detected in the nearby universe.\n", "  We analyse the evolution of the largest ionized region using the topological\nand morphological evolution of the redshifted 21-cm signal coming from the\nneutral hydrogen distribution during the different stages of reionization. For\nthis analysis, we use the \"Largest Cluster Statistics\" - LCS. We mainly study\nthe impact of the array synthesized beam on the LCS analysis of the 21-cm\nsignal considering the upcoming low-frequency Square Kilometer Array (SKA1-Low)\nobservations using a realistic simulation for such observation based on the\n21cmE2E-pipeline using OSKAR. We find that bias in LCS estimation is introduced\nin synthetic observations due to the array beam. This in turn shifts the\napparent percolation transition point towards the later stages of reionization.\nThe biased estimates of LCS, occurring due to the effect of the lower\nresolution (lack of longer baselines) and the telescope synthesized beam will\nlead to a biased interpretation of the reionization history. This is important\nto note while interpreting any future 21-cm signal images from upcoming or\nfuture telescopes like the SKA, HERA, etc. We conclude that one may need denser\n$uv$-coverage at longer baselines for a better deconvolution of the array\nsynthesized beam from the 21-cm images and a relatively unbiased estimate of\nLCS from such images.\n", "  We measure the three-dimensional cross-power spectrum of galaxy density and\nintrinsic alignment (IA) fields for the first time from the spectroscopic and\nimaging data of SDSS-III BOSS galaxies, for each of the four samples in the\nredshift range $0.2 < z < 0.75$. In the measurement we use the power spectrum\nestimator, developed in our previous work, to take into account the\nline-of-sight dependent projection of galaxy shapes onto the sky coordinate and\nthe $E/B$-mode decomposition of the spin-2 shape field. Our method achieves a\nsignificant detection of the $E$-mode power spectrum with the total\nsignal-to-noise ratio comparable with that of the quadrupole moment of the\ngalaxy density power spectrum, while the measured $B$-mode power spectra are\nconsistent with a null signal to within the statistical errors for all the\ngalaxy samples. We also show that, compared to the previous results based on\nthe two-dimensional projected correlation function, our method improves the\nprecision of the linear shape bias parameter estimation by up to a factor of\ntwo thanks to the three-dimensional information. By performing a joint analysis\nof the galaxy density and IA power spectra in the linear regime, we constrain\nthe isotropic and anisotropic local primordial non-Gaussianities (PNGs)\nparameters, $f_\\mathrm{NL}^{s=0}$ and $f_\\mathrm{NL}^{s=2}$, simultaneously,\nwhere the two types of PNGs induce characteristic scale-dependent biases at\nvery large scales in the density and IA power spectra, respectively. We do not\nfind any significant detection for both PNGs: the constraints\n$f^{s=0}_\\mathrm{NL}=57^{+30}_{-29}$ and $f^{s=2}_\\mathrm{NL} =\n-67_{-269}^{+285}$ ($68\\%$ C.L.), respectively. Our method paves the way for\nusing the IA power spectrum as a cosmological probe for current and future\ngalaxy surveys.\n", "  Critical points represent a subset of special points tracing cosmological\nstructures, carrying remarkable topological properties. They thus offer a\nricher high-level description of the multiscale cosmic web, being more robust\nto systematic effects. For the first time, we characterize here their\nclustering statistics in massive neutrino cosmologies, including\ncross-correlations, and quantify their simultaneous imprints on the\ncorresponding web constituents - i.e., halos, filaments, walls, and voids - for\na series of rarity levels. Our first analysis is centered on a\ndensity-threshold-based approach in configuration space. In particular, we show\nthat the presence of massive neutrinos does affect the baryon acoustic\noscillation peak amplitudes of all of the critical point correlation functions\nabove/below the rarity threshold, as well as the positions of their\ncorrespondent inflection points at large scales: departures from analogous\nmeasurements carried out in the baseline massless neutrino scenario can reach\nup to ~7% in autocorrelations and ~9% in cross-correlations at z=0 when\nM_nu=0.1 eV, and are more pronounced for higher neutrino mass values. In turn,\nthese combined multiscale effects can be used as a novel technique to set upper\nlimits on the summed neutrino mass and infer the type of hierarchy. Our study\nis particularly relevant for ongoing and future large-volume redshift surveys\nsuch as the Dark Energy Spectroscopic Instrument and the Rubin Observatory\nLegacy Survey of Space and Time, which will provide unique datasets suitable\nfor establishing competitive neutrino mass constraints.\n", "  Time-delay cosmography uses strong gravitational lensing of a time-variable\nsource to infer the Hubble Constant. The measurement is independent from both\ntraditional distance ladder and CMB measurements. An accurate measurement with\nthis technique requires considering the effects of objects along the line of\nsight outside the primary lens, which is quantified by the external convergence\n($\\kappa_{\\rm{ext}}$). In absence of such corrections, $H_0$ will be biased\ntowards higher values in overdense fields and lower values in underdense\nfields. We discuss the current state of the methods used to account for\nenvironment effects. We present a new software package built for this kind of\nanalysis and others that can leverage large astronomical survey datasets. We\napply these techniques to the SDSS J0924+0219 strong lens field. We infer the\nrelative density of the SDSS J0924+0219 field by computing weighted number\ncounts for all galaxies in the field, and comparing to weighted number counts\ncomputed for a large number of fields in a reference survey. We then compute\nweighted number counts in the Millennium Simulation and compare these results\nto infer the external convergence of the lens field.Results. Our results show\nthe SDSS J0924+0219 field is a fairly typical line of sight, with median\n$\\kappa_{\\rm{ext}} = -0.012$ and standard deviation $\\sigma_{\\kappa} = 0.028$.\n", "  Multifrequency studies of galaxy clusters are crucial for inferring their\ndynamical states and physics. Moreover, these studies allow us to investigate\ncluster-embedded sources, whose evolution is affected by the physical and\ndynamical condition of the cluster itself. So far, these kinds of studies have\nbeen preferentially conducted on clusters visible from the northern hemisphere\ndue to the high-fidelity imaging capabilities of ground-based radio\ninterferometers located there. In this paper, we conducted a multifrequency\nstudy of the poorly known galaxy cluster Abell 3718. We investigated the\nunknown origin of an extended radio source with a length of $\\sim$612 kpc at\n943 MHz detected in images from the Evolutionary Map of the Universe (EMU) and\nPOlarisation Sky Survey of the Universe's Magnetism (POSSUM) surveys. We\nanalyzed optical and X-ray data to infer the dynamical state of the cluster\nand, in particular, the merger activity. We conducted a radio spectral index\nstudy from 943 MHz up to 9 GHz. We also evaluated the polarization properties\nof the brightest cluster-embedded sources to understand if they are related to\nthe radio emission observed on larger scales. [Abstract truncated due to arxiv\nlimit! Please see the pdf version]\n", "  We investigate the sensitivity of a universe's nuclear entropy after Big Bang\nnucleosynthesis (BBN) to variations in both the baryon-to-photon ratio and the\ntemporal evolution of cosmological expansion. Specifically, we construct\ncounterfactual cosmologies to quantify the degree by which these two parameters\nmust vary from those in our Universe before we observe a substantial change in\nthe degree of fusion, and thus nuclear entropy, during BBN. We find that, while\nthe post-BBN nuclear entropy is indeed linked to baryogenesis and the\nUniverse's expansion history, the requirement of leftover light elements does\nnot place strong constraints on the properties of these two cosmological\nprocesses.\n", "  The galaxy distribution in dark matter-dominated halos is expected to\napproximately trace the details of the underlying dark matter substructure. In\nthis paper we introduce halo `core-tracking' as a way to efficiently follow the\nsmall-scale substructure in cosmological simulations and apply the technique to\nmodel the galaxy distribution in observed clusters. The method relies on\nexplicitly tracking the set of particles identified as belonging to a halo's\ncentral density core, once a halo has attained a certain threshold mass. The\nhalo cores are then followed throughout the entire evolution of the simulation.\nThe aim of core-tracking is to simplify substructure analysis tasks by avoiding\nthe use of subhalos and, at the same time, to more easily account for the\nso-called ``orphan'' galaxies, which have lost substantial dark mass due to\ntidal stripping. We show that simple models based on halo cores can reproduce\nthe number and spatial distribution of galaxies found in optically-selected\nclusters in the Sloan Digital Sky Survey. We also discuss future applications\nof the core-tracking methodology in studying the galaxy-halo connection.\n", "  This work considers which higher-order effects in modelling the cosmic shear\nangular power spectra must be taken into account for Euclid. We identify which\nterms are of concern, and quantify their individual and cumulative impact on\ncosmological parameter inference from Euclid. We compute the values of these\nhigher-order effects using analytic expressions, and calculate the impact on\ncosmological parameter estimation using the Fisher matrix formalism. We review\n24 effects and find the following potentially need to be accounted for: the\nreduced shear approximation, magnification bias, source-lens clustering, source\nobscuration, local Universe effects, and the flat Universe assumption. Upon\ncomputing these explicitly, and calculating their cosmological parameter\nbiases, using a maximum multipole of $\\ell=5000$, we find that the\nmagnification bias, source-lens clustering, source obscuration, and local\nUniverse terms individually produce significant ($\\,>0.25\\sigma$) cosmological\nbiases in one or more parameters, and accordingly must be accounted for. In\ntotal, over all effects, we find biases in $\\Omega_{\\rm m}$, $\\Omega_{\\rm b}$,\n$h$, and $\\sigma_{8}$ of $0.73\\sigma$, $0.28\\sigma$, $0.25\\sigma$, and\n$-0.79\\sigma$, respectively, for flat $\\Lambda$CDM. For the $w_0w_a$CDM case,\nwe find biases in $\\Omega_{\\rm m}$, $\\Omega_{\\rm b}$, $h$, $n_{\\rm s}$,\n$\\sigma_{8}$, and $w_a$ of $1.49\\sigma$, $0.35\\sigma$, $-1.36\\sigma$,\n$1.31\\sigma$, $-0.84\\sigma$, and $-0.35\\sigma$, respectively; which are\nincreased relative to the $\\Lambda$CDM due to additional degeneracies as a\nfunction of redshift and scale.\n", "  The idea of neutrino-assisted early dark energy ($\\nu$EDE), where a coupling\nbetween neutrinos and the scalar field that models early dark energy (EDE) is\nconsidered, was introduced with the aim of reducing some of the fine-tuning and\ncoincidence problems that appear in usual EDE models. In order to be relevant\nin ameliorating the $H_0$ tension, the contribution of EDE to the total energy\ndensity ($f_\\text{EDE}$) should be around 10\\% near the redshift of\nmatter-radiation equality. We verify under which conditions $\\nu$EDE models can\nfulfill these requirements for a model with a quartic self-coupling of the EDE\nfield and an exponential coupling to neutrinos. We find that in the situation\nwhere the EDE field is frozen initially, the contribution to $f_\\text{EDE}$ can\nbe significant but it is not sensitive to the neutrino-EDE coupling and does\nnot address the EDE coincidence problem. On the other hand, if the EDE field\nstarts already dynamical at the minimum of the effective potential, it tracks\nthis time-dependent minimum that presents a feature triggered by the neutrino\ntransition from relativistic to nonrelativistic particles. This feature\ngenerates $f_\\text{EDE}$ in a natural way at around this transition epoch, that\nroughly coincides with the matter-radiation equality redshift. For the set of\nparameters that we considered we did not find values that satisfy the\nrequirements on the background cosmological evolution to mitigate the Hubble\ntension in a natural way in this particular $\\nu$EDE model.\n", "  With mock strong gravitational lensing images, we investigate the performance\nof the broken power-law (BPL) model proposed by \\citet{2020ApJ...892...62D} on\nthe mass reconstruction of galaxy-scale lenses. An end-to-end test is carried\nout, including the creation of mock strong lensing images, the subtraction of\nlens light, and the reconstruction of lensed images, where the lenses are\nselected from the galaxies in the Illustris-1 simulation. We notice that,\nregardless of the adopted mass models (the BPL model or its special cases), the\nEinstein radius can be robustly determined from imaging data alone, and the\nmedian bias is typically less than $1\\%$. Away from the Einstein radius, the\nlens mass distribution tends to be harder to measure, especially at radii where\nthere are no lensed images detected. We find that, with rigid priors, the BPL\nmodel can clearly outperform the single power-law models by achieving $<5\\%$\nmedian bias on the radial convergence profile within the Einstein radius. As\nfor the source light reconstructions, they are found to be sensitive to both\nlens light contamination and lens mass models, where the BPL model with rigid\npriors still performs best when there is no lens light contamination. We show\nthat, by correcting for the projection effect, the BPL model can estimate the\naperture and luminosity weighted line-of-sight velocity dispersions to an\naccuracy of $\\sim6\\%$ scatter. These results highlight the great potential of\nthe BPL model in strong lensing related studies.\n", "  The knowledge of the main features of the bulk flow in the Local Universe is\nimportant for a better determination of the relative motions there, an\ninformation that would contribute to a precise calculation of the\nHubble-Lema\\^{\\i}tre law at very low redshifts. We study how to obtain the\nHubble-Lema\\^{\\i}tre law in two sky regions using the catalog of HI sources of\nthe ALFALFA survey, with data $cz_{\\odot} < 6000$ km/s. Our methodology aims to\ncompute $H_0$ in two regions -- located in opposite galactic hemispheres --\nmapped by the ALFALFA survey, and look for dependence with distance, direction,\nand also test for reference frame changes. We calculate the Hubble constant, in\nthe Cosmic Microwave Background reference frame, in opposite galactic\nhemispheres: $H_0^N = 70.87 \\pm 2.38$ and $H_0^S = 66.07 \\pm 3.02$, which\nallows us to measure the bulk flow velocity $V_{BF} = 401.06 \\pm 150.55$ km/s\nat the effective distance $31.3 \\pm 6.26$ Mpc, a novel result found analysing\nthe ALFALFA data at low redshift. We confirm the influence of the bulk flow on\nthe structures of the Local Universe which manifests through a dipolar behavior\nof the Hubble constant in opposite hemispheres.\n", "  We study the potential of the galaxy cluster sample expected from the China\nSpace Station Telescope (CSST) survey to constrain dark energy properties. By\nmodelling the distribution of observed cluster mass for a given true mass to be\nlog-normal and adopting a selection threshold in the observed mass $M_{200m}\n\\geq 0.836 \\times 10^{14} h^{-1}M_{\\odot}$, we find about $4.1 \\times 10^{5}$\nclusters in the redshift range $0 \\leq z \\leq 1.5$ can be detected by the CSST.\nWe construct the Fisher matrix for the cluster number counts from CSST, and\nforecast constraints on dark energy parameters for models with constant\n($w_0$CDM) and time dependent ($w_0w_a$CDM) equation of state. In the\nself-calibration scheme, the dark energy equation of state parameter $w_0$ of\n$w_0$CDM model can be constrained to $\\Delta w_0 = 0.036$. If $w_a$ is added as\na free parameter, we obtain $\\Delta w_0 = 0.077$ and $\\Delta w_a = 0.39$ for\nthe $w_0w_a$CDM model, with a Figure of Merit for ($w_0,w_a$) to be 68.99.\nShould we had perfect knowledge of the observable-mass scaling relation\n(``known SR\" scheme), we would obtain $\\Delta w_0 = 0.012$ for $w_0$CDM model,\n$\\Delta w_0 = 0.062$ and $\\Delta w_a = 0.24$ for $w_0w_a$CDM model. The dark\nenergy Figure of Merit of ($w_0,w_a$) increases to 343.25. By extending the\nmaximum redshift of the clusters from $z_{max} \\sim 1.5$ to $z_{max} \\sim 2$,\nthe dark energy Figure of Merit for ($w_0,w_a$) increases to 89.72\n(self-calibration scheme) and 610.97 (``known SR\" scheme), improved by a factor\nof $\\sim 1.30$ and $\\sim 1.78$, respectively. We find that the impact of\nclusters' redshift uncertainty on the dark energy constraints is negligible as\nlong as the redshift error of clusters is smaller than 0.01, achievable by\nCSST. We also find that the bias in logarithm mass must be calibrated to be\n$0.30$ or better to avoid significant dark energy parameter bias.\n", "  The orbital evolution of a binary system consisting of two primordial black\nhole clusters is investigated. Such clusters are predicted in some theoretical\nmodels with broken symmetry in the inflation Lagrangian. A cluster consists of\nthe most massive central black hole surrounded by many smaller black holes.\nSimilar to single primordial black holes, clusters can form gravitationally\nbounded pairs and merge during their orbital evolution. The replacement of\nsingle black holes by such clusters significantly changes the entire merger\nprocess and the final rate of gravitational wave bursts in some parameter\nranges (with sufficiently large cluster radii). A new important factor is the\ntidal gravitational interaction of the clusters. It leads to an additional\ndissipation of the orbital energy, which is transferred into the internal\nenergy of the clusters or carried away by black holes flying out of the\nclusters. Comparison with the data of gravitational-wave telescopes allows one\nto constrain the fractions of primordial black holes in clusters, depending on\ntheir mass and compactness. Even the primordial black hole fraction in the\ncomposition of dark matter $\\simeq1$ turns out to be compatible with LIGO/Virgo\nobservational data, if the black holes are in clusters.\n", "  LiteBIRD is a planned JAXA-led CMB B-mode satellite experiment aiming for\nlaunch in the late 2020s, with a primary goal of detecting the imprint of\nprimordial inflationary gravitational waves. Its current baseline focal-plane\nconfiguration includes 15 frequency bands between 40 and 402 GHz, fulfilling\nthe mission requirements to detect the amplitude of gravitational waves with\nthe total uncertainty on the tensor-to-scalar ratio, $\\delta r$, down to\n$\\delta r<0.001$. A key aspect of this performance is accurate astrophysical\ncomponent separation, and the ability to remove polarized thermal dust emission\nis particularly important. In this paper we note that the CMB frequency\nspectrum falls off nearly exponentially above 300 GHz relative to the thermal\ndust SED, and a relatively minor high frequency extension can therefore result\nin even lower uncertainties and better model reconstructions. Specifically, we\ncompare the baseline design with five extended configurations, while varying\nthe underlying dust modeling, in each of which the HFT (High-Frequency\nTelescope) frequency range is shifted logarithmically towards higher\nfrequencies, with an upper cutoff ranging between 400 and 600 GHz. In each\ncase, we measure the tensor-to-scalar ratio $r$ uncertainty and bias using both\nparametric and minimum-variance component-separation algorithms. When the\nthermal dust sky model includes a spatially varying spectral index and\ntemperature, we find that the statistical uncertainty on $r$ after foreground\ncleaning may be reduced by as much as 30--50 % by extending the upper limit of\nthe frequency range from 400 to 600 GHz, with most of the improvement already\ngained at 500 GHz. We also note that a broader frequency range leads to better\nability to discriminate between models through higher $\\chi^2$ sensitivity.\n(abridged)\n", "  We study three different extended scalar-tensor theories of gravity by also\nallowing a negative sign for the kinetic term for the scalar field in the\nJordan frame. Our scope is to understand how the observational constraints for\nthese models cope with the volume of the parameter space in which the theory is\nhealthy. Models with a negative kinetic term lead to decreasing effective\ngravitational constant with redshift and behave as an effective relativistic\ncomponent with a negative energy density as opposite to their corresponding\nversion with a standard kinetic term. As a consequence, we find that the\nextended branch with a negative sign for the kinetic term correspond in general\nto lower $H_0$ and $\\sigma_8$ compared to $\\Lambda$CDM. We find that in all the\ncases with a negative sign for the kinetic term studied here, cosmological\nobservations constrain these models around GR and prefer a volume of the\nparameter space in which the theory is not healthy since the scalar field\nbehave as a ghost also in the related Einstein frame. We show that also in the\nphantom branch early modify gravity with a quartic coupling can substantially\nreduce the $H_0$ tension fitting the combination of cosmic microwave background\ndata from Planck, baryon acoustic oscillations from BOSS and eBOSS, and\nSupernovae from the Pantheon sample with calibration information by SH0ES.\n", "  We investigate the cosmological constraints that can be expected from\nmeasurement of the cross-correlation of galaxies with cosmic voids identified\nin the Euclid spectroscopic survey, which will include spectroscopic\ninformation for tens of millions of galaxies over $15\\,000$ deg$^2$ of the sky\nin the redshift range $0.9\\leq z<1.8$. We do this using simulated measurements\nobtained from the Flagship mock catalogue, the official Euclid mock that\nclosely matches the expected properties of the spectroscopic data set. To\nmitigate anisotropic selection-bias effects, we use a velocity field\nreconstruction method to remove large-scale redshift-space distortions from the\ngalaxy field before void-finding. This allows us to accurately model\ncontributions to the observed anisotropy of the cross-correlation function\narising from galaxy velocities around voids as well as from the\nAlcock-Paczynski effect, and we study the dependence of constraints on the\nefficiency of reconstruction. We find that Euclid voids will be able to\nconstrain the ratio of the transverse comoving distance $D_{\\rm M}$ and Hubble\ndistance $D_{\\rm H}$ to a relative precision of about $0.3\\%$, and the growth\nrate $f\\sigma_8$ to a precision of between $5\\%$ and $8\\%$ in each of four\nredshift bins covering the full redshift range. In the standard cosmological\nmodel, this translates to a statistical uncertainty\n$\\Delta\\Omega_\\mathrm{m}=\\pm0.0028$ on the matter density parameter from voids,\nbetter than can be achieved from either Euclid galaxy clustering and weak\nlensing individually. We also find that voids alone can measure the dark energy\nequation of state to $6\\%$ precision.\n", "  In this paper, we present the formalism of simulating Lyman-$\\alpha$ emission\nand polarization around reionization ($z$ = 8) from a plane-parallel ionization\nfront. We accomplish this by using a Monte Carlo method to simulate the\nproduction of a Lyman-$\\alpha$ photon, its propagation through an ionization\nfront, and the eventual escape of this photon. This paper focuses on the\nrelation of the input parameters of ionization front speed $U$, blackbody\ntemperature $T_{\\rm bb}$, and neutral hydrogen density $n_{\\rm HI}$, on\nintensity $I$ and polarized intensity $P$ as seen by a distant observer. The\nresulting values of intensity range from $3.18\\times 10^{-14}$\nerg/cm$^{2}$/s/sr to $1.96 \\times 10^{-9}$ erg/cm$^{2}$/s/sr , and the\npolarized intensity ranges from $5.73\\times 10^{-17}$ erg/cm$^{2}$/s/sr to\n$5.31 \\times 10^{-12}$ erg/cm$^{2}$/s/sr. We found that higher $T_{\\rm bb}$,\nhigher $U$, and higher $n_{\\rm HI}$ contribute to higher intensity, as well as\npolarized intensity, though the strongest dependence was on the hydrogen\ndensity. The dependence of viewing angle of the front is also explored. We\npresent tests to support the validity model, which makes the model suitable for\nfurther use in a following paper where we will calculate the intensity and\npolarized intensity power spectrum on a full reionization simulation.\n", "  This is the second paper in a series whose aim is to predict the power\nspectrum of intensity and polarized intensity from cosmic reionization fronts.\nAfter building the analytic models for intensity and polarized intensity\ncalculations in paper I, here we apply these models to simulations of\nreionization. We construct a geometric model for identifying front boundaries,\ncalculate the intensity and polarized intensity for each front, and compute a\npower spectrum of these results. This method was applied to different\nsimulation sizes and resolutions, so we ensure that our results are convergent.\nWe find that the power spectrum of fluctuations at $z=8$ in a bin of width\n$\\Delta z=0.5$ ($\\lambda/\\Delta\\lambda=18$) is $\\Delta_\\ell \\equiv\n[\\ell(\\ell+1)C_\\ell/2\\pi]^{1/2}$ is $3.2\\times 10^{-11}$ erg s$^{-1}$ cm$^{-2}$\nsr$^{-1}$ for the intensity $I$, $7.6\\times10^{-13}$ erg s$^{-1}$ cm$^{-2}$\nsr$^{-1}$ for the $E$-mode polarization, and $5.8\\times10^{-13}$ erg s$^{-1}$\ncm$^{-2}$ sr$^{-1}$ for the $B$-mode polarization at $\\ell=1.5\\times10^4$.\nAfter computing the power spectrum, we compare results to detectable scales and\ndiscuss implications for observing this signal based on a proposed experiment.\nWe find that, while fundamental physics does not exclude this kind of mapping\nfrom being attainable, an experiment would need to be highly ambitious and\nrequire significant advances to make mapping Lyman-$\\alpha$ polarization from\ncosmic reionization fronts a feasible goal.\n", "  The widely used MASTER approach for angular power spectrum estimation was\ndeveloped as a fast $C_{\\ell}$ estimator on limited regions of the sky. This\nmethod expresses the power spectrum of a masked map (\"pseudo-$C_\\ell$\") in\nterms of the power spectrum of the unmasked map (the true $C_\\ell$) and that of\nthe mask or weight map. However, it is often the case that the map and mask are\ncorrelated in some way, such as point source masks used in cosmic microwave\nbackground (CMB) analyses, which have nonzero correlation with CMB secondary\nanisotropy fields and other mm-wave sky signals. In such situations, the MASTER\napproach gives biased results, as it assumes that the unmasked map and mask\nhave zero correlation. While such effects have been discussed before with\nregard to specific physical models, here we derive a completely general\nformalism for any case where the map and mask are correlated. We show that our\nresult (\"reMASTERed\") reconstructs ensemble-averaged pseudo-$C_\\ell$ to\neffectively exact precision, with significant improvements over traditional\nestimators for cases where the map and mask are correlated. In particular, we\nobtain an improvement in the mean absolute percent error from 30% with the\nMASTER result to essentially no error with the reMASTERed result for an\nintegrated Sachs-Wolfe (ISW) field map with a mask built from the thresholded\nISW field, and 10% to effectively zero for a Compton-$y$ map combined with an\ninfrared source mask (the latter being directly relevant to actual data\nanalysis). An important consequence of our result is that for maps with\ncorrelated masks it is no longer possible to invert a simple equation to obtain\nthe true $C_\\ell$ from the pseudo-$C_\\ell$. Instead, our result necessitates\nthe use of forward modeling from theory space into the observable domain of the\npseudo-$C_\\ell$. Our code is publicly available at\nhttps://github.com/kmsurrao/reMASTERed.\n", "  We study how well void-finding algorithms identify cosmic void regions and\nwhether we can quantitatively and qualitatively describe their biases by\ncomparing the voids they find with dynamical information from the underlying\nmatter distribution. Using the ORIGAMI algorithm to determine the number of\ndimensions along which dark matter particles have undergone shell-crossing\n(crossing number) in $N$-body simulations from the AbacusSummit simulation\nsuite, we identify dark matter particles which have undergone no shell crossing\nas belonging to voids. We then find voids in the corresponding halo\ndistribution using two different void-finding algorithms: VoidFinder and V$^2$,\na ZOBOV-based algorithm. The resulting void catalogs are compared to the\ndistribution of dark matter particles to examine how their crossing numbers\ndepend on void proximity. While both algorithms' voids have a similar\ndistribution of crossing numbers near their centers, we find that beyond 0.25\ntimes the effective void radius, voids found by VoidFinder exhibit a stronger\npreference for particles with low crossing numbers than those found by V$^2$.\nWe examine two possible methods of mitigating this difference in efficacy\nbetween the algorithms. While we are able to partially mitigate the\nineffectiveness of V$^2$ by using distance from the void edge as a measure of\ncentrality, we conclude that VoidFinder more reliably identifies\ndynamically-distinct regions of low crossing number.\n", "  We discuss a cosmological scenario with a stochastic background of\ngravitational waves sourced by the tensor perturbation due to a hybrid\ninflationary model with cubic potential. The tensor-to-scalar ratio for the\npresent hybrid inflationary model is obtained as $r \\approx 0.0006$.\nGravitational wave spectrum of this stochastic background, for large-scale CMB\nmodes, $10^{-4}Mpc^{-1}$ to $1Mpc^{-1}$ is studied. The present-day energy\nspectrum of gravitational waves $\\Omega_0^{gw}(f)$ is sensitively related to\nthe tensor power spectrum and r which is, in turn, dependent on the unknown\nphysics of the early cosmos. This uncertainty is characterized by two\nparameters: $\\hat{n_t}(f)$ logarithmic average over the primordial tensor\nspectral index and $\\hat{w}(f)$ logarithmic average over the effective equation\nof state parameter. Thus, exact constraints in the $\\hat{w}(f)$, $\\hat{n_t}(f)$\nplane can be obtained by comparing theoretical constraints of our model on r\nand $\\Omega_0^{gw}(f)$. We obtain a limit on $\\hat{w}(10^{-15}Hz)$<$0.33$\naround the modes probed by CMB scales.\n", "  We provide novel constraints on the parameters defining the universal\npressure profile (UPP) within clusters of galaxies, and explore their\ndependence on the cluster mass and redshift, from measurements of\nSunyaev-Zel'dovich Compton-$y$ profiles. We employ both the $\\textit{Planck}$\n2015 MILCA and the ACT-DR4 $y$ maps over the common $\\sim 2,100\\,\\text{deg}^2$\nfootprint. We combine existing cluster catalogs based on KiDS, SDSS and DESI\nobservations, for a total of 23,820 clusters spanning the mass range\n$10^{14.0}\\,\\text{M}_{\\odot}<M_{500}<10^{15.1}\\,\\text{M}_{\\odot}$ and the\nredshift range $0.02<z<0.98$. We split the clusters into three independent bins\nin mass and redshift; for each combination we detect the stacked SZ cluster\nsignal and extract the mean $y$ angular profile. The latter is predicted\ntheoretically adopting a halo model framework, and MCMCs are employed to\nestimate the UPP parameters, the hydrostatic mass bias $b_{\\rm h}$ and possible\ncluster miscentering effects. We constrain $[P_0,c_{500},\\alpha,\\beta]$ to\n$[5.9,2.0,1.8,4.9]$ with $\\textit{Planck}$ and to $[3.8,1.3,1.0,4.4]$ with ACT\nusing the full cluster sample, in agreement with previous findings. We do not\nfind any compelling evidence for a residual mass or redshift dependence, thus\nexpanding the validity of the cluster pressure profile over much larger\n$M_{500}$ and $z$ ranges; this is the first time the model has been tested on\nsuch a large (complete and representative) cluster sample. Finally, we obtain\nloose constraints on the hydrostatic mass bias in the range 0.2-0.3, again in\nbroad agreement with previous works.\n", "  Single field inflationary models are investigated within Palatini quadratic\ngravity represented by $R+\\alpha R^2$ along with a non-minimal coupling of the\nform $f(\\phi) R$ between the inflaton field $\\phi$ and the gravity. The\ntreatment is performed in the Einstein frame, where the minimal coupling to\ngravity is recovered through conformal transformation. We consider various\nlimits of the model with different inflationary scenarios characterized as\ncanonical slow-roll inflation in the limit $\\alpha \\dot{\\phi}^2\\ll (1+f(\\phi))\n$, constant-roll k-inflation for $\\alpha \\ll 1$, and slow-roll K-inflation for$\n\\alpha \\gg 1$ . A cosine and exponential potential are examined with the limits\nmentioned above and different well-motivated non-minimal couplings to gravity.\nWe compare the theoretical results, exemplified by the tensor-to-scalar $r$\nratio and spectral index $n_s$, with the recent observational results of Planck\n2018 $\\&$ BICEP/Keck . Furthermore, we include the results of a new study\nforecast precision with which $n_s$ and $r$ can be constrained by currently\nenvisaged observations, including CMB (Simons Observatory, CMB-S4, and\nLiteBIRD)\n", "  The 21-cm power spectrum of reionization is a promising probe for cosmology\nand fundamental physics. Exploiting this new observable, however, requires fast\npredictors capable of efficiently scanning the very large parameter space of\ncosmological and astrophysical uncertainties. In this paper, we introduce the\nhalo model of reionization (HMreio), a new analytical tool that combines the\nhalo model of the cosmic dawn with the excursion-set bubble model for\nreionization, assuming an empirical correction factor to deal with overlapping\nionization bubbles. First, HMreio is validated against results from the\nwell-known semi-numerical code 21cmFAST, showing a good overall agreement for\nwave-modes of $k\\lesssim 1$ h/Mpc. Based on this result, we perform a\nMonte-Carlo Markov-Chain (MCMC) forecast analysis assuming mock data from\n1000-hour observations with the low-frequency part of the Square Kilometre\nArray (SKA) observatory. We simultaneously vary the six standard cosmological\nparameters together with seven astrophysical nuisance parameters quantifying\nthe abundance and spectral properties of sources. Depending on the assumed\ntheory error, we find very competitive constraints on cosmological parameters.\nIn particular, it will be possible to conclusively test current cosmological\ntensions related to the Hubble parameter ($H_0$-tension) and the matter\nclustering amplitude ($S_8$-tension). Furthermore, the sum of the neutrino\nmasses can be strongly constrained, making it possible to determine the\nneutrino mass hierarchy at the $\\sim 90$ percent confidence level. However,\nthese goals can only be achieved if the current modelling uncertainties are\nsubstantially reduced to below $\\sim 3$ percent.\n", "  We report a new test of modified gravity theories using the large-scale\nstructure of the Universe. This paper is the first attempt to (1) apply a joint\nanalysis of the anisotropic components of galaxy two- and three-point\ncorrelation functions (2 and 3PCFs) to actual galaxy data and (2) constrain the\nnonlinear effects of degenerate higher-order scalar-tensor (DHOST) theories on\ncosmological scales. Applying this analysis to the Baryon Oscillation\nSpectroscopic Survey (BOSS) data release 12, we obtain the lower bounds of\n$-1.655 < \\xi_{\\rm t}$ and $-0.504 < \\xi_{\\rm s}$ at the $95\\%$ confidence\nlevel on the parameters characterising the time evolution of the tidal and\nshift terms of the second-order velocity field. These constraints are\nconsistent with GR predictions of $\\xi_{\\rm t}=15/1144$ and $\\xi_{\\rm s}=0$.\nMoreover, they represent a $35$-fold and $20$-fold improvement, respectively,\nover the joint analysis with only the isotropic 3PCF. We ensure the validity of\nour results by investigating various quantities, including theoretical models\nof the 3PCF, window function corrections, cumulative ${\\rm S/N}$, Fisher\nmatrices, and statistical scattering effects of mock simulation data. We also\nfind statistically significant discrepancies between the BOSS data and the\nPatchy mocks for the 3PCF measurement. Finally, we package all of our 3PCF\nanalysis codes under the name \\textsc{HITOMI} and make them publicly available\nso that readers can reproduce all the results of this paper and easily apply\nthem to ongoing future galaxy surveys.\n", "  A perturbation on the background inflaton potential can lead inflation into\nthe ultraslow-roll stage and can thus remarkably enhance the power spectrum\n${\\cal P}_{\\cal R}(k)$ of the primordial curvature perturbation on small\nscales. Such an enhanced ${\\cal P}_{\\cal R}(k)$ will result in primordial black\nholes (PBHs), contributing a significant fraction of dark matter, and will\nsimultaneously generate sizable scalar-induced gravitational waves (SIGWs) as a\nsecondorder effect. In this work, we calculate the PBH abundances $f_{\\rm\nPBH}(M)$ and SIGW spectra $\\Omega_{\\rm GW}(f)$ in peak theory. We obtain the\nPBHs with desirable abundances in one or two typical mass windows at\n$10^{-17}\\, M_\\odot$, $10^{-13}\\, M_\\odot$, and $30\\, M_\\odot$, respectively.\nAt the same time, the relevant SIGWs are expected to be observed by the\nnext-generation gravitational wave detectors, without spoiling the current\nconstraint. Especially, the SIGW associated with the PBH of $30\\, M_\\odot$ can\nalso interpret the potential isotropic stochastic gravitational wave background\nfrom the NANOGrav 12.5-year dataset.\n", "  The abundance, temperature, and clustering of metals in the intergalactic\nmedium are important parameters for understanding their cosmic evolution and\nquantifying their impact on cosmological analysis with the Ly $\\alpha$ forest.\nThe properties of these systems are typically measured from individual quasar\nspectra redward of the quasar's Ly $\\alpha$ emission line, yet that approach\nmay provide biased results due to selection effects. We present an alternative\napproach to measure these properties in an unbiased manner with the two-point\nstatistics commonly employed to quantify large-scale structure. Our model\ntreats the observed flux of a large sample of quasar spectra as a continuous\nfield and describes the one-dimensional, two-point statistics of this field\nwith three parameters per ion: the abundance (column density distribution),\ntemperature (Doppler parameter) and clustering (cloud-cloud correlation\nfunction). We demonstrate this approach on multiple ions (e.g., C IV, Si IV, Mg\nII) with early data from the Dark Energy Spectroscopic Instrument (DESI) and\nhigh-resolution spectra from the literature. Our initial results show some\nevidence that the C IV abundance is higher than previous measurements and\nevidence for abundance evolution over time. The first full year of DESI\nobservations will have over an order of magnitude more quasar spectra than this\nstudy. In a future paper we will use those data to measure the growth of\nclustering and its impact on the Ly $\\alpha$ forest, as well as test other DESI\nanalysis infrastructure such as the pipeline noise estimates and the resolution\nmatrix.\n", "  Blind cleaning methods are currently the preferred strategy for handling\nforeground contamination in single-dish HI intensity mapping surveys. Despite\nthe increasing sophistication of blind techniques, some signal loss will be\ninevitable across all scales. Constructing a corrective transfer function using\nmock signal injection into the contaminated data has been a practice relied on\nfor HI intensity mapping experiments. However, assessing whether this approach\nis viable for future intensity mapping surveys where precision cosmology is the\naim, remains unexplored. In this work, using simulations, we validate for the\nfirst time the use of a foreground transfer function to reconstruct power\nspectra of foreground-cleaned low-redshift intensity maps and look to expose\nany limitations. We reveal that even when aggressive foreground cleaning is\nrequired, which causes ${>}\\,50\\%$ negative bias on the largest scales, the\npower spectrum can be reconstructed using a transfer function to within\nsub-percent accuracy. We specifically outline the recipe for constructing an\nunbiased transfer function, highlighting the pitfalls if one deviates from this\nrecipe, and also correctly identify how a transfer function should be applied\nin an auto-correlation power spectrum. We validate a method that utilises the\ntransfer function variance for error estimation in foreground-cleaned power\nspectra. Finally, we demonstrate how incorrect fiducial parameter assumptions\n(up to ${\\pm}100\\%$ bias) in the generation of mocks, used in the construction\nof the transfer function, do not significantly bias signal reconstruction or\nparameter inference (inducing ${<}\\,5\\%$ bias in recovered values).\n", "  The halo occupation distribution (HOD) framework is an empirical method to\ndescribe the connection between dark matter halos and galaxies, which is\nconstrained by small scale clustering data. Efficient fitting procedures are\nrequired to scan the HOD parameter space. This paper describes such a method\nbased on Gaussian Processes to iteratively build a surrogate model of the\nposterior of the likelihood surface from a reasonable amount of likelihood\ncomputations, typically two orders of magnitude less than standard Monte Carlo\nMarkov chain algorithms. Errors in the likelihood computation due to stochastic\nHOD modelling are also accounted for in the method we propose. We report\nresults of reproducibility, accuracy and stability tests of the method derived\nfrom simulation, taking as a test case star-forming emission line galaxies,\nwhich constitute the main tracer of the Dark Energy Spectroscopic Instrument\nand have so far a poorly constrained galaxy-halo connection from observational\ndata.\n", "  The growth of large-scale structure, as revealed in the anisotropic of\nclustering of galaxies in the low redshift Universe, provides a stringent test\nof our cosmological model. The strongest current constraints come from the BOSS\nand eBOSS surveys, with uncertainties on the amplitude of clustering of less\nthan 10 per cent. A number of different approaches have been taken to fitting\nthis signal, leading to apparently discrepant conclusions about the amplitude\nof fluctuations at late times. We compare in some detail two of the leading\napproaches, one based on a fitting a template cosmology whose amplitude and\nlength scales are allowed to float with one based on a more traditional forward\nmodeling approach, when fitting to the BOSS DR12 data. Holding the input data,\nscale cuts, window functions and modeling framework fixed we are able to\nisolate the cause of the differences and discuss the implications for future\nsurveys.\n", "  The position of the peak of the matter power spectrum, the so-called turnover\nscale, is set by the horizon size at the epoch of matter-radiation equality. It\ncan easily be predicted in terms of the physics of the Universe in the\nrelativistic era, and so can be used as a standard ruler, independent of other\nfeatures present in the matter power spectrum, such as baryon acoustic\noscillations (BAO). We use the distribution of quasars measured by the extended\nBaryon Oscillation Spectroscopic Survey (eBOSS) to determine the turnover scale\nin a model-independent fashion statistically. We avoid modelling the BAO by\ndown-weighting affected scales in the covariance matrix using the mode\ndeprojection technique. We measure the wavenumber of the peak to be\n$k_\\mathrm{TO} = \\left( 17.6^{+1.9}_{-1.8} \\right) \\times\n10^{-3}h/\\mathrm{Mpc}$, corresponding to a dilation scale of $\nD_\\mathrm{V}(z_\\mathrm{eff} = 1.48) =\n\\left({36.2^{+4.1}_{-4.4}}\\right)r_\\mathrm{H}$. This is not competitive with\ncurrent BAO distance measures in terms of determining the expansion history but\ndoes provide a useful cross-check. We combine this measurement with\nlow-redshift distance measurements from type-Ia supernova data from Pantheon\nand BAO data from eBOSS to make a sound-horizon free estimate of the\nHubble-Lema\\^itre parameter and find it to be $H_0=\\left({74.7\\pm 9.6}\\right) \\\n\\mathrm{km/s/Mpc}$ with Pantheon, and $H_0=\\left({72.9^{+10.0}_{-8.6}}\\right) \\\n\\mathrm{km/s/Mpc}$ with eBOSS BAO. We make predictions for the measurement of\nthe turnover scale by the Dark Energy Spectroscopic Instrument (DESI) survey,\nthe Maunakea Spectroscopic Explorer (MSE) and MegaMapper, which will make more\nprecise and accurate distance determinations.\n", "  Despite the tremendous advance of observational cosmology, the value of the\nHubble constant ($H_0$) is still controversial (the so called ``Hubble\ntension'') because of the inconsistency between local/late-time measurements\nand those derived from the cosmic microwave background. As the age of the\nUniverse is very sensitive to $H_0$, we explored whether the present-day oldest\nstars could place independent constraints on the Hubble constant. To this\npurpose, we selected from the literature the oldest objects (globular clusters,\nstars, white dwarfs, ultra-faint and dwarf spheroidal galaxies) with accurate\nage estimates. Adopting a conservative prior on their formation redshifts ($11\n\\leq z_{\\rm f} \\leq 30$) and assuming $\\Omega_{\\rm M} = 0.3 \\pm 0.02$, we\ndeveloped a method based on Bayesian statistics to estimate the Hubble\nconstant. We selected the oldest objects ($>13.3$ Gyr) and estimated $H_0$ both\nfor each of them individually and for the average ages of homogeneous\nsubsamples. Statistical and systematic uncertainties were properly taken into\naccount. The constraints based on individual ages indicate that $H_0<70.6$\nkm/s/Mpc when selecting the most accurate estimates. If the ages are averaged\nand analyzed independently for each subsample, the most stringent constraints\nimply $H_0<73.0$ with a probability of 90.3% and errors around 2.5 km/s/Mpc. We\nalso constructed an ``accuracy matrix'' to assess how the constraints on $H_0$\nbecome more stringent with further improvements in the accuracy of stellar ages\nand $\\Omega_{\\rm M}$. The results show the high potential of the oldest stars\nas independent and competitive cosmological probes not only limited to the\nHubble constant.\n", "  On the largest scales, galaxies are pulled together by gravity to form\nclusters, which are connected by filaments making a web-like pattern. Radio\nemission is predicted from this cosmic web, which should originate from the\nstrong accretion shocks around the cosmic structures. We present the first\nobservational evidence that Fermi-type acceleration from strong shocks\nsurrounding the filaments of the cosmic web, as well as in peripherals of\nlow-mass clusters, is at work in the Universe. Using all-sky radio maps and\nstacking on clusters and filaments, we have detected the polarization signature\nof the synchrotron emission with polarization fractions >= 20%, which is best\nexplained by the organization of local magnetic fields by strong shock waves\nboth at the cluster peripheries and between clusters. Our interpretation is\nwell supported by a detailed comparison with state-of-the-art cosmological\nsimulations.\n", "  The characteristic signatures of massive neutrinos on large-scale structure\n(LSS), if fully captured, can be used to put a stringent constraint on their\nmass sum, $M_{\\nu}$. Previous work utilizing N-body simulations has shown the\nMinkowski functionals (MFs) of LSS can reveal the imprints of massive neutrinos\non LSS, provide important complementary information to two-point statistics and\nsignificantly improve constraints on $M_{\\nu}$. In this work, we take a step\nforward and apply the statistics to the biased tracers of LSS, i.e. the\ngalaxies, and in redshift space. We perform a Fisher matrix analysis and\nquantify the constraining power of the MFs by using the Molino mock galaxy\ncatalogs, which are constructed based on the halo occupation distribution (HOD)\nframework with parameters for the SDSS $M_r < -21.5$ and -22 galaxy samples. We\nfind the MFs give tighter constraints on all of the cosmological parameters\nthat we consider than the power spectrum. The constraints on\n$\\Omega_{\\mathrm{m}}, \\Omega_{\\mathrm{b}}, h, n_s, \\sigma_8$, and $M_\\nu$ from\nthe MFs are better by a factor of 1.9, 2.9, 3.7, 4.2, 2.5, and 5.7,\nrespectively, after marginalizing over the HOD parameters. Specifically, for\n$M_{\\nu}$, we obtain a 1$\\sigma$ constraint of 0.059 eV with the MFs alone for\na volume of only $\\left(1 h^{-1} \\mathrm{Gpc}\\right)^3$.\n", "  In weak-lensing cosmological studies, peak statistics is sensitive to\nnonlinear structures and thus complementary to cosmic shear two-point\ncorrelations. In this paper, we explore a new approach, namely, the peak\nsteepness statistics, with the overall goal to understand the cosmological\ninformation embedded there in comparison with the commonly used peak height\nstatistics. We perform the analyses with ray-tracing simulations considering\ndifferent sets of cosmological parameters $\\Omega_{\\rm m}$ and $\\sigma_8$. A\ntheoretical model to calculate the abundance of high peaks based on steepness\nis also presented, which can well describe the main trend of the peak\ndistribution from simulations. We employ $\\Delta\\chi^2$ and Fisher analyses to\nstudy the cosmological dependence of the two peak statistics using our limited\nsets of simulations as well as our theoretical model. Within our considerations\nwithout including potential systematic effects, the results show that the\nsteepness statistics tends to have higher sensitivities to the cosmological\nparameters than the peak height statistics and this advantage is diluted with\nthe increase of the shape noise. Using the theoretical model, we investigate\nthe physical reasons accounting for the different cosmological information\nembedded in the two statistics. Our analyses indicate that the projection\neffect from large-scale structures plays an important role to enhance the gain\nfrom the steepness statistics. The redshift and cosmology dependence of dark\nmatter halo density profiles also contributes to the differences between the\ntwo statistics.\n", "  Recently, several studies reported a significant discrepancy between the\nclustering and lensing of the Baryon Oscillation Spectroscopic Survey (BOSS)\ngalaxies in the $\\textit{Planck}$ cosmology. We construct a simple yet powerful\nmodel based on the linear theory to assess whether this discrepancy points\ntoward deviations from $\\textit{Planck}$. Focusing on scales $10<R<30$\n$h^{-1}\\mathrm{Mpc}$, we model the amplitudes of clustering and lensing of BOSS\nLOWZ galaxies using three parameters: galaxy bias $b_\\mathrm{g}$, galaxy-matter\ncross-correlation coefficient $r_\\mathrm{gm}$, and $A$, defined as the ratio\nbetween the true and $\\textit{Planck}$ values of $\\sigma_8$. Using the\ncross-correlation matrix as a diagnostic, we detect systematic uncertainties\nthat drive spurious correlations among the low-mass galaxies. After building a\nclean LOWZ sample with $r_\\mathrm{gm}\\sim1$, we derive a joint constraint of\n$b_\\mathrm{g}$ and $A$ from clustering+lensing, yielding\n$b_\\mathrm{g}=2.47_{-0.30}^{+0.36}$ and $A=0.81_{-0.09}^{+0.10}$, i.e., a\n$2\\sigma$ tension with $\\textit{Planck}$. However, due to the strong degeneracy\nbetween $b_\\mathrm{g}$ and $A$, systematic uncertainties in $b_\\mathrm{g}$\ncould masquerade as a tension with $A=1$. To ascertain this possibility, we\ndevelop a new method to measure $b_\\mathrm{g}$ from the cluster-galaxy\ncross-correlation and cluster weak lensing using an overlapping cluster sample.\nBy applying the independent bias measurement ($b_\\mathrm{g}=1.76\\pm0.22$) as a\nprior, we successfully break the degeneracy and derive stringent constraints of\n$b_\\mathrm{g}=2.02_{-0.15}^{+0.16}$ and $A=0.96\\pm0.07$. Therefore, our result\nsuggests that the large-scale clustering and lensing of LOWZ galaxies are\nconsistent with $\\textit{Planck}$, while the different bias estimates may be\nrelated to some observational systematics in the target selection.\n", "  We discuss the potential of the multi-tracer technique to improve\nobservational constraints of the local primordial non-Gaussianity (PNG)\nparameter $f_{\\rm NL}$ from the galaxy power spectrum. For two galaxy samples\n$A$ and $B$, the constraining power is $\\propto |b_1^B b_\\phi^A -\nb_1^Ab_\\phi^B|$, where $b_1$ and $b_\\phi$ are the linear and PNG galaxy bias\nparameters. We show this allows for significantly improved constraints compared\nto the traditional expectation $\\propto |b_1^A - b_1^B|$ based on naive\nuniversality-like relations where $b_\\phi \\propto b_1$. Using IllustrisTNG\ngalaxy simulation data, we find that different equal galaxy number splits of\nthe full sample lead to different $|b_1^B b_\\phi^A - b_1^Ab_\\phi^B|$, and thus\nhave different constraining power. Of all of the strategies explored, splitting\nby $g-r$ color is the most promising, more than doubling the significance of\ndetecting $f_{\\rm NL}b_\\phi \\neq 0$. Importantly, since these are constraints\non $f_{\\rm NL}b_\\phi$ and not $f_{\\rm NL}$, they do not require priors on the\n$b_\\phi(b_1)$ relation. For direct constraints on $f_{\\rm NL}$, we show that\nmulti-tracer constraints can be significantly more robust than single-tracer to\n$b_\\phi$ misspecifications and uncertainties; this relaxes the precision and\naccuracy requirements for $b_\\phi$ priors. Our results present new\nopportunities to improve our chances to detect and robustly constrain $f_{\\rm\nNL}$, and strongly motivate galaxy formation simulation campaigns to calibrate\nthe $b_\\phi(b_1)$ relation.\n", "  We present the measurements of the small-scale clustering for the emission\nline galaxy (ELG) sample from the extended Baryon Oscillation Spectroscopic\nSurvey (eBOSS) in the Sloan Digital Sky Survey IV (SDSS-IV). We use conditional\nabundance matching method to interpret the clustering measurements from\n$0.34h^{-1}\\textrm{Mpc}$ to $70h^{-1}\\textrm{Mpc}$. In order to account for the\ncorrelation between properties of emission line galaxies and their environment,\nwe add a secondary connection between star formation rate of ELGs and halo\naccretion rate. Three parameters are introduced to model the ELG [OII]\nluminosity and to mimic the target selection of eBOSS ELGs. The parameters in\nour models are optimized using Markov Chain Monte Carlo (MCMC) method. We find\nthat by conditionally matching star formation rate of galaxies and the halo\naccretion rate, we are able to reproduce the eBOSS ELG small scale clustering\nwithin 1$\\sigma$ error level. Our best fit model shows that the eBOSS ELG\nsample only consists of $\\sim 12\\%$ of all star-forming galaxies, and the\nsatellite fraction of eBOSS ELG sample is 19.3\\%. We show that the effect of\nassembly bias is $\\sim20\\%$ on the two-point correlation function and $\\sim5\\%$\non the void probability function at scale of $r\\sim 20 h^{-1}\\rm Mpc$.\n", "  This study examines interacting quintessence dark energy models and their\nobservational constraints for a general parameterization of the quintessence\npotential, which encompasses a broad range of popular potentials. Four\ndifferent forms of interactions are considered. The analysis is done by\nexpressing the system as a set of autonomous equations for each interaction.\nThe Bayesian Model Comparison has been used to compare these models with the\nstandard Lambda Cold Dark Matter ({\\Lambda}CDM) model. Our analysis shows\npositive and moderate evidence for the interacting models over the {\\Lambda}CDM\nmodel.\n", "  We investigate the fraction of baryon mass in intergalactic medium\n($f_\\mathrm{IGM}$), using 18 well-localized FRBs in the redshift range $z\\in\n(0.0039,0.66)$. We construct a five-parameter Bayesian inference model, with\nthe probability distributions of dispersion measures (DM) of IGM and host\ngalaxy properly taken into account. To check the possible redshift evolution,\nwe parameterize $f_\\mathrm{IGM}$ as a mildly evolving function of redshift,\n$f_\\mathrm{IGM}=f_\\mathrm{IGM,0}[1+\\alpha z/(1+z)]$. By simultaneously\nconstraining five parameters, we get $f_\\mathrm{IGM,0} = 0.92^{+0.06}_{-0.12}$\nand $\\alpha = 0.49^{+0.59}_{-0.47}$, and the median value of DM of host galaxy\nis $\\exp(\\mu)=72.49^{+33.31}_{-25.62}~{\\rm pc ~ cm ^ {-3}}$. By fixing two\nparameters which can be constrained independently with other observations, we\nobtain $\\alpha =0.11^{+0.24}_{-0.27}$ in the three-parameter fit, which is\nconsistent with zero within $1\\sigma$ uncertainty. Monte Carlo simulations show\nthat even 300 FRBs are not enough to tightly constrain five parameters\nsimultaneously. This is mainly caused by the correlation between parameters.\nOnly if two parameters are fixed, 100 FRBs are necessary to achieve unbiased\nconstraints on the remaining parameters.\n", "  The number counts of homogeneous samples of radio sources are a tried and\ntrue method of probing the large scale structure of the Universe, as most radio\nsources outside the galactic plane are at cosmological distances. As such they\nare expected to trace the cosmic radio dipole, an anisotropy analogous to the\ndipole seen in the cosmic microwave background (CMB). Results have shown that\nalthough the cosmic radio dipole matches the direction of the CMB dipole, it\nhas a significantly larger amplitude. This result challenges our assumption of\nthe Universe being isotropic, which can have large repercussions for the\ncurrent cosmological paradigm. Though significant measurements have been made,\nsensitivity to the radio dipole is generally hampered by systematic effects\nthat can cause large biases in the measurement. Here we assess these\nsystematics with data from the MeerKAT Absorption Line Survey (MALS). We\npresent the analysis of ten MALS pointings, focusing on systematic effects that\ncould lead to an inhomogeneous catalogue. We describe the calibration and\ncreation of full band continuum images and catalogues, producing a combined\ncatalogue containing 16,313 sources and covering 37.5 square degrees of sky\ndown to a sensitivity of 10 $\\mu$Jy/beam. We measure the completeness, purity,\nand flux recovery statistics for these catalogues using simulated data. We\ninvestigate different source populations in the catalogues by looking at flux\ndensities and spectral indices, and how they might influence source counts.\nUsing the noise characteristics of the pointings, we find global measures that\ncan be used to correct for the incompleteness of the catalogue, producing\ncorrected number counts down to 100 - 200 $\\mu$Jy. We show that we can\nhomogenise the catalogues and properly account for systematic effects. We\ndetermine that we can measure the dipole to $3\\sigma$ significance with 100\nMALS pointings.\n", "  The relationship linking a galaxy cluster's total mass with the concentration\nof its mass profile and its redshift is a fundamental prediction of the Cold\nDark Matter (CDM) paradigm of cosmic structure formation. However, confronting\nthose predictions with observations is complicated by the fact that simulated\nclusters are not representative of observed samples where detailed mass profile\nconstraints are possible. In this work, we calculate the\nSymmetry-Peakiness-Alignment (SPA) morphology metrics for maps of X-ray\nemissivity from THE THREE HUNDRED project hydrodynamical simulations of galaxy\nclusters at four redshifts, and thereby select a sample of morphologically\nrelaxed, simulated clusters, using observational criteria. These clusters have\non average earlier formation times than the full sample, confirming that they\nare both morphologically and dynamically more relaxed than typical. We\nconstrain the concentration-mass-redshift relation of both the relaxed and\ncomplete sample of simulated clusters, assuming power-law dependences on mass\n($\\kappa_m$) and $1+z$ ($\\kappa_\\zeta$), finding $\\kappa_m = -0.12 \\pm 0.07$\nand $\\kappa_\\zeta = -0.27 \\pm 0.19$ for the relaxed subsample. From an\nequivalently selected sample of massive, relaxed clusters observed with ${\\it\nChandra}$, we find $\\kappa_m = -0.12 \\pm 0.08$ and $\\kappa_\\zeta = -0.48 \\pm\n0.19$, in good agreement with the simulation predictions. The simulated and\nobserved samples also agree well on the average concentration at a pivot mass\nand redshift providing further validation of the $\\Lambda$CDM paradigm in the\nproperties of the largest gravitationally collapsed structures observed. This\nalso represents the first clear detection of decreasing concentration with\nredshift, a longstanding prediction of simulations, in data.\n", "  The discovery of cosmic acceleration motivated extensive studies of dynamical\ndark energy and modified gravity models. Of particular interest are the\nscalar-tensor theories, with a scalar field dark energy non-minimally coupled\nto matter. Cosmological constraints on these models often employ the\nquasi-static approximation (QSA), in which the dynamics of the scalar field\nperturbations is proportional to the perturbation in the matter density. Using\nthe QSA simplifies the physical interpretation of the phenomenology of\nscalar-tensor theories, and results in substantial savings of computing time\nwhen deriving parameter constraints. Focusing on the symmetron model, which is\na well-motivated scalar-tensor theory with a screening mechanism, we compare\nthe exact solution of the linearly perturbed field equations to those obtained\nunder the QSA and identify the range of the model parameters for which the QSA\nis valid. We find that the evolution of background scalar field is most\nimportant, namely, whether it is dominated by the Hubble friction or the scalar\nfield potential. This helps us derive a criterion for the symmetron model, but\nsame argument can be applied to other scalar-tensor theories of generalized\nBrans-Dicke type. We consider two scenarios, one where the scalar field is only\ncoupled to dark matter and where it couples to all of the matter.\n", "  We present a survey strategy to detect the neutral hydrogen (HI) power\nspectrum at $5<z<6$ using the SKA-Low radio telescope in presence of\nforegrounds and instrumental effects. We simulate observations of the\ninherently weak HI signal post-reionization with varying levels of noise and\ncontamination with foreground amplitudes equivalent to residuals after sky\nmodel subtraction. We find that blind signal separation methods on imaged data\nare required in order to recover the HI signal at large cosmological scales.\nComparing different methods of foreground cleaning, we find that Gaussian\nProcess Regression (GPR) performs better than Principle Component Analysis\n(PCA), with the key difference being that GPR uses smooth kernels for the total\ndata covariance. The integration time of one field needs to be larger than\n$\\sim 250$ h to provide large enough signal-to-noise ratio (SNR) to accurately\nmodel the data covariance for foreground cleaning. Images within the primary\nbeam field-of-view give measurements of the HI power spectrum at scales $k\\sim\n0.02\\,{\\rm Mpc^{-1}}-0.3\\,{\\rm Mpc^{-1} }$ with SNR $\\sim 2-5$ in $\\Delta[{\\rm\nlog}( k/{\\rm Mpc^{-1}})] = 0.25$ bins assuming an integration time of $600$ h.\nSystematic effects, which introduce small-scale fluctuations across frequency\nchannels, need to be $\\lesssim 5\\times 10^{-5}$ to enable unbiased measurements\noutside the foreground wedge. Our results provide an important validation\ntowards using the SKA-Low array for measuring the HI power spectrum in the\npost-reionization Universe.\n", "  The Hot Big Bang is often considered as the origin of all matter and\nradiation in the Universe. Primordial nucleosynthesis (BBN) provides strong\nevidence that the early Universe contained a hot plasma of photons and baryons\nwith a temperature $T>\\text{MeV}$. However, the earliest probes of dark matter\noriginate from much later times around the epoch of structure formation. In\nthis work we describe a scenario in which dark matter (and possibly dark\nradiation) can be formed around or even after BBN in a second Big Bang which we\ndub the ``Dark Big Bang''. The latter occurs through a phase transition in the\ndark sector which transforms dark vacuum energy into a hot dark plasma of\nparticles; in this paper we focus on a first-order phase transition for the\nDark Big Bang. The correct dark matter abundance can be set by dark matter\ncannibalism or by pair-annihilation within the dark sector followed by a\nthermal freeze-out. Alternatively ultra-heavy ``dark-zilla'' dark matter can\noriginate directly from bubble collisions during the Dark Big Bang. We will\nshow that the Dark Big Bang is consistent with constraints from structure\nformation and the Cosmic Microwave Background (CMB) if it occurred when the\nUniverse was less than one month old, corresponding to a temperature in the\nvisible sector above $\\mathcal{O}$(keV). While the dark matter evades direct\nand indirect detection, the Dark Big Bang gives rise to striking gravity wave\nsignatures to be tested at pulsar timing array experiments. Furthermore, the\nDark Big Bang allows for realizations of self-interacting and/or warm dark\nmatter which suggest exciting discovery potential in future small-scale\nstructure observations.\n", "  Constraints on the linear growth rate, $f\\sigma_8$, using small scale\nredshift space distortion measurements have a significant statistical advantage\nover those made on large scales. However, these measurements need to carefully\ndisentangle the linear and non-linear information when interpreting redshift\nspace distortions in terms of $f\\sigma_8$. It is particularly important to do\nthis given that some previous measurements found a significant deviation from\nthe expectation based on the $\\Lambda$CDM model constrained by Planck CMB data.\nWe construct a new emulator-based model for small scale galaxy clustering with\nscaling parameters for both the linear and non-linear velocities of galaxies,\nallowing us to isolate the linear growth rate. We train the emulator using\nsimulations from the AbacusCosmos suite, and apply it to data from the extended\nBaryon Oscillation Spectroscopic Survey (eBOSS) luminous red galaxy sample. We\nobtain a value of $f\\sigma_8(z=0.737)=0.368\\pm0.041$, in 2.3-$\\sigma$ tension\nwith the Planck 2018 $\\Lambda$CDM expectation, and find less dependence on the\nminimum measurement scale than previous analyses.\n", "  It has been suggested recently that the appparent accelerated expansion of\nthe universe could be explained by a bias in the SNIa measurements. Such events\nindeed occur mainly in overdense regions, where matter is located, and whose\ndynamics can perhaps not been considered as representative of the one of the\nuniverse. In this article, we develop a model to investigate in more detail the\neffect of this bias. This model depends on one single parameter, related to the\nvoid fraction of space, and leads to simple analytical relations. We in\nparticular determine the average metric tensor in overdense regions, and deduce\nthat the scale factor and the rate at which time progresses in such regions\ndiffer significantly from the corresponding values expected on the average\nspace. We then quantitatively deduce how redshift and luminosity distance\nmeasurements are affected by the bias, taking into account the perturbation of\nthe metric tensor. Using a value for the void fraction corresponding to the\norder of magnitude found in the literature, we show that the model is able to\npredict a distance modulus versus redshift relation being in excellent\naggreement with the one corresponding to a universe characterized by\n$\\Omega_{m,0} = 0.3$ and $\\Omega_{\\Lambda,0} = 0.7$.\n", "  Cosmological analyses of second-order weak lensing statistics require precise\nand accurate covariance estimates. These covariances are impacted by two\nsometimes neglected terms: A negative contribution to the Gaussian covariance\ndue to finite survey area and the super-sample covariance (SSC) which for the\npower spectrum contains the impact by Fourier modes larger than the survey\nwindow. We show here that these two effects are connected and can be seen as\ncorrection terms to the \"large-field-approximation\", the asymptotic case of an\ninfinitely large survey area. We describe the two terms collectively as\n\"Finite-Field-Terms\".\n  We derive the covariance of second-order shear statistics from first\nprinciples. For this, we use an estimator in real space without relying on an\nestimator for the power spectrum. The resulting covariance does not scale\ninversely with the survey area, as naively assumed. This scaling is only\ncorrect under the large-field approximation when the contribution of the\nfinite-field terms tends to zero. Furthermore, all parts of the covariance, not\nonly the SSC, depend on the power- and trispectrum at all modes, including\nthose larger than the survey. We also show that it is generally impossible to\ntransform an estimate for the power spectrum covariance into the covariance of\na real-space statistic. Such a transformation is only possible in the\nasymptotic case of the \"large-field approximation\".\n  Additionally, we find that the total covariance of a real-space statistic can\nbe calculated using correlation functions estimates on spatial scales smaller\nthan the survey window. Consequently, estimating covariances of real-space\nstatistics, in principle, does not require information on spatial scales larger\nthan the survey area. We demonstrate that this covariance estimation method is\nequivalent to the standard sample covariance method.\n", "  Clusters of galaxies are sensitive to the most nonlinear peaks in the cosmic\ndensity field. The weak gravitational lensing of background galaxies by\nclusters can allow us to infer their masses. However, galaxies associated with\nthe local environment of the cluster can also be intrinsically aligned due to\nthe local tidal gradient, contaminating any cosmology derived from the lensing\nsignal. We measure this intrinsic alignment in Dark Energy Survey (DES) Year 1\nredMaPPer clusters. We find evidence of a non-zero mean radial alignment of\ngalaxies within clusters between redshift 0.1-0.7. We find a significant\nsystematic in the measured ellipticities of cluster satellite galaxies that we\nattribute to the central galaxy flux and other intracluster light. We attempt\nto correct this signal, and fit a simple model for intrinsic alignment\namplitude ($A_{\\textrm{IA}}$) to the measurement, finding\n$A_{\\textrm{IA}}=0.15\\pm 0.04$, when excluding data near the edge of the\ncluster. We find a significantly stronger alignment of the central galaxy with\nthe cluster dark matter halo at low redshift and with higher richness and\ncentral galaxy absolute magnitude (proxies for cluster mass). This is an\nimportant demonstration of the ability of large photometric data sets like DES\nto provide direct constraints on the intrinsic alignment of galaxies within\nclusters. These measurements can inform improvements to small-scale modeling\nand simulation of the intrinsic alignment of galaxies to help improve the\nseparation of the intrinsic alignment signal in weak lensing studies.\n", "  We construct accurate emulators for the projected and redshift space galaxy\ncorrelation functions and excess surface density as measured by galaxy-galaxy\nlensing, based on Halo Occupation Distribution (HOD) modeling. Using the\ncomplete Mira-Titan suite of 111 $N$-body simulations, our emulators vary over\neight cosmological parameters and include the effects of neutrino mass and\ndynamical dark energy. We demonstrate that our emulators are sufficiently\naccurate for the analysis of the BOSS DR12 CMASS galaxy sample over the range\n0.5 < r < 50 Mpc/h. Furthermore, we show that our emulators are capable of\nrecovering unbiased cosmological constraints from realistic mock catalogs over\nthe same range. Our mock catalog tests show the efficacy of combining small\nscale galaxy-galaxy lensing with redshift space clustering and that we can\nconstrain the growth rate and \\sigma_8 to 7% and 4.5% respectively for a\nCMASS-like sample using only the measurements covered by our emulator. With the\ninclusion of a CMB prior on H_0, this reduces to a 2% measurement on the growth\nrate.\n", "  The CMB is a powerful probe of early-universe physics but is only observed\nafter passing through large-scale structure, which changes the observed spectra\nin important model-dependent ways. This is of particular concern given recent\nclaims of significant discrepancies with low redshift data sets when a standard\n$\\Lambda$CDM model is assumed. By using empirical measurements of the CMB\nlensing reconstruction, combined with weak priors on the smoothness of the\nlensing spectrum, foregrounds, and shape of any additional integrated\nSachs-Wolfe effect, we show how the early-universe parameters can be\nconstrained from CMB observations almost independently of the late-time\nevolution. This provides a way to test new models for early-universe physics,\nand measure early-universe parameters, independently of late-time cosmology.\nUsing the empirical measurement of lensing keeps the size of the effect of\nlate-time modelling uncertainty under control, leading to only modest increases\nin error bars of most early-universe parameters compared to assuming a full\nevolution model. We provide robust constraints on early-$\\Lambda$CDM model\nparameters using the latest Planck PR4 data and show that with future data\nmarginalizing over a single lensing amplitude parameter is sufficient to remove\nsensitivity to late-time cosmological model only if the spectral shape matches\npredictions.\n", "  The 'optical depth-linear growth rate' ($\\tau_{\\rm T}-f$) degeneracy is a\nlong-standing problem in the kinetic Sunyaev Zel'dovich (kSZ) cosmology. It can\nbe spontaneously broken in redshift space, where the velocity field leaves its\nown distinct imprint on the galaxies' redshift space positions and provides\nvaluable information of the linear growth rate. We validate this idea with the\nFisher matrix and Monte Carlo Markov Chain techniques in this work, finding\nthat the level of this degeneracy breaking is further enhanced on non-linear\nscales due to the non-linear evolution of the density and velocity fields, if\nwe have a good prior knowledge of the non-linear bias of galaxies. This result\nemphasizes the importance of the redshift space analysis of the kSZ effect and\nits potential as a powerful cosmological probe, especially on non-linear\nscales. As a by-product, we develop a non-linear model of the redshift space\ndensity-weighted pairwise kSZ power spectrum. The fitted $f$ and $\\tau_{\\rm T}$\nvalues from this model are shown to be accurate within $1-2\\sigma$ ranges of\nthe fiducial ones when confronted to the mock galaxies mimicking a DESI+CMB-S4\nsurvey combination, even on small scales of $k\\sim 0.5h/{\\rm Mpc}$.\n", "  Weak gravitational lensing of the cosmic microwave background (CMB) carries\nimprints of the physics operating at redshifts much lower than that of\nrecombination and serves as an important probe of cosmological structure\nformation, dark matter physics, and the mass of neutrinos. Reconstruction of\nthe CMB lensing deflection field through use of quadratic estimators has proven\nsuccessful with existing data but is known to be sub-optimal on small angular\nscales ($\\ell > 3000$) for experiments with low noise levels. Future\nexperiments will provide better observations in this regime, but these\ntechniques will remain statistically limited by their approximations. We show\nthat correlations between fluctuations of the large-scale temperature gradient\npower of the CMB sourced by $\\ell < 2000$, and fluctuations to the local\nsmall-scale temperature power reveal a lensing signal which is prominent in\neven the real-space pixel statistics across a CMB temperature map. We present\nthe development of the Small Correlated Against Large Estimator (SCALE), a\nnovel estimator for the CMB lensing spectrum which offers promising\ncomplementary analysis alongside other reconstruction techniques in this\nregime. The SCALE method computes correlations between both the\nlarge/small-scale temperature gradient power in harmonic space, and it is able\nto quantitatively recover unbiased statistics of the CMB lensing field without\nthe need for map-level reconstruction. SCALE can outperform quadratic estimator\nsignal-to-noise by a factor of up to 1.5 in current and upcoming experiments\nfor CMB lensing power spectra $C_{6000<L<8000}^{\\phi\\phi}$.\n", "  Primordial B-mode detection is one of the main goals of current and future\ncosmic microwave background (CMB) experiments. However, the weak B-mode signal\nis overshadowed by several Galactic polarized emissions, such as thermal dust\nemission and synchrotron radiation. Subtracting foreground components from CMB\nobservations is one of the key challenges in searching for the primordial\nB-mode signal. Here, we construct a deep convolutional neural network (CNN)\nmodel, called \\texttt{CMBFSCNN} (Cosmic Microwave Background Foreground\nSubtraction with CNN), which can cleanly remove various foreground components\nfrom simulated CMB observational maps at the sensitivity of the CMB-S4\nexperiment. Noisy CMB Q (or U) maps are recovered with a mean absolute\ndifference of $0.018 \\pm 0.023\\ \\mu$K (or $0.021 \\pm 0.028\\ \\mu$K). To remove\nthe residual instrumental noise from the foreground-cleaned map, inspired by\nthe needlet internal linear combination method, we divide the whole data set\ninto two ``half-split maps,'' which share the same sky signal, but have\nuncorrelated noise, and perform a cross-correlation technique to reduce the\ninstrumental noise effects at the power spectrum level. We find that the CMB EE\nand BB power spectra can be precisely recovered with significantly reduced\nnoise effects. Finally, we apply this pipeline to current Planck observations.\nAs expected, various foregrounds are cleanly removed from the Planck\nobservational maps, with the recovered EE and BB power spectra being in good\nagreement with the official Planck results.\n", "  Combining the `time-delay distance' ($D_{\\Delta t}$) measurements from galaxy\nlenses and other distance indicators provides model-independent determinations\nof the Hubble constant ($H_0$) and spatial curvature ($\\Omega_{K,0}$), only\nbased on the validity of the Friedmann-Lema\\^itre-Robertson-Walker (FLRW)\nmetric and geometrical optics. To take the full merit of combining $D_{\\Delta\nt}$ measurements in constraining $H_0$, we use gamma-ray burst (GRB) distances\nto extend the redshift coverage of lensing systems much higher than that of\nType Ia Supernovae (SNe Ia) and even higher than quasars, whilst the general\ncosmography with a curvature component is implemented for the GRB distance\nparametrizations. Combining Lensing+GRB yields $H_0=71.5^{+4.4}_{-3.0}$~km\ns$^{-1}$Mpc$^{-1}$ and $\\Omega_{K,0} = -0.07^{+0.13}_{-0.06}$ (1$\\sigma$). A\nflat-universe prior gives slightly an improved $H_0 = 70.9^{+4.2}_{-2.9}$~km\ns$^{-1}$Mpc$^{-1}$. When combining Lensing+GRB+SN Ia, the error bar $\\Delta\nH_0$ falls by 25\\%, whereas $\\Omega_{K,0}$ is not improved due to the\ndegeneracy between SN Ia absolute magnitude, $M_B$, and $H_0$ along with the\nmismatch between the SN Ia and GRB Hubble diagrams at $z\\gtrsim 1.4$. Future\nincrement of GRB observations can help to moderately eliminate the $M_B-H_0$\ndegeneracy in SN Ia distances and ameliorate the restrictions on cosmographic\nparameters along with $\\Omega_{K,0}$ when combining Lensing+SN Ia+GRB. We\nconclude that there is no evidence of significant deviation from a (an) flat\n(accelerating) universe and $H_0$ is currently determined at 3\\% precision. The\nmeasurements show great potential to arbitrate the $H_0$ tension between the\nlocal distance ladder and cosmic microwave background measurements and provide\na relevant consistency test of the FLRW metric.\n", "  We analysed the 3D clustering of the Planck sample of Sunyaev-Zeldovich (SZ)\nselected galaxy clusters, focusing on the redshift-space two-point correlation\nfunction (2PCF). We compared our measurements to theoretical predictions of the\nstandard $\\Lambda$ cold dark matter ($\\Lambda$CDM) cosmological model, deriving\nan estimate of the Planck mass bias, $b_{\\mathrm SZ}$, and cosmological\nparameters. We measured the 2PCF of the sample in the cluster-centric radial\nrange $r\\in[10,150]$ $h^{-1}$Mpc, considering 920 galaxy clusters with redshift\n$z\\leq0.8$. A Markov chain Monte Carlo analysis has been performed to constrain\n$b_{\\mathrm SZ}$, assuming priors on cosmological parameters from Planck Cosmic\nMicrowave Background (CMB) results. We also adopted priors on $b_{\\mathrm SZ}$\nfrom external data sets to constrain the cosmological parameters\n$\\Omega_{\\mathrm m}$ and $\\sigma_8$. We obtained $(1-b_{\\mathrm\nSZ})=0.62^{+0.14}_{-0.11}$, which is in agreement with the value required to\nreconcile primary CMB and cluster count observations. By adopting priors on\n$(1-b_{\\mathrm SZ})$ from external data sets, we derived results on\n$\\Omega_{\\mathrm m}$ that are fully in agreement and competitive, in terms of\nuncertainties, with those derived from cluster counts. This confirms the\nimportance of including clustering in cosmological studies, in order to fully\nexploit the information from galaxy cluster statistics. On the other hand, we\nfound that $\\sigma_8$ is not constrained.\n", "  We discover analytic equations that can infer the value of $\\Omega_{\\rm m}$\nfrom the positions and velocity moduli of halo and galaxy catalogues. The\nequations are derived by combining a tailored graph neural network (GNN)\narchitecture with symbolic regression. We first train the GNN on dark matter\nhalos from Gadget N-body simulations to perform field-level likelihood-free\ninference, and show that our model can infer $\\Omega_{\\rm m}$ with $\\sim6\\%$\naccuracy from halo catalogues of thousands of N-body simulations run with six\ndifferent codes: Abacus, CUBEP$^3$M, Gadget, Enzo, PKDGrav3, and Ramses. By\napplying symbolic regression to the different parts comprising the GNN, we\nderive equations that can predict $\\Omega_{\\rm m}$ from halo catalogues of\nsimulations run with all of the above codes with accuracies similar to those of\nthe GNN. We show that by tuning a single free parameter, our equations can also\ninfer the value of $\\Omega_{\\rm m}$ from galaxy catalogues of thousands of\nstate-of-the-art hydrodynamic simulations of the CAMELS project, each with a\ndifferent astrophysics model, run with five distinct codes that employ\ndifferent subgrid physics: IllustrisTNG, SIMBA, Astrid, Magneticum,\nSWIFT-EAGLE. Furthermore, the equations also perform well when tested on galaxy\ncatalogues from simulations covering a vast region in parameter space that\nsamples variations in 5 cosmological and 23 astrophysical parameters. We\nspeculate that the equations may reflect the existence of a fundamental physics\nrelation between the phase-space distribution of generic tracers and\n$\\Omega_{\\rm m}$, one that is not affected by galaxy formation physics down to\nscales as small as $10~h^{-1}{\\rm kpc}$.\n", "  In this paper we show how response function corrections to shear measurements\n(e.g. as required by Metacalibration) propagate into cosmic shear power\nspectra. We investigate a 2-sphere pixel (also known as HEALpixel') correction\nand a forward-modelling approach using simple Gaussian simulations. In the\n2-sphere pixel-correction approach we find a free parameter that is the\ntolerated condition number of the local response matrices: if this is too large\nthen this can cause an amplification of the shot noise power spectrum, if too\nsmall it can lead to a loss of area (and a possible selection bias). In\ncontrast by forward-modelling the power spectrum this choice can be avoided.\nThis also applies to map-based inference methods using shear-response\ncalibrated maps.\n", "  We propose a machine learning approach to the blind detection of\nextragalactic point sources on maps of the temperature anisotropies of the\ncosmic microwave background. Using realistic simulations of the microwave sky\nas seen by Planck, we train a convolutional neural network (CNN) that solves\nsource detection as an image segmentation problem. We divide the sky into\nregions of progressively increasing Galactic foreground intensity and\nindependently train specialized CNNs for each region. This strategy leads to\npromising levels of completeness and reliability, with our CNN substantially\noutperforming traditional detection methods like the matched filter in regions\nclose to the Galactic plane.\n", "  We evaluate the effectiveness of deep learning (DL) models for reconstructing\nthe masses of galaxy clusters using X-ray photometry data from next-generation\nsurveys. We establish these constraints using a catalogue of realistic mock\neROSITA X-ray observations which use hydrodynamical simulations to model\nrealistic cluster morphology, background emission, telescope response, and AGN\nsources. Using bolometric X-ray photon maps as input, DL models achieve a\npredictive mass scatter of $\\sigma_{\\ln M_\\mathrm{500c}} = 17.8\\%$, a factor of\ntwo improvements on scalar observables such as richness $N_\\mathrm{gal}$, 1D\nvelocity dispersion $\\sigma_\\mathrm{v,1D}$, and photon count $N_\\mathrm{phot}$\nas well as a $32\\%$ improvement upon idealised, volume-integrated measurements\nof the bolometric X-ray luminosity $L_X$. We then show that extending this\nmodel to handle multichannel X-ray photon maps, separated in low, medium, and\nhigh energy bands, further reduces the mass scatter to $16.2\\%$. We also tested\na multimodal DL model incorporating both dynamical and X-ray cluster probes and\nachieved marginal gains at a mass scatter of $15.9\\%$. Finally, we conduct a\nquantitative interpretability study of our DL models and find that they greatly\ndown-weight the importance of pixels in the centres of clusters and at the\nlocation of AGN sources, validating previous claims of DL modelling\nimprovements and suggesting practical and theoretical benefits for using DL in\nX-ray mass inference.\n", "  We present a detailed analysis of numerical discreteness errors in\ntwo-species, gravity-only, cosmological simulations using the density power\nspectrum as a diagnostic probe. In a simple setup where both species are\ninitialized with the same total matter transfer function, biased growth of\npower forms on small scales when the solver force resolution is finer than the\nmean interparticle separation. The artificial bias is more severe when\nindividual density and velocity transfer functions are applied. In particular,\nsignificant large-scale offsets in power are measured between simulations with\nconventional offset grid initial conditions when compared against converged\nhigh-resolution results where the force resolution scale is matched to the\ninterparticle separation. These offsets persist even when the cosmology is\nchosen so that the two particle species have the same mass, indicating that the\nerror is sourced from discreteness in the total matter field as opposed to\nunequal particle mass. We further investigate two mitigation strategies to\naddress discreteness errors: the frozen potential method and softened\ninterspecies short-range forces. The former evolves particles under the\napproximately \"frozen\" total matter potential in linear theory at early times,\nwhile the latter filters cross-species gravitational interactions on small\nscales in low density regions. By modeling closer to the continuum limit, both\nmitigation strategies demonstrate considerable reductions in large-scale power\nspectrum offsets.\n", "  Measurements of the growth rate of structures at $z < 0.1$ with peculiar\nvelocity surveys have the potential of testing the validity of general\nrelativity on cosmic scales. In this work, we present growth-rate measurements\nfrom realistic simulated sets of type-Ia supernovae (SNe Ia) from the Zwicky\nTransient Facility (ZTF). We describe our simulation methodology, the\nlight-curve fitting and peculiar velocity estimation. Using the maximum\nlikelihood method, we derive constraints on $f\\sigma_8$ using only ZTF SN Ia\npeculiar velocities. We carefully tested the method and we quantified biases\ndue to selection effects (photometric detection, spectroscopic follow-up for\ntyping) on several independent realizations. We simulated the equivalent of 6\nyears of ZTF data, and considering an unbiased spectroscopically typed sample\nat $z < 0.06$, we obtained unbiased estimates of $f\\sigma_8$ with an average\nuncertainty of 19% precision. We also investigated the information gain in\napplying bias correction methods. Our results validate our framework which can\nbe used on real ZTF data.\n", "  We use the emulation framework CosmoPower to construct and publicly release\nneural network emulators of cosmological observables, including the Cosmic\nMicrowave Background (CMB) temperature and polarization power spectra, matter\npower spectrum, distance-redshift relation, baryon acoustic oscillation (BAO)\nand redshift-space distortion (RSD) observables, and derived parameters. We\ntrain our emulators on Einstein-Boltzmann calculations obtained with\nhigh-precision numerical convergence settings, for a wide range of cosmological\nmodels including $\\Lambda$CDM, $w$CDM, $\\Lambda$CDM+$N_\\mathrm{eff}$, and\n$\\Lambda$CDM+$\\Sigma m_\\nu$. Our CMB emulators are accurate to better than 0.5%\nout to $\\ell=10^4$ which is sufficient for Stage-IV data analysis, and our\n$P(k)$ emulators reach the same accuracy level out to $k=50 \\,\\,\n\\mathrm{Mpc}^{-1}$, which is sufficient for Stage-III data analysis. We release\nthe emulators via an online repository CosmoPower Organisation, which will be\ncontinually updated with additional extended cosmological models. Our emulators\naccelerate cosmological data analysis by orders of magnitude, enabling\ncosmological parameter extraction analyses, using current survey data, to be\nperformed on a laptop. We validate our emulators by comparing them to CLASS and\nCAMB and by reproducing cosmological parameter constraints derived from Planck\nTT, TE, EE, and CMB lensing data, as well as from the Atacama Cosmology\nTelescope Data Release 4 CMB data, Dark Energy Survey Year-1 galaxy lensing and\nclustering data, and Baryon Oscillation Spectroscopic Survey Data Release 12\nBAO and RSD data.\n", "  A macroscopic and kinetic relativistic description for a decoupled\nmulti-fluid cosmology endowed with gravitationally induced particle production\nof all components is proposed. The temperature law for each decoupled particle\nspecies is also kinetically derived. The present approach points to the\npossibility of an exact (semi-classical) quantum-gravitational kinetic\ntreatment by incorporating back reaction effects for an arbitrary set of\ndominant decoupled components. As an illustration we show that a cosmology\ndriven by creation of cold dark matter and baryons (without dark energy)\nevolves like $\\Lambda$CDM. However, the complete physical emulation is broken\nwhen photon creation is added to the mixture thereby pointing to a crucial test\nin the future. The present analysis also open up a new window to investigate\nthe Supernova-CMB tension on the values of $H_0$, as well as the $S_8$ tension\nsince creation of all components changes slightly the CMB results and the\nexpansion history both at early and late times. Finally, it is also argued that\ncross-correlations between CMB temperature maps and the Sunyaev-Zeldovich\neffect may provide a crucial and accurate test confronting extended CCDM and\n$\\Lambda$CDM models.\n", "  We constrain the Chameleon \\textit{screening} mechanism in galaxy clusters,\nessentially obtaining limits on the coupling strength $\\beta$ and the\nasymptotic value of the field $\\phi_{\\infty}$. For this purpose, we utilized a\ncollection of the 9 relaxed galaxy clusters within the X-COP compilation in the\nredshift range of $z \\le 0.1$. We implement the formalism assuming an NFW mass\nprofile for the dark matter density and study the degeneracy present between\nthe mass $\\M$ and the chameleon coupling with a high degree of improvement in\nthe constraints for excluded parameter space. We recast our constrain to an\nupper limit on the scalaron field in \\fofr sub-class of models of $|f_{R0}|\\le\n9.2\\times 10^{-6}$, using all the nine clusters and $|f_{R0}|\\le 1.2\\times\n10^{-5}$ using only 5 clusters with WL priors taken into account, at a $95\\%$\nconfidence level. These bounds are consistent with existing limits in the\nliterature and tighter than the constraints obtained with the same method by\nprevious studies.\n", "  Context. Abell 1213, a low-richness galaxy system, is known to host an\nanomalous radio halo detected in data of the VLA. It is an outlier with regard\nto the relation between the radio halo power and the X-ray luminosity of the\nparent clusters. Aims. Our aim is to analyze the cluster in the optical, X-ray,\nand radio bands to characterize the environment of its diffuse radio emission\nand to shed new light on its nature. Methods. We used optical data from the\nSDSS to study the internal dynamics of the cluster. We also analyzed archival\nXMM-Newton X-ray data to unveil the properties of its hot intracluster medium.\nFinally, we used recent data from LOFAR at 144 MHz, together with VLA data at\n1.4 GHz, to study the spectral behavior of the diffuse radio source. Results.\nBoth our optical and X-ray analysis reveal that this low-mass cluster exhibits\ndisturbed dynamics. In fact, it is composed of several galaxy groups in the\nperipheral regions and, in particular, in the core, where we find evidence of\nsubstructures oriented in the NE-SW direction, with hints of a merger nearly\nalong the line of sight. The analysis of the X-ray emission adds further\nevidence that the cluster is in an unrelaxed dynamical state. At radio\nwavelengths, the LOFAR data show that the diffuse emission is ~510 kpc in size.\nMoreover, there are hints of low-surface-brightness emission permeating the\ncluster center. Conclusions. The environment of the diffuse radio emission is\nnot what we would expect for a classical halo. The spectral index map of the\nradio source is compatible with a relic interpretation, possibly due to a\nmerger in the N-S or NE-SW directions, in agreement with the substructures\ndetected through the optical analysis. The fragmented, diffuse radio emissions\nat the cluster center could be attributed to the surface brightness peaks of a\nfaint central radio halo.\n", "  A substantial fraction of the cosmic baryons is expected to hide in the form\nof diffuse warm-hot intergalactic medium (WHIM), the majority of which resides\nin the filaments of the Cosmic Web and has proven very difficult to detect due\nto its low density. Close to galaxy clusters, the filament gas is affected by\nthe cluster's gravitational potential and attains substantial infall\nvelocities, eventually undergoing a termination shock which may boost its X-ray\nsignal. We aim to identify the optimal locations of the enhanced X-ray emission\nand absorption arising from cluster-filament interactions, as well as improve\nour understanding of the various physical processes affecting the WHIM as it\napproaches the cluster. We applied the DisPerSE filament finder to the galaxy\ndistribution in the surroundings of a Coma-like ($M_{200} \\sim 10^{15.4}~{\\rm\nM}_{\\odot}$) simulated C-EAGLE galaxy cluster. We characterised the\nthermodynamic properties of the gas in such filaments as well as their\ndependence on distance from the cluster, and provided a physical interpretation\nfor the results. The identified filaments account for $\\sim 50$% of the hot\nWHIM ($T > 10^{5.5}$ K) in the cluster vicinity. The filament gas is in\napproximate free-fall all the way down to $\\sim 2 \\ r_{200}$ from the cluster,\nat which stage it begins to slow down due to the increasing pressure of the\nambient gas. The deceleration is accompanied by the conversion of gas bulk\nkinetic energy into heat and the increase of density and temperature from the\ngeneral Cosmic Web level of $\\rho \\sim 10\\rho_{\\rm av}$ and $T = 10^5-10^6$ K\ntowards $\\rho \\sim 100\\rho_{\\rm av}$ and $T = 10^7-10^8$ K near the cluster\nboundary. We conclude that the detection of the cosmic filaments of galaxies\naround clusters may provide a practical observational avenue for locating the\ndensest and hottest phase of the missing baryons.\n", "  CUSP is a powerful formalism that recovers, from first principles and with no\nfree parameter, all the macroscopic properties of dark matter haloes found in\ncosmological N-body simulations and unveils the origin of their characteristic\nfeatures. Since it is not restricted by the limitations of simulations, it\ncovers the whole mass and redshift ranges. In the present Paper we use CUSP to\ncalculate the mass-scale relations holding for halo density profiles fitted to\nthe usual NFW and Einasto functions in the most relevant cosmologies and for\nthe most usual mass definitions. We clarify the origin of these relations and\nprovide accurate analytic expressions holding for all masses and redshifts. The\nperformance of those expressions is compared to that of previous models and to\nthe mass-concentration relation spanning more than 20 orders of magnitude in\nmass at $z=0$ obtained in recent simulations of a 100 GeV WIMP universe.\n", "  In this work, we study the applications of entropy bounds in two toy\ncosmological models with particle production (annihilation), i.e., a\nradiation-dominated universe and a dust-dominated universe. We consider the\nco-moving volume and the volume covered by the particle horizon of a given\nobserver as the thermodynamic systems satisfying entropy bounds. For the\nBekenstein bound and the spherical entropy bound, it is found that the\ncosmological singularity can be avoided and cosmological particle production\nneeds to be truncated in some special cases. Our study can be extended to other\ncosmological models with particle production.\n", "  In this work we consider a class of interacting vacuum corresponding to a\ngeneralised Chaplygin gas (gCg) cosmology. In particular we analyse two\ndifferent scenarios at perturbation level for the same background interaction\ncharacterised by the parameter $\\alpha$: (i) matter that follows geodesics,\ncorresponding to homogeneous vacuum, and (ii) a covariant ansatz for vacuum\ndensity perturbations. In the latter case, we show that the vacuum\nperturbations are very tiny as compared to matter perturbations on sub-horizon\nscales. In spite of that, depending on the value of the Chaplygin gas parameter\n$\\alpha$, vacuum perturbations suppress or enhance the matter growth rate as\ncompared to the case (i). We use Cosmic Microwave Background (CMB), type Ia\nsupernovae (SNe) and Redshift Space Distortion (RSD) measurements to test the\nobservational viability of the model. We found that the mean value of our joint\nanalysis clearly favours a positive interaction, i.e., an energy flux from dark\nmatter to dark energy, with $\\alpha \\approx 0.143$ in both cases, while the\ncosmological standard model, recovered for $\\alpha$=0, is ruled out by\n3$\\sigma$ confidence level. Noteworthy, the positive value of interaction can\nalleviate both the $H_0$ and $S_8$ tension for the dataset considered here.\n", "  In recent years, large radio surveys of Active Galactic Nuclei (AGNs),\ncomprising millions of sources, have become available where one could\ninvestigate dipole asymmetries, assumedly arising due to a peculiar motion of\nthe Solar system. Investigations of such dipoles have yielded in past much\nlarger amplitudes than the cosmic microwave background (CMB) dipole, though\ntheir directions seem to lie close to the CMB dipole. Here we investigate\ndipole asymmetries in two recent large radio surveys, Very Large Array Sky\nSurvey (VLASS) containing 1.9 million sources, covering the sky north of\n$-40^\\circ$ declination, and the Rapid ASKAP Continuum Survey (RACS) containing\n2.1 million sources, covering the sky south of $+30^\\circ$ declination. We find\ndipoles determined from the VLASS and RACS surveys to be significantly larger\nthan the CMB dipole. Dipole directions from the VLASS and RACS data differ\nsignificantly from each other. Nevertheless, along with a number of other\npreviously determined dipoles, including the CMB, they all appear to lie in a\nnarrow sky region, which argues for the various dipoles to be related somehow.\nHowever, significant differences in their derived peculiar velocities,\nincluding that of the CMB, cannot be explained by a peculiar motion of the\nSolar system, which should necessarily be a single value. Instead, their\ndiscordant peculiar velocities may be indicating that different cosmic\nreference frames are moving relative to each other or that the matter\ndistribution on cosmic scales is not homogeneous and isotropic, either scenario\nbeing in contravention of what expected from the Cosmological Principle (CP).\n", "  Inhomogeneous reionization enhances the 1D Lyman-$\\alpha$ forest power\nspectrum on large scales at redshifts $z\\geq4$. This is due to coherent\nfluctuations in the ionized hydrogen fraction that arise from large-scale\nvariations in the post-reionization gas temperature, which fade as the gas\ncools. It is therefore possible to use these relic fluctuations to constrain\ninhomogeneous reionization with the power spectrum at wavenumbers\n$\\log_{10}(k/{\\rm km^{-1}\\,s})\\lesssim -1.5$. We use the Sherwood-Relics suite\nof hybrid radiation hydrodynamical simulations to perform a first analysis of\nnew Lyman-$\\alpha$ forest power spectrum measurements at $4.0\\leq z \\leq 4.6$.\nThese data extend to wavenumbers $\\log_{10}(k/{\\rm km^{-1}\\,s})\\simeq -3$, with\na relative uncertainty of $10$--$20$ per cent in each wavenumber bin. Our\nanalysis returns a $2.7\\sigma$ preference for an enhancement in the\nLyman-$\\alpha$ forest power spectrum at large scales, in excess of that\nexpected for a spatially uniform ultraviolet background. This large-scale\nenhancement could be a signature of inhomogeneous reionization, although the\nstatistical precision of these data is not yet sufficient for obtaining a\nrobust detection of the relic post-reionization fluctuations. We show that\nfuture power spectrum measurements with relative uncertainties of $\\lesssim\n2.5$ per cent should provide unambiguous evidence for an enhancement in the\npower spectrum on large scales.\n", "  Primordial black holes (PBHs) are black holes that might have formed in high\ndensity regions in the early universe. The presence of local-type\nnon-Gaussianity can lead to large-scale fluctuations in the PBH formation rate.\nIf PBHs make up a non-negligible fraction of dark matter, these fluctuations\ncan appear as isocurvature modes, and be used to constrain the amplitude of\nnon-Gaussianity. Assuming that the parameters of non-Gaussianity are constant\nover all scales, we build upon the results of previous work by extending the\ncalculation to include peaks theory and making use of the compaction $C$ for\nthe formation criteria, accounting for non-linearities between $C$ and the\ncurvature perturbation $\\zeta$. For quadratic models of non-Gaussianity, our\nupdated calculation gives constraints that are largely unaltered compared to\nthose previously found, while for cubic models the constraints worsen\nsignificantly. In case all of the DM is made up of PBHs, the parameters of\nnon-Gaussianity are $-2.9\\cdot10^{-4}<f<3.8\\cdot10^{-4}$ and\n$-1.5\\cdot10^{-3}<g<1.9\\cdot10^{-3}$ for quadratic and cubic models\nrespectively.\n", "  We present the first analysis of cosmic shear measured in DES Y3 that employs\nthe entire range of angular scales in the data. To achieve this, we build upon\nrecent advances in the theoretical modelling of weak lensing provided by a\ncombination of $N$-body simulations, physical models of baryonic processes, and\nneural networks. Specifically, we use BACCOemu to model the linear and\nnonlinear matter power spectrum including baryonic physics, allowing us to\nrobustly exploit scales smaller than those used by the DES Collaboration. We\nshow that the additional data produce cosmological parameters that are tighter\nbut consistent with those obtained from larger scales, while also constraining\nthe distribution of baryons. In particular, we measure the mass scale at which\nhaloes have lost half of their gas, $\\log\\,M_{\\rm\nc}=14.38^{+0.60}_{-0.56}\\log(h^{-1}{\\rm M_{ \\odot}})$, and a parameter that\nquantifies the weighted amplitudes of the present-day matter inhomogeneities,\n$S_8=0.799^{+0.023}_{-0.015}$. Our constraint on $S_8$ is statistically\ncompatible with that inferred from the Planck satellite's data at the\n$0.9\\sigma$ level. We find instead a $1.4\\sigma$ shift in comparison to that\nfrom the official DES Y3 cosmic shear, because of different choices in the\nmodelling of intrinsic alignment, non-linearities, baryons, and lensing shear\nratios. We conclude that small scales in cosmic shear data contain valuable\nastrophysical and cosmological information and thus should be included in\nstandard analyses.\n", "  Cosmic microwave background radiation (CMB) observations are unavoidably\ncontaminated by emission from various extra-galactic foregrounds, which must be\nremoved to obtain reliable measurements of the cosmological signal. In this\npaper, we demonstrate CMB lensing reconstruction in AliCPT-1 after foreground\nremoval, combine the two bands of AliCPT-1 (90 and 150~GHz) with Planck HFI\nbands (100, 143, 217 and 353~GHz) and with the WMAP-K band (23~GHz). In order\nto balance contamination by instrumental noise and foreground residual bias, we\nadopt the Needlet Internal Linear Combination (NILC) method to clean the E-map\nand the constrained Internal Linear Combination (cILC) method to clean the\nB-map. The latter utilizes additional constraints on average frequency scaling\nof the dust and synchrotron to remove foregrounds at the expense of somewhat\nnoisier maps. Assuming 4 modules observing 1 season from simulation data, the\nresulting effective residual noise in E- and B-map are roughly $15~\\mu{\\rm\nK}\\cdot{\\rm arcmin}$ and $25~\\mu{\\rm K}\\cdot{\\rm arcmin}$, respectively. As a\nresult, the CMB lensing reconstruction signal-to-noise ratio (SNR) from\npolarization data is about SNR$\\,\\approx\\,$4.5. This lensing reconstruction\ncapability is comparable to that of other stage-III small aperture millimeter\nCMB telescopes.\n", "  Massive neutrinos and $f(R)$ modified gravity have degenerate observational\nsignatures that can impact the interpretation of results in galaxy survey\nexperiments, such as cosmological parameter estimations and gravity model\ntests. Because of this, it is important to investigate astrophysical\nobservables that can break these degeneracies. Cosmic voids are sensitive to\nboth massive neutrinos and modifications of gravity and provide a promising\nground for disentangling the above mentioned degeneracies. In order to analyse\ncosmic voids in the context of non-$\\Lambda$CDM cosmologies, we must first\nunderstand how well the current theoretical framework operates in these\nsettings. We performed a suite of simulations with the RAMSES-based N-body code\nANUBISIS, including massive neutrinos and $f(R)$ modified gravity both\nindividually and simultaneously. The data from the simulations were compared to\nmodels of the void velocity profile and the void-halo cross-correlation\nfunction (CCF). This was done both with the real space simulation data as model\ninput and by applying a reconstruction method to the redshift space data. In\naddition, we ran Markov chain Monte Carlo (MCMC) fits on the data sets to\nassess the capability of the models to reproduce the fiducial simulation values\nof $f\\sigma_8(z)$ and the Alcock-Paczy\\`{n}ski parameter, $\\epsilon$. The void\nmodelling applied performs similarly for all simulated cosmologies, indicating\nthat more accurate models and higher resolution simulations are needed in order\nto directly observe the effects of massive neutrinos and $f(R)$ modified\ngravity through studies of the void-galaxy CCF. The MCMC fits show that the\nchoice of void definition plays an important role in the recovery of the\ncorrect cosmological parameters, but otherwise, there is no clear distinction\nbetween the ability to reproduce $f\\sigma_8$ and $\\epsilon$ for the various\nsimulations.\n", "  We present the cosmological implications of measurements of void-galaxy and\ngalaxy-galaxy clustering from the Sloan Digital Sky Survey (SDSS) Main Galaxy\nSample (MGS), Baryon Oscillation Spectroscopic Survey (BOSS), and extended BOSS\n(eBOSS) luminous red galaxy catalogues from SDSS Data Release 7, 12, and 16,\ncovering the redshift range $0.07 < z < 1.0$. We fit a standard $\\Lambda$CDM\ncosmological model as well as various extensions including a constant dark\nenergy equation of state not equal to $-1$, a time-varying dark energy equation\nof state, and these same models allowing for spatial curvature. Results on key\nparameters of these models are reported for void-galaxy and galaxy-galaxy\nclustering alone, both of these combined, and all these combined with\nmeasurements from the cosmic microwave background (CMB) and supernovae (SN).\nFor the combination of void-galaxy and galaxy-galaxy clustering, we find tight\nconstraints of $\\Omega_\\mathrm{m} = 0.356\\pm 0.024$ for a base $\\Lambda$CDM\ncosmology, $\\Omega_\\mathrm{m} = 0.391^{+0.028}_{-0.021}, w =\n-1.50^{+0.43}_{-0.28}$ additionally allowing the dark energy equation of state\n$w$ to vary, and $\\Omega_\\mathrm{m} = 0.331^{+0.067}_{-0.094},\nw=-1.41^{+0.70}_{-0.31},\\ \\mathrm{and}\\ \\Omega_\\mathrm{k} =\n0.06^{+0.18}_{-0.13}$ further extending to non-flat models. The combined SDSS\nresults from void-galaxy and galaxy-galaxy clustering in combination with\nCMB+SN provide a 30% improvement in parameter $\\Omega_\\mathrm{m}$ over CMB+SN\nfor $\\Lambda$CDM, a 5% improvement in parameter $\\Omega_\\mathrm{m}$ when $w$ is\nallowed to vary, and a 32% and 68% improvement in parameters\n$\\Omega_\\mathrm{m}$ and $\\Omega_\\mathrm{k}$ when allowing for spatial\ncurvature.\n", "  The presence of an extra radio background besides the cosmic microwave\nbackground has important implications for the observation of the 21-cm signal\nduring the cosmic Dark Ages, Cosmic Dawn, and epoch of Reionization. The strong\nabsorption trough found in the 21-cm global spectrum measured by the EDGES\nexperiment, which has a much greater depth than the standard model prediction,\nhas drawn great interest to this scenario, but more generally it is still of\ngreat interest to consider such a cosmic radio background (CRB) in the early\nUniverse. To be effective in affecting the 21-cm signal at early time, such a\nradio background must be produced by sources which can emit strong radio\nsignals but modest amount of X-rays, so that the gas is not heated up too\nearly. We investigate the scenario that such a radio background is produced by\nthe primordial black holes (PBHs). For PBH with a single mass, we find that if\nthe PBHs' abundance $\\log(f_{\\rm PBH})$ (ratio of total PBH mass density to\ntotal matter density) and mass satisfy the relation $\\log(f_{\\rm PBH}) \\sim\n-1.8\\log(M_\\bullet/{\\rm M}_{\\odot})-3.5$ for $1\\,{\\rm M}_\\odot \\lesssim\nM_\\bullet \\lesssim 300 {\\rm M}_\\odot$, and have jet emission, they can generate\na CRB required for reproducing the 21-cm absorption signal seen by the EDGES.\nThe accretion rate can be boosted if the PBHs are surrounded by dark matter\nhalos, which permits lower $f_{\\rm PBH}$ value to satisfy the EDGES\nobservation. In the latter scenario, since the accretion rate can evolve\nrapidly during the Cosmic Dawn, the frequency (redshift) and depth of the\nabsorption trough can determine the mass and abundance of the PBHs\nsimultaneously. For absorption trough redshift $\\sim$ 17 and depth $\\sim -500$\nmK, it corresponds to $M_\\bullet \\sim 1.05\\,{\\rm M}_{\\odot}$ and $f_{\\rm\nPBH}\\sim 1.5\\times10^{-4}$.\n", "  The redshift drift is computed along light rays propagating through a\nsimulated universe based on the Newtonian N-body simulation code GADGET-2\ncombined with a perturbed Friedmann-Lemaitre-Robertson-Walker metric in the\nNewtonian gauge. It is found that the mean redshift drift is equal to the drift\nof the mean redshift to the precision of the numerical computations and that\nthis is due to a high degree of cancellation between two dominant components of\nthe redshift drift. This result is contrary to earlier findings based on\ninhomogeneous cosmological models exhibiting cosmic backreaction.\n\\newline\\indent For simplicity, the results neglect contributions from optical\ndrift. Based on a study of the redshift drift in a Lemaitre-Tolman-Bondi model,\nthe optical drift effects are estimated to be at most of order 10\\% of the\nredshift drift signal. In addition, it is found that the redshift drift\ncontribution from peculiar acceleration of the emitter is negligible in the\nsimulation setup. However, it is expected that the contribution from peculiar\nacceleration of the emitter is suppressed in the setup due to low resolution of\nstructures and it is hence expected that this contribution will be larger for\nreal observations.\n", "  Cosmic Dawn (CD) and Epoch of Reionization (EoR) are epochs of the Universe\nwhich host invaluable information about the cosmology and astrophysics of X-ray\nheating and hydrogen reionization. Radio interferometric observations of the\n21-cm line at high redshifts have the potential to revolutionize our\nunderstanding of the universe during this time. However, modeling the evolution\nof these epochs is particularly challenging due to the complex interplay of\nmany physical processes. This makes it difficult to perform the conventional\nstatistical analysis using the likelihood-based Markov-Chain Monte Carlo (MCMC)\nmethods, which scales poorly with the dimensionality of the parameter space. In\nthis paper, we show how the Simulation-Based Inference (SBI) through Marginal\nNeural Ratio Estimation (MNRE) provides a step towards evading these issues. We\nuse 21cmFAST to model the 21-cm power spectrum during CD-EoR with a\nsix-dimensional parameter space. With the expected thermal noise from the\nSquare Kilometre Array (SKA), we are able to accurately recover the posterior\ndistribution for the parameters of our model at a significantly lower\ncomputational cost than the conventional likelihood-based methods. We further\nshow how the same training dataset can be utilized to investigate the\nsensitivity of the model parameters over different redshifts. Our results\nsupport that such efficient and scalable inference techniques enable us to\nsignificantly extend the modeling complexity beyond what is currently\nachievable with conventional MCMC methods.\n", "  We study the impact of kinks on the cosmic microwave background (CMB)\nanisotropies generated by cosmic string networks. To do so, we extend the\nUnconnected Segment Model to describe the stress-energy tensor of a network of\ncosmic strings with kinks and implement this extension in CMBACT to compute the\nCMB anisotropies generated by these wiggly string networks. Our results show\nthat the inclusion of kinks leads, in general, to an enhancement of the\ntemperature and polarization angular power spectra, when compared to those\ngenerated by cosmic string networks without small-scale structure with the same\nenergy density, on scales corresponding to the distance between kinks. This\nenhancement, that is more prominent in the case of the temperature\nanisotropies, is essentially caused by a significant increase of the\nvector-mode anisotropies, since kinks, due to their shape, generate vortical\nmotions of matter -- a phenomenon that is not taken into account when resorting\nto an effective description of wiggly cosmic strings.\n", "  The dark age of the universe, when no luminous object had existed, ended with\nthe birth of the first stars, galaxies, and blackholes. This epoch is called\ncosmic dawn. Cosmic reionization is the major transition of the intergalactic\nmedium (IGM) in the universe driven by ionizing photons emitted from luminous\nobjects. Although the epoch through the dark age to reionization is a milestone\nin the universe, our knowledge of this epoch has not been sufficient yet.\nCosmic 21cm signal, which is emitted from neutral hydrogen, is expected to open\na new window for this epoch. In this review paper, we first introduce the basic\nphysics of the 21cm line and how first stars impact on the 21cm line signal.\nNext, we briefly summarize how we extract astrophysical information from the\n21cm line signal by means of statistical and machine learning approaches. We\nalso discuss the synergy between the 21cm line signal and other emission lines.\nFinally, we summarize the current status of 21cm experiments.\n", "  We present Cosmoglobe Data Release 1, which implements the first joint\nanalysis of WMAP and Planck LFI time-ordered data, processed within a single\nBayesian end-to-end framework. This framework builds directly on a similar\nanalysis of the LFI measurements by the BeyondPlanck collaboration, and\napproaches the CMB analysis challenge through Gibbs sampling of a global\nposterior distribution, simultaneously accounting for calibration, mapmaking,\nand component separation. The computational cost of producing one complete\nWMAP+LFI Gibbs sample is 812 CPU-hr, of which 603 CPU-hrs are spent on WMAP\nlow-level processing; this demonstrates that end-to-end Bayesian analysis of\nthe WMAP data is computationally feasible. We find that our WMAP posterior mean\ntemperature sky maps and CMB temperature power spectrum are largely consistent\nwith the official WMAP9 results. Perhaps the most notable difference is that\nour CMB dipole amplitude is $3366.2 \\pm 1.4\\ \\mathrm{\\mu K}$, which is $11\\\n\\mathrm{\\mu K}$ higher than the WMAP9 estimate and $2.5\\ {\\sigma}$ higher than\nBeyondPlanck; however, it is in perfect agreement with the HFI-dominated Planck\nPR4 result. In contrast, our WMAP polarization maps differ more notably from\nthe WMAP9 results, and in general exhibit significantly lower large-scale\nresiduals. We attribute this to a better constrained gain and transmission\nimbalance model. It is particularly noteworthy that the W-band polarization sky\nmap, which was excluded from the official WMAP cosmological analysis, for the\nfirst time appears visually consistent with the V-band sky map. Similarly, the\nlong standing discrepancy between the WMAP K-band and LFI 30 GHz maps is\nfinally resolved, and the difference between the two maps appears consistent\nwith instrumental noise at high Galactic latitudes. All maps and the associated\ncode are made publicly available through the Cosmoglobe web page.\n", "  Extracting the CMB blackbody temperature power spectrum -- which is dominated\nby the primary CMB signal and the kinematic Sunyaev-Zel'dovich (kSZ) effect --\nfrom mm-wave sky maps requires cleaning other sky components. In this work, we\ndevelop new methods to use large-scale structure (LSS) tracers to remove cosmic\ninfrared background (CIB) and thermal Sunyaev-Zel'dovich (tSZ) contamination in\nsuch measurements. Our methods rely on the fact that LSS tracers are correlated\nwith the CIB and tSZ signals, but their two-point correlations with the CMB and\nkSZ signals vanish on small scales, thus leaving the CMB blackbody power\nspectrum unbiased after cleaning. We develop methods analogous to delensing\n($\\textit{de-CIB}$ or $\\textit{de-(CIB+tSZ)}$) to clean CIB and tSZ\ncontaminants using these tracers. We compare these methods to internal linear\ncombination (ILC) methods, including novel approaches that incorporate the\ntracer maps in the ILC procedure itself, without requiring exact assumptions\nabout the CIB SED. As a concrete example, we use the $\\textit{unWISE}$ galaxy\nsamples as tracers. We provide calculations for a combined Simons Observatory\nand $\\textit{Planck}$-like experiment, with our simulated sky model comprising\neight frequencies from 93 to 353 GHz. Using $\\textit{unWISE}$ tracers,\nimprovements with our methods over current approaches are already\nnon-negligible: we find improvements up to 20% in the kSZ power spectrum\nsignal-to-noise ratio (SNR) when applying the de-CIB method to a\ntSZ-deprojected ILC map. These gains could be more significant when using\nadditional LSS tracers from current surveys, and will become even larger with\nfuture LSS surveys, with improvements in the kSZ power spectrum SNR up to 50%.\nFor the total CMB blackbody power spectrum, these improvements stand at 4% and\n7%, respectively. Our code is publicly available at\nhttps://github.com/olakusiak/deCIBing.\n", "  Very light pseudoscalar fields, often referred to as axions, are compelling\ndark matter candidates and can potentially be detected through their coupling\nto the electromagnetic field. Recently a novel detection technique using the\ncosmic microwave background (CMB) was proposed, which relies on the fact that\nthe axion field oscillates at a frequency equal to its mass in appropriate\nunits, leading to a time-dependent birefringence. For appropriate oscillation\nperiods this allows the axion field at the telescope to be detected via the\ninduced sinusoidal oscillation of the CMB linear polarization. We search for\nthis effect in two years of POLARBEAR data. We do not detect a signal, and\nplace a median $95 \\%$ upper limit of $0.65 ^\\circ$ on the sinusoid amplitude\nfor oscillation frequencies between $0.02\\,\\text{days}^{-1}$ and\n$0.45\\,\\text{days}^{-1}$, which corresponds to axion masses between $9.6 \\times\n10^{-22} \\, \\text{eV}$ and $2.2\\times 10^{-20} \\,\\text{eV}$. Under the\nassumptions that 1) the axion constitutes all the dark matter and 2) the axion\nfield amplitude is a Rayleigh-distributed stochastic variable, this translates\nto a limit on the axion-photon coupling $g_{\\phi \\gamma} < 2.4 \\times 10^{-11}\n\\,\\text{GeV}^{-1} \\times ({m_\\phi}/{10^{-21} \\, \\text{eV}})$.\n", "  The properties of the matter density field in the initial conditions have a\ndecisive impact on the features of the large-scale structure of the Universe as\nobserved today. These need to be studied via $N$-body simulations, which are\nimperative to analyze high density collapsed regions into dark matter halos. In\nthis paper, we train Machine Learning algorithms with information from N -body\nsimulations to infer two properties: dark matter particle halo classification\nthat leads to halo formation prediction with the characteristics of the matter\ndensity field traced back to the initial conditions, and dark matter halo\nformation by calculating the Halo Mass Function (HMF), which offers the number\ndensity of dark matter halos with a given threshold. We map the initial\nconditions of the matter density field into classification labels of dark\nmatter halo structures. The Halo Mass Function of the simulations is calculated\nand reconstructed with theoretical methods as well as our trained algorithms.\nWe test several Machine Learning techniques where we could find that the Random\nForest and Neural Networks proved to be the better performing tools to classify\ndark matter particles in cosmological simulations. We also show that that it is\nnot compulsory to use a high amount of data to train the algorithms in order to\nreconstruct the HMF, giving us a very good fitting function for both simulation\nand theoretical results.\n", "  The Euclid mission of the European Space Agency will perform a survey of weak\nlensing cosmic shear and galaxy clustering in order to constrain cosmological\nmodels and fundamental physics. We expand and adjust the mock Euclid\nlikelihoods of the MontePython software in order to match the exact recipes\nused in previous Euclid Fisher matrix forecasts for several probes: weak\nlensing cosmic shear, photometric galaxy clustering, the cross-correlation\nbetween the latter observables, and spectroscopic galaxy clustering. We also\nestablish which precision settings are required when running the\nEinstein-Boltzmann solvers CLASS and CAMB in the context of Euclid. For the\nminimal cosmological model, extended to include dynamical dark energy, we\nperform Fisher matrix forecasts based directly on a numerical evaluation of\nsecond derivatives of the likelihood with respect to model parameters. We\ncompare our results with those of other forecasting methods and tools. We show\nthat such MontePython forecasts agree very well with previous Fisher forecasts\npublished by the Euclid Collaboration, and also, with new forecasts produced by\nthe CosmicFish code, now interfaced directly with the two Einstein-Boltzmann\nsolvers CAMB and CLASS. Moreover, to establish the validity of the Gaussian\napproximation, we show that the Fisher matrix marginal error contours coincide\nwith the credible regions obtained when running Monte Carlo Markov Chains with\nMontePython while using the exact same mock likelihoods. The new Euclid\nforecast pipelines presented here are ready for use with additional\ncosmological parameters, in order to explore extended cosmological models.\n", "  A measurement of the neutrino mass scale will be achieved with cosmological\nprobes in the upcoming decade. On one hand, the inclusion of massive neutrinos\nin the linear perturbation theory of cosmological structure formation is well\nunderstood and can be done accurately with state of the art Boltzmann solvers.\nOn the other hand, the numerical implementation of the Boltzmann equation is\ncomputationally expensive and is a bottleneck in those codes. This has\nmotivated the development of more efficient fluid approximations, despite their\nlimited accuracy over all scales of interest, $k \\sim (10^{-3}-10)$Mpc$^{-1}$.\nIn this work we account for the dispersive nature of the neutrino fluid, i.e.,\nthe scale dependence in the sound speed, leading to an improved fluid\napproximation. We show that overall $\\lesssim 5\\%$ errors can be achieved for\nthe neutrino density and velocity transfer functions at redshift $z \\lesssim\n5$, which corresponds to an order of magnitude improvement over previous\napproximation schemes that can be discrepant by as much as a factor of two.\n", "  We present the Aemulus $\\nu$ simulations: a suite of 150 $(1.05 h^{-1}\\rm\nGpc)^3$ $N$-body simulations with a mass resolution of $3.51\\times 10^{10}\n\\frac{\\Omega_{cb}}{0.3} ~ h^{-1} M_{\\odot}$ in a $w\\nu$CDM cosmological\nparameter space. The simulations have been explicitly designed to span a broad\nrange in $\\sigma_8$ to facilitate investigations of tension between large scale\nstructure and cosmic microwave background cosmological probes. Neutrinos are\ntreated as a second particle species to ensure accuracy to $0.5\\, \\rm eV$, the\nmaximum neutrino mass that we have simulated. By employing Zel'dovich control\nvariates, we increase the effective volume of our simulations by factors of\n$10-10^5$ depending on the statistic in question. As a first application of\nthese simulations, we build new hybrid effective field theory and matter power\nspectrum surrogate models, demonstrating that they achieve $\\le 1\\%$ accuracy\nfor $k\\le 1\\, h\\,\\rm Mpc^{-1}$ and $0\\le z \\le 3$, and $\\le 2\\%$ accuracy for\n$k\\le 4\\, h\\,\\rm Mpc^{-1}$ for the matter power spectrum. We publicly release\nthe trained surrogate models, and estimates of the surrogate model errors in\nthe hope that they will be broadly applicable to a range of cosmological\nanalyses for many years to come.\n", "  Cosmology inference of galaxy clustering at the field level with the EFT\nlikelihood in principle allows for extracting all non-Gaussian information from\nquasi-linear scales, while robustly marginalizing over any astrophysical\nuncertainties. A pipeline in this spirit is implemented in the\n\\texttt{LEFTfield} code, which we extend in this work to describe the\nclustering of galaxies in redshift space. Our main additions are: the\ncomputation of the velocity field in the LPT gravity model, the fully nonlinear\ndisplacement of the evolved, biased density field to redshift space, and a\nsystematic expansion of velocity bias. We test the resulting analysis pipeline\nby applying it to synthetic data sets with a known ground truth at increasing\ncomplexity: mock data generated from the perturbative forward model itself,\nsub-sampled matter particles, and dark matter halos in N-body simulations. By\nfixing the initial-time density contrast to the ground truth, while varying the\ngrowth rate $f$, bias coefficients and noise amplitudes, we perform a stringent\nset of checks. These show that indeed a systematic higher-order expansion of\nthe velocity bias is required to infer a growth rate consistent with the ground\ntruth within errors. Applied to dark matter halos, our analysis yields unbiased\nconstraints on $f$ at the level of a few percent for a variety of halo masses\nat redshifts $z=0,\\,0.5,\\,1$ and for a broad range of cutoff scales\n$0.08\\,h/\\mathrm{Mpc} \\leq \\Lambda \\leq 0.20\\,h/\\mathrm{Mpc}$. Importantly,\ndeviations between true and inferred growth rate exhibit the scaling with halo\nmass, redshift and cutoff that one expects based on the EFT of Large Scale\nStructure. Further, we obtain a robust detection of velocity bias through its\neffect on the redshift-space density field and are able to disentangle it from\nhigher-derivative bias contributions.\n", "  Cosmic voids are a powerful probe of cosmology and are one of the core\nobservables of upcoming galaxy surveys. The cross-correlations between voids\nand other large-scale structure tracers such as galaxy clustering and galaxy\nlensing have been shown to be very sensitive probes of cosmology and among the\nmost promising to probe the nature of gravity and the neutrino mass. However,\nrecent measurements of the void imprint on the lensed Cosmic Microwave\nBackground (CMB) have been shown to be in tension with expectations based on\nLCDM simulations, hinting to a possibility of non-standard cosmological\nsignatures due to massive neutrinos. In this work we use the DEMNUni\ncosmological simulations with massive neutrino cosmologies to study the\nneutrino impact on voids selected in photometric surveys, e.g. via Luminous Red\nGalaxies, as well as on the void- CMB lensing cross-correlation. We show how\nthe void properties observed in this way (size function, profiles) are affected\nby the presence of massive neutrinos compared to the neutrino massless case,\nand show how these can vary as a function of the selection method of the void\nsample. We comment on the possibility for massive neutrinos to be the source of\nthe aforementioned tension. Finally, we identify the most promising setup to\ndetect signatures of massive neutrinos in the voids-CMB lensing\ncross-correlation and define a new quantity useful to distinguish among\ndifferent neutrino masses by comparing future observations against predictions\nfrom simulations including massive neutrinos.\n", "  In this project, the cosmological parameters are determined by applying six\ncosmological models to fit the magnitude-redshift relation of the Pantheon\nSample consisting of 1048 Type Ia supernovae (SNe Ia) in the range of $0.01 < z\n< 2.26$. Apart from the well-known flat $\\Lambda$CDM model as well as other\nmodels that have been broadly studied, this project includes two new models,\nwhich are the $\\textit{o}\\textit{w}$CDM model and the\n$\\textit{o}\\textit{w}_0\\textit{w}_a$CDM model, to fully evaluate the\ncorrelations between the cosmological parameters by performing the MCMC\nalgorithm and to explore the geometry and mass content of the Universe.\nCombining the measurements of the baryon acoustic oscillation (BAO) and the\ncosmic microwave background (CMB) with the SNe Ia constraints, the matter\ndensity parameter $\\Omega_M = 0.328^{+0.018}_{-0.026}$, the curvature of space\nparameter $\\Omega_k = 0.0045^{+0.0666}_{-0.0741}$, and the dark energy equation\nof state parameter $w = -1.120^{+0.143}_{-0.185}$ are measured for the\n$\\textit{o}\\textit{w}$CDM model. When it comes to the\n$\\textit{o}\\textit{w}_0\\textit{w}_a$CDM model, if the parameter $\\textit{w}$ is\nallowed to evolve with the redshift as $w = w_0 + w_a(1-a)$, the cosmological\nparameters are found to be $\\Omega_M = 0.344^{+0.018}_{-0.027}$, $\\Omega_k =\n0.0027^{+0.0665}_{-0.0716}$, $w_0 = -0.739^{+0.336}_{-0.378}$, and $w_a =\n-0.812^{+0.750}_{-0.678}$. The parameters of the $\\textit{o}\\textit{w}$CDM\nmodel and the $\\textit{o}\\textit{w}_0\\textit{w}_a$CDM model are consistent with\nthe literature results, although the parameter $\\textit{w}$ is not well\nconstrained in both models. The large uncertainties of the parameter\n$\\textit{w}$ can be reduced by running more steps for the MCMC algorithm to\nbetter constrain the parameters and estimate their uncertainties.\n", "  The {\\it Linear Point} (LP), defined as the midpoint between the BAO peak and\nthe associated left dip of the two-point correlation function (2PCF), $\\xi(s)$,\nis proposed as a new standard ruler which is insensitive to nonlinear effects.\nIn this paper, we use a Bayesian sampler to measure the LP and estimate the\ncorresponding statistical uncertainty, and then perform cosmological parameter\nconstraints with LP measurements. Using the Patchy mock catalogues, we find\nthat the measured LPs are consistent with theoretical predictions at 0.6 per\ncent level. We find constraints with midpoints identified from the rescaled\n2PCF ($s^2 \\xi$) more robust than those from the traditional LP based on $\\xi$,\nas the BAO peak is not always prominent when scanning the cosmological\nparameter space, with the cost of 2--4 per cent increase of statistical\nuncertainty. This problem can also be solved by an additional dataset that\nprovides strong parameter constraints. Measuring LP from the reconstructed data\nslightly increases the systematic error but significantly reduces the\nstatistical error, resulting in more accurate measurements. The 1$\\,\\sigma$\nconfidence interval of distance scale constraints from LP measurements are\n20--30 per cent larger than those of the corresponding BAO measurements. For\nthe reconstructed SDSS DR12 data, the constraints on $H_0$ and $\\Omega_{\\rm m}$\nin a flat-$\\Lambda$CDM framework with the LP are generally consistent with\nthose from BAO. When combined with Planck cosmic microwave background data, we\nobtain $H_0=68.02_{-0.37}^{+0.36}$ ${\\rm km}\\,{\\rm s}^{-1}\\,{\\rm Mpc}^{-1}$ and\n$\\Omega_{\\rm m}=0.3055_{-0.0048}^{+0.0049}$ with the LP.\n", "  We develop a self-consistent and accurate halo model by partitioning matter\naccording to the depletion radii of haloes. Unlike conventional models that\ndefine haloes with the virial radius while relying on a separate exclusion\nradius or ad-hoc fixes to account for halo exclusion, our model distributes\nmass across all scales self-consistently and accounts for both the virialized\nand non-virialized matter distribution around each halo. Using a cosmological\nsimulation, we show that our halo definition leads to very simple and intuitive\nmodel components, with the one-halo term given by the Einasto profile with no\ntruncation needed, and the halo-halo correlation function following a universal\npower-law form down to the halo boundary. The universal halo-halo correlation\nalso allows us to easily model the distribution of unresolved haloes as well as\ndiffuse matter. Convolving the halo profile with the halo-halo correlation\nfunction, we obtain a complete description of the halo-matter correlation\nacross all scales, which self-consistently accounts for halo exclusion at the\ntransition scale. Mass conservation is explicitly maintained in our model, and\nthe scale dependence of the classical halo bias is easily reproduced. Our model\ncan successfully reconstruct the halo-matter correlation function within an\naccuracy of $9\\%$ for halo virial masses in the range of $10^{11.5}h^{-1}{\\rm\nM}_{\\odot}<M_{\\rm vir}<10^{15.35}h^{-1}{\\rm M}_{\\odot}$ at $z=0$, and covers\nthe radial range of $0.01h^{-1}{\\rm Mpc}<r<20h^{-1}{\\rm Mpc}$. We also show\nthat our model profile can accurately predict the characteristic depletion\nradius at the minimum bias and the splash-back radius at the steepest density\nslope locations.\n", "  We investigate the build-up of the halo profile out to large scale in a\ncosmological simulation, focusing on the roles played by the recently proposed\ndepletion radii. We explicitly show that halo growth is accompanied by the\ndepletion of the environment, with the inner depletion radius demarcating the\ntwo. This evolution process is also observed via the formation of a trough in\nthe bias profile, with the two depletion radii identifying key scales in the\nevolution. The ratio between the inner depletion radius and the virial radius\nis approximately a constant factor of 2 across redshifts and halo masses. The\nratio between their enclosed densities is also close to a constant of 0.18.\nThese simple scaling relations reflect the largely universal scaled mass\nprofile on these scales, which only evolves weakly with redshift. The overall\npicture of the boundary evolution can be broadly divided into three stages\naccording to the maturity of the depletion process, with cluster halos lagging\nbehind low mass ones in the evolution. We also show that the traditional slow\nand fast accretion dichotomy of halo growth can be identified as accelerated\nand decelerated depletion phases respectively.\n", "  The use of the baryonic acoustic oscillations (BAO) datasets offers a unique\nopportunity to connect the early universe and the late one. In this proceeding,\nwe discuss recent results that used a marginalised likelihood to remove the\n$H_0-r_d $ degeneracy and then tested it on different dark energy (DE) models.\nIt was found that this approach which does not rely on calibration on $r_d$ or\n$H_0$, allows us to obtain results, comparable to the ones calculated with\nstandard likelihoods. Here we emphasize on the major differences that we\nobserved for the two different BAO datasets that we employed -- a transversal\none, containing only angular BAO measurements, and a mixed one, containing both\nangular and radial BAO measurements. We see that the two datasets have\ndifferent statistical preferences for DE models and also different preference\nfor the curvature of the universe.\n", "  Semi-numerical simulations are the leading candidates for evolving\nreionization on cosmological scales. These semi-numerical models are efficient\nin generating large-scale maps of the 21cm signal, but they are too slow to\nenable inference at the field level. We present different strategies to train a\nU-Net to accelerate these simulations. We derive the ionization field directly\nfrom the initial density field without using the ionizing sources' location,\nand hence emulating the radiative transfer process. We find that the U-Net\nachieves higher accuracy in reconstructing the ionization field if the input\nincludes either white noise or a noisy version of the ionization map beside the\ndensity field during training. Our model reconstructs the power spectrum over\nall scales perfectly well. This work represents a step towards generating\nlarge-scale ionization maps with a minimal cost and hence enabling rapid\nparameter inference at the field level.\n", "  In this dissertation, we study two cosmological models based on $f(Q)$\ngravity. We resort to mock catalogs of standard siren (SS) events to see\nwhether data from future gravitational wave (GWs) observatories will be able to\ndistinguish these models from $\\Lambda$CDM.\n  The first model is the most general $f(Q)$ formulation that replicates a\n$\\Lambda$CDM background, with deviations appearing only at the perturbative\nlevel. It has one additional free parameter compared to $\\Lambda$CDM, $\\alpha$,\nwhich when set to zero falls back to $\\Lambda$CDM. We show that LIGO-Virgo is\nunable to constrain $\\alpha$, due to the high error and low redshift of the\nmeasurements, whereas LISA and the ET will, with the ET outperforming LISA. The\ncatalogs for both LISA and LIGO-Virgo show non-negligible statistical\nfluctuations, where we consider three representative catalogs (the best, median\nand worst), whereas for the ET, only a single catalog is considered, as the\nnumber of events is large enough for statistical fluctuations to be neglected.\nThe best LISA catalog is the one with more low redshift events, while the worst\nLISA catalog features fewer low redshift events. Additionally, if we are to\nobserve a bad LISA catalog, we can rely on data from LIGO-Virgo to improve the\nquality of the constrains, bringing it closer to a median LISA catalog.\n  The second model attempts to replace dark energy by making use of a specific\nform of the function $f(Q)$. We study this model resorting to dynamical system\ntechniques to show the regions in parameter space with viable cosmologies.\nUsing model selection criteria, we show that no number of SS events is, by\nitself, able to tell this model and $\\Lambda$CDM apart. We then show that if we\nadd current type Ia Supernova (SnIa) data, tensions in this model arise when\ncompared to the constrains set by the SS events.\n", "  Current cosmological controversies can be solved if a sufficient level of\nprecision is achieved by observations. Future surveys with the next generation\nof telescopes will offer significantly improved depth and angular resolution\nwith respect to existing observations, opening the so-called \"era of precision\ncosmology\". But, that era can be considered already started at the radio\nwavelengths with Very Long Baseline Interferometry (VLBI). In this paper, we\ngive an overview on how VLBI is contributing to some open questions in\ncontemporary cosmology by reaching simultaneously the largest distances and the\nsmallest scales.\n", "  A large number of observations have shown that the dark matter halo surface\ndensity, given by the product of halo core radius and core density is nearly\nconstant for a diverse suite of galaxies. Although this invariance of the halo\nsurface density is violated at galaxy cluster and group scales, it is still an\nopen question on whether the aforementioned constancy on galactic scales can be\nexplained within $\\Lambda$CDM. For this purpose, we probe the variation of halo\nsurface density as a function of mass using multi-wavelength mock galaxy\ncatalogs from $\\Lambda$CDM simulations, where the adiabatic contraction of dark\nmatter halos in the presence of baryons has been taken into account. We find\nthat these baryonified $\\Lambda$CDM halos were best fitted with a\ngeneralized-NFW profile, and the halo surface density from these halos has a\ndegeneracy with respect to both the halo mass and the virial concentration. We\nfind that the correlation with mass when averaged over concentration is\nconsistent with a constant halo surface density. However, a power-law\ndependence as a function of halo mass also cannot be ruled out.\n", "  Extended gravity is widely constrained in different astrophysical and\nastronomical systems. Since these different systems are based on different\nscales it is not trivial to get a combined constraint that is based on\ndifferent phenomenology. Here, for the first time (to the best of our\nknowledge), we combine constraints for $f(R)$ gravity from late time Cosmology\nand the orbital motion of the stars around the galactic center. $f(R)$ gravity\nmodels give different potentials that are tested directly in the galactic\ncenter. The cosmological data set includes the type Ia supernova and baryon\nacoustic oscillations. For the galactic star center data set we use the\npublished orbital measurements of the S2 star. The constraints on the universal\nparameter $\\beta$ from the combined system give: $\\beta_{HS}=0.154 \\pm 0.109$\nfor the Hu-Sawicki model, while $\\beta_{St}= 0.309 \\pm 0.19 $ for the\nStarobinsky dark energy model. These results improve on the cosmological\nresults we obtain. The results show that {{\\it combined constraint}} from\ndifferent systems yields a stronger constraint for different theories under\nconsideration. Future measurements from the galactic center and from cosmology\nwill give better constraints on models with $f(R)$ gravity.\n", "  Measurements of the characteristic length scale $r_s$ of the baryon acoustic\noscillations (BAO) provide a robust determination of the distance-redshift\nrelation. Currently, the best (sub-per cent) estimate of $r_s$ at the drag\nepoch is provided by Cosmic Microwave Background (CMB) observations assuming\nthe validity of the standard $\\Lambda$CDM model at $z \\sim 1000$. Therefore,\ninferring $r_s$ from low-$z$ observations in a model-independent way and\ncomparing its value with CMB estimates provides a consistency test of the\nstandard cosmology and its assumptions at high-$z$. In this paper, we address\nthis question and estimate the absolute BAO scale combining angular BAO\nmeasurements and type Ia Supernovae data. Our analysis uses two different\nmethods to connect these data sets and finds a good agreement between the\nlow-$z$ estimates of $r_{s}$ with the CMB sound horizon at drag epoch,\nregardless of the value of the Hubble constant $H_0$ considered. These results\nhighlight the robustness of the standard cosmology at the same time that they\nalso reinforce the need for more precise cosmological observations at low-$z$.\n", "  Turbulent processes at work in the intracluster medium perturb this\nenvironment, displacing gas, and creating local density fluctuations that can\nbe quantified via X-ray surface brightness fluctuation analyses. Improved\nknowledge of these phenomena would allow for a better determination of the mass\nof galaxy clusters, as well as a better understanding of their dynamic\nassembly. In this work, we aim to set constraints on the structure of\nturbulence using X-ray surface brightness fluctuations. We seek to consider the\nstochastic nature of this observable and to constrain the structure of the\nunderlying power spectrum. We propose a new Bayesian approach, relying on\nsimulation-based inference to account for the whole error budget. We used the\nX-COP cluster sample to individually constrain the power spectrum in four\nregions and within $R_{500}$. We spread the analysis on the 12 systems to\nalleviate the sample variance. We then interpreted the density fluctuations as\nthe result of either gas clumping or turbulence. For each cluster considered\nindividually, the normalisation of density fluctuations correlates positively\nwith the Zernike moment and centroid shift, but negatively with the\nconcentration and the Gini coefficient. The spectral index within $R_{500}$ and\nevaluated over all clusters is consistent with a Kolmogorov cascade. The\nnormalisation of density fluctuations, when interpreted in terms of clumping,\nis consistent within $0.5 R_{500}$ with the literature results and numerical\nsimulations; however, it is higher between 0.5 and $1 R_{500}$. Conversely,\nwhen interpreted on the basis of turbulence, we deduce a non-thermal pressure\nprofile that is lower than the predictions of the simulations within 0.5\n$R_{500}$, but still in agreement in the outer regions. We explain these\nresults by the presence of central structural residues that are remnants of the\ndynamic assembly of the clusters.\n", "  Much of the research in supernova cosmology is based on an assumption that\nthe peak luminosity of type Ia supernovae (SNe Ia), after a standardization\nprocess, is independent of the galactic environment. A series of recent studies\nsuggested that there is a significant correlation between the standardized\nluminosity and the progenitor age of SNe Ia. The correlation found in the most\nrecent work by Lee et al. is strong enough to explain the extra dimming of\ndistant SNe Ia and therefore casts doubts on the direct evidence of cosmic\nacceleration. The present work incorporates the uncertainties of progenitor\nages, which were ignored in Lee et al., into a fully Bayesian inference\nframework. We find a weaker dependence of supernova standardized luminosity on\nthe progenitor age, but the detection of correlation remains significant\n(3.5$\\sigma$). Assuming that such correlation can be extended to high redshift\nand applying it to the Pantheon SN Ia data set, we confirm that when the Hubble\nresidual does not include intrinsic scatter, the age-bias could be the primary\ncause of the observed extra dimming of distant SNe Ia. Furthermore, we use the\nPAge formalism, which is a good approximation to many dark energy and modified\ngravity models, to do a model comparison. We find that if intrinsic scatter is\nincluded in the Hubble residual, the Lambda cold dark matter model remains a\ngood fit. However, in a scenario without intrinsic scatter, the Lambda cold\ndark matter model faces a challenge.\n", "  We present GEO-FPT (Geometric Fitted Perturbation Theory), a new model for\nthe galaxy bispectrum anisotropic signal in redshift space, with functional\nform rooted in perturbation theory. It also models the dependence of the\nbispectrum with the geometric properties of the triangles in Fourier space, and\nhas a broader regime of validity than state-of-the-art theoretical models based\non perturbation theory. We calibrate the free parameters of this model using\nhigh-resolution dark matter simulations and perform stringent tests to show\nthat GEO-FPT describes the galaxy bispectrum accurately up to scales of\n$k\\simeq0.12 h{\\rm Mpc}^{-1}$ for different cosmological models, as well as for\nbiased tracers of the dark matter field, considering a survey volume of $100$\n(Gpc $h^{-1})^3$. In particular, a joint analysis of the power spectrum and\nbispectrum anisotropic signals, taking into account their full covariance\nmatrix, reveals that the relevant physical quantities -- the BAO peak position\n(along and across the line-of-sight), and the growth of structure parameters\ntimes the amplitude of dark matter fluctuations, $f\\sigma_8$-- are recovered in\nan unbiased way, with an accuracy better than $0.4\\%$ and $2\\%$ respectively\n(which is our $2\\sigma$ statistical limit of the systematic error estimate). In\naddition, the bispectrum signal breaks the $f\\sigma_8$ degeneracy without\ndetectable bias: $f$ and $\\sigma_8$ are recovered with better than $2.7\\%$ and\n$3.8\\%$ accuracy respectively (which is our $2\\sigma$ statistical limit of the\nsystematic error estimate).\n  GEO-FPT boosts the applicability of the bispectrum signal of galaxy surveys\nbeyond the current limitation of $k\\lesssim 0.08\\,h$ Mpc$^{-1}$ % and makes the\nbispectrum a key statistic to unlock the information content from the mildly\nnon-linear regime in the on-going and forthcoming galaxy redshift surveys.\n", "  We test the regime of validity of the effective field theory (EFT) of\nintrinsic alignments (IA) at the one-loop level by comparing with 3D halo shape\nstatistics in N-body simulations. This model is based on the effective field\ntheory of large-scale structure (EFT of LSS) and thus a theoretically\nwell-motivated extension of the familiar non-linear alignment (NLA) model and\nthe tidal-alignment-tidal-torquing (TATT) model. It contains a total of $8$\nfree bias parameters. Specifically, we measure the dark matter halo shape-shape\nmultipoles $P_{EE}^{(0)}(k), P_{EE}^{(2)}(k), P_{BB}^{(0)}(k), P_{BB}^{(2)}(k)$\nas well as the matter-shape multipoles $P_{\\delta E}^{(0)}(k), P_{\\delta\nE}^{(2)}(k)$ from the simulations and perform a joint fit to determine the\nlargest wavenumber $k_{\\text{max}}$ up to which the theory predictions from the\nEFT of IA are consistent with the measurements. We find that the EFT of IA is\nable to describe intrinsic alignments of dark matter halos up to\n$k_\\text{max}=0.30\\,h/\\text{Mpc}$ at $z=0$. This demonstrates a clear\nimprovement over other existing alignment models like NLA and TATT, which are\nonly accurate up to $k_\\text{max}=0.05\\,h/\\text{Mpc}$ . We examine the\nposterior distributions of the higher-order bias parameters, and show that\ntheir inclusion is necessary to describe intrinsic alignments in the\nquasi-linear regime. Further, the EFT of IA is able to accurately describe the\nauto-spectrum of intrinsic alignment B-modes, in contrast to the other\nalignment models considered.\n", "  We use subhalo abundance and age distribution matching to create\nmagnitude-limited mock galaxy catalogs at $z\\sim0.43$, $0.52$, and $0.63$ with\n$z$-band and $3.4$ micron $W1$-band absolute magnitudes and ${r-z}$ and\n${r-W1}$ colors. From these magnitude-limited mocks we select mock luminous red\ngalaxy (LRG) samples according to the $(r-z)$-based (optical) and\n$(r-W1)$-based (infrared) selection criteria for the LRG sample of the Dark\nEnergy Spectroscopic Instrument (DESI) Survey. Our models reproduce the number\ndensities, luminosity functions, color distributions, and projected clustering\nof the DESI Legacy Surveys that are the basis for DESI LRG target selection. We\npredict the halo occupation statistics of both optical and IR DESI LRGs at\nfixed cosmology, and assess the differences between the two LRG samples. We\nfind that IR-based SHAM modeling represents the differences between the optical\nand IR LRG populations better than using the $z$-band, and that age\ndistribution matching overpredicts the clustering of LRGs, implying that galaxy\ncolor is uncorrelated with halo age in the LRG regime. Both the optical and IR\nDESI LRG target selections exclude some of the most luminous galaxies that\nwould appear to be LRGs based on their position on the red sequence in optical\ncolor-magnitude space. Both selections also yield populations with a\nnon-trivial LRG-halo connection that does not reach unity for the most massive\nhalos. We find the IR selection achieves greater completeness ($\\gtrsim 90\\%$)\nthan the optical selection across all redshift bins studied.\n", "  If, after primordial inflation, the universe undergoes a relatively long\nreheating period, it could present a phase of matter domination supported by\nthe oscillating inflaton field. During this epoch, small perturbations from the\ninflaton that reenter the cosmological horizon could virialize to form\n\\textit{inflaton} structures. If the primordial overdensities are large enough,\ntheir associated inflaton structures could collapse to form primordial black\nholes (PBHs) [L.E.Padilla, J.C.Hidalgo and K.A.Malik, Phys.Rev.D, vol.106,\np.023519, Jul 2022; hereinafter P1]. For this to happen at a considerable rate,\nthe primordial power spectrum should be enhanced at small scales, a feature\ntypically induced in single-field inflation through an ultra-slow roll phase\n(produced by a nearly-inflection point in the inflationary potential). In this\narticle we consider two specific inflationary potentials that present this\nnearly-inflection point and we look at the PBH formation rate through the\nmechanism proposed in P1. We report on constraints to these two specific models\nfrom the bounds to PBH abundances. This serves as an illustration of the\nusefulness of the PBH formation mechanism proposed in P1.\n", "  In this work, we adopt a cosmological model-independent approach for the\nfirst time to test the question of whether the mass density power-law\nindex($\\gamma$) of the strong gravitational lensing system(SGLS) evolves with\nredshift, and the JLA SNe Ia sample and the quasar sample from Risaliti \\&\nLusso (2019) are used to provide the luminosity distances to be calibrated. Our\nwork is based on the flat universe assumption and the cosmic distance duality\nrelation. A reliable data-matching method is used to pair SGLS-SNe and\nSGLS-quasar. By using the maximum likelihood method to constrain the luminosity\ndistance and $\\gamma$ index, we obtain the likelihood function values for the\nevolved and non-evolved cases, and then use the Akaike weights and the BIC\nselection weights to compare the advantages and disadvantages of these two\ncases. We find that the $\\gamma$ index is slightly more likely to be a\nnon-evolutionary model for $\\gamma=2$ in the case of the currently used samples\nwith low redshift ($z_l<\\sim$0.66). With Akaike weights, the relative\nprobability is 66.3\\% versus 33.7\\% and 69.9\\% versus 30.1\\% for the SGLS+SNe\nIa sample and SGLS+quasar sample, respectively, and with BIC selection weights,\nthe relative probability is 87.4\\% versus 12.6\\% and 52.0\\% versus 48.0\\% for\nthe two samples. In the evolving case for the relatively low redshift lens\n(SGLS+SNe Ia), with redshift 0.0625 to 0.659, $\\gamma=\n2.058^{+0.041}_{-0.040}-0.136^{+0.163}_{-0.165}z$. At high redshift\n(SGLS+quasar ), with redshift 0.0625 to 1.004, $\\gamma=\n2.051^{+0.076}_{-0.077}-0.171^{+0.214}_{-0.196}z$. Although not the more likely\nmodel, this evolved $\\gamma$ case also fits the data well, with a negative and\nmild evolution for both low and high redshift samples.\n", "  The TNG300-1 run of the IllustrisTNG simulations includes 1697 clusters of\ngalaxies with $M_{200c}>10^{14}$M$_\\odot$ covering the redshift range\n$0.01-1.04$. We build mock spectroscopic redshift catalogues of simulated\ngalaxies within these clusters and apply the caustic technique to estimate the\ncumulative cluster mass profiles. We compute the total true cumulative mass\nprofile from the 3D simulation data and calculate the ratio of caustic mass to\ntotal 3D mass, $\\mathcal{F}_\\beta$, as a function of cluster-centric distance\nand identify the radial range where $\\mathcal{F}_\\beta$ is roughly constant.\nThe filling factor, $\\mathcal{F}_\\beta=0.41\\pm 0.08$, is constant on a plateau\nthat covers a wide cluster-centric distance range, $(0.6-4.2)R_{200c}$. This\ncalibration is insensitive to redshift. The calibrated caustic mass profiles\nare unbiased, with an average uncertainty of $23\\%$. At $R_{200c}$, the average\n$M^C/M^{3D}=1.03\\pm 0.22$; at $2R_{200c}$, the average $M^C/M^{3D}=1.02\\pm\n0.23$. Simulated galaxies are unbiased tracers of the mass distribution.\nIllustrisTNG is a broad statistical platform for application of the caustic\ntechnique to large samples of clusters with spectroscopic redshifts for\n$\\gtrsim 200$ members in each system. These observations will allow extensive\ncomparisons with weak lensing masses and will complement other techniques for\nmeasuring the growth rate of structure in the universe.\n", "  The Primordial Inflation Explorer (PIXIE) is an Explorer-class mission\nconcept to measure the spectrum and polarization of the cosmic microwave\nbackground. Cosmological signals are small compared to the instantaneous\ninstrument noise, requiring strict control of instrumental signals. The\ninstrument design provides multiple levels of null operation, signal\nmodulation, and signal differences, with only few-percent systematic error\nsuppression required at each level. Jackknife tests based on discrete\ninstrument symmetries provide an independent means to identify, model, and\nremove remaining instrumental signals. We use detailed time-ordered\nsimulations, including realistic performance and tolerance parameters, to\nevaluate the instrument response to broad classes of systematic errors for both\nspectral distortions and polarization. The largest systematic errors contribute\nadditional white noise at the few-percent level compared to the dominant photon\nnoise. Coherent instrumental effects which do not integrate down are smaller\nstill, and remain several orders of magnitude below the targeted cosmological\nsignals.\n", "  We perform a blinded cosmology analysis with cosmic shear two-point\ncorrelation functions (2PCFs) measured from more than 25 million galaxies in\nthe Hyper Suprime-Cam three-year shear catalog in four tomographic redshift\nbins ranging from 0.3 to 1.5. After conservative masking and galaxy selection,\nthe survey covers 416 deg$^2$ of the northern sky with an effective galaxy\nnumber density of 15 arcmin$^{-2}$ over the four redshift bins. The 2PCFs\nadopted for cosmology analysis are measured in the angular range: $7.1 <\n\\theta/{\\rm arcmin} < 56.6$ for $\\xi_+$ and $31.2 <\\theta/{\\rm arcmin} < 248$\nfor $\\xi_-$, with a total signal-to-noise ratio of 26.6. We apply a\nconservative, wide, flat prior on the photometric redshift errors on the last\ntwo tomographic bins, and the relative magnitudes of the cosmic shear amplitude\nacross four redshift bins allow us to calibrate the photometric redshift\nerrors. With this flat prior on redshift errors, we find $\\Omega_{\\rm\nm}=0.256_{-0.044}^{+0.056}$ and $S_8\\equiv \\sigma_8 \\sqrt{\\Omega_{\\rm\nm}/0.3}=0.769_{-0.034}^{+0.031}$ (both 68\\% CI) for a flat $\\Lambda$ cold dark\nmatter cosmology. We find, after unblinding, that our constraint on $S_8$ is\nconsistent with the Fourier space cosmic shear and the 3$\\times$2pt analyses on\nthe same HSC dataset. We carefully study the potential systematics from\nastrophysical and systematic model uncertainties in our fiducial analysis using\nsynthetic data, and report no biases (including projection bias in the\nposterior space) greater than $0.5\\sigma$ in the estimation of $S_8$. Our\nanalysis hints that the mean redshifts of the two highest tomographic bins are\nhigher than initially estimated. In addition, a number of consistency tests are\nconducted to assess the robustness of our analysis. Comparing our result with\nPlanck-2018 cosmic microwave background observations, we find a ~$2\\sigma$\ntension for the $\\Lambda$CDM model.\n", "  We use the Sloan Digital Sky Survey (SDSS) BOSS galaxies and their overlap\nwith approximately 416 sq. degree of deep $grizy$-band imaging from the Subaru\nHyper Suprime-Cam Survey (HSC). We measure three two-point correlations that\nform the basis of the cosmological inference presented in our companion papers,\nMiyatake et al. and Sugiyama et al. We use three approximately volume limited\nsubsamples of spectroscopic galaxies by their $i$-band magnitude from the\nSDSS-BOSS: LOWZ (0.1<z<0.35), CMASS1 (0.43<z<0.55) and CMASS2 (0.55<z<0.7),\nrespectively. We present high signal-to-noise ratio measurements of the\nprojected correlation functions of these galaxies, which is expected to be\nproportional to the matter correlation function times the bias of galaxies on\nlarge scales. In order to break the degeneracy between the amplitude of the\nmatter correlation and the bias of these galaxies, we use the distortions of\nthe shapes of galaxies in HSC due to weak gravitational lensing, to measure the\ngalaxy-galaxy lensing signal, which probes the galaxy-matter cross-correlation\nof the SDSS-BOSS galaxies. We also measure the cosmic shear correlation\nfunctions from HSC galaxies which is related to the projected matter\ncorrelation function. We demonstrate the robustness of our measurements with a\nvariety of systematic tests. Our use of a single sample of HSC source galaxies\nis crucial to calibrate any residual systematic biases in the inferred\nredshifts of our galaxies. We also describe the construction of a suite of\nmocks: i) spectroscopic galaxy catalogs which obey the clustering and abundance\nof each of the three SDSS-BOSS subsamples, and ii) galaxy shape catalogs which\nobey the footprint of the HSC survey and have been appropriately sheared by the\nlarge-scale structure expected in a $\\Lambda$-CDM model. We use these mock\ncatalogs to compute the covariance of each of our observables.\n", "  We present cosmology results from a blinded joint analysis of cosmic shear,\n$\\xi_{\\pm}(\\vartheta)$, galaxy-galaxy weak lensing, $\\Delta\\!\\Sigma(R)$, and\nprojected galaxy clustering, $w_{\\rm p}(R)$, measured from the Hyper\nSuprime-Cam three-year (HSC-Y3) shape catalog and the Sloan Digital Sky Survey\n(SDSS) DR11 spectroscopic galaxy catalog - a 3$\\times$2pt cosmology analysis.\nWe define luminosity-cut samples of SDSS galaxies to serve as the tracers of\n$w_{\\rm p}$ and as the lens samples for $\\Delta\\!\\Sigma$ in three spectroscopic\nredshift bins spanning the range $0.15<z<0.7$. For the $\\xi_{\\pm}$ and\n$\\Delta\\!\\Sigma$ measurements, we use a single source sample over 416 deg$^2$,\nselected from HSC-Y3 based on having photometric redshifts (photo-$z$) greater\nthan 0.75. For cosmological parameter inference, we use Dark Emulator combined\nwith a halo occupation distribution prescription to model $w_{\\rm p}$ and\n$\\Delta\\!\\Sigma$ down to quasi-nonlinear scales. In our baseline analysis we\nemploy an uninformative flat prior of the residual photo-$z$ error to model a\nresidual bias in the mean redshift of HSC source galaxies. We obtain a robust\nconstraint on the cosmological parameters for the flat $\\Lambda$CDM model:\n$S_8=\\sigma_8(\\Omega_{\\rm m}/0.3)^{0.5}=0.763^{+0.040}_{-0.036}$ (68% C.I.), or\nthe best-constrained parameter given by $S'_8=\\sigma_8(\\Omega_{\\rm\nm}/0.3)^{0.22}=0.721\\pm 0.028$, determined with about 4% fractional precision.\nOur HSC-Y3 data exhibits about 2.5$\\sigma$ tension with the Planck inferred\n$S_8$ value for the $\\Lambda$CDM model, and hints at a non-zero residual\nphoto-$z$ bias implying that the true mean redshift of the HSC galaxies at\n$z\\gtrsim 0.75$ is higher than that implied by the original photo-$z$\nestimates.\n", "  We present cosmological parameter constraints from a blind joint analysis of\nthree two-point correlation functions measured from the Year 3 Hyper\nSuprime-Cam (HSC-Y3) imaging data, covering 416 deg$^2$, and the SDSS DR11\nspectroscopic galaxies spanning the redshift range $[0.15, 0.70]$. We subdivide\nthe SDSS galaxies into three volume-limited samples separated in redshift, each\nof which acts as a large-scale structure tracer characterized by the\nmeasurement of the projected correlation function, $w_{\\rm p}(R)$. We also use\nthe measurements of the galaxy-galaxy weak lensing signal $\\Delta \\Sigma(R)$\nfor each of these SDSS samples which act as lenses for a secure sample of\nsource galaxies selected from the HSC-Y3 shape catalog based on their\nphotometric redshifts. We combine these measurements with the cosmic shear\ncorrelation functions, $\\xi_{\\pm}(\\vartheta)$, measured for our HSC source\nsample. We model these observables with the minimal bias model of the galaxy\nclustering observables in the context of a flat $\\Lambda$CDM cosmology. We use\nconservative scale cuts, $R>12$ and $8~h^{-1}$Mpc, for $\\Delta\\Sigma$ and\n$w_{\\rm p}$, respectively, where the minimal bias model is valid, in addition\nto conservative prior on the residual bias in the mean redshift of the HSC\nphotometric source galaxies. Our baseline analysis yields\n$S_8=0.775^{+0.043}_{-0.038}$ (68% C.I.) for the $\\Lambda$CDM model, after\nmarginalizing over uncertainties in other parameters. Our value of $S_8$ is\nconsistent with that from the Planck 2018 data, but the credible interval of\nour result is still relatively large. Our results are statistically consistent\nwith those of a companion paper, which extends this analysis to smaller scales\nwith an emulator-based halo model.\n", "  The first generation of stars in the Universe is yet to be observed. There\nare two leading theories for those objects that mark the beginning of the\ncosmic dawn: hydrogen burning Population~III stars and Dark Stars, made of\nhydrogen and helium but powered by Dark Matter heating. The latter can grow to\nbecome supermassive ($M_\\star\\sim 10^6\\Msun$) and extremely bright ($L\\sim\n10^9L_\\odot$). We show that each of the following three objects:\nJADES-GS-z13-0, JADES-GS-z12-0, and JADES-GS-z11-0 (at redshifts $z\\in[11,14]$)\nare consistent with a Supermassive Dark Star interpretation, thus identifying,\nfor the first time, Dark Star candidates.\n", "  The integrated shear 3-point correlation function $\\zeta_{\\pm}$ measures the\ncorrelation between the local shear 2-point function $\\xi_{\\pm}$ and the\n1-point shear aperture mass in patches of the sky. Unlike other higher-order\nstatistics, $\\zeta_{\\pm}$ can be efficiently measured from cosmic shear data,\nand it admits accurate theory predictions on a wide range of scales as a\nfunction of cosmological and baryonic feedback parameters. Here, we develop and\ntest a likelihood analysis pipeline for cosmological constraints using\n$\\zeta_{\\pm}$. We incorporate treatment of systematic effects from photometric\nredshift uncertainties, shear calibration bias and galaxy intrinsic alignments.\nWe also develop an accurate neural-network emulator for fast theory predictions\nin MCMC parameter inference analyses. We test our pipeline using realistic\ncosmic shear maps based on $N$-body simulations with a DES Y3-like footprint,\nmask and source tomographic bins, finding unbiased parameter constraints.\nRelative to $\\xi_{\\pm}$-only, adding $\\zeta_{\\pm}$ can lead to $\\approx\n10-25\\%$ improvements on the constraints of parameters like $A_s$ (or\n$\\sigma_8$) and $w_0$. We find no evidence in $\\xi_{\\pm} + \\zeta_{\\pm}$\nconstraints of a significant mitigation of the impact of systematics. We also\ninvestigate the impact of the size of the apertures where $\\zeta_{\\pm}$ is\nmeasured, and of the strategy to estimate the covariance matrix ($N$-body vs.\nlognormal). Our analysis solidifies the strong potential of the $\\zeta_{\\pm}$\nstatistic and puts forward a pipeline that can be readily used to improve\ncosmological constraints using real cosmic shear data.\n", "  The sensitivity and wide area reached by ongoing and future wide-field\noptical surveys allows for the detection of an increasing number of galaxy\nclusters uniquely through their weak lensing (WL) signal. This motivates the\ndevelopment of new methods to analyse the unprecedented volume of data faster\nand more efficiently. Here we introduce a new multi-scale WL detection method\nbased on application of wavelet filters to the convergence maps. We compare our\nresults to those obtained from four commonly-used single scale approaches based\non the application of aperture mass filters to the shear in real and Fourier\nspace. The method is validated on Euclid-like mocks from the\nDUSTGRAIN-pathfinder simulations. We introduce a new matching procedure that\ntakes into account the theoretical signal-to-noise of detection by WL and the\nfilter size. We perform a complete analysis of the filters, and a comparison of\nthe purity and the completeness of the resulting detected catalogues. We show\nthat equivalent results are obtained when the detection is undertaken in real\nand Fourier space, and when the algorithms are applied to the shear and the\nconvergence. We show that the multiscale method applied to the convergence is\nfaster and more efficient at detecting clusters than single scale methods\napplied to the shear. We obtained an increase of 25% in the number of\ndetections while maintaining the same purity compared to the most up-to-date\naperture mass filter. We analyse the detected catalogues and quantify the\nefficiency of the matching procedure, showing in particular that less than 5%\nof the detections from the multiscale method can be ascribed to line-of-sight\nalignments. The method is well-adapted to the more sensitive, wider-area,\noptical surveys that will be available in the near future, and paves the way to\ncluster samples that are as near as possible to being selected by total matter\ncontent.\n", "  Wavelength-dependent atmospheric effects impact photometric supernova flux\nmeasurements for ground-based observations. We present corrections on supernova\nflux measurements from the Dark Energy Survey Supernova Program's 5YR sample\n(DES-SN5YR) for differential chromatic refraction (DCR) and\nwavelength-dependent seeing, and we show their impact on the cosmological\nparameters $w$ and $\\Omega_m$. We use $g-i$ colors of Type Ia supernovae (SNe\nIa) to quantify astrometric offsets caused by DCR and simulate point spread\nfunctions (PSFs) using the GalSIM package to predict the shapes of the PSFs\nwith DCR and wavelength-dependent seeing. We calculate the magnitude\ncorrections and apply them to the magnitudes computed by the DES-SN5YR\nphotometric pipeline. We find that for the DES-SN5YR analysis, not accounting\nfor the astrometric offsets and changes in the PSF shape cause an average bias\nof $+0.2$ mmag and $-0.3$ mmag respectively, with standard deviations of $0.7$\nmmag and $2.7$ mmag across all DES observing bands (\\textit{griz}) throughout\nall redshifts. When the DCR and seeing effects are not accounted for, we find\nthat $w$ and $\\Omega_m$ are lower by less than $0.004\\pm0.02$ and\n$0.001\\pm0.01$ respectively, with $0.02$ and $0.01$ being the $1\\sigma$\nstatistical uncertainties. Although we find that these biases do not limit the\nconstraints of the DES-SN5YR sample, future surveys with much higher\nstatistics, lower systematics, and especially those that observe in the $u$\nband will require these corrections as wavelength-dependent atmospheric effects\nare larger at shorter wavelengths. We also discuss limitations of our method\nand how they can be better accounted for in future surveys.\n", "  All single-field inflationary models invoke varying degrees of tuning in\norder to account for cosmological observations. Mechanisms that generate\nprimordial black holes (PBHs) from enhancement of primordial power at small\nscales posit inflationary potentials that transiently break scale invariance\nand possibly adiabaticity over a range of modes. This requires additional\ntuning on top of that required to account for observations at scales probed by\ncosmic microwave background (CMB) anisotropies. In this paper we study the\nparametric dependence of various single-field models of inflation that enhance\npower at small scales and quantify the degree to which coefficients in the\nmodel construction have to be tuned in order for certain observables to lie\nwithin specified ranges. We find significant tuning: changing the parameters of\nthe potentials by between one part in a hundred and one part in $10^8$\n(depending on the model) is enough to change the power spectrum peak amplitude\nby an order one factor. The fine-tuning of the PBH abundance is larger still by\n1-2 orders of magnitude. We highlight the challenges imposed by this tuning on\nany given model construction. Furthermore, polynomial potentials appear to\nrequire significant additional fine-tuning to also match the CMB observations.\n", "  We introduce grlic, a publicly available Python tool for generating\nglass-like point distributions with a radial density profile $n(r)$ as it is\nobserved in large-scale surveys of galaxy distributions on the past light cone.\nUtilising these glass-like catalogues, we assess the bias and variance of the\nLandy-Szalay (LS) estimator of the first three two-point correlation function\n(2PCF) multipoles in halo and particle catalogues created with the cosmological\nN-body code gevolution. Our results demonstrate that the LS estimator\ncalculated with the glass catalogues is biased by less than $10^{-4}$ with\nrespect to the estimate derived from Poisson-sampled random catalogues, for all\nmultipoles considered and on all but the smallest scales. Additionally, the\nestimates derived from glass-like catalogues exhibit significantly smaller\nstandard deviation $\\sigma$ than estimates based on commonly used\nPoisson-sampled random catalogues of comparable size. The standard deviation of\nthe estimate depends on a power of the number of objects $N_R$ in the random\ncatalogue; we find a power law $\\sigma \\propto N_R^{-0.9}$ for glass-like\nrandom catalogues as opposed to $\\sigma \\propto N_R^{-0.48}$ using\nPoisson-sampled random catalogues. Given a required precision, this allows for\na much reduced number of objects in the glass-like random catalogues used for\nthe LS estimate of the 2PCF multipoles, significantly reducing the\ncomputational costs of each estimate.\n", "  Deep surveys of the CMB polarization have more information on the lensing\nsignal than the quadratic estimators (QE) can capture. We showed in a recent\nwork that a CMB lensing power spectrum built from a single optimized CMB\nlensing mass map, working in close analogy to state-of-the-art QE techniques,\ncan result in an essentially optimal spectrum estimator at reasonable numerical\ncost. We extend this analysis here to account for real-life non-idealities\nincluding masking and realistic instrumental noise maps. As in the QE case, it\nis necessary to include small corrections to account for the estimator response\nto these anisotropies, which we demonstrate can be estimated easily from\nsimulations. The realization-dependent debiasing of the spectrum remains\nrobust, allowing unbiased recovery of the band powers even in cases where the\nstatistical model used for the lensing map reconstruction is grossly wrong.\nThis allows now robust and at the same time optimal CMB lensing constraints\nfrom CMB data, on all scales relevant for the inference of the neutrino mass,\nor other parameters of our cosmological model.\n", "  Compensated isocurvature perturbations (CIPs) are perturbations to the\nprimordial baryon density that are accompanied by dark-matter-density\nperturbations so that the total matter density is unperturbed. Such CIPs, which\nmay arise in some multi-field inflationary models, can be long-lived and only\nweakly constrained by current cosmological measurements. Here we show that the\nCIP-induced modulation of the electron number density interacts with the\nelectron-temperature fluctuation associated with primordial adiabatic\nperturbations to produce, via the Biermann-battery mechanism, a magnetic field\nin the post-recombinaton Universe. Assuming the CIP amplitude saturates the\ncurrent BBN bounds, this magnetic field can be stronger than\n$10^{-15}\\,\\mathrm{nG}$ at $z\\simeq20$ and stronger by an order of magnitude\nthan that (produced at second order in the adiabatic-perturbation amplitude) in\nthe standard cosmological model, and thus can serve as a possible seed for\ngalactic dynamos.\n", "  When coupled to electromagnetism via a Chern-Simons interaction, axion-like\nparticles (ALP) produce a rotation of the plane of linear polarization of\nphotons known as cosmic birefringence. Recent measurements of cosmic\nbirefringence obtained from the polarization of the cosmic microwave background\n(CMB) hint at the existence of an isotropic birefringence angle of\n$\\beta\\approx 0.3^\\circ$, currently excluding $\\beta=0$ with a statistical\nsignificance of $3.6\\sigma$. Were such measurement to be confirmed as a\ncosmological signal, CMB information alone could constrain the ALP parameter\nspace for masses $m_\\phi\\lesssim 10^{-27}$eV and axion-photon coupling\nconstants $g_{\\phi\\gamma}\\gtrsim 10^{-20}$GeV$^{-1}$.\n", "  Gaussian Process (GP) has gained much attention in cosmology due to its\nability to reconstruct cosmological data in a model-independent manner. In this\nstudy, we compare two methods for GP kernel selection: Approximate Bayesian\nComputation (ABC) Rejection and nested sampling. We analyze three types of\ndata: cosmic Chronometer data (CC), Type Ia Supernovae (SNIa), and Gamma Ray\nBurst (GRB), using five kernel functions. To evaluate the differences between\nkernel functions, we assess the strength of evidence using Bayes factors. Our\nresults show that, for ABC Rejection, the Mat\\'ern kernel with $\\nu$=5/2 (M52\nkernel) outperformes the commonly used Radial Basis Function (RBF) kernel in\napproximating all three datasets. Bayes factors indicate that the M52 kernel\ntypically supports the observed data better than the RBF kernel, but with no\nclear advantage over other alternatives. However, nested sampling gives\ndifferent results, with the M52 kernel losing its advantage. Nevertheless,\nBayes factors indicate no significant dependence of the data on each kernel.\n", "  The precise estimation of the statistical errors and accurate removal of the\nsystematical errors are the two major challenges for the stage IV cosmic shear\nsurveys. We explore their impact for the China Space-Station Telescope (CSST)\nwith survey area $\\sim17,500\\deg^2$ up to redshift $\\sim4$. We consider\nstatistical error contributed from Gaussian covariance, connected non-Gaussian\ncovariance and super-sample covariance. We find the non-Gaussian covariances,\nwhich is dominated by the super-sample covariance, can largely reduce the\nsignal-to-noise of the two-point statistics for CSST, leading to a $\\sim1/3$\nloss in the figure-of-merit for the matter clustering properties\n($\\sigma_8-\\Omega_m$ plane) and $1/6$ in the dark energy equation-of-state\n($w_0-w_a$ plane). We further put requirements of systematics-mitigation on:\nintrinsic alignment of galaxies, baryonic feedback, shear multiplicative bias,\nand bias in the redshift distribution, for an unbiased cosmology. The $10^{-2}$\nto $10^{-3}$ level requirements emphasize strong needs in related studies, to\nsupport future model selections and the associated priors for the nuisance\nparameters.\n", "  Dark energy is a premier mystery of physics, both theoretical and\nexperimental. As we look to develop plans for high energy physics over the next\ndecade, within a two decade view, we consider benchmarks for revealing the\nnature of dark energy. We conclude, based on fundamental physical principles\ndetailed below, that understanding will come from experiments reaching key\nbenchmarks:\n  $\\bullet\\ \\sigma(w_a)<2.5\\sigma(w_0)$\n  $\\bullet\\ \\sigma(w_0)<0.02$\n  $ \\bullet\\ \\sigma(\\rho_{\\rm de}/\\rho_{\\rm crit})<(1/3)\\rho_\\Lambda/\\rho_{\\rm\ncrit}$ for all redshifts $z<5$\n  where the dark energy equation of state $w(a)=w_0+w_a(1-a)$. Beyond the\ncosmic expansion history we also discuss benchmarks for the cosmic growth\nhistory appropriate for testing classes of gravity theories. All benchmarks can\nbe achieved by a robust Stage 5 program, using extensions of existing probes\nplus the highly complementary, novel probe of cosmic redshift drift.\n", "  Observations are beginning to constrain the history of the epoch of\nreionization (EoR). Modeling the reionization process is indispensable to\ninterpret the observations, to infer the properties of ionizing sources, and to\nprobe the various astrophysical processes from the observational data. Here we\npresent an improved version of the semi-numerical simulation islandFAST, by\nincorporating inhomogeneous recombinations and a corresponding inhomogeneous\nionizing background, and simulate the reionization process of neutral islands\nduring the late EoR. We find that the islands are more fragmented in models\nwith inhomogeneous recombinations than the case with a homogeneous\nrecombination number. In order to investigate the effects of basic assumptions\nin the reionization modeling, we compare the results from islandFAST with those\nfrom 21cmFAST for the same assumptions on the ionizing photon sources and\nsinks, to find how the morphology of the ionization field and the reionization\nhistory depend on the different treatments of these two models. Such systematic\nbias should be noted when interpreting the upcoming observations.\n", "  We investigate the impact and mitigation of extragalactic foregrounds for the\nCMB lensing power spectrum analysis of Atacama Cosmology Telescope (ACT) data\nrelease 6 (DR6) data. Two independent microwave sky simulations are used to\ntest a range of mitigation strategies. We demonstrate that finding and then\nsubtracting point sources, finding and then subtracting models of clusters, and\nusing a profile bias-hardened lensing estimator, together reduce the fractional\nbiases to well below statistical uncertainties, with the inferred lensing\namplitude, $A_{\\mathrm{lens}}$, biased by less than $0.2\\sigma$. We also show\nthat another method where a model for the cosmic infrared background (CIB)\ncontribution is deprojected and high frequency data from Planck is included has\nsimilar performance. Other frequency-cleaned options do not perform as well,\nincurring either a large noise cost, or resulting in biased recovery of the\nlensing spectrum. In addition to these simulation-based tests, we also present\nnull tests performed on the ACT DR6 data which test for sensitivity of our\nlensing spectrum estimation to differences in foreground levels between the two\nACT frequencies used, while nulling the CMB lensing signal. These tests pass\nwhether the nulling is performed at the map or bandpower level. The\nCIB-deprojected measurement performed on the DR6 data is consistent with our\nbaseline measurement, implying contamination from the CIB is unlikely to\nsignificantly bias the DR6 lensing spectrum. This collection of tests gives\nconfidence that the ACT DR6 lensing measurements and cosmological constraints\npresented in companion papers to this work are robust to extragalactic\nforegrounds.\n", "  A new determination of the temperature of the intergalactic medium over $3.9\n\\leq z \\leq 4.3$ is presented. We applied the curvature method on a sample of\n10 high resolution quasar spectra from the Ultraviolet and Visual Echelle\nSpectrograph on the VLT/ESO. We measured the temperature at mean density by\ndetermining the temperature at the characteristic overdensity, which is tight\nfunction of the absolute curvature irrespective of $\\gamma$. Under the\nassumption of fiducial value of $\\gamma = 1.4$, we determined the values of\ntemperatures at mean density $T_{0} = 7893^{+1417}_{-1226}$ K and $T_{0} =\n8153^{+1224}_{-993}$ K for redshift range of $3.9 \\leq z \\leq 4.1$ and $4.1\n\\leq z \\leq 4.3$, respectively. Even though the results show no strong\ntemperature evolution over the studied redshift range, our measurements are\nconsistent with an intergalactic medium thermal history that includes a\ncontribution from He II reionization.\n", "  We utilize the probability distribution function (PDF) of normalized\nconvergence maps reconstructed from the Subaru Hyper Suprime-Cam (HSC) Y1 shear\ncatalogue, in combination with the power spectrum, to measure the matter\nclustering amplitude $S_8=\\sigma_8\\sqrt{\\Omega_m/0.3}$. The large-scale\nstructure's statistical properties are incompletely described by the\ntraditional two-point statistics, motivating our investigation of the PDF -- a\ncomplementary higher-order statistic. By defining the PDF over the standard\ndeviation-normalized convergence map we are able to isolate the non-Gaussian\ninformation. We use tailored simulations to compress the data vector and\nconstruct a likelihood approximation. We mitigate the impact of survey and\nastrophysical systematics with cuts on smoothing scales, redshift bins, and\ndata vectors. We find $S_8=0.860^{+0.066}_{-0.109}$ from the PDF alone and\n$S_8=0.798^{+0.029}_{-0.042}$ from the combination of PDF and power spectrum\n(68% CL). The PDF improves the power spectrum-only constraint by about 10%.\n", "  Dark matter subhalos with extended profiles and density cores, and globular\nstars clusters of mass $10^6-10^8 M_\\odot$, that live near the critical curves\nin galaxy cluster lenses can potentially be detected through their lensing\nmagnification of stars in background galaxies. In this work we study the effect\nsuch subhalos have on lensed images, and compare to the case of more well\nstudied microlensing by stars and black holes near critical curves. We find\nthat the cluster density gradient and the extended mass distribution of\nsubhalos are important in determining image properties. Both lead to an\nasymmetry between the image properties on the positive and negative parity\nsides of the cluster that is more pronounced than in the case of microlensing.\nFor example, on the negative parity side, subhalos with cores larger than about\n$50\\,$pc do not generate any images with magnification above $\\sim 100$ outside\nof the immediate vicinity of the cluster critical curve. We discuss these\nfactors using analytical and numerical analysis, and exploit them to identify\nobservable signatures of subhalos: subhalos create pixel-to-pixel flux\nvariations of $\\gtrsim 0.1$ magnitudes, on the positive parity side of\nclusters. These pixels tend to cluster around (otherwise invisible) subhalos.\nUnlike in the case of microlensing, signatures of subhalo lensing can be found\nup to $1''$ away from the critical curves of massive clusters.\n", "  The Tip of the Red Giant Branch (TRGB) provides a luminous standard candle\nfor constructing distance ladders to measure the Hubble constant. In practice\nits measurements via edge-detection response (EDR) are complicated by the\napparent fuzziness of the tip and the multi-peak landscape of the EDR. As a\nresult, it can be difficult to replicate due to a case-by-case measurement\nprocess. Previously we optimized an unsupervised algorithm, Comparative\nAnalysis of TRGBs (CATs), to minimize the variance among multiple halo fields\nper host without reliance on individualized choices, achieving state-of-the-art\n$\\sim$ $<$ 0.05 mag distance measures for optimal data. Further, we found an\nempirical correlation at 5$\\sigma$ confidence in the GHOSTS halo survey between\nour measurements of the tip and their contrast ratios (ratio of stars 0.5 mag\njust below and above the tip), useful for standardizing the apparent tips at\ndifferent host locations. Here, we apply this algorithm to an expanded sample\nof SN Ia hosts to standardize these to multiple fields in the geometric anchor,\nNGC 4258. In concert with the Pantheon$+$ SN Ia sample, this analysis produces\na (baseline) result of $H_0= 73.22 \\pm 2.06$ km/s/Mpc. The largest difference\nin $H_0$ between this and similar studies employing the TRGB derives from\ncorrections for SN survey differences and local flows used in most recent SN Ia\ncompilations but which were absent in earlier studies. SN-related differences\ntotal $\\sim$ 2.0 km/s/Mpc. A smaller share, $\\sim$ 1.4 km/s/Mpc, results from\nthe inhomogeneity of the TRGB calibration across the distance ladder. We employ\na grid of 108 variants around the optimal TRGB algorithm and find the median of\nvariants is $72.94\\pm1.98$ km/s/Mpc with an additional uncertainty due to\nalgorithm choices of 0.83 km/s/Mpc. None of these TRGB variants result in $H_0$\nless than 71.6 km/s/Mpc.\n", "  We calculate the neutrino luminosity in an astrophysical scenario where dark\nmatter is captured by a neutron star which eventually implodes to form a low\nmass black hole. The Trojan horse scenario involves the collapse of a neutron\nstar (NS) due to the accumulation of a critical amount of dark matter (DM)\nduring its lifetime. As a result, a central disk forms out of the ejected\nmaterial with a finite radial extension, density, temperature, and lepton\nfraction, producing fainter neutrino luminosities and colder associated spectra\nthan found in a regular core-collapse supernova. The emitted gravitational wave\n(GW) signal from the imploding NS should be detectable at ultra-high $\\gtrsim\n0.1$ GHz frequencies.\n", "  We present a novel approach for estimating cosmological parameters,\n$\\Omega_m$, $\\sigma_8$, $w_0$, and one derived parameter, $S_8$, from 3D\nlightcone data of dark matter halos in redshift space covering a sky area of\n$40^\\circ \\times 40^\\circ$ and redshift range of $0.3 < z < 0.8$, binned to\n$64^3$ voxels. Using two deep learning algorithms, Convolutional Neural Network\n(CNN) and Vision Transformer (ViT), we compare their performance with the\nstandard two-point correlation (2pcf) function. Our results indicate that CNN\nyields the best performance, while ViT also demonstrates significant potential\nin predicting cosmological parameters. By combining the outcomes of Vision\nTransformer, Convolution Neural Network, and 2pcf, we achieved a substantial\nreduction in error compared to the 2pcf alone. To better understand the inner\nworkings of the machine learning algorithms, we employed the Grad-CAM method to\ninvestigate the sources of essential information in activation maps of the CNN\nand ViT. Our findings suggest that the algorithms focus on different parts of\nthe density field and redshift depending on which parameter they are\npredicting. This proof-of-concept work paves the way for incorporating deep\nlearning methods to estimate cosmological parameters from large-scale\nstructures, potentially leading to tighter constraints and improved\nunderstanding of the Universe.\n", "  A source lying near hyperbolic umbilic (HU) leads to a ring-like image\nformation, constituting four images with high magnification factors and lying\nin a small region of the lens plane. Since (based on our earlier work) the\nobserved number of HU image formations in cluster lenses is expected to\nincrease in future, it is timely to investigate them in more detail. Like fold\nand cusp, HU also satisfies the magnification relation, i.e., the signed\nmagnification sum of the four images equals zero. This work presents a detailed\nstudy of HU magnification relation ($R_{\\rm hu}$) considering the elliptical\nNavarro-Frenk-White (eNFW) lens profile suitable for cluster scale dark matter\nhalos. Our results show that for an isolated eNFW lens, $R_{\\rm hu}$ is more\nsensitive to ellipticity than its mass or concentration parameter. An\nellipticity greater than 0.3 results in $R_{\\rm hu}$ lying close to zero with a\nsmall scatter around it. A substructure near the HU image formation causes the\naverage $R_{\\rm hu}$ value to deviate from zero and increases the scatter, with\nthe amount of deviation depending on the image type near which the substructure\nlies. However, a population of substructures in the lens plane (equivalent to\nthe galaxy lenses inside the cluster) does not significantly shift the average\n$R_{\\rm hu}$ value from zero but increases the scatter around it. We find that\n$R_{\\rm hu} \\simeq 0$ for HU image formation in the Abell 1703 cluster.\nRepeating this test in other clusters where HU formations are discovered can be\na useful indicator of substructure in cluster halos.\n", "  We present the first detection of the baryon acoustic oscillations (BAO)\nsignal obtained using unblinded data collected during the initial two months of\noperations of the Stage-IV ground-based Dark Energy Spectroscopic Instrument\n(DESI). From a selected sample of 261,291 Luminous Red Galaxies spanning the\nredshift interval 0.4 < z < 1.1 and covering 1651 square degrees with a 57.9%\ncompleteness level, we report a ~5 sigma level BAO detection and the\nmeasurement of the BAO location at a precision of 1.7%. Using a Bright Galaxy\nSample of 109,523 galaxies in the redshift range 0.1 < z < 0.5, over 3677\nsquare degrees with a 50.0% completeness, we also detect the BAO feature at ~3\nsigma significance with a 2.6% precision. These first BAO measurements\nrepresent an important milestone, acting as a quality control on the optimal\nperformance of the complex robotically-actuated, fiber-fed DESI spectrograph,\nas well as an early validation of the DESI spectroscopic pipeline and data\nmanagement system. Based on these first promising results, we forecast that\nDESI is on target to achieve a high-significance BAO detection at sub-percent\nprecision with the completed 5-year survey data, meeting the top-level science\nrequirements on BAO measurements. This exquisite level of precision will set\nnew standards in cosmology and confirm DESI as the most competitive BAO\nexperiment for the remainder of this decade.\n", "  The Sunyaev Zel'dovich (SZ) effect is sensitive to the pressure of ionized\ngas inside galaxy clusters, which is in turn controlled largely by the\ngravitational potential of the cluster. Changing the concentration parameter\ndescribing the cluster mass distribution impacts the gravitational potential\nand thus the cluster SZ signal, with implications for cosmological and other\nanalyses of SZ-selected clusters. We investigate the concentration-SZ relation\nin theory and simulations. We find that the impact of concentration on the\ninner SZ profile ($R \\lesssim 0.75 R_{200c}$) can be captured with standard\npolytropic gas models. However, we find that such models do a poor job of\nreproducing the outer SZ profiles ($R \\gtrsim 0.75 R_{200c}$) and the relation\nbetween the integrated SZ signal, $Y$, and concentration. This disagreement\nresults from a sharp truncation of the gas pressure profile near the splashback\nradius, likely caused by virial shocks. We develop a simple description of the\ntruncation that leads to a good match with the simulated SZ profiles out to\nseveral $R_{200c}$ for clusters of varying mass and concentration, and that\nalso accurately predicts the concentration-$Y$ relationship. Finally, we\ndetermine how inference of the linear bias parameter and splashback radius for\nSZ-selected clusters can be biased by ignoring the concentration dependence of\nthe SZ signal, finding that bias to the former is essentially negligible, while\nbias to the latter can be as much as 2\\%.\n", "  We quantify the evolution of matter and galaxy clustering in cosmological\nhydrodynamical simulations via correlation and bias functions of matter and\ngalaxies. We use simulations TNG100 and TNG300 with epochs from $z=5$ to $z=0$.\nWe calculate spatial correlation functions of galaxies, $\\xi(r)$, for simulated\ngalaxies and dark matter (DM) particles to characterise the evolving cosmic\nweb. We find that bias parameters decrease during the evolution, confirming\nearlier results. At low and medium luminosities, bias parameters of galaxies,\n$b_0$, are equal, suggesting that dwarf galaxies reside in the same filamentary\nweb as brighter galaxies. Bias parameters of the lowest luminosity galaxies\nestimated from CFs are lower relative to CFs of particle density-limited\nclustered samples of DM. We find that bias parameters $b_0$, estimated from CFs\nof clustered DM, agree with the expected values from the fraction of particles\nin the clustered population, $b=1/F_c$. The cosmic web contains filamentary\nstructures of various densities, and fractions of matter in the clustered and\nthe unclustered populations are both less than unity. Thus the CF amplitude of\nthe clustered matter is always higher than for all matter, i.e. bias parameter\nmust be $b>1$. Differences between CFs of galaxies and clustered DM suggest\nthat these functions describe different properties of the cosmic web.\n", "  We measured the average Compton profile of 461 clusters detected jointly by\nthe South Pole Telescope (SPT) and Planck. The number of clusters included in\nthis analysis is about one order of magnitude larger than in previous analyses.\nWe propose an innovative method developed in Fourier space to combine optimally\nthe Planck and SPT-SZ data, allowing us to perform a clean deconvolution of the\npoint spread and transfer functions while simultaneously rescaling by the\ncharacteristic radial scale $R_{\\rm 500}$ with respect to the critical density.\nThe method additionally corrects for the selection bias of SPT clusters in the\nSPT-SZ data. We undertake a generalised Navarro-Frenk-White (gNFW) fit to the\nprofile with only one parameter fixed, allowing us to constrain the other four\nparameters with excellent precision. The best-fitting profile is in good\nagreement with the universal pressure profile based on REXCESS in the inner\nregion and with the Planck intermediate paper V profile based on Planck and the\nXMM-Newton archive in the outer region. We investigate trends with redshift and\nmass, finding no indication of redshift evolution but detecting a significant\ndifference in the pressure profile of the low- versus high-mass subsamples, in\nthe sense that the low mass subsample has a profile that is more centrally\npeaked than that of the high mass subsample. [abridged]\n", "  We propose a cross-internal linear combination (cross-ILC) approach to\nmeasure the small-scale cosmic microwave background (CMB) anisotropies robustly\nagainst the contamination from astrophysical signals. In particular, we focus\non the mitigation of systematics from cosmic infrared background (CIB) and\nthermal Sunyaev-Zeldovich (tSZ) signals in kinematic SZ (kSZ) power spectrum\nand CMB lensing. We show the cross-spectrum measurement between two CMB maps\ncreated by nulling the contributions from CIB (CIB-free map) and tSZ (tSZ-free\nmap) to be robust for kSZ as the approach significantly suppresses the total\ncontribution of CIB and tSZ signals. Similarly, for CMB lensing, we use the\napproach introduced by Madhavacheril & Hill (2018) but with a slight\nmodification by using the tSZ-free and CIB-free maps in the two legs of the\nquadratic estimator. By cross-correlating the CMB lensing map created using\nthis technique with galaxy surveys, we show that the biases from both CIB/tSZ\nare negligible. We also compute the impact of unmodeled CIB/tSZ residuals on\nkSZ and cosmological parameters finding that the kSZ measured using the\nstandard ILC to be significantly biased. The kSZ estimate from the cross-ILC\nremains less affected by CIB/tSZ making it crucial for CMB surveys such as the\nSouth Pole Telescope (SPT), Simons Observatory (SO) and CMB-S4. With the\ncross-ILC method, we find the total kSZ power spectrum can be measured at very\nhigh significance: $35\\sigma$ by SPT, $22\\sigma$ by SO, and $80\\sigma$ by\nCMB-S4. We forecast constraints on the epoch of reionization using the kSZ\npower spectrum and find that the duration of reionization, currently\nunconstrained by {\\it Planck}, can be constrained to $\\sigma(z_{\\rm dur})$= 1.5\n(or) 0.5 depending on the choice of $\\tau_{\\rm re}$ prior. The data products\nand codes can be downloaded from\nhttps://github.com/sriniraghunathan/cross_ilc_methods_paper.\n", "  Surveys with a narrow field-of-view can play an important role in probing\ncosmology, but inferences from these surveys suffer from large sample variance,\narising from random fluctuations around the cosmic mean. The standard method\nfor computing the sample variance is based on two key approximations: treating\nperturbations linearly and the survey geometry as a box. We demonstrate that it\ncan lead to a significant underestimate of the sample variance in narrow\nsurveys. We present a new method for accurately computing the sample variance\nand apply our method to the recent observations of the warm-hot intergalactic\nmedium (WHIM) based on spectroscopic measurements of blazars. We find that the\nsample variances in these surveys are significantly larger than the quoted\nmeasurement errors; for example, the cosmic mean baryon density contained in\nthe WHIM could be lower by $54\\%$ at $1\\text{-}\\sigma$ fluctuation than\nestimated in one observation. Accurately quantifying the sample variance is\nessential in deriving correct interpretations of the measurements in surveys\nwith a small field-of-view.\n", "  We develop a framework for self-consistently extracting cosmological\ninformation from the clustering of tracers in redshift space,\n$\\textit{without}$ relying on model-dependent templates to describe the baryon\nacoustic oscillation (BAO) feature. Our approach uses the recently proposed\nLaguerre reconstruction technique for the BAO feature and its linear point\n$r_{\\rm LP}$, and substantially extends it to simultaneously model the\nmultipoles $\\ell=0,2,4$ of the anisotropic galaxy 2-point correlation function\n(2pcf). The approach is `model-agnostic': it assumes that the non-linear growth\nof structure smears the BAO feature by an approximately Gaussian kernel with a\nsmearing scale $\\sigma_{\\rm v}$, but does not assume any fiducial cosmology for\ndescribing the shape of the feature itself. Using mock observations for two\nrealistic survey configurations assuming $\\Lambda$ cold dark matter\n($\\Lambda$CDM), combined with Bayesian parameter inference, we show that the\nlinear point $r_{\\rm LP}$ and smearing scale $\\sigma_{\\rm v}$ can be accurately\nrecovered by our method in both existing and upcoming surveys. The precision of\nthe recovery of $r_{\\rm LP}$ is always better than $1\\%$, while $\\sigma_{\\rm\nv}$ can be recovered with $\\lesssim10\\%$ uncertainty provided the linear galaxy\nbias $b$ is separately constrained, e.g., using weak lensing observations. Our\nmethod is also sensitive to the linear growth rate $f$, albeit with larger\nuncertainties and systematic errors, especially for upcoming surveys such as\nDESI. We discuss how our model can be modified to improve the recovery of $f$,\nsuch that the resulting constraints on $\\{f,\\sigma_{\\rm v},r_{\\rm LP}\\}$ can\npotentially be used as a test of cosmological models including and beyond\n$\\Lambda$CDM.\n", "  With the help of our previously built MCMC-based parameter estimation package\n\\texttt{CosmoReionMC}, we investigate in detail the potential of 21 cm global\nsignal, when combined with CMB and observations related to the QSO absorption\nspectra, to constraint the mass of Warm Dark Matter (WDM) particle. For the\nfirst time, we simultaneously vary all the free parameters (mass of WDM\nparticle, cosmological parameters, and astrophysical parameters) in a joint\nanalysis with CMB, observations related to the QSO absorption spectra and 21 cm\nglobal signal, to address the long-overlooked issue of the possible\ndegeneracies between the Dark Matter particle mass $m_X$ and\ncosmological/astrophysical parameters. From the existing CMB and QSO absorption\nspectra data, we can rule out $m_X < 2.8$ keV at 95\\% confidence level.\nIncluding a mock 21~cm global signal in the redshift range $z = 25 - 5$\nexpected to be observed with upcoming instruments designed for global signal,\nthe forecasted constraint is found to be much tighter $m_X > 7.7$ keV, assuming\nthat the true dark matter model is the usual cold dark matter. In case the mock\n21 cm signal is constructed for dark matter particles having $m_X = 7$ keV, our\nforecasts indicate that $\\left(m_X / \\text{keV}\\right)^{-1}$ is in the range\n$[0.1, 0.2]$ ($95\\%$ confidence level). This implies that the future 21 cm data\nshould allow detection of the WDM particle mass if $m_X \\sim 7$ keV.\n", "  We build a deep learning framework that connects the local formation process\nof dark matter halos to the halo bias. We train a convolutional neural network\n(CNN) to predict the final mass and concentration of dark matter halos from the\ninitial conditions. The CNN is then used as a surrogate model to derive the\nresponse of the halos' mass and concentration to long-wavelength perturbations\nin the initial conditions, and consequently the halo bias parameters following\nthe \"response bias\" definition. The CNN correctly predicts how the local\nproperties of dark matter halos respond to changes in the large-scale\nenvironment, despite no explicit knowledge of halo bias being provided during\ntraining. We show that the CNN recovers the known trends for the linear and\nsecond-order density bias parameters $b_1$ and $b_2$, as well as for the local\nprimordial non-Gaussianity linear bias parameter $b_\\phi$. The expected\nsecondary assembly bias dependence on halo concentration is also recovered by\nthe CNN: at fixed mass, halo concentration has only a mild impact on $b_1$, but\na strong impact on $b_\\phi$. Our framework opens a new window for discovering\nwhich physical aspects of the halo's Lagrangian patch determine assembly bias,\nwhich in turn can inform physical models of halo formation and bias.\n", "  Accurate detection of the cosmological 21-cm global signal requires galactic\nforeground models which can remove power over ~$10^6$. Although foreground and\nglobal signal models unavoidably exhibit overlap in their vector-spaces\ninducing bias error in the extracted signal, a second source of bias and error\narises from inadequate foreground models, i.e. models which cannot fit spectra\ndown to the noise level of the signal. We therefore test the level to which\nseven commonly employed foreground models -- including nonlinear and linear\nforward-models, polynomials, and maximally-smooth polynomials -- fit realistic\nsimulated mock foreground spectra, as well as their dependence upon model\ninputs. The mock spectra are synthesized for an EDGES-like experiment and we\ncompare all models' goodness-of-fit and preference using a Kolomogorov-Smirnov\ntest of the noise-normalized residuals in order to compare models with\ndiffering, and sometimes indeterminable, degrees of freedom. For a single LST\nbin spectrum and p-value threshold of $p=0.05$, the nonlinear-forward model\nwith 4 parameters is preferred ($p=0.99$), while the linear forward-model fits\nwell with 6-7 parameters ($p=0.94,0.97$ respectively). The polynomials and\nmaximally-smooth polynomials, like those employed by the EDGES and SARAS3\nexperiments, cannot produce good fits with 5 parameters for the experimental\nsimulations in this work ($p<10^{-6}$). However, we find that polynomials with\n6 parameters pass the KS-test ($p=0.4$), although a 9 parameter fit produces\nthe highest p-value ($p\\sim0.67$). When fitting multiple LST bins\nsimultaneously, we find that the linear forward-model outperforms (a higher\np-value) the nonlinear for 2, 5 and 10 LST bins. Importantly, the KS-test\nconsistently identifies best-fit \\textit{and} preferred models.\n", "  While collisionless cold dark matter models have been largely successful in\nexplaining a wide range of observational data, some tensions still exist, and\nit remains possible that dark matter possesses a non-negligible level of self\ninteractions. In this paper, we investigate a possible observable consequence\nof self-interacting dark matter: offsets between the central galaxy and the\ncenter of mass of its parent halo. We examine 23 relaxed galaxy clusters in a\nredshift range of 0.1 to 0.3 drawn from clusters in the Dark Energy Survey and\nthe Sloan Digital Sky Survey which have archival Chandra X-ray data of\nsufficient depth for center and relaxation determination. We find that most\nclusters in our sample show non-zero offsets between the X-ray center, taken to\nbe the centroid within the cluster core, and the central galaxy position. All\nof the measured offsets are larger, typically by an order of magnitude, than\nthe uncertainty in the X-ray position due to Poisson noise. In all but six\nclusters, the measured offsets are also larger than the estimated, combined\nastrometric uncertainties in the X-ray and optical positions. A more\nconservative cut on concentration to select relaxed clusters marginally reduces\nbut does not eliminate the observed offset. With our more conservative sample,\nwe find an estimated mean X-ray to central galaxy offset of $\\mu = 5.5 \\pm 1.0$\nkpc. Comparing to recent simulations, this distribution of offsets is\nconsistent with some level of dark matter self interaction, though further\nsimulation work is needed to place constraints.\n", "  We use parameterized post-Friedmann (PPF) description for dark energy and\napply ellipsoidal nested sampling to perform the Bayesian model selection\nmethod on different time-dependent dark energy models using a combination of\n$Planck$ and data based on distance measurements, namely baryon acoustic\noscillations and supernovae luminosity distance. Models with two and three free\nparameters described in terms of linear scale factor $a$, or scaled in units of\ne-folding $\\ln a$ are considered. Our results show that parameterizing dark\nenergy in terms of $\\ln a$ provides better constraints on the free parameters\nthan polynomial expressions. In general, two free-parameter models are adequate\nto describe the dynamics of the dark energy compared to their three\nfree-parameter generalizations. According to the Bayesian evidence, determining\nthe strength of support for cosmological constant $\\Lambda$ over polynomial\ndark energy models remains inconclusive. Furthermore, considering the $R$\nstatistic as the tension metric shows that one of the polynomial models gives\nrise to a tension between $Planck$ and distance measurements data sets. The\npreference for the logarithmic equation of state over $\\Lambda$ is\ninconclusive, and the strength of support for $\\rm \\Lambda$CDM over the\noscillating model is moderate.\n", "  We present weak gravitational lensing measurements of a sample of 157\nclusters within the Kilo Degree Survey (KiDS), detected with a $>5\\sigma$\nthermal Sunyaev-Zel'dovich (SZ) signal by the Atacama Cosmology Telescope\n(ACT). Using a halo-model approach we constrain the average total cluster mass,\n$M_{\\rm WL}$, accounting for the ACT cluster selection function of the full\nsample. We find that the SZ cluster mass estimate $M_{\\rm SZ}$, which was\ncalibrated using X-ray observations, is biased with $M_{\\rm SZ}/M_{\\rm WL} =\n(1-b_{\\rm SZ}) = 0.65\\pm 0.05$. Separating the sample into six mass bins, we\nfind no evidence of a strong mass-dependency for the mass bias, $(1-b_{\\rm\nSZ})$. Adopting this ACT-KiDS SZ mass-calibration would bring the Planck SZ\ncluster count into agreement with the counts expected from the {\\it Planck}\ncosmic microwave background $\\Lambda$CDM cosmological model, although it should\nbe noted that the cluster sample considered in this work has a lower average\nmass $M_{\\rm SZ, uncor} = 3.64 \\times 10^{14} M_{\\odot}$ compared to the Planck\ncluster sample which has an average mass in the range $M_{\\rm SZ, uncor} =\n(5.5-8.5) \\times 10^{14} M_{\\odot}$, depending on the sub-sample used.\n", "  We propose a new probe of inflationary gravitational waves (IGWs): the\ncross-correlation of the lensing of inflationary $B$-mode polarization with a\nlarge-scale structure (LSS) tracer, which can also be a cosmic microwave\nbackground (CMB) lensing map. This is equivalent to measuring a three-point\nfunction of two CMB $B$-modes and an LSS tracer. We forecast expected\n$1\\,\\sigma$ constraints on the tensor-to-scalar ratio $r$, albeit with a\nsimplistic foreground treatment, and find constraints of $\\sigma_r \\simeq 7\n\\times 10^{-3}$ from the correlation of CMB-S4-Deep $B$-mode lensing and LSST\ngalaxies, $\\sigma_r \\simeq 5 \\times 10^{-3}$ from the correlation of\nCMB-S4-Deep $B$-mode lensing and CMB-S4-Deep CMB lensing, and $\\sigma_r \\simeq\n10^{-2}$ from the correlation of LiteBIRD $B$-mode lensing and CMB-S4-Wide\nlensing. Because this probe is inherently non-Gaussian, simple Gaussian\nforegrounds will not produce any biases to the measurement of $r$. While a\ndetailed investigation of non-Gaussian foreground contamination for different\ncross-correlations will be essential, this observable has the potential to be a\nuseful probe of IGWs, which, due to different sensitivity to many potential\nsources of systematic errors, can be complementary to standard methods for\nconstraining $r$.\n", "  Deep cosmic microwave background polarization experiments allow a very\nprecise internal reconstruction of the gravitational lensing signal in\npricinple. For this aim, likelihood-based or Bayesian methods are typically\nnecessary, where very large numbers of lensing and delensing remappings on the\nsphere are sometimes required before satisfactory convergence. We discuss here\nan optimized piece of numerical code in some detail that is able to efficiently\nperform both the lensing operation and its adjoint (closely related to\ndelensing) to arbitrary accuracy, using nonuniform fast Fourier transform\ntechnology. Where applicable, we find that the code outperforms current\nwidespread software by a very wide margin. It is able to produce\nhigh-resolution maps that are accurate enough for next-generation cosmic\nmicrowave background experiments on the timescale of seconds on a modern\nlaptop. The adjoint operation performs similarly well and removes the need for\nthe computation of inverse deflection fields. This publicly available code\nenables de facto efficient spherical harmonic transforms on completely\narbitrary grids, and it might be applied in other areas as well.\n", "  Beyond standard summary statistics are necessary to summarize the rich\ninformation on non-linear scales in the era of precision galaxy clustering\nmeasurements. For the first time, we introduce the 2D k-th nearest neighbor\n(kNN) statistics as a summary statistic for discrete galaxy fields. This is a\ndirect generalization of the standard 1D kNN by disentangling the projected\ngalaxy distribution from the redshift-space distortion signature along the\nline-of-sight. We further introduce two different flavors of 2D $k$NNs that\ntrace different aspects of the galaxy field: the standard flavor which\ntabulates the distances between galaxies and random query points, and a ''DD''\nflavor that tabulates the distances between galaxies and galaxies. We showcase\nthe 2D kNNs' strong constraining power both through theoretical arguments and\nby testing on realistic galaxy mocks. Theoretically, we show that 2D kNNs are\ncomputationally efficient and directly generate other statistics such as the\npopular 2-point correlation function, voids probability function, and\ncounts-in-cell statistics. In a more practical test, we apply the 2D kNN\nstatistics to simulated galaxy mocks that fold in a large range of\nobservational realism and recover parameters of the underlying extended halo\noccupation distribution (HOD) model that includes velocity bias and galaxy\nassembly bias. We find unbiased and significantly tighter constraints on all\naspects of the HOD model with the 2D kNNs, both compared to the standard 1D\nkNN, and the classical redshift-space 2-point correlation functions.\n", "  Ongoing and upcoming galaxy surveys are providing precision measurements of\ngalaxy clustering. However a major obstacle in its cosmological application is\nthe stochasticity in the galaxy bias. We explore whether the principal\ncomponent analysis (PCA) of galaxy correlation matrix in hyperspace of galaxy\nproperties (e.g. magnitude and color) can reveal further information on\nmitigating this issue. Based on the hydrodynamic simulation TNG300-1, we\nanalyze the cross power spectrum matrix of galaxies in the magnitude and color\nspace of multiple photometric bands. (1) We find that the first principal\ncomponent $E_i^{(1)}$ is an excellent proxy of the galaxy deterministic bias\n$b_{D}$, in that $E_i^{(1)}=\\sqrt{P_{mm}/\\lambda(1)}b_{D,i}$. Here $i$ denotes\nthe $i$-th galaxy sub-sample. $\\lambda^{(1)}$ is the largest eigenvalue and\n$P_{mm}$ is the matter power spectrum. We verify that this relation holds for\nall the galaxy samples investigated, down to $k\\sim 2h/$Mpc. Since $E_i^{(1)}$\nis a direct observable, we can utilize it to design a linear weighting scheme\nto suppress the stochasticity in the galaxy-matter relation. For an LSST-like\nmagnitude limit galaxy sample, the stochasticity $\\mathcal{S}\\equiv 1-r^2$ can\nbe suppressed by a factor of $\\ga 2$ at $k=1h/$Mpc. This reduces the\nstochasticity-induced systematic error in the matter power spectrum\nreconstruction combining galaxy clustering and galaxy-galaxy lensing from $\\sim\n12\\%$ to $\\sim 5\\%$ at $k=1h/$Mpc. (2) We also find that $\\mathcal{S}$\nincreases monotonically with $f_\\lambda$ and $f_{\\lambda^2}$.\n$f_{\\lambda,\\lambda^2}$ quantify the fractional contribution of other\neigenmodes to the galaxy clustering and are direct observables. Therefore the\ntwo provide extra information on mitigating galaxy stochasticity.\n", "  We generalize previously derived analytic results for the one-loop power\nspectrum (PS) in scale-free models (with linear PS $P(k) \\propto k^n$) to a\nbroader class of such models in which part of the matterlike component driving\nthe Einstein de Sitter expansion does not cluster. These models can be\nconveniently parametrized by $\\alpha$, the constant logarithmic linear growth\nrate of fluctuations (with $\\alpha=1$ in the usual case). For $-3< n<-1$, where\nthe one-loop PS is both infrared and ultraviolet convergent and thus explicitly\nself-similar, it is characterized conveniently by a single numerical\ncoefficient $c(n, \\alpha)$. We compare the analytical predictions for $c(n=-2,\n\\alpha)$ with results from a suite of $N$-body simulations with $\\alpha \\in\n[0.25, 1]$ performed with an appropriately modified version of the GADGET code.\nAlthough the simulations are of small ($256^3$) boxes, the constraint of\nself-similarity allows the identification of the converged PS at a level of\naccuracy sufficient to test the analytical predictions for the $\\alpha$\ndependence of the evolved PS. Good agreement for the predicted dependence on\n$\\alpha$ of the PS is found. To treat the UV sensitivity of results which grows\nas one approaches $n =-1$, we derive exact results incorporating a\nregularization $k_c$ and obtain expressions for $c(n, \\alpha, k_c/k)$. Assuming\nthat this regularization is compatible with self-similarity allows us to infer\na predicted functional form of the PS equivalent to that derived in effective\nfield theory (EFT). The coefficient of the leading EFT correction at one loop\nhas a strong dependence on $\\alpha$, with a change in sign at $\\alpha \\approx\n0.16$, providing a potentially stringent test of EFT.\n", "  The intrinsic alignment (IA) of observed galaxy shapes with the underlying\ncosmic web is a source of contamination in weak lensing surveys. Sensitive\nmethods to identify the IA signal will therefore need to be included in the\nupcoming weak lensing analysis pipelines. Hydrodynamical cosmological\nsimulations allow us to directly measure the intrinsic ellipticities of\ngalaxies and thus provide a powerful approach to predict and understand the IA\nsignal. Here we employ the novel, large-volume hydrodynamical simulation\nMTNG740, a product of the MillenniumTNG (MTNG) project, to study the IA of\ngalaxies. We measure the projected correlation functions between the intrinsic\nshape/shear of galaxies and various tracers of large-scale structure, $w_{+g},\\\nw_{+m},\\ w_{++}$ over the radial range $r_{\\rm p} \\in [0.02 , 200]\\,h^{-1}{\\rm\nMpc}$ and at redshifts $z=0.0$, $0.5$ and $1.0$. We detect significant\nsignal-to-noise IA signals with the density field for both elliptical and\nspiral galaxies. We also find significant intrinsic shear-shear correlations\nfor ellipticals. We further examine correlations of the intrinsic shape of\ngalaxies with the local tidal field. Here we find a significant IA signal for\nelliptical galaxies assuming a linear model. We also detect a weak IA signal\nfor spiral galaxies under a quadratic tidal torquing model. Lastly, we measure\nthe alignment between central galaxies and their host dark-matter halos,\nfinding small to moderate misalignments between their principal axes that\ndecline with halo mass.\n", "  Plasma lensing displays interesting characteristics that set it apart from\ngravitational lensing. The magnetised medium induces birefringence in the two\npolarisation modes. As the lensing deflection grows stronger, e.g. when images\nform near the critical curve, the geometric delay of the signal can cause\nrotation in linear polarisation, in addition to Faraday rotation. This rotation\nhas a frequency dependence to the power of four. We study the geometric\nrotation of the lensed image in a Gaussian density model and find that it is\nnecessary to take into account the geometric rotation when estimating\nmagnetised media, especially in the under-dense lens. At frequencies of $\\sim\n1$ GHz or lower, the geometric rotation can dominate. We simulate the flux of\nlensed images and find that when the image forms near the lensing critical\ncurve, the birefringence can convert the linear polarisation and\nun-polarisation pulse into a circular mode. The lensing magnification has the\npotential to increase the probability of detecting such events.\n", "  We cross-match and compare characteristics of galaxy clusters identified in\nobservations from two sky surveys using two completely different techniques.\nOne sample is optically selected from the analysis of three years of Dark\nEnergy Survey observations using the redMaPPer cluster detection algorithm. The\nsecond is X-ray selected from XMM observations analysed by the XMM Cluster\nSurvey. The samples comprise a total area of 57.4 deg$^2$, bounded by the area\nof 4 contiguous XMM survey regions that overlap the DES footprint. We find that\nthe X-ray selected sample is fully matched with entries in the redMaPPer\ncatalogue, above $\\lambda>$20 and within 0.1$< z <$0.9. Conversely, only 38\\%\nof the redMaPPer catalogue is matched to an X-ray extended source. Next, using\n120 optically clusters and 184 X-ray selected clusters, we investigate the form\nof the X-ray luminosity-temperature ($L_{X}-T_{X}$), luminosity-richness\n($L_{X}-\\lambda$) and temperature-richness ($T_{X}-\\lambda$) scaling relations.\nWe find that the fitted forms of the $L_{X}-T_{X}$ relations are consistent\nbetween the two selection methods and also with other studies in the\nliterature. However, we find tentative evidence for a steepening of the slope\nof the relation for low richness systems in the X-ray selected sample. When\nconsidering the scaling of richness with X-ray properties, we again find\nconsistency in the relations (i.e., $L_{X}-\\lambda$ and $T_{X}-\\lambda$)\nbetween the optical and X-ray selected samples. This is contrary to previous\nsimilar works that find a significant increase in the scatter of the luminosity\nscaling relation for X-ray selected samples compared to optically selected\nsamples.\n", "  In the past few years, we built a Hubble diagram of quasars up to redshift\nz$\\sim$7, based on the nonlinear relation between quasars' x-ray and UV\nluminosities. Such a Hubble diagram shows a >4$\\sigma$ deviation from the\nstandard flat $\\Lambda$CDM model at z>1.5. Given the important consequences of\nthis result, it is fundamental to rule out any systematic effect in the\nselection of the sample and/or in the flux measurements, and to investigate\npossible redshift dependences of the relation, that would invalidate the use of\nquasars as standard candles. Here we review all the observational results\nsupporting our method: the match of the Hubble diagram of quasars with that of\nsupernovae in the common redshift range, the constant slope of the relation at\nall redshifts, the redshift non-evolution of the spectral properties of our\nsources both in the x-rays and in the UV. An independent test of our results\nrequires the observation of other standard candles at high redshift. In\nparticular, we expect that future observations of supernovas at z>2 will\nconfirm the deviation from the concordance model found with the Hubble diagram\nof quasars.\n", "  In this paper, we revisit the hydrogen recombination history from a novel\nperspective: the evolution of chemical potentials. We derive expressions for\nthe chemical potentials, which depend on the thermal bath temperature and the\nionization degree of the universe. Our main finding reveals a constraint\nbetween the chemical potentials of hydrogen and proton at $z\\approx 1200$ when\nthe free electron fraction is $X_e\\approx 1/3$. Furthermore, we present\nimportant data on the chemical potentials during recombination, highlighting\nthe differences between the predictions of the Peebles' and CosmoRec code\nsolutions. Finally, we discuss a particular case related to the chemical\npotential of hydrogen.\n", "  The Epoch of Reionization (EoR) neutral Hydrogen (HI) 21-cm signal evolves\nsignificantly along the line-of-sight (LoS) due to the light-cone (LC) effect.\nIt is important to accurately incorporate this in simulations in order to\ncorrectly interpret the signal. 21-cm LC simulations are typically produced by\nstitching together slices from a finite number $(N_{\\rm RS})$ of ''reionization\nsnapshot'', each corresponding to a different stage of reionization. In this\npaper, we have quantified the errors in the 21-cm LC simulation due to the\nfinite value of $N_{\\rm RS}$. We show that this can introduce large\ndiscontinuities $(> 200 \\%)$ at the stitching boundaries when $N_{\\rm RS}$ is\nsmall $(= 2,4)$ and the mean neutral fraction jumps by $\\delta \\bar{x}_{\\rm HI}\n= 0.2,0.1$ respectively at the stitching boundaries. This drops to $17 \\%$ for\n$N_{\\rm RS} = 13$ where $\\delta \\bar{x}_{\\rm HI}=0.02$. We present and also\nvalidate a method for mitigating this error by increasing $N_{\\rm RS}$ without\na proportional increase in the computational costs which are mainly incurred in\ngenerating the dark matter and halo density fields. Our method generates these\nfields only at a few redshifts, and interpolates them to generate reionization\nsnapshots at closely spaced redshifts. We use this to generate 21-cm LC\nsimulations with $N_{\\rm RS} = 26,51,101$ and $201$, and show that the errors\ngo down as $N_{\\rm RS}^{-1}$.\n", "  We present a new suite of over 1,500 cosmological N-body simulations with\nvaried Warm Dark Matter (WDM) models ranging from 2.5 to 30 keV. We use these\nsimulations to train Convolutional Neural Networks (CNNs) to infer WDM particle\nmasses from images of DM field data. Our fiducial setup can make accurate\npredictions of the WDM particle mass up to 7.5 keV at a 95% confidence level\nfrom small maps that cover an area of (25 h$^{-1}$ Mpc)$^2$. We vary the image\nresolution, simulation resolution, redshift, and cosmology of our fiducial\nsetup to better understand how our model is making predictions. Using these\nvariations, we find that our models are most dependent on simulation\nresolution, minimally dependent on image resolution, not systematically\ndependent on redshift, and robust to varied cosmologies. We also find that an\nimportant feature to distinguish between WDM models is present with a linear\nsize between 100 and 200 h$^{-1}$ kpc. We compare our fiducial model to one\ntrained on the power spectrum alone and find that our field-level model can\nmake 2x more precise predictions and can make accurate predictions to 2x as\nmassive WDM particle masses when used on the same data. Overall, we find that\nthe field-level data can be used to accurately differentiate between WDM models\nand contain more information than is captured by the power spectrum. This\ntechnique can be extended to more complex DM models and opens up new\nopportunities to explore alternative DM models in a cosmological environment.\n", "  The mean matter density within the turnaround radius, which is the boundary\nthat separates a nonexpanding structure from the Hubble flow, was recently\nproposed as a novel cosmological probe. According to the spherical collapse\nmodel, the evolution with cosmic time of this turnaround density, $\\rm\n\\rho_{ta}(z)$, can be used to determine both $\\rm \\Omega_m$ and\n$\\Omega_\\Lambda$, independently of any other currently used probe. The\nproperties of $\\rm \\rho_{ta}$ predicted by the spherical collapse model were\nalso shown to persist in the presence of full three-dimensional effects in $\\rm\n\\Lambda$CDM N-body cosmological simulations when considering galaxy clusters at\nthe present time, $z=0$. However, a small offset was discovered between the\nspherical-collapse prediction of the value of $\\rho_{ta}$ at $z=0$ and its\nvalue measured in simulations. In this letter, we explore whether this offset\nevolves with cosmic time; whether it differs in different cosmologies; whether\nits origin can be confidently identified; and whether it can be corrected. We\nfound that the offset does evolve slightly with redshift, and that it\ncorrelates strongly with the deviation from spherical symmetry of the dark\nmatter halo distribution inside and outside of the turnaround radius. We used\nan appropriate metric to quantify deviations in the environment of a structure\nfrom spherical symmetry. We found that using this metric, we can construct a\nsphericity-selected sample of halos for which the offset of $\\rho_{ta}$ from\nthe spherical collapse prediction is zero, independently of redshift and\ncosmology. We found that a sphericity-selected halo sample allows us to recover\nthe simulated cosmology, and we conclude that the turnaround density evolution\nindeed encodes the cosmology in N-body simulations.\n", "  We develop a neural network based pipeline to estimate masses of galaxy\nclusters with a known redshift directly from photon information in X-rays. Our\nneural networks are trained using supervised learning on simulations of eROSITA\nobservations, focusing in this paper on the Final Equatorial Depth Survey\n(eFEDS). We use convolutional neural networks which are modified to include\nadditional information of the cluster, in particular its redshift. In contrast\nto existing work, we utilize simulations including background and point sources\nto develop a tool which is usable directly on observational eROSITA data for an\nextended mass range from group size halos to massive clusters with masses in\nbetween $10^{13}M_\\odot<M<10^{15}M_\\odot.$ Using this method, we are able to\nprovide for the first time neural network mass estimation for the observed\neFEDS cluster sample from Spectrum-Roentgen-Gamma/eROSITA observations and we\nfind consistent performance with weak lensing calibrated masses. In this\nmeasurement, we do not use weak lensing information and we only use previous\ncluster mass information which was used to calibrate the cluster properties in\nthe simulations. When compared to simulated data, we observe a reduced scatter\nwith respect to luminosity and count-rate based scaling relations.\n  We comment on the application for other upcoming eROSITA All-Sky Survey\nobservations.\n", "  The apparent shape of galaxy clustering depends on the adopted cosmology used\nto convert observed redshift to comoving distance, the $r(z)$ relation, as it\nchanges the line elements along and across the line of sight differently. The\nAlcock-Paczy\\'nski (AP) test exploits this property to constrain the expansion\nhistory of the universe. We present an extensive review of past studies on the\nAP test. We adopt an extended AP test method introduced by Park et al. (2019),\nwhich uses the full shape of redshift-space two-point correlation function (CF)\nas the standard shape, and apply it to the SDSS DR7, BOSS, and eBOSS LRG\nsamples covering the redshift range up to $z=0.8$.We calibrate the test against\nthe nonlinear cosmology-dependent systematic evolution of the CF shape using\nthe Multiverse simulations. We focus on examining whether or not the flat\n$\\Lambda$CDM `concordance' model is consistent with observation. We constrain\nthe flat $w$CDM model to have $w=-0.892_{-0.050}^{+0.045}$ and\n$\\Omega_m=0.282_{-0.023}^{+0.024}$ from our AP test alone, which is\nsignificantly tighter than the constraints from the BAO or SNe I$a$ methods by\na factor of 3 - 6. When the AP test result is combined with the recent BAO and\nSNe I$a$ results, we obtain $w=-0.903_{-0.023}^{+0.023}$ and\n$\\Omega_m=0.285_{-0.009}^{+0.014}$. This puts a strong tension with the flat\n$\\Lambda$CDM model with $w=-1$ at $4.2\\sigma$ level. Consistency with $w=-1$ is\nobtained only when the Planck CMB observation is combined. It remains to see if\nthis tension between observations of galaxy distribution at low redshifts and\nCMB anisotropy at the decoupling epoch becomes greater in the future studies\nand leads us to a new paradigm of cosmology.\n", "  In Luparello et al. 2023, a new and hitherto unknown CMB foreground was\ndetected. A systematic decrease in Cosmic Microwave Background (CMB)\ntemperatures around nearby large spiral galaxies points to an unknown\ninteraction with CMB photons in a sphere up to several projected Mpc around\nthese galaxies. We investigate to which extent this foreground may impact the\nCMB fluctuations map and create the so-called CMB anomalies. Using the observed\ntemperature decrements around the galaxies, and making some general assumptions\nabout the unknown interaction, we propose a common radial temperature profile.\nBy assigning this profile to nearby galaxies in the redshift range\n$z=[0.004,0.02]$ we create a foreground map model. We find a remarkable\nresemblance between this temperature model map based on nearby galaxies and the\nPlanck CMB map. Out of 1000 simulated maps, none of them show such a strong\ncorrelation with the foreground map over both large and small angular scales.\nIn particular, the quadrupole, octopole, as well as $\\ell=4$ and $\\ell=5$ modes\ncorrelate with the foreground map to high significance. Furthermore, one of the\nmost prominent temperature decrements in the foreground map coincides with the\nposition of the CMB cold spot. The largest scales of the CMB and thereby the\ncosmological parameters, may have important changes after proper corrections of\nthis foreground component. However, a reliable corrected CMB map can only be\nderived when suitable physical mechanisms are proposed and tested.\n", "  The China Space Station Telescope (CSST) is a forthcoming Stage IV galaxy\nsurvey. It will simultaneously undertake the photometric redshift (photo-z) and\nslitless spectroscopic redshift (spec-z) surveys mainly for weak lensing and\ngalaxy clustering studies. The two surveys cover the same sky area and overlap\non the redshift range. At $z>1$, due to the sparse number density of the spec-z\nsample, it limits the constraints on the scale of baryon acoustic oscillations\n(BAO). By cross-correlating the spec-z sample with the high density photo-z\nsample, we can effectively enhance the constraints on the angular diameter\ndistances $D_A(z)$ from the BAO measurement. Based on the Fisher matrix, we\nforecast a $\\geq$ 30 per cent improvement on constraining $D_A(z)$ from the\njoint analysis of the spec-z and cross galaxy power spectra at $1.0<z<1.2$.\nSuch improvement is generally robust against different systematic effects\nincluding the systematic noise and the redshift success rate of the spec-z\nsurvey, as well as the photo-z error. We also show the BAO constraints from\nother Stage-IV spectroscopic surveys for the comparison with CSST. Our study\ncan be a reference for the future BAO analysis on real CSST data. The\nmethodology can be applied to other surveys with spec-z and photo-z data in the\nsame survey volume.\n", "  In the coming years, Sunyaev-Zel'dovich (SZ) measurements can dramatically\nimprove our understanding of the Intergalactic Medium (IGM) and the role of\nfeedback processes on galaxy formation, allowing us to calibrate important\nastrophysical systematics in cosmological constraints from weak lensing galaxy\nclustering surveys. However, the signal is only measured in a two-dimensional\nprojection, and its correct interpretation relies on understanding the\nconnection between observable quantities and the underlying intrinsic\nproperties of the gas, in addition to the relation between the gas and the\nunderlying matter distribution. One way to address these challenges is through\nthe use of hydrodynamical simulations such as the high-resolution, large-volume\nMillenniumTNG suite. We find that measurements of the optical depth, $\\tau$,\nand the Compton-y parameter, $Y$, receive large line-of-sight contributions\nwhich can be removed effectively by applying a Compensated Aperture Photometry\n(CAP) filter. In contrast with other $\\tau$ probes (e.g., X-rays and Fast Radio\nBursts), the kSZ-inferred $\\tau$ receives most of its signal from a confined\ncylindrical region around the halo due to the velocity decorrelation along the\nline-of-sight. Additionally, we perform fits to the $Y-M$ and $\\tau-M$ scaling\nrelations and report best-fit parameters adopting the smoothly broken power law\n(SBPL) formalism. We note that subgrid physics modeling can broaden the error\nbar on these by 30\\% for intermediate-mass halos ($\\sim$$10^{13} \\, {\\rm\nM}_{\\odot}$). The scatter of the scaling relations can be captured by an\nintrinsic dependence on concentration, and an extrinsic dependence on tidal\nshear. Finally, we comment on the effect of using galaxies rather than halos in\nreal observations, which can bias the inferred SZ profiles by $\\sim$20\\% for\n$L_\\ast$-galaxies.\n", "  Using Low Brightness Surface Galaxies (LBSG) rotational curves we inferred\nthe free parameters of $\\ell$-boson stars as a dark matter component. The\n$\\ell$-boson stars are numerical solutions to the non-relativistic limit of the\nEinstein-Klein-Gordon system, the Schr\\\"odinger-Poisson (SP) system. These\nsolutions are parametrized by an angular momentum number $\\ell = (N-1)/2$ and\nan excitation number $n$. We perform a bayesian analysis by modifying the\nSimpleMC code to perform the parameter inference, for the cases with $\\ell =\n0$, $\\ell = 1$ and multi-states of $\\ell$-boson stars. We used the Akaike\ninformation criterion (AIC), Bayesian information criterion and the Bayes\nfactor to compare the excited state ($\\ell$=1) and the multi-state case with\nthe ground state ($\\ell$=0) as the base model due to its simplicity. We found\nthat the data in most galaxies in the sample favours the multi-states case and\nthat the scalar field mass tends to be slightly bigger than the ground state\ncase.\n", "  The possibility of obtaining symbolic expressions for cosmic backreaction is\nexplored through a case study of so-called 2-region models. By using the\npublicly available symbolic regression algorithm AI Feynman, it is shown that\nthe kinematical backreaction from a single 2-region model can be well described\nas a function of the mean redshift (or, equivalently, the volume averaged scale\nfactor). A single expression depending on the redshift/scale factor as well as\na model parameter, $f$, that can accurately describe the backreaction for a\nsignificant range of models is naturally more complicated but is also achieved\nwith percent-level accuracy. \\newline\\indent Data sets of redshift drift in the\n2-region models are also considered. Again utilizing AI Feynman, expressions\nfor the redshift drift are found. In particular, an expression for the\ndifference between the mean redshift drift and the drift of the mean redshift\nin terms of the kinematical backreaction is easily obtained for a single\n2-region model. An accurate symbolic expression that describes this difference\nfor an array of 2-region models is achieved by using the redshift as a feature\ninstead of the kinematical backreaction.\n", "  Symbolic expressions for cosmic backreaction and mean redshift drift in a\nrange of 2-region models in terms of average quantities are presented. The\ndemonstration that these expressions can be obtained constitutes the opening of\na new avenue towards understanding the effects of cosmic backreaction in our\nuniverse: With a symbolic expression for the redshift drift at hand, the\nredshift drift can be used to constrain cosmological parameters including the\nlarge-scale expansion rate and backreaction. In addition, by introducing\nsymbolic expressions for cosmic backreaction, this quantity can be constrained\nwith observations such as redshift-distance measures.\n", "  The time delay between images of strongly gravitationally lensed quasars is\nan established cosmological probe. Its limitations, however, include\nuncertainties in the assumed mass distribution of the lens. We re-examine the\nmethodology of a prior work presenting a geometric probe of cosmology\nindependent of the lensing potential which considers differential time delays\nover images, originating from spatially-separated photometric signals within a\nstrongly lensed quasar. We give an analytic description of the effect of the\ndifferential lensing on the emission line spectral flux for axisymmetric Broad\nLine Region geometries, with the inclined ring or disk, spherical shell, and\ndouble cone as examples. The proposed method is unable to recover cosmological\ninformation as the observed time delay and inferred line-of-sight velocity do\nnot uniquely map to the three-dimensional position within the source.\n", "  This paper presents an analysis of XMM X--ray spectra of the quasar 1ES\n1553+113, in search for absorption lines from the intervening warm--hot\nintergalactic medium. A search for OVII, OVIII and NeIX resonance absorption\nlines was performed at eight fixed redshifts that feature OVI or HI broad\nLyman--$\\alpha$ absorption lines that were previously detected from HST data.\nThe search yielded one possible detection of OVII at a redshift z=0.1877 with\nan OVI prior, with a statistical significance that is equivalent to a\n2.6-$\\sigma$ confidence level. The spectra were also stacked at the wavelengths\nof the expected redshifted OVII and OVIII lines, but the analysis did not\nreveal evidence for the presence of additional X--ray absorbing WHIM. Moreover,\nthe spectra were used to investigate two putative OVII absorption lines that\nwere detected serendipitously in an earlier analysis of the same data by F.\nNicastro and collaborators. The paper also presents a comprehensive statistical\nframework for cosmological inferences from the analysis of absorption lines,\nwhich makes use of cosmological simulations for the joint probability\ndistributions of FUV and X--ray ions. Accordingly, we conclude that the new\npossible OVII absorption at z=0.1877 is consistent with a contribution from the\nhot WHIM to the baryon density in an amount of $\\Omega_{WHIM,X}/\\Omega_b =\n44\\pm22$\\%. However, there are large systematic uncertainties associated with\nthe temperature and abundances of the absorbers, and only a larger sample of\nX-ray sources can provide an accurate determination of the cosmological density\nof the WHIM.\n", "  We extract the galaxy density and momentum power spectra from a subset of\nearly-type galaxies in the SDSS DR7 main galaxy catalog. Using galaxy distance\ninformation inferred from the improved fundamental plane described in\n\\citet{Yoon_2020}, we reconstruct the peculiar velocities of the galaxies and\ngenerate number density and density-weighted velocity fields, from which we\nextract the galaxy density and momentum power spectra. We compare the measured\nvalues to the theoretical expectation of the same statistics, assuming an input\n$\\Lambda$CDM model and using a third-order perturbative expansion. After\nvalidating our analysis pipeline with a series of mock data sets, we apply our\nmethodology to the SDSS data and arrive at constraints $f\\sigma_{8} =\n0.471_{-0.080}^{+0.077}$ and $b_{1}\\sigma_{8} = 0.920_{-0.070}^{+0.070}$ at a\nmean redshift $\\bar{z} = 0.04$. Our result is consistent with the Planck\ncosmological best fit parameters for the $\\Lambda$CDM model. The momentum power\nspectrum is found to be strongly contaminated by small scale velocity\ndispersion, which suppresses power by $\\sim {\\cal O}(30\\%)$ on intermediate\nscales $k \\sim 0.05 \\, h \\, {\\rm Mpc}^{-1}$.\n", "  Cosmic birefringence is a parity-violating effect that might have rotated the\nplane of linearly polarized light of the cosmic microwave background (CMB) by\nan angle $\\beta$ since its emission. This has recently been measured to be\nnon-zero at a statistical significance of $3.6\\sigma$ in the official Planck\nPR4 and 9-year WMAP data. In this work, we constrain $\\beta$ using the\nreprocessed BeyondPlanck LFI and Cosmoglobe DR1 WMAP polarization maps. These\nnovel maps have both lower systematic residuals and a more complete error\ndescription than the corresponding official products. Foreground $EB$\ncorrelations could bias measurements of $\\beta$, and while thermal dust $EB$\nemission has been argued to be statistically non-zero, no evidence for\nsynchrotron $EB$ power has been reported. Unlike the dust-dominated Planck HFI\nmaps, the majority of the LFI and WMAP polarization maps are instead dominated\nby synchrotron emission. Simultaneously constraining $\\beta$ and the\npolarization miscalibration angle, $\\alpha$, of each channel, we find a\nbest-fit value of $\\beta=0.35^{\\circ}\\pm0.70^{\\circ}$ with LFI and WMAP data\nonly. When including the Planck HFI PR4 maps, but fitting $\\beta$ separately\nfor dust-dominated, $\\beta_{>70\\,\\mathrm{GHz}}$, and synchrotron-dominated\nchannels, $\\beta_{\\leq 70\\,\\mathrm{GHz}}$, we find $\\beta_{\\leq\n70\\,\\mathrm{GHz}}=0.53^{\\circ}\\pm0.28^\\circ$. This differs from zero with a\nstatistical significance of $1.9\\sigma$, and the main contribution to this\nvalue comes from the LFI 70 GHz channel. While the statistical significances of\nthese results are low on their own, the measurement derived from the LFI and\nWMAP synchrotron-dominated maps agrees with the previously reported\nHFI-dominated constraints, despite the very different astrophysical and\ninstrumental systematics involved in all these experiments.\n", "  This article delivers the dynamical cosmography of the Local Universe within\nz=0.1 (1 giga light-years). We exploit the gravitational velocity field\ncomputed using the CosmicFlows-4 catalog of galaxy distances to delineate\nsuperclusters as watersheds, publishing for the first time their size, shape,\nmain streams of matter and the location of their central attractor. Laniakea,\nour home supercluster's size is confirmed to be 2 $\\times 10^6$ (Mpc\n$h^{-1}$)$^3$. Five more known superclusters are now dynamically defined in the\nsame way: Apus, Hercules, Lepus, Perseus-Pisces and Shapley. Also, the central\nrepellers of the Bootes and Sculptor voids are found and the Dipole and Cold\nSpot repellers now appear as a single gigantic entity. Interestingly the\nobserved superclusters are an order of magnitude larger than the theoretical\nones predicted by cosmological $\\Lambda$CDM simulations.\n", "  Observations support the idea that supermassive black holes (SMBHs) power the\nemission at the center of active galaxies. However, contrary to stellar-mass\nBHs, there is a poor understanding of their origin and physical formation\nchannel. In this article, we propose a new process of SMBH formation in the\nearly Universe that is not associated with baryonic matter (massive stars) or\nprimordial cosmology. In this novel approach, SMBH seeds originate from the\ngravitational collapse of fermionic dense dark matter (DM) cores that arise at\nthe center of DM halos as they form. We show that such a DM formation channel\ncan occur before star formation, leading to heavier BH seeds than standard\nbaryonic channels. The SMBH seeds subsequently grow by accretion. We compute\nthe evolution of the mass and angular momentum of the BH using a geodesic\ngeneral relativistic disk accretion model. We show that these SMBH seeds grow\nto $\\sim 10^9$-$10^{10} M_\\odot$ in the first Gyr of the lifetime of the\nUniverse without invoking unrealistic (or fine-tuned) accretion rates.\n", "  Primordial B-mode detection is one of the main goals of next-generation\ncosmic microwave background (CMB) experiments. Primordial B-modes are a unique\nsignature of primordial gravitational waves (PGWs). However, the gravitational\ninteraction of CMB photons with large-scale structures will distort the\nprimordial E modes, adding a lensing B-mode component to the primordial B-mode\nsignal. Removing the lensing effect (`delensing') from observed CMB\npolarization maps will be necessary to improve the constraint of PGWs and\nobtain a primordial E-mode signal. Here, we introduce a deep convolutional\nneural network model named multi-input multi-output U-net (MIMO-UNet) to\nperform CMB delensing. The networks are trained on simulated CMB maps with size\n$20^{\\circ} \\times 20^{\\circ}$. We first use MIMO-UNet to reconstruct the\nunlensing CMB polarization ($Q$ and $U$) maps from observed CMB maps. The\nrecovered E-mode power spectrum exhibits excellent agreement with the\nprimordial EE power spectrum. The recovery of the primordial B-mode power\nspectrum for noise levels of 0, 1, and 2 $\\mu$K-arcmin is greater than 98\\% at\nthe angular scale of $\\ell<150$. We additionally reconstruct the lensing B map\nfrom observed CMB maps. The recovery of the lensing B-mode power spectrum is\ngreater than roughly 99\\% at the scales of $\\ell>200$. We delens observed\nB-mode power spectrum by subtracting reconstructed lensing B-mode spectrum. The\nrecovery of tensor B-mode power spectrum for noise levels of 0, 1, 2\n$\\mu$K-arcmin is greater than 98 \\% at the angular scales of $\\ell<120$. Even\nat $\\ell=160$, the recovery of tensor B-mode power spectrum is still around 71\n\\%.\n", "  We investigate whether the two cosmological discrepancies on the Hubble\nconstant ($H_0$) and the matter fluctuation parameter ($\\sigma_8$) are\nsuggesting and compatible with the existence of an additional one on the matter\ndensity. Knowing that the latter effects on observables is degenerate with\nthose coming from $H_0$ and $\\sigma_8$, we combined different probes to break\nthese degeneracies while adopting the agnostic approach of, either relaxing the\ncalibration parameters in each probe, or by only including priors with the\ncondition that they are obtained independently from the discrepant parameters.\nWe also compiled and used a dataset from previous direct measurements of\n$\\Omega_{\\rm{M}}$ obtained in a model independent way using the Oort technique.\nWe found when combining galaxy cluster counts + cluster gas mass fraction probe\n+ cosmic chronometers + direct $\\Omega_{\\rm{M}}$ + priors from BBN and CMB,\nthat both parameters, $H_0$ and $\\sigma_8$, are consistent with those inferred\nfrom local probes, with $\\sigma_8 = 0.745 \\pm 0.05$ while $H_0 = 73.8 \\pm\n3.01$, and that for a value of $\\Omega_{\\rm{M}} = 0.22 \\pm 0.01$ at more than\n3$\\sigma$ from that determined by the CMB. However discrepancies appeared when\nwe combined SN in addition to CC suggesting either inconsistencies between the\nSN sample and the other probes or a challenge to our hypothesis, while only a\nprior on the matter density obtained from the CMB data keeps $\\sigma_8$ within\nthe values usually obtained when adopting the calibration parameters of the low\nredshift growth of structures probes. We conclude that, either both tensions\nare compatible with the local inferred low values of matter density at odd with\nthose obtained by CMB, reviving by then an overlooked discrepancy, or that the\n$\\Lambda$CDM model is facing more difficulties to accommodate simultaneously\nall the current available observations.(abridged)\n", "  The matter fluctuation parameter $\\sigma_8$ is, by model construction,\ndegenerate with the growth index $\\gamma$. Here, we study the effect on the\ncosmological parameter constraints by treating each independently from one\nanother, considering $\\sigma_8$ as a free and non-derived parameter along with\na free $\\gamma$. We then try to constrain all parameters using three probes\nthat span from deep to local redshifts, namely the CMB spectrum, the growth\nmeasurements from redshift space distortions and the galaxy cluster counts. We\nalso aim to assess the impact of this relaxation on the $\\sigma_8$ tension. We\nalso propose a more sophisticated correction, along with the classical one,\nthat takes into account the impact of cosmology on the growth measurements by\nadjusting the growth to keep the observed power spectrum invariant with the\nbackground evolution. We found that untying the two parameters does not shift\nthe maximum likelihood of either $\\sigma_8$ or $\\gamma$, but rather enables\nlarger bounds with respect to when $\\sigma_8$ is a derived parameter. More\nprecisely, we obtain $\\sigma_8 = 0.809\\pm 0.043 $ and $\\gamma = 0.613\\pm 0.046$\nin agreement with Planck's constraint for the former and compatible with\n$\\Lambda$CDM for the latter but with bounds wide enough to accommodate both\nvalues subject to the tensions. On the other hand, considering a tiered\ncorrection yields $\\sigma_8 = 0.734\\pm 0.013$ close to the inferred local\nvalues albeit with a growth index of $\\gamma = 0.636\\pm 0.022$, while allowing\nfor massive neutrinos yielded $\\sigma_8 = 0.756\\pm 0.024$, still preferring low\nvalues but with looser constraints on $\\gamma$ and a slight preference for\n$\\Sigma m_\\nu \\sim 0.19$. We conclude that untying $\\sigma_8$ and $\\gamma$\nhelps in relieving the discomfort on the former and that careful analysis\nshould be followed when using data products treated in a model-dependent\nway.(abridged)\n", "  Models of dark energy or modified gravity that tries to alleviate the\ntensions on the Hubble constant ($H_0$) and the matter fluctuation parameter\n($\\sigma_8$) are usually parameterized as function of either late or early time\ncosmic evolution. In this work we rather focus on one that could privilege\nextensions to $\\Lambda$CDM on intermediate redshifts by mean of a Gaussian-like\nwindow function with a free moving centre $a_{Gwin}$ combined with a modified\ngravity parameter $\\mu_{Gwin}$ and an extension of the equation of state\nparameter $\\omega_{Gwin}$. Using different combinations of the latest available\ncurrent datasets subject of the discrepancies, such as the cosmic microwave\n(CMB) background power spectrum, the baryonic acoustic scale (BAO) in galaxy\ndistribution, Weak lensing (WL) shear and galaxy clustering cross correlations\nand local hubble constant measurements, we investigate whether such model could\nalleviate each or both $H_0$ and $\\sigma_8$ tensions. We found when combining\nall probes that the $\\sigma_8$ tension is alleviated while the $H_0$ is reduced\nwith a small preference for a positive $\\omega_{Gwin}$ without a particular\npreference for a redshift or a $\\mu_{Gwin}$ different from its equivalent\n$\\Lambda$CDM value. However, if we follow another approach and compare the two\nsets of the probes subject of discrepancy i.e. CMB+BAO vs WL+local $H_0$, we\nfound that the model is able of solving the $\\sigma_8$ discrepancy at the\nexpense of a enlargement of the constraints, while the Hubble constant\ndiscrepancy is not that affected due to the fact that the two likelihood\ncontours are stretched in parallel directions. We conclude that modifying\n$\\Lambda$CDM cosmology at intermediate redshifts within our model, and the\nconstraints from the datasets used in this study, are not likely a viable\nsolution to solve both tensions.\n", "  We implement a novel formalism to constrain primordial non-Gaussianity of the\nlocal type from the large-scale modulation of the small-scale power spectrum.\nOur approach combines information about primordial non-Gaussianity contained in\nthe squeezed bispectrum and the collapsed trispectrum of large-scale structure\ntogether in a computationally amenable and consistent way, while avoiding the\nneed to model complicated covariances of higher $N$-point functions. This work\ngeneralizes our recent work, which used a neural network estimate of local\npower, to the more conventional local power spectrum statistics, and explores\nusing both matter field and halo catalogues from the Quijote simulations. We\nfind that higher $N$-point functions of the matter field can provide strong\nconstraints on $f_{NL}$, but higher $N$-point functions of the halo field, at\nthe halo density of Quijote, only marginally improve constraints from the\ntwo-point function.\n", "  We investigate the statistical properties and the origin of the scatter\nwithin the spatially resolved surface brightness profiles of the CHEX-MATE\nsample, formed by 118 galaxy clusters selected via the SZ effect. These objects\nhave been drawn from the Planck SZ catalogue and cover a wide range of masses,\nM$_{500}=[2-15] \\times 10^{14} $M$_{\\odot}$, and redshift, z=[0.05,0.6]. We\nderived the surface brightness and emission measure profiles and determined the\nstatistical properties of the full sample. We found that there is a critical\nscale, R$\\sim 0.4 R_{500}$, within which morphologically relaxed and disturbed\nobject profiles diverge. The median of each sub-sample differs by a factor of\n$\\sim 10$ at $0.05\\,R_{500}$. There are no significant differences between\nmass- and redshift-selected sub-samples once proper scaling is applied. We\ncompare CHEX-MATE with a sample of 115 clusters drawn from the The Three\nHundred suite of cosmological simulations. We found that simulated emission\nmeasure profiles are systematically steeper than those of observations. For the\nfirst time, the simulations were used to break down the components causing the\nscatter between the profiles. We investigated the behaviour of the scatter due\nto object-by-object variation. We found that the high scatter, approximately\n110%, at $R<0.4R_{500}$ is due to a genuine difference between the distribution\nof the gas in the core. The intermediate scale, $R_{500} =[0.4-0.8]$, is\ncharacterised by the minimum value of the scatter on the order of 0.56,\nindicating a region where cluster profiles are the closest to the self-similar\nregime. Larger scales are characterised by increasing scatter due to the\ncomplex spatial distribution of the gas. Also for the first time, we verify\nthat the scatter due to projection effects is smaller than the scatter due to\ngenuine object-by-object variation in all the considered scales. [abridged]\n", "  The weak gravitational lensing is a powerful tool in modern cosmology. To\naccurately measure the weak lensing signal, one has to control the systematic\nbias to a small level. One of the most difficult problems is how to correct the\nsmearing effect of the Point Spread Function (PSF) on the shape of the\ngalaxies. The chromaticity of PSF for a broad-band observation can lead to new\nsubtle effects. Since the PSF is wavelength dependent and the spectrum energy\ndistributions between stars and galaxies are different, the effective PSF\nmeasured from the star images will be different from that smears the galaxies.\nSuch a bias is called colour bias. We estimate it in the optical bands of the\nChinese Space Station Survey Telescope from simulated PSFs, and show the\ndependence on the colour and redshift of the galaxies. Moreover, due to the\nspatial variation of spectra over the galaxy image, there exists another\nhigher-order bias, colour gradient bias. Our results show that both colour bias\nand colour gradient bias are generally below $0.1$ percent in CSST. Only for\nsmall-size galaxies, one needs to be careful about the colour gradient bias in\nthe weak lensing analysis using CSST data.\n", "  Many galaxy clusters show diffuse cluster-scale emission in the form of radio\nhalos, showing that magnetic fields and relativistic electrons are mixed in\nwith the intra-cluster medium (ICM). There is general agreement that the origin\nof radio halos is connected to turbulence, generated during cluster mergers.\nStatistical studies of large samples of galaxy clusters in the radio band have\nthe potential to unveil the connection between the properties of radio halos\nand the mass and dynamics of the host clusters. Previous studies have been\nlimited to massive clusters and based on a small number of radio halos. The aim\nof this paper is to investigate the scaling relation between the radio power of\nradio halos and the mass of the host clusters at low frequencies and down to\nlower cluster masses. We analysed the clusters from the second catalogue of\nPlanck Sunyaev Zel'dovich sources that lie within the 5634 sq deg covered by\nthe second Data Release of the LOFAR Two-meter Sky Survey. We derived the\ncorrelation between the radio power and the mass of the host clusters and we\ninvestigated the distribution of clusters without radio halos with respect to\nthe correlation. We use X-ray observations to classify the dynamical state of\nclusters and investigate its role on the power of radio halos. We found a\ncorrelation between the power of radio halos at 150 MHz and the mass of the\nhost clusters down to 3e14 Msun. This correlation has a large scatter, part of\nwhich can be attributed to the different dynamical states of host clusters. We\nused two statistical test to show that the distribution of clusters with and\nwithout (upper limits) radio halos in the mass-radio power diagram is not\ncompatible with a single correlation and that it is also not compatible with\nclusters being uniformly distributed below an upper envelope constituted by the\ncorrelation.\n", "  We present the first hydrodynamical cosmological simulations in the $\\nu$HDM\nframework based on Milgromian dynamics (MOND) with light (11~eV) sterile\nneutrinos. $\\nu$HDM can explain the expansion history, CMB anisotropies, and\ngalaxy cluster dynamics similarly to standard cosmology while preserving MOND's\nsuccesses on galaxy scales, making this the most conservative Milgromian\nframework. We generate initial conditions including sterile neutrinos using\n\\textsc{camb} and \\textsc{music} and modify the publicly available code\n\\textsc{phantom of ramses} to run $\\nu$HDM models. The simulations start at\nredshift $z_e=199$, when the gravitational fields are stronger than $a_{_0}$\nprovided this does not vary. We analyse the growth of structure and investigate\nthe impact of resolution and box size, which is at most 600 comoving Mpc. Large\ndensity contrasts arise at late times, which may explain the KBC void and\nHubble tension. We quantify the mass function of formed structures at different\nredshifts. We show that the sterile neutrino mass fraction in these structures\nis similar to the cosmic fraction at high masses (consistent with MOND\ndynamical analyses) but approaches zero at lower masses, as expected for\ngalaxies. We also identify structures with a low peculiar velocity comparable\nto the Local Group, but these are rare. The onset of group/cluster scale\nstructure formation at $z_e\\approx4$ appears to be in tension with observations\nof high redshift galaxies, which we discuss in comparison to prior analytical\nwork in a MONDian framework. The formation of a cosmic web of filaments and\nvoids demonstrates that this is not unique to standard Einstein/Newton-based\ncosmology.\n", "  The galaxy cluster Zwicky 3146 is a sloshing cool core cluster at $z{=}0.291$\nthat in SZ imaging does not appear to exhibit significant pressure substructure\nin the intracluster medium (ICM). We perform a surface brightness fluctuation\nanalysis via Fourier amplitude spectra on SZ (MUSTANG-2) and X-ray (XMM-Newton)\nimages of this cluster. These surface brightness fluctuations can be\ndeprojected to infer pressure and density fluctuations from the SZ and X-ray\ndata, respectively. In the central region (Ring 1, $r < 100^{\\prime\\prime} =\n440$ kpc, in our analysis) we find fluctuation spectra that suggest injection\nscales around 200 kpc ($\\sim 140$ kpc from pressure fluctuations and $\\sim 250$\nkpc from density fluctuations). When comparing the pressure and density\nfluctuations in the central region, we observe a change in the effective\nthermodynamic state from large to small scales, from isobaric (likely due to\nthe slow sloshing) to adiabatic (due to more vigorous motions). By leveraging\nscalings from hydrodynamical simulations, we find an average 3D Mach number\n$\\approx0.5$. We further compare our results to other studies of Zwicky 3146\nand, more broadly, to other studies of fluctuations in other clusters.\n", "  Galaxy clusters induce a distinct dipole pattern in the cosmic microwave\nbackground (CMB) through the effect of gravitational lensing. Extracting this\nlensing signal will enable us to constrain cluster masses, even for high\nredshift clusters ($z \\gtrsim 1$) that are expected to be detected by future\nCMB surveys. However, cluster-correlated foreground signals, like the kinematic\nand thermal Sunyaev-Zel'dovich (kSZ and tSZ) signals, present a challenge when\nextracting the lensing signal from CMB temperature data. While CMB\npolarization-based lensing reconstruction is one way to mitigate these\nforeground biases, the sensitivity from CMB temperature-based reconstruction is\nexpected to be similar to or higher than polarization for future surveys. In\nthis work, we extend the cluster lensing estimator developed in Raghunathan et\nal. (2019) to CMB temperature and test its robustness against systematic biases\nfrom foreground signals. We find that the kSZ signal only acts as an additional\nsource of variance and provide a simple stacking-based approach to mitigate the\nbias from the tSZ signal. Additionally, we study the bias induced due to\nuncertainties in the cluster positions and show that they can be easily\nmitigated. The estimated signal-to-noise ratio (SNR) of this estimator is\ncomparable to other standard lensing estimators such as the maximum likelihood\n(MLE) and quadratic (QE) estimators. We predict the cluster mass uncertainties\nfrom CMB temperature data for current and future cluster samples to be: 6.6%\nfor SPT-3G with 7,000 clusters, 4.1% for SO and 3.9% for SO + FYST with 25,000\nclusters, and 1.8% for CMB-S4 with 100,000 clusters.\n", "  The gravitationally lensed Supernova Refsdal appeared in multiple images,\nproduced through gravitational lensing by a massive foreground galaxy cluster.\nAfter the supernova appeared in 2014, lens models of the galaxy cluster\npredicted an additional image of the supernova would appear in 2015, which was\nsubsequently observed. We use the time delays between the images to perform a\nblinded measurement of the expansion rate of the Universe, quantified by the\nHubble constant (H0). Using eight cluster lens models, we infer H0 = 64.8\n+4.4-4.3 km / s / Mpc, where Mpc is the megaparsec. Using the two models most\nconsistent with the observations, we find H0 = 66.6 +4.1-3.3 km / s / Mpc. The\nobservations are best reproduced by models that assign dark-matter halos to\nindividual galaxies and the overall cluster.\n", "  In late 2014, four images of Supernova (SN) \"Refsdal,\" the first known\nexample of a strongly lensed SN with multiple resolved images, were detected in\nthe MACS J1149 galaxy-cluster field. Following the images' discovery, the SN\nwas predicted to reappear within hundreds of days at a new position ~8\narcseconds away in the field. The observed reappearance in late 2015 makes it\npossible to carry out Refsdal's (1964) original proposal to use a multiply\nimaged SN to measure the Hubble constant H0, since the time delay between\nappearances should vary inversely with H0. Moreover, the position, brightness,\nand timing of the reappearance enable a novel test of the blind predictions of\ngalaxy-cluster models, which are typically constrained only by the positions of\nmultiply imaged galaxies. We have developed a new photometry pipeline that uses\nDOLPHOT to measure the fluxes of the five images of SN Refsdal from difference\nimages. We apply four separate techniques to perform a blind measurement of the\nrelative time delays and magnification ratios (mu_i/mu_1) between the last\nimage SX and the earlier images S1-S4. We measure the relative time delay of\nSX-S1 to be 376.0+5.6-5.5 days and the relative magnification to be\n0.30+0.05-0.03. This corresponds to a 1.5% precision on the time delay and 17%\nprecision for the magnification ratios, and includes uncertainties due to\nmillilensing and microlensing. In an accompanying paper, we place initial and\nblind constraints on the value of the Hubble constant.\n", "  Due to the non-linear ionizing and heating processes, the 21-cm signals from\nepoch of reionization (EoR) are expected to have strong non-Gaussian\nfluctuations. In this paper, we use the semi-numerical simulations to study the\nnon-Gaussian statistics i.e. skew spectrum and smoothed skewness of the 21-cm\nsignals from EoR. We find the 21-cm skew spectrum and smoothed skewness have\nsimilar evolution features with the 21-cm bispectrum. All of them are sensitive\nto the EoR models, while not too much to the cosmic volume applied. With the\nSKA1-low telescope as reference, we find both the skew spectrum and smoothed\nskewness have much higher S/N ratios than the 21-cm bispectrum.\n", "  We present a novel test of the cosmological principle: the idea that, on\nsufficiently large scales, the universe should appear homogeneous and isotropic\nto observers comoving with the Hubble flow. This is a fundamental assumption in\nmodern cosmology, underpinning the use of the\nFriedmann-Lema\\^itre-Robertson-Walker metric as part of the concordance\n$\\Lambda$CDM paradigm. However, the observed dipole imprinted on the Cosmic\nMicrowave Background (CMB) is interpreted as our departure from the Hubble\nflow, and such a proper motion will induce a directionally-dependent time\ndilation over the sky. We illustrate the feasibility of detection of this 'time\ndilation dipole' and sketch the practical steps involved in its extraction from\na catalogue of sources with intrinsic time-scales. In essence, whilst the scale\nof this dilation is small, being of order of 0.1%, it will in principle be\ndetectable in large scale surveys of variable cosmological sources, such as\nquasars and supernovae. The degree of alignment of the time dilation dipole\nwith the kinematic dipole derived from the CMB will provide a new assessment of\nthe cosmological principle, and address the tension in dipole measures from\nother observations.\n", "  The kinematic and thermal Sunyaev-Zel'dovich (kSZ and tSZ) effects probe the\nabundance and thermodynamics of ionized gas in galaxies and clusters. We\npresent a new hybrid estimator to measure the kSZ effect by combining cosmic\nmicrowave background temperature anisotropy maps with photometric and\nspectroscopic optical survey data. The method interpolates a velocity\nreconstruction from a spectroscopic catalog at the positions of objects in a\nphotometric catalog, which makes it possible to leverage the high number\ndensity of the photometric catalog and the precision of the spectroscopic\nsurvey. Combining this hybrid kSZ estimator with a measurement of the tSZ\neffect simultaneously constrains the density and temperature of free electrons\nin the photometrically selected galaxies. Using the 1000 deg2 of overlap\nbetween the Atacama Cosmology Telescope (ACT) Data Release 5, the first three\nyears of data from the Dark Energy Survey (DES), and the Baryon Oscillation\nSpectroscopic Survey (BOSS) Data Release 12, we detect the kSZ signal at\n4.8${\\sigma}$ and reject the null (no-kSZ) hypothesis at 5.1${\\sigma}$. This\ncorresponds to 2.0${\\sigma}$ per 100,000 photometric objects with a velocity\nfield based on a spectroscopic survey with 1/5th the density of the photometric\ncatalog. For comparison, a recent ACT analysis using exclusively spectroscopic\ndata from BOSS measured the kSZ signal at 2.1${\\sigma}$ per 100,000 objects.\nOur derived constraints on the thermodynamic properties of the galaxy halos are\nconsistent with previous measurements. With future surveys, such as the Dark\nEnergy Spectroscopic Instrument and the Rubin Observatory Legacy Survey of\nSpace and Time, we expect that this hybrid estimator could result in\nmeasurements with significantly better signal-to-noise than those that rely on\nspectroscopic data alone.\n", "  The Macquart relation describes the correlation between the dispersion\nmeasure (DM) of fast radio bursts (FRBs) and the redshift $z$ of their host\ngalaxies. The scatter of the Macquart relation is sensitive to the distribution\nof baryons in the intergalactic medium (IGM) including those ejected from\ngalactic halos through feedback processes. The width of the distribution in DMs\nfrom the cosmic web (${\\rm DM}_{\\rm cosmic}$) is parameterized by a fluctuation\nparameter $F$, which is related to the cosmic DM variance by $\\sigma_{\\rm DM}=\nF z^{-0.5}$. In this work, we present a new measurement of $F$ using 78 FRBs of\nwhich 21 have been localized to host galaxies. Our analysis simultaneously fits\nfor the Hubble constant $H_0$ and the DM distribution due to the FRB host\ngalaxy. We find that the fluctuation parameter is degenerate with these\nparameters, most notably $H_0$, and use a uniform prior on $H_0$ to measure\n$\\log_{10} F > -0.89$ at the $3\\sigma$ confidence interval and a new constraint\non the Hubble constant $H_0 = 85.3_{-8.1}^{+9.4} \\, {\\rm km \\, s^{-1} \\,\nMpc^{-1}}$. Using a synthetic sample of 100 localized FRBs, the constraint on\nthe fluctuation parameter is improved by a factor of $\\sim 2$. Comparing our\n$F$ measurement to simulated predictions from cosmological simulation\n(IllustrisTNG), we find agreement between $0.4 < z < 2$. However, at $z < 0.4$,\nthe simulations underpredict $F$ which we attribute to the rapidly changing\nextragalactic DM excess distribution at low redshift.\n", "  Recent observations of radio relics - diffuse radio emission in galaxy\nclusters - have revealed that these sources are not smooth but consist of\nstructures in the form of threads and filaments. We investigate the origin of\nthese filamentary structures and the role of projection effects. To this end,\nwe have developed a tool that extracts the filamentary structures from\nbackground emission. Moreover, it is capable of studying both two-dimensional\nand three-dimensional objects. We apply our structure extractor to, both,\nobservations and cosmological simulations of radio relics. Using Minkowski\nfunctionals, we determine the shape of the identified structures. In our 2D\nanalysis, we find that the brightest structures in the observed and simulated\nmaps are filaments. Our analysis of the 3D simulation data shows that radio\nrelics do not consist of sheets but only of filaments and ribbons. Furthermore,\nwe did not find any measurable projection effects that could hide any\nsheet-like structures in projection. We find that, both, the magnetic field and\nthe shock front consist of filaments and ribbons that cause filamentary radio\nemission.\n", "  The 21 cm signal from the dark ages provides a potential new probe of\nfundamental cosmology. While exotic physics could be discovered, here we\nquantify the expected benefits within the standard cosmology. A measurement of\nthe global (sky-averaged) 21 cm signal to the precision of thermal noise from a\n1,000 h integration would yield a measurement within 10% of a combination of\ncosmological parameters. A 10,000 h integration would improve this measurement\nto 3.2% and constrain the cosmic helium fraction to 9.9%. Precision cosmology\nwith 21 cm fluctuations requires a collecting area of 10 km$^2$ (corresponding\nto 400,000 stations), which, with a 1,000 h integration, would exceed the same\nglobal case by a factor of $\\sim2$. Enhancing the collecting area or\nintegration time by an order of magnitude would yield a 0.5% parameter\ncombination, a helium measurement five times better than Planck and a\nconstraint on the neutrino mass as good as Planck. Our analysis sets a baseline\nfor upcoming lunar and space-based dark-ages experiments.\n", "  The full-shape correlations of the Lyman alpha (Ly$\\alpha$) forest contain a\nwealth of cosmological information through the Alcock-Paczy\\'{n}ski effect.\nHowever, these measurements are challenging to model without robustly testing\nand verifying the theoretical framework used for analyzing them. Here, we\nleverage the accuracy and volume of the $N$-body simulation suite\n\\textsc{AbacusSummit} to generate high-resolution Ly$\\alpha$ skewers and\nquasi-stellar object (QSO) catalogs. One of the main goals of our mocks is to\naid in the full-shape Ly$\\alpha$ analysis planned by the Dark Energy\nSpectroscopic Instrument (DESI) team. We provide optical depth skewers for six\nof the fiducial cosmology base-resolution simulations ($L_{\\rm box} =\n2\\,h^{-1}{\\rm Gpc}$, $N = 6912^3$) at $z = 2.5$. We adopt a simple recipe based\non the Fluctuating Gunn-Peterson Approximation (FGPA) for constructing these\nskewers from the matter density in an $N$-body simulation and calibrate it\nagainst the 1D and 3D Ly$\\alpha$ power spectra extracted from the\nhydrodynamical simulation IllustrisTNG (TNG; $L_{\\rm box} = 205\\,h^{-1}{\\rm\nMpc}$, $N = 2500^3$). As an important application, we study the non-linear\nbroadening of the baryon acoustic oscillation (BAO) peak and show the\ncross-correlation between DESI-like QSOs and our Ly$\\alpha$ forest skewers. We\nfind differences on small scales between the Kaiser approximation prediction\nand our mock measurements of the Ly$\\alpha$$\\times$QSO cross-correlation, which\nwould be important to account for in upcoming analyses. The\n\\textsc{AbacusSummit} Ly$\\alpha$ forest mocks open up the possibility for\nimproved modelling of cross correlations between Ly$\\alpha$ and cosmic\nmicrowave background (CMB) lensing and Ly$\\alpha$ and QSOs, and for forecasts\nof the 3-point Ly$\\alpha$ correlation function. Our catalogues and skewers are\npublicly available on Globus.\n", "  It has been pointed out that the spurious Cosmic Microwave Background (CMB)\nB-mode polarization signals caused by the absorption of the CMB monopole\ncomponent due to the Galactic interstellar matter, called the CMB shadow,\ndegrade the accuracy of detecting the CMB B-mode polarization signals imprinted\nby primordial gravitational waves. We have made a realistic estimation using\nsimulated sky maps of how the CMB shadow affects forthcoming high-precision CMB\nB-mode experiments for the first time. The Delta-map method, an internal\ntemplate method taking into account the first-order spatial variation of\nforegrounds' spectral parameters, is applied as a foreground removal method. We\nshow that if the CMB shadow effects are not taken into account in the\nforeground removal process, future observations would lead to the false\ndetection of the CMB B-mode polarization signals originating from primordial\ngravitational waves. We also show that the effect of the CMB shadow can be\nmitigated by our revised Delta-map method to target the CMB B-mode polarization\nsignals at the level of tensor-to-scalar ratio r=0.001.\n", "  The primary purpose of this work is the provision of accurate, analytic,\nevolutionary templates for cosmological parameters and fundamental constants in\na dynamical cosmology. A flat quintessence cosmology with a dark energy\npotential that has the mathematical form of the Higgs potential is the specific\ncosmology and potential addressed in this work. These templates, based on the\nphysics of the cosmology and potential are intended to replace the\nparameterizations currently used to determine the likelihoods of dynamical\ncosmologies. Acknowledging that, unlike {\\Lambda}CDM, the evolutions are\ndependent on both the specific cosmology and the dark energy potential the\ntemplates are referred to as Specific Cosmology and Potential, SCP, templates.\nThe requirements set for the SCP templates are that they must be accurate,\nanalytic functions of an observable such as the scale factor or redshift. This\nis achieved through the utilization of a modified beta function formalism that\nis based on a physically motivated dark energy potential to calculate the beta\nfunction. The methodology developed here is designed to be adaptable to other\ncosmologies and dark energy potentials. The SCP templates are essential tools\nin determining the relative likelihoods of a range of dynamical cosmologies and\npotentials. An ultimate purpose is the determination whether dark energy is\ndynamical or static in a quantitative manner. It is suggested that the SCP\ntemplates calculated in this work can serve as fiducial dynamical templates in\nthe same manner as {\\Lambda}CDM serves for static dark energy.\n", "  Perturbation theory is a powerful tool for studying large-scale structure\nformation in the universe and calculating observables such as the power\nspectrum or bispectrum. However, beyond linear order, typically this is done by\nassuming a simplification in the time-dependence of gravitational-coupling\nkernels between the matter and velocity fluctuations. Though the true\ndependencies are known for Lambda cold dark matter cosmologies, they are\nignored due to the computational costs associated with considering them in full\nand, instead, are replaced by simpler dependencies valid for an\nEinstein--de-Sitter cosmology. Here we develop, implement and demonstrate the\neffectiveness of a new numerical method for finding the full dynamical\nevolution of these kernels to all perturbative orders based upon spectral\nmethods using Chebyshev polynomials. This method is found to be orders of\nmagnitude more efficient than direct numerical solvers while still producing\nhighly accurate and reliable results. A code implementation of the Chebyshev\nspectral method is then presented and characterised. The code has been made\npublicly available alongside this paper. We expect our method to be of use for\ninterpretation of upcoming galaxy clustering measurements.\n", "  In the expanding Universe, the dimensional quantities like the wavelength and\nthe temperature of photons are cosmologically redshifted by the relative\ndifference between the observed and emitted ones. Therefore, it can be\nphysically meaningful to talk about the constancy or variability of any\ndimensional constant (not only of dimensionless one) when the Universe is\nexpanding. It has been known that one can measure the temporal variation of the\nfine structure constant $\\alpha$ in the emission and absorption lines of quasar\nspectra when the speed of light varies for cosmic time, even though this\nstatement is model dependent. Current observations based on the alkali doublet\nmethod and on the many-multiplet one show superficially contradictory results.\nThe former finds no statistically significant evidence for a time dependence of\n$\\alpha$, while the latter does. The so-called meVSL model can reconcile these\nresults naturally without any contradiction.\n", "  We study the redshift evolution of the baryon budget in a large set of galaxy\nclusters from the {\\it Magneticum} suite of SPH cosmological simulations. At\nhigh redshifts, we obtain \"closed box\" systems independently by the mass of the\nsystems on radii greater than $3R_{500,\\mathrm c}$, whereas at lower redshifts,\nonly the most massive halos could be considered as `\"closed box\". The baryon\nfraction shows a general decrease with the redshift and, for less massive\nobjects, we observe a much more prominent decrease than for massive halos. The\ngas depletion parameter $Y_{\\rm gas}$ shows a steeper and highly scattered\nradial distribution in the central regions of less massive halos with respect\nto massive objects at all redshifts, while on larger radii the gas fraction\ndistributions are independent of the masses or the redshifts. The hot component\nof the gas traces well the total amount of gas at low redshifts. At higher\nredshifts, the cold component provides a not negligible contribution to the\ntotal amount of baryon in our systems. Moreover, the behaviour of the baryonic,\nentire gas, and hot gas phase depletion parameters as a function of radius,\nmass, and redshift are described by some functional forms. The evolution of\nmetallicity and stellar mass in halos suggests that the early enrichment\nprocess is dominant. We investigate correlations between the time evolution of\nAGN feedback and the depletion parameters. We demonstrate that the energy\ninjected by the AGN activity shows a particularly strong positive correlation\nwith $Y_{\\rm bar}$, $Y_{\\rm cold}$,$Y_{\\rm star}$ and a negative one with\n$Y_{\\rm hot}$, $Z_{\\rm Tot}$. These trends are consistent with previous works,\nmeaning that our results, combined with findings derived from current and\nfuture X-rays observations, represent possible proxies to test the AGN feedback\nmodels used in different suites of numerical simulations.\n", "  Weak galaxy lensing surveys have consistently reported low values of the\n$S_8$ parameter compared to the $\\textit{Planck}\\ \\Lambda\\rm{CDM}$ cosmology.\nAmon & Efstathiou (2022) used KiDS-1000 cosmic shear measurements to propose\nthat this tension can be reconciled if the matter fluctuation spectrum is\nsuppressed more strongly on non-linear scales than assumed in state-of-the-art\nhydrodynamical simulations. In this paper, we investigate cosmic shear data\nfrom the Dark Energy Survey (DES) Year 3. The non-linear suppression of the\nmatter power spectrum required to resolve the $S_8$ tension between DES and the\n$\\textit{Planck}\\ \\Lambda\\rm{CDM}$ model is not as strong as inferred using\nKiDS data, but is still more extreme than predictions from recent numerical\nsimulations. An alternative possibility is that non-standard dark matter\ncontributes to the required suppression. We investigate the redshift and scale\ndependence of the suppression of the matter power spectrum. If our proposed\nexplanation of the $S_8$ tension is correct, the required suppression must\nextend into the mildly non-linear regime to wavenumbers $k\\sim 0.2 h {\\rm\nMpc}^{-1}$. In addition, all measures of $S_8$ using linear scales should agree\nwith the $\\textit{Planck}\\ \\Lambda\\rm{CDM}$ cosmology, an expectation that will\nbe testable to high precision in the near future.\n", "  The thermal Sunyaev-Zel'dovich (tSZ) effect is a spectral distortion of the\ncosmic microwave background (CMB) resulting from inverse Compton scattering of\nCMB photons with electrons in the medium of galaxy clusters. The spectrum of\nthe tSZ effect is typically calculated assuming the spectrum of the CMB is a\nblackbody. However, energy or photon number injection at any epoch after photon\ncreation processes become inefficient will distort the blackbody, potentially\nleading to a chemical potential or $\\mu$-distortion for early injection. These\n$primordial$ spectral distortions will therefore introduce a change in the tSZ\neffect, effectively a distortion of a distortion. While this effect is small\nfor an individual cluster's spectrum, upcoming and proposed CMB surveys expect\nto detect tens of thousands of clusters with the tSZ effect. In this paper, we\nforecast constraints on the $\\mu$-distortion monopole from the distortion of\nthe tSZ spectrum of clusters measured by CMB surveys. We find that planned\nexperiments have the raw sensitivity to place constraints on $\\mu$ that are\ncomparable to or better than existing constraints but control over foregrounds\nand other systematics will be critical.\n", "  We identify cosmic voids from galaxy density fields under the theory of\nvoid-cluster correspondence. We extend the previous novel void-identification\nmethod developed for the matter density field to the galaxy density field for\npractical applications. From cosmological N-body simulations, we construct\ngalaxy number- and mass-weighted density fields to identify cosmic voids that\nare counterparts of galaxy clusters of specific mass. The parameters for the\ncluster-counterpart void identification such as Gaussian smoothing scale,\ndensity threshold, and core volume fraction are found for galaxy density\nfields. We achieve about $60$--$67\\%$ of completeness and reliability for\nidentifying the voids of corresponding cluster mass above\n$3\\times10^{14}h^{-1}M_{\\odot}$ from a galaxy sample with the mean number\ndensity, $\\bar{n}=4.4\\times10^{-3} (h^{-1}{\\rm Mpc})^{-3}$. When the mean\ndensity is increased to $\\bar{n}=10^{-2} (h^{-1}{\\rm Mpc})^{-3}$, the detection\nrate is enhanced by $\\sim2$--$7\\%$ depending on the `mass scale' of voids. We\nfind that the detectability is insensitive to the density weighting scheme\napplied to generate the density field. Our result demonstrates that we can\napply this method to the galaxy redshift survey data to identify cosmic voids\ncorresponding statistically to the galaxy clusters in a given mass range.\n", "  Taking advantage of the reduced levels of noise and systematics in the data\nof the latest Planck release (PR4, also known as NPIPE), we construct a new\nall-sky Compton-$y$ parameter map (hereafter, $y$-map) of the thermal\nSunyaev-Zeldovich (SZ) effect from the Planck PR4 data. A tailored Needlet\nInternal Linear Combination (NILC) pipeline, first validated on detailed sky\nsimulations, is applied to the nine single-frequency Planck PR4 sky maps,\nranging from $30$ to $857$ GHz, to produce the PR4 $y$-map over 98% of the sky.\nUsing map comparisons, angular power spectra and one-point statistics we show\nthat the PR4 NILC $y$-map is of improved quality compared to that of the\nprevious PR2 release. The new $y$-map shows reduced levels of large-scale\nstriations associated with $1/f$ noise in the scan direction. Regions near the\nGalactic plane also show lower residual contamination by Galactic thermal dust\nemission. At small angular scales, the residual contamination by thermal noise\nand cosmic infrared background (CIB) emission is found to be reduced by around\n7% and 34%, respectively, in the PR4 $y$-map. The PR4 NILC $y$-map is made\npublicly available for astrophysical and cosmological analyses of the thermal\nSZ effect.\n", "  The Weakly Interacting Massive Particles(WIMPs) have long been the favored\nCDM candidate in the standard $\\Lambda$CDM model. However, owing to great\nimprovement in the experimental sensitivity in the past decade, some parameter\nspace of the SUSY-based WIMP model is ruled out. In addition, WIMP as the CDM\nparticle is also at variance with other astrophysical observables at small\nscales. We consider a model that addresses both these issues. In the model, the\nWIMP decays into a massive particle and radiation. We study the background\nevolution and the first order perturbation theory (coupled Einstein-Boltzmann\nequations) for this model and show that the dynamics can be captured by a\nsingle parameter $r=m_L/q$, which is the ratio of the lighter mass and the\ncomoving momentum of the decay particle. We incorporate the relevant equations\nin the existing Boltzmann code CLASS to compute the matter power spectra and\nCMB angular power spectra. The decaying WIMP model is akin to a non-thermal\nWarm Dark Matter(WDM) model and suppresses matter power at small scales, which\ncould alleviate several issues that plague the CDM model. We compare the\npredictions of the model with CMB, galaxy clustering, and high-z HI data. Both\nthese data sets yield $r\\gtrsim 10^6$, which can be translated into the bounds\non other parameters. In particular, we obtain the following lower bounds on the\nthermally-averaged self-annihilation cross-section of WIMPs $\\langle \\sigma v\n\\rangle$, and the lighter mass $m_L$: $\\langle \\sigma v \\rangle \\gtrsim\n4.9\\times 10^{-34} \\, \\rm cm^3 \\, sec^{-1}$ and $m_L \\gtrsim 2.4 \\, \\rm keV$.\nThe lower limit on $m_L$ is comparable to constraints on the mass of\nthermally-produced WDM particle. The limit on the self-annihilation\ncross-section greatly expands the available parameter space as compared to the\nstable WIMP scenario.\n", "  Ultralight dark matter (ULDM) is an interesting alternative to the cold dark\nmatter (CDM) paradigm. Due to the extremely low mass of the constituent\nparticle ($\\sim 10^{-22}$ eV), ULDM can exhibit quantum effects up to\nkiloparsec scales. In particular, runaway collapse in the centres of ULDM halos\nis prevented by quantum pressure, providing a possible resolution to the\n'core-cusp problem' of CDM. However, the the detailed relationship between the\nULDM core mass and that of the overall halo is poorly understood. We simulate\nthe collapse of both spherical and aspherical isolated ULDM overdensities using\nAxioNyx, finding that the central cores of collapsed halos undergo sustained\noscillatory behaviour which affects both their peak density and overall\nmorphology. The variability in core morphology increases with the asphericity\nof the initial overdensity and remnants of initial asphericity persist long\nafter collapse. Furthermore, the peak central densities are higher in spherical\nconfigurations. Consequently, astrophysically realistic halos may exhibit\nsubstantial departures from theoretical core-halo profiles and we would expect\na significant variance of the properties of halos with the same mass.\n", "  Interloper contamination due to line misidentification is an important issue\nin the future low-resolution spectroscopic surveys. We realize that the\nalgorithm previously used for photometric redshift self-calibration, with minor\nmodifications, can be particularly applicable to calibrate the interloper bias.\nIn order to explore the robustness of the modified self-calibration algorithm,\nwe construct the mock catalogues based on China Space Station Telescope (CSST),\ntaking two main target emission lines, H$\\alpha$ and [O III]. The\nself-calibration algorithm is tested in cases with different interloper\nfractions at 1 per cent, 5 per cent and 10 per cent. We find that the\ninterloper fraction and mean redshift in each redshift bin can be successfully\nreconstructed at the level of ~ 0.002 and ~ 0.001(1+z), respectively. We also\nfind the impact of the cosmic magnification can be significant, which is\nusually ignored in previous works, and therefore propose a convenient and\nefficient method to eliminate it. Using the elimination method, we show that\nthe calibration accuracy can be effectively recovered with slightly larger\nuncertainty.\n", "  Herein, we present a deep-learning technique for reconstructing the\ndark-matter density field from the redshift-space distribution of dark-matter\nhalos. We built a UNet-architecture neural network and trained it using the\nCOmoving Lagrangian Acceleration fast simulation, which is an approximation of\nthe N-body simulation with $512^3$ particles in a box size of 500 Mpc $h^{-1}$.\nFurther, we tested the resulting UNet model not only with training-like test\nsamples but also with standard N-body simulations, such as the Jiutian\nsimulation with $6144^3$ particles in a box size of 1000 Mpc $h^{-1}$ and the\nELUCID simulation, which has a different cosmology. The real-space dark-matter\ndensity fields in the three simulations can be reconstructed reliably with only\na small reduction of the cross-correlation power spectrum at 1% and 10% levels\nat $k=0.1$ and $0.3~h\\mathrm{Mpc^{-1}}$, respectively. The reconstruction\nclearly helps to correct for redshift-space distortions and is unaffected by\nthe different cosmologies between the training (Planck2018) and test samples\n(WMAP5). Furthermore, we tested the application of the UNet-reconstructed\ndensity field to obtain the velocity \\& tidal field and found that this\napproach provides better results compared to the traditional approach based on\nthe linear bias model, showing a 12.2% improvement in the correlation slope and\na 21.1% reduction in the scatter between the predicted and true velocities.\nThus, our method is highly efficient and has excellent extrapolation\nreliability beyond the training set. This provides an ideal solution for\ndetermining the three-dimensional underlying density field from the plentiful\ngalaxy survey data.\n", "  The joint analysis of different cosmological probes, such as galaxy\nclustering and weak lensing, can potentially yield invaluable insights into the\nnature of the primordial Universe, dark energy and dark matter. However, the\ndevelopment of high-fidelity theoretical models that cover a wide range of\nscales and redshifts is a necessary stepping-stone. Here, we present public\nhigh-resolution weak lensing maps on the light cone, generated using the\n$N$-body simulation suite AbacusSummit in the Born approximation, and\naccompanying weak lensing mock catalogues, tuned via fits to the Early Data\nRelease small-scale clustering measurements of the Dark Energy Spectroscopic\nInstrument (DESI). Available in this release are maps of the cosmic shear,\ndeflection angle and convergence fields at source redshifts ranging from $z =\n0.15$ to 2.45 with $\\Delta z = 0.05$ as well as CMB convergence maps ($z\n\\approx 1090$) for each of the 25 ${\\tt base}$-resolution simulations ($L_{\\rm\nbox} = 2000\\,h^{-1}{\\rm Mpc}$, $N_{\\rm part} = 6912^3$) as well as for the two\n${\\tt huge}$ simulations ($L_{\\rm box} = 7500\\,h^{-1}{\\rm Mpc}$, $N_{\\rm part}\n= 8640^3$) at the fiducial AbacusSummit cosmology ($Planck$ 2018). The pixel\nresolution of each map is 0.21 arcmin, corresponding to a HEALPiX $N_{\\rm\nside}$ of 16384. The sky coverage of the ${\\tt base}$ simulations is an octant\nuntil $z \\approx 0.8$ (decreasing to about 1800 deg$^2$ at $z \\approx 2.4$),\nwhereas the ${\\tt huge}$ simulations offer full-sky coverage until $z \\approx\n2.2$. Mock lensing source catalogues are sampled matching the ensemble\nproperties of the Kilo-Degree Survey, Dark Energy Survey, and Hyper-Suprime Cam\nweak lensing datasets. The produced mock catalogues are validated against\ntheoretical predictions for various clustering and lensing statistics such as\ngalaxy clustering multipoles, galaxy-shear and shear-shear, showing excellent\nagreement.\n", "  For 100 years since galaxies were found to be flying apart from each other,\nastronomers have been trying to determine how fast. The expansion,\ncharacterized by the Hubble constant, H0, is confused locally by peculiar\nvelocities caused by gravitational interactions, so observers must obtain\naccurate distances at significant redshifts. Very nearby in our Galaxy,\naccurate distances can be determined through stellar parallaxes. There is no\ngood method for obtaining galaxy distances that is applicable from the near\ndomain of stellar parallaxes to the far domain free from velocity anomalies.\nThe recourse is the distance ladder involving multiple methods with overlapping\ndomains. Good progress is being made on this project, with satisfactory\nprocedures and linkages identified and tested across the necessary distance\nrange. Best values of H0 from the distance ladder lie in the range 73 - 75\nkm/s/Mpc. On the other hand, from detailed information available from the power\nspectrum of fluctuations in the cosmic microwave background, coupled with\nconstraints favoring the existence of dark energy from distant supernova\nmeasurements, there is the precise prediction that H0 = 67.4 to 1%. If it is\nconclusively determined that the Hubble constant is well above 70 km/s/Mpc as\nindicated by distance ladder results then the current preferred LambdaCDM\ncosmological model based on the Standard Model of particle physics may be\nincomplete. There is reason for optimism that the value of the Hubble constant\nfrom distance ladder observations will be rigorously defined with 1% accuracy\nin the near future.\n", "  One important source of systematics in galaxy redshift surveys comes from the\nestimation of the galaxy window function. Up until now, the impact of the\nuncertainty in estimating the galaxy window function on parameter inference has\nnot been properly studied. In this paper, we show that the uncertainty and the\nbias in estimating the galaxy window function will be salient for ongoing and\nnext-generation galaxy surveys using a simulation-based approach. With a\nspecific case study of cross-correlating Emission-line galaxies from the DESI\nLegacy Imaging Surveys and the Planck CMB lensing map, we show that neural\nnetwork-based regression approaches to modelling the window function are\nsuperior in comparison to linear regression-based models. We additionally show\nthat the definition of the galaxy overdensity estimator can impact the overall\nsignal-to-noise of observed power spectra. Finally, we show that the additive\nbiases coming from the window functions can significantly bias the modes of the\ninferred parameters and also degrade their precision. Thus, a careful\nunderstanding of the window functions will be essential to conduct cosmological\nexperiments.\n", "  In this work, we extend our recently developed super-resolution (SR) model\nfor cosmological simulations to produce fully time consistent evolving\nrepresentations of the particle phase-space distribution. We employ a\nstyle-based constrained generative adversarial network (Style-GAN) where the\nchanging cosmic time is an input style parameter to the network. The matter\npower spectrum and halo mass function agree well with results from\nhigh-resolution N-body simulations over the full trained redshift range ($10\n\\le z \\le 0$). Furthermore, we assess the temporal consistency of our SR model\nby constructing halo merger trees. We examine progenitors, descendants and mass\ngrowth along the tree branches. All statistical indicators demonstrate the\nability of our SR model to generate satisfactory high-resolution simulations\nbased on low-resolution inputs.\n", "  We present a new independent pipeline for the CMB bispectrum estimation of\nprimordial non-Gaussianity and release a public code for constraining\nbispectrum shapes of interest based on the Planck 2018 temperature and\npolarization data. The estimator combines the strengths of the conventional KSW\nand Modal estimators at the cost of increased computational complexity, which\nhas been made manageable through intensive algorithmic and implementation\noptimization. We also detail some methodological advances in numerical\nintegration over a tetrapyd - domain where the bispectrum is defined on - via\nnew quadrature rules. The pipeline has been validated both internally and\nagainst Planck. As a proof-of-concept example, we constrain some highly\noscillatory models that were out of reach in conventional analyses using a\ntargeted basis with a fixed oscillation frequency, and no significant evidence\nfor primordial non-Gaussianity of these shapes is found. The methodology and\ncode developed in this work will be directly applicable to future surveys where\nwe expect a notable boost in sensitivity.\n", "  We present a new class of models that have potential to alleviate tensions\npresent in the cosmological data today. We postulate variation in the sound\nhorizon scale on super-horizon scales, i.e. on scales that are larger than that\nof the present observable low-redshift universe ($\\gtrsim 1\\,$Gpc) while at the\nsame time smaller than the largest scales probed by the cosmic microwave\nbackground (CMB) ($\\lesssim10\\,$Gpc). In this scenario, CMB peaks are naturally\nsmoothed as preferred by the Planck data, while at the same time the\nlow-redshift baryon acoustic oscillation calibration is partially decoupled\nfrom the CMB. Taking super-horizon variations in baryon fraction as an example\nand using approximate modeling, we find improvement in the best fit Planck\npower spectrum model $\\Delta \\chi^2 \\sim 6$ for one extra degree of freedom\nwith the relevant extension parameter $10^3 \\sigma_b = 2.12 \\pm 0.50 $,\nimplying about 10\\% variations in baryon fraction across the universe. At the\nsame time, $S_8$ drops by about 1 sigma, easing tension with weak lensing\nsurveys. While $H_0$ increases in this model by about 1 sigma, this is\ninsufficient to explain the Hubble tension in $\\Lambda$CDM. Since the power of\nlow redshift BAO is relaxed, we find that the combination of Planck 2018 data,\neBOSS BAO data and Riess et al distance ladder Hubble parameter determination\nproduce a satisfactory fit in the model with free dark energy equation of\nstate. Such a fit, however, favors a phantom dark energy equation of state\n$w<-1$ at 2-3 sigma.\n", "  The cosmic radio dipole is an anisotropy in the number counts of radio\nsources, analogous to the dipole seen in the cosmic microwave background (CMB).\nMeasurements of source counts of large radio surveys have shown that though the\nradio dipole is generally consistent in direction with the CMB dipole, the\namplitudes are in tension. These observations present an intriguing puzzle as\nto the cause of this discrepancy, with a true anisotropy breaking with the\nassumptions of the cosmological principle, invalidating the most common\ncosmological models that are built on these assumptions. We present a novel set\nof Bayesian estimators to determine the cosmic radio dipole and compare the\nresults with commonly used methods on the Rapid ASKAP Continuum Survey (RACS)\nand the NRAO VLA Sky Survey (NVSS) radio surveys. In addition, we adapt the\nBayesian estimators to take into account systematic effects known to affect\nsuch large radio surveys, folding information such as the local noise floor or\narray configuration directly into the parameter estimation. The enhancement of\nthese estimators allows us to greatly increase the amount of sources used in\nthe parameter estimation, yielding tighter constraints on the cosmic radio\ndipole estimation than previously achieved with NVSS and RACS. We extend the\nestimators further to work on multiple catalogues simultaneously, leading to a\ncombined parameter estimation using both NVSS and RACS. The result is a dipole\nestimate that perfectly aligns with the CMB dipole in terms of direction but\nwith an amplitude that is three times as large, and a significance of\n4.8$\\sigma$. This new dipole measurement is made to an unprecedented level of\nprecision for radio sources, which is only matched by recent results using\ninfrared quasars.\n", "  A leading way to constrain physical theories from cosmological observations\nis to test their predictions for the angular clustering statistics of matter\ntracers, a technique that is set to become ever more central with the next\ngeneration of large imaging surveys. Interpretation of this clustering requires\nknowledge of the projection kernel, or the redshift distribution of the\nsources, and the typical assumption is an isotropic redshift distribution for\nthe objects. However, variations in the kernel are expected across the survey\nfootprint due to photometric variations and residual observational systematic\neffects. We develop the formalism for anisotropic projection and present\nseveral limiting cases that elucidate the key aspects. We quantify the impact\nof anisotropies in the redshift distribution on a general class of angular\ntwo-point statistics. In particular, we identify a mode-coupling effect that\ncan add power to auto-correlations, including galaxy clustering and cosmic\nshear, and remove it from certain cross-correlations. If the projection\nanisotropy is primarily at large scales, the mode-coupling depends upon its\nvariance as a function of redshift; furthermore, it is often of similar shape\nto the signal. In contrast, the cross-correlation of a field whose selection\nfunction is anisotropic with another one featuring no such variations -- such\nas CMB lensing -- is immune to these effects. We discuss explicitly several\nspecial cases of the general formalism including galaxy clustering,\ngalaxy-galaxy lensing, cosmic shear and cross-correlations with CMB lensing,\nand publicly release a code to compute the biases.\n", "  An observer that is moving towards a high-density region sees, on average, a\nhigher matter density and more foreground-emitting sources ahead than behind\nthemself. Consequently, the average abundance and luminosity of objects\nproducing cosmological signals around an in-falling dark matter halo is larger\nin the direction of the halo's motion. In this Letter, we demonstrate this\neffect from simulated cosmological maps of the thermal Sunyaev Zel'dovich\neffect and the cosmic infrared background. We find that, for a wide range of\nhalo masses and redshifts, oriented stacked profiles of these foregrounds show\nsignificant, potentially detectable gradients aligned with the transverse\nvelocity of halos. The signal depends on the halo's mass and redshift, as well\nas the physical properties of the cosmic web surrounding the halos. We show\nthat this signal is sufficiently prominent to be detected in future Cosmic\nMicrowave Background experiments, therefore offering a new window into the\nstudy of cosmological structures. We argue that the dipolar morphological\nstructure of this signal, its orientation, as well as its overall large\namplitude, constitute a challenge for the detection of the transverse velocity\nthrough the study of the moving lens effect for stacked halos.\n", "  The cosmological principle has been verified using electromagnetic (EM)\nobservations. However its verification with high accuracy is challenging due to\nvarious foregrounds and selection effects, and possible violation of the\ncosmological principle has been reported in the literature. In contrast,\ngravitational wave (GW) observations are free of these foregrounds and related\nselection biases. This may enable future GW experiments to test the\ncosmological principle robustly with full sky distribution of millions of\nstandard bright/dark sirens. However, the sensitivities of GW detectors are\nhighly anisotropic, resulting in significant instrument induced anisotropies in\nthe observed GW catalog. We investigate these instrumental effects for 3rd\ngeneration detector networks in term of multipoles $a_{\\ell m}$ of the observed\nGW source distribution, using Monte Carlo simulations. (1) We find that the\ninstrument induced anisotropy primarily exists at the $m=0$ modes on large\nscales ($\\ell \\lesssim 10$), with amplitude $\\langle |a_{\\ell 0}|^2 \\rangle\n\\sim 10^{-3}$ for two detectors (ET-CE) and $\\sim 10^{-4}$ for three detectors\n(ET-2CE). This anisotropy is correlated with the sky distribution of\nsignal-to-noise ratio (SNR) and localization accuracy. Such anisotropy sets a\nlower limit on the detectable cosmological $a_{\\ell 0}$. (2) However, we find\nthat the instrument induced anisotropy is efficiently canceled by rotation of\nthe Earth in $m\\neq 0$ components of $a_{\\ell m}$. Therefore $a_{\\ell m}$\n($m\\neq 0$) are clean windows to detect cosmological anisotropies. (3) We\ninvestigate the capability of 3rd generation GW experiments to measure the\ncosmic dipole. Through Monte Carlo simulations, we find that cosmic dipole with\nan amplitude of $\\sim 10^{-2}$ reported in the literature can be detected/ruled\nout by ET-CE and ET-2CE robustly, through the measurement of $a_{11}$.\n", "  Inference in cosmology often starts with noisy observations of random fields\non the celestial sphere, such as maps of the microwave background radiation,\ncontinuous maps of cosmic structure in different wavelengths, or maps of point\ntracers of the cosmological fields. Almanac uses Hamiltonian Monte Carlo\nsampling to infer the underlying all-sky noiseless maps of cosmic structures,\nin multiple redshift bins, together with their auto- and cross-power spectra.\nIt can sample many millions of parameters, handling the highly variable\nsignal-to-noise of typical cosmological signals, and it provides science-ready\nposterior data products. In the case of spin-weight 2 fields, Almanac infers\n$E$- and $B$-mode power spectra and parity-violating $EB$ power, and, by\nsampling the full posteriors rather than point estimates, it avoids the problem\nof $EB$-leakage. For theories with no $B$-mode signal, inferred non-zero\n$B$-mode power may be a useful diagnostic of systematic errors or an indication\nof new physics. Almanac's aim is to characterise the statistical properties of\nthe maps, with outputs that are completely independent of the cosmological\nmodel, beyond an assumption of statistical isotropy. Inference of parameters of\nany particular cosmological model follows in a separate analysis stage. We\ndemonstrate our signal extraction on a CMB-like experiment.\n", "  The Ly$\\alpha$ forest (LAF) at $z>5$ probes the thermal and reionization\nhistory of the intergalactic medium (IGM) and the nature of dark matter, but\nits interpretation requires comparison to cosmological hydrodynamical\nsimulations. At high-$z$, convergence of these simulations is more exacting\nsince transmission is dominated by underdense voids that are challenging to\nresolve. With evidence mounting for a late end to reionization, small\nstructures down to the sub-kpc level may survive to later times than\nconventionally thought due to the reduced time for pressure smoothing to impact\nthe gas, further tightening simulation resolution requirements. We perform a\nsuite of simulations using the Eulerian cosmological hydrodynamics code Nyx,\nspanning domain sizes of 1.25-10 $h^{-1}$ Mpc and 5-80 $h^{-1}$ kpc cells, and\nexplore the interaction of these variables with the timing of reionization on\nthe properties of the matter distribution and the simulated LAF at $z=5.5$. In\nobservable Ly$\\alpha$ power, convergence within 10% is achieved for $k< 0.1$\ns/km, but larger $k$ shows deviation of up to 20 percent. While a later\nreionization retains more small structure in the density field, because of the\ngreater thermal broadening there is little difference in the convergence of LAF\npower between early ($z=9$) and later ($z=6$) reionizations. We conclude that\nat $z\\sim5.5$, resolutions of 10 kpc are necessary for convergence of LAF power\nat $k<0.1$ s/km, while higher-$k$ modes require higher resolution, and that the\ntiming of reionization does not significantly impact convergence given\nrealistic photoheating.\n", "  Forthcoming galaxy surveys will provide measurements of galaxy clustering\nwith an unprecedented level of precision, that will require comparably good\naccuracy. Current models for galaxy correlations rely on approximations and\nidealizations that might be inadequate for ultra precise measurements. On the\nother hand, exact calculations have proven to be computationally too expensive\nto be efficiently implemented in real data analyses. We start a project to\nprovide precise and accurate formalisms for galaxy correlations, and in this\npaper we investigate the 3D angular power spectrum including effects of unequal\ntime correlations. We establish an explicit link between the full- and flat-sky\nspectra by performing an asymptotic expansion of the full-sky result around the\nequal time case. The limiting case coincides with the idealized spectrum that a\nmeta-observer would measure if it had access to the entire 4D Universe. The\nleading term in the obtained flat-sky expansion is the only translationally\ninvariant term in the plane perpendicular to the line of sight, while the\nhigher-order terms account for the deviation from this invariance. We study the\nbehavior of such corrections for a simplified universe where we can\nanalytically solve the power spectrum and have full control of the equations,\ntherefore being able to understand the exact nature of all the terms and the\norigin of the corrections. We highlight that the conclusions and the structure\nof the unequal time spectra are fully general and serve as lessons and guidance\nin understanding galaxy clustering in any cosmology. Finally, we show that our\nflat-sky unequal time expression matches the exact full-sky calculation\nremarkably better than commonly adopted approximations, even at the largest\nscales and for both shallow and deep redshift bins.\n", "  The cosmological dark sector remains an enigma, offering numerous\npossibilities for exploration. One particularly intriguing option is the\n(non-minimal) interaction scenario between dark matter and dark energy. In this\npaper, to investigate this scenario, we have implemented Binned and Gaussian\nmodel-independent reconstructions for the interaction kernel alongside the\nequation of state; while using data from BAOs, Pantheon+ and Cosmic\nChronometers. In addition to the reconstruction process, we conducted a model\nselection to analyze how our methodology performed against the standard\n$\\Lambda$CDM model. The results revealed a slight indication, of at least\n1$\\sigma$ confidence level, for some oscillatory dynamics in the interaction\nkernel and, as a by-product, also in the DE and DM. A consequence of this\noutcome is the possibility of a sign change in the direction of the energy\ntransfer between DE and DM and a possible transition from a negative DE energy\ndensity in early-times to a positive one at late-times. While our\nreconstructions provided a better fit to the data compared to the standard\nmodel, the Bayesian Evidence showed an intrinsic penalization due to the extra\ndegrees of freedom. Nevertheless these reconstructions could be used as a basis\nfor other physical models with lower complexity but similar behavior.\n", "  We derive a new constraint on the expansion history of the Universe by\napplying the cosmic chronometers method, studying the age evolution of\nhigh-redshift galaxies with a full-spectral-fitting approach. We select a\nsample of 39 massive ($log(M/M_\\odot)>10.8$) and passive\n($log(sSFR/yr^{-1})<-11$) galaxies from the data release 4 of the VANDELS\nsurvey at $1<z<1.5$, combining different selection criteria to minimize the\npotential contamination by star-forming outliers. We perform\nfull-spectral-fitting jointly on spectra and photometry of our sources with the\ncode BAGPIPES, without any cosmological assumption on the age of the\npopulation. The derived physical properties of the selected galaxies are\ncharacteristic of a passive population, with short star formation timescales\n($<\\tau>=0.28\\pm0.02$ Gyr), low dust extinction ($<A_{V,dust}>=0.43\\pm0.02$\nmag), and sub-solar metallicities ($<Z/Z_{\\odot}>=0.44\\pm0.01$). The ages show\na decreasing trend with redshift compatible with a standard cosmological model,\neven if no cosmological constraint is assumed in the fit, and a clear\nmass-downsizing pattern. Testing the impact of the star formation history on\nthe results, we find only a maximum 2\\% fluctuation in age and metallicity. By\nfitting the median age-redshift relation with a flat $\\Lambda$CDM model and\nassuming a Gaussian prior on $\\Omega_{M,0}= 0.3\\pm0.02$ from late-Universe\nprobes, we obtain $H_0=67_{-15}^{+14}\\:km\\:s^{-1}\\:Mpc^{-1}$. In the end, we\nderive a new estimate of the Hubble parameter with the cosmic chronometers\nmethod, $H(z=1.26)=135\\pm65\\:km\\:s^{-1}\\:Mpc^{-1}$ including statistical and\nsystematic errors. While the error budget is currently dominated by the\nscarcity of the sample, this work proves the potential strength of the cosmic\nchronometers approach up to $z>1$, especially in view of incoming large\nspectroscopic surveys like Euclid. (abridged)\n", "  We present the integrated 3-point correlation functions (3PCF) involving both\nthe cosmic shear and the galaxy density fields. These are a set of higher-order\nstatistics that describe the modulation of local 2-point correlation functions\n(2PCF) by large-scale features in the fields, and which are easy to measure\nfrom galaxy imaging surveys. Based on previous works on the shear-only\nintegrated 3PCF, we develop the theoretical framework for modelling 5 new\nstatistics involving the galaxy field and its cross-correlations with cosmic\nshear. Using realistic galaxy and cosmic shear mocks from simulations, we\ndetermine the regime of validity of our models based on leading-order standard\nperturbation theory with an MCMC analysis that recovers unbiased constraints of\nthe amplitude of fluctuations parameter $A_s$ and the linear and quadratic\ngalaxy bias parameters $b_1$ and $b_2$. Using Fisher matrix forecasts for a\nDES-Y3-like survey, relative to baseline analyses with conventional\n3$\\times$2PCFs, we find that the addition of the shear-only integrated 3PCF can\nimprove cosmological parameter constraints by $20-40\\%$. The subsequent\naddition of the new statistics introduced in this paper can lead to further\nimprovements of $10-20\\%$, even when utilizing only conservatively large scales\nwhere the tree-level models are valid. Our results motivate future work on the\ngalaxy and shear integrated 3PCFs, which offer a practical way to extend\nstandard analyses based on 3$\\times$2PCFs to systematically probe the\nnon-Gaussian information content of cosmic density fields.\n", "  We present a joint cosmic shear analysis of the Dark Energy Survey (DES Y3)\nand the Kilo-Degree Survey (KiDS-1000) in a collaborative effort between the\ntwo survey teams. We find consistent cosmological parameter constraints between\nDES Y3 and KiDS-1000 which, when combined in a joint-survey analysis, constrain\nthe parameter $S_8 = \\sigma_8 \\sqrt{\\Omega_{\\rm m}/0.3}$ with a mean value of\n$0.790^{+0.018}_{-0.014}$. The mean marginal is lower than the maximum a\nposteriori estimate, $S_8=0.801$, owing to skewness in the marginal\ndistribution and projection effects in the multi-dimensional parameter space.\nOur results are consistent with $S_8$ constraints from observations of the\ncosmic microwave background by Planck, with agreement at the $1.7\\sigma$ level.\nWe use a Hybrid analysis pipeline, defined from a mock survey study quantifying\nthe impact of the different analysis choices originally adopted by each survey\nteam. We review intrinsic alignment models, baryon feedback mitigation\nstrategies, priors, samplers and models of the non-linear matter power\nspectrum.\n", "  The use of multiple independent methods with their own systematic\nuncertainties is crucial for resolving the ongoing tension between local and\ndistant measurements of the Hubble constant ($H_{0}$). While type Ia supernovae\n(SNe Ia) have historically been the most widely used distance indicators,\nrecent studies have shown that type II supernovae (SNe II) can provide\nindependent measurements of extragalactic distances with different systematic\nuncertainties. Unlike SNe Ia, the progenitors of SNe II are well understood,\narising from the explosion of red supergiants in late-type galaxies via\ncore-collapse. While SNe II do not exhibit the same level of uniformity in peak\nluminosity as SNe Ia, their differences can be calibrated using theoretical or\nempirical methods. Overall, this chapter presents a comprehensive overview of\nthe use of SNe II as extragalactic distance indicators, with a particular focus\non their application to measuring $H_0$ and addressing the Hubble tension. We\ndescribe the underlying theory of each method, discuss the challenges\nassociated with them, including uncertainties in the calibration of the\nsupernova absolute magnitude, and present a comprehensive list of the most\nupdated Hubble constant measurements.\n", "  It is accepted in modern cosmology that the scalar field responsible for the\ninflationary stage of the early Universe is completely transformed into matter.\nIt is assumed that the accelerated expansion is currently driven by dark energy\n(DE), which is likely determined by Einstein's cosmological constant. We\nconsider a cosmological model where DE can have two components, one of which is\nEinstein's constant ($\\Lambda$) and the other, smaller variable component DEV\n($\\Lambda_V$), is associated with the remnant of the scalar field that caused\ninflation after the main part of the scalar field has turned into matter. It is\nassumed that such a transformation continues at the present time and is\naccompanied by the reverse process of the DM transformation into a scalar\nfield. The interconnection between DM and DEV, which leads to a linear\nrelationship between the energy densities of these components after\nrecombination $\\rho_{DM}=\\alpha\\;\\rho_{DEV}$, is considered. Variants with a\ndependence of the coefficient $\\alpha(z)$ on the redshift are also considered.\nOne of the problems that have arisen in modern cosmology, called Hubble Tension\n(HT), is the discrepancy between the present values of the Hubble constant\nmeasured from observations at small redshifts $z\\lesssim1$ and the values found\nfrom fluctuations of the cosmic microwave background at large redshifts\n$z\\approx1100$. In the considered model, this discrepancy can be explained by\nthe deviation of the real cosmological model from the conventional cold dark\nmatter (CDM) model of the Universe by action of the additional DE component at\nthe stages after recombination. Within this extended model, we consider various\n$\\alpha(z)$ functions that can eliminate the HT. To maintain the ratio of DEV\nand DM energy densities close to constant over the interval $0\\le z\\le1100$, we\nassume the existence of a wide spectrum of DM particle masses.\n", "  Since the very first observations, the Cosmic Microwave Background (CMB) has\nrevealed on large-scales unexpected features known as anomalies, which\nchallenge the standard $\\Lambda$ cold dark matter ($\\Lambda$CDM) cosmological\nmodel. One such anomaly is the \"lack-of-correlation\", where the measured\ntwo-point angular correlation function of CMB temperature anisotropies is\ncompatible with zero, differently from the predictions of the standard model.\nThis anomaly could indicate a deviation from the standard model, unknown\nsystematics, or simply a rare realization of the model itself. In this study,\nwe explore the possibility that the lack-of-correlation anomaly is a\nconsequence of living in a rare realization of the standard model, by\nleveraging the potential information provided by the cosmological gravitational\nwave background (CGWB) detectable by future gravitational wave (GW)\ninterferometers. We analyze both constrained and unconstrained realizations of\nthe CGWB to investigate the extent of information that GWs can offer. To\nquantify the impact of the CGWB on the lack-of-correlation anomaly, we employ\nestablished estimators and introduce a new estimator that addresses the\n\"look-elsewhere\" effect. Additionally, we consider three different maximum\nmultipoles, denoted as $\\ell_{\\rm max}$, to account for the anticipated\ncapabilities of future GW detectors ($\\ell_{\\rm max} = 4, 6, 10$). Summarizing\nour findings for the case of $\\ell_{\\rm max} = 4$, we identify the angular\nrange $[63^\\circ - 180^\\circ]$ as the region where future observations of the\nCGWB maximize the probability of rejecting the standard model. Furthermore, we\ncalculate the expected significance of this observation, demonstrating that\n98.81% (81.67%) of the GW realizations enhance the current significance of the\nanomaly when considering the full-sky (masked) Planck SMICA map as our CMB sky.\n", "  The presence of supermassive black holes at redshift z > 6 raises some\nquestions about their formation and growth in the early universe. Due to the\nconstruction of new telescopes like the ELT to observe and detect SMBHs, it\nwill be useful to derive theoretical estimates for the population and to\ncompare observations and model predictions in the future. In consequence our\nmain goal is to estimate the population of SMBHs using a semi-analytic code\nknown as Galacticus which is a code for the formation and evolution of galaxies\nwhere we are about to include different scenarios for SMBHs formation\nindicating the initial mass of the black hole seed, its formation conditions\nand recipes for the evolution of the components of the galaxies. We found that\nthe principal mechanism of growing SMBHs is is via galaxy mergers and accretion\nof matter. For the comparison of our results with observations, we calculate\nthe radius of influence of the black hole to estimate which part of the\npopulation could be detected, leading to relations similar to the observed\nones.\n", "  Recently, the cosmological tensions, $H_0$ and $S_8$ in particular, have\ninspired modification of both pre- and postrecombination physics\nsimultaneously. Early dark energy is a promising pre-recombination solution of\nthe $H_0$ tension, known to be compatible with the cosmic microwave background\n(CMB). However, the compatibility of early dark energy, as well as general\nearly resolutions, with the CMB is no longer obvious if the late Universe is\nalso modified. Aside from cosmological parameters, the main channel through\nwhich late Universe physics affects CMB observables is gravitational lensing.\nWe employed a new method of sampling functions using the Gaussian Process in\nthe Monte Carlo Markov Chain analysis to constrain the shape of the CMB lensing\npotential. We obtained the early Universe (CMB) only constraints on the full\nshape of the CMB lensing potential, with the late-time Universe being\nmarginalized over. It is found that CMB data prefers a lensing potential shape\nthat is $\\Lambda$CDM-like at $80\\lesssim L\\lesssim400$ but with enhanced\namplitude beyond this range. The obtained shape constraints can serve as a\nCMB-compatibility guideline for both late and early Universe model building\nthat modifies the lensing potential.\n", "  The non-linear dynamics of scalar fields coupled to matter and gravity can\nlead to remarkable density-dependent screening effects. In this short review we\npresent the main classes of screening mechanisms, and discuss their tests in\nlaboratory and astrophysical systems. We particularly focus on reviewing\nnumerical and technical aspects involved in modeling the non-linear dynamics of\nscreening. In this review, we focus on tests using laboratory experiments and\nastrophysical systems, such as stars, galaxies and dark matter halos.\n", "  Recent studies suggest spectroscopic differences explain a fraction of the\nvariation in Type Ia supernova (SN Ia) luminosities after light-curve/color\nstandardization. In this work, (i) we empirically characterize the variations\nof standardized SN Ia luminosities, and (ii) we use a spectroscopically\ninferred parameter, SIP, to improve the precision of SNe Ia along the distance\nladder and the determination of the Hubble constant ($H_0$). First, we show\nthat the \\texttt{Pantheon+} covariance model modestly overestimates the\nuncertainty of standardized magnitudes by $\\sim 7$%, in the parameter space\nused by the $\\texttt{SH0ES}$ Team to measure $H_0$; accounting for this alone\nyields $H_0 = 73.01 \\pm 0.92$ km s$^{-1}$ Mpc$^{-1}$. Furthermore, accounting\nfor spectroscopic similarity between SNe~Ia on the distance ladder reduces\ntheir relative scatter to $\\sim0.12$ mag per object (compared to $\\sim 0.14$\nmag previously). Combining these two findings in the model of SN covariance, we\nfind an overall 14% reduction (to $\\pm 0.85$km s$^{-1}$ Mpc$^{-1}$) of the\nuncertainty in the Hubble constant and a modest increase in its value.\nIncluding a budget for systematic uncertainties itemized by Riess et al.\n(2022a), we report an updated local Hubble constant with $\\sim1.2$%\nuncertainty, $H_0 = 73.29 \\pm 0.90$km s$^{-1}$ Mpc$^{-1}$. We conclude that\nspectroscopic differences among photometrically standardized SNe Ia do not\nexplain the ``Hubble tension.\" Rather, accounting for such differences\nincreases its significance, as the discrepancy against $\\Lambda$CDM calibrated\nby the ${\\it Planck}$ 2018 measurement rises to 5.7$\\sigma$.\n", "  The two-point summary statistics is one of the most commonly used tools in\nthe study of cosmological structure. Starting from the theoretical power\nspectrum defined in the 3D volume and obtained via the process of ensemble\naveraging, we establish the construction of the observed 3D power spectrum,\nfolding the unequal-time information around the average position into the wave\nmodes along the line of sight. We show how these unequal-time cross-correlation\neffects give rise to scale-dependent corrections in the observable 3D power\nspectrum. We also introduce a new dimensionless observable, the\nfrequency-angular power spectrum, which is a function of dimensionless and\ndirectly observable quantities corresponding to Fourier counterparts of angles\nand redshifts. While inheriting many useful characteristics of the canonical\nobserved power spectrum, this newly introduced statistic does not depend on\nphysical distances and is hence free of so-called Alcock-Paczynski effects.\nSuch observable thus presents a clear advantage and simplification over the\ntraditional power spectrum. Moreover, relying on linear theory calculations, we\nestimate that unequal-time corrections, while generally small, can amount to a\nfew percent on large scales and high redshifts. Interestingly, such corrections\ndepend on the bias of the tracers, the growth rate, but also their time\nderivatives, opening up the possibility of new tests of cosmological models.\nThese radial mode effects also introduce anisotropies in the observed power\nspectrum, in addition to the ones arising from redshift-space distortions,\ngenerating non-vanishing odd multiples and imaginary contributions. Lastly, we\ninvestigate the effects of unequal-time corrections in resumming long\ndisplacements (IR-resummation) of the observed power spectrum.\n", "  The JWST mission is in the process of probing the galaxy mass function at\n$z>10$, when conceivably any delay in halo assembly due to the presence of a\ndwarf galaxy-scale power spectrum cutoff may drastically suppress the number of\ngalaxies relative to the cold dark matter (CDM) expectation. We employ N-body\nsimulations of CDM and warm dark matter (WDM) to explore how the difference in\nhalo collapse time between these models scales with $z=0$ descendant halo mass.\nWe demonstrate that collapse begins first for the most massive haloes, and the\ndelay in collapse time between CDM and WDM haloes correlates inversely with\ndescendant mass. We thus infer that only present-day dwarf galaxies exhibit any\ndifference in their assembly history between CDM and WDM at $z=10$, and\ntherefore support previous studies that have found JWST is unlikely to\ndetermine whether our Universe is better described by the CDM cosmology or the\nWDM cosmology without favourable lensing studies.\n", "  Recently different cosmological measurements have shown a tension in the\nvalue of the Hubble constant, $H_0$. Assuming the $\\Lambda$CDM model, the\nPlanck satellite mission has inferred the Hubble constant from the cosmic\nmicrowave background (CMB) anisotropies to be $H_0 = 67.4 \\pm 0.5 \\, \\rm{km \\,\ns^{-1} \\, Mpc^{-1}}$. On the other hand, low redshift measurements such as\nthose using Cepheid variables and supernovae Type Ia (SNIa) have obtained a\nsignificantly larger value. For instance, Riess et al. reported $H_0 = 73.04\n\\pm 1.04 \\, \\rm{km \\, s^{-1} \\, Mpc^{-1}}$, which is $5\\sigma$ apart of the\nprediction from Planck observations. This tension is a major problem in\ncosmology nowadays, and it is not clear yet if it comes from systematic effects\nor new physics. The use of new methods to infer the Hubble constant is\ntherefore essential to shed light on this matter. In this paper, we discuss\nusing the ages of the oldest astrophysical objects (OAO) to probe the Hubble\ntension. We show that, although this data can provide additional information,\nthe method can also artificially introduce a tension. Reanalyzing the ages of\n114 OAO, we obtain that the constraint in the Hubble constant goes from\nslightly disfavoring local measurements to favoring them.\n", "  The lensing effect of the cosmic microwave background (CMB) is a powerful\ntool for our study of the distribution of matter in the universe. Currently,\nthe quadratic estimator (EQ) method, which is widely used to reconstruct\nlensing potential, has been known to be sub-optimal for the low-noise levels\npolarization data from next-generation CMB experiments. To improve the\nperformance of the reconstruction, other methods, such as the maximum\nlikelihood estimator and machine learning algorithms are developed. In this\nwork, we present a deep convolutional neural network model named the Residual\nDense Local Feature U-net (RDLFUnet) for reconstructing the CMB lensing\nconvergence field. By simulating lensed CMB data with different noise levels to\ntrain and test network models, we find that for noise levels less than\n$5\\mu$K-arcmin, RDLFUnet can recover the input gravitational potential with a\nhigher signal-to-noise ratio than the previous deep learning and the\ntraditional QE methods at almost the entire observation scales.\n", "  We investigate the robustness of baryon acoustic oscillations (BAO)\nmeasurements with a photometric galaxy sample using mock galaxy catalogues with\nvarious sizes of photometric redshift (photo-$z$) uncertainties. We first\nconduct the robustness of BAO measurements, assuming we have a perfect\nknowledge of photo-$z$ uncertainties. We find that the BAO shift parameter\n$\\alpha$ can be constrained in an unbiased manner even for 3% photometric\nredshift uncertainties up to $z\\sim 1$. For instance, $\\alpha=1.006 \\pm 0.078$\nwith 95% confidence level is obtained from 3% photo-$z$ uncertainty data at\n$z=1.03$ using the sample of $M_* \\ge 10^{10.25} M_{\\odot}/h^2$. We also find\nthat a sparse galaxy sample, e.g. $<2\\times10^{-4}$ [$h$ Mpc$^{-1}]^3$ causes\nadditional noise in the covariance matrix calculation and can bias the\nconstraint on $\\alpha$. Following this, we look into the scenario where\nincorrect photometric redshift uncertainties are assumed in the fitting model.\nWe find that underestimating the photo-$z$ uncertainty leads to a degradation\nin the constraining power on $\\alpha$. However, the constrained value of\n$\\alpha$ is not biased. We also quantify the constraining power on $\\Omega_{\\rm\nm0}$ assuming the LSST-like covariance and find that the 95% confidence level\nis $\\sigma(\\Omega_{\\rm m0})\\sim0.03$-$0.05$ corresponding to the photo-$z$\nuncertainties of 1% to 3% respectively. Finally, we examine whether the\nskewness in the photometric redshift can bias the constraint on $\\alpha$ and\nconfirm that the constraint on $\\alpha$ is unbiased, even assuming a Gaussian\nphoto-$z$ uncertainty in our model.\n", "  Understanding the astrophysical nature of the first stars still remains an\nunsolved problem in cosmology. The redshifted global 21-cm signal\n$(\\text{T}_{21})$ acts as a treasure trove to probe the Cosmic Dawn era -- when\nthe intergalactic medium was mostly neutral. Many experiments, like SARAS 3,\nEDGES, and DARE have been proposed to probe the cosmic dawn era. However,\nextracting the faint cosmological signal buried inside a brighter foreground\n$\\mathcal{O}(10^4)$ remains challenging. Thus we use two artificial neural\nnetworks, one for extraction of foreground, via parameter estimation with\nR-square $(R^2)$ score $(0.8034 - 0.9984)$, from the total sky-averaged\nspectrum. The other is for extraction of a global 21-cm signal in the presence\nof noise with $R^2$ score $(0.6960 - 0.9978)$. Considering an excess radio\nbackground scenario, we constructed all possible $\\text{T}_{21}$ signals in the\nEDGES limit, along with the foreground signal, to train the neural networks.\nHere, we also explore the variation in parameter estimation due to the presence\nof heating of intergalactic medium by background radio radiation mediated via\nLy$\\alpha$ photons from first stars, and we found that the presence and absence\nof this effect can change the global 21-cm signal estimation by $\\sim 33$ mK in\nthe EDGES limit $(\\sim -0.5\\text{ K})$\n", "  We investigate the connection between the full- and flat-sky angular power\nspectra. First, we revisit this connection established on the geometric and\nphysical grounds, namely that the angular correlations on the sphere and in the\nplane (flat-sky approximation) correspond to each other in the limiting case of\nsmall angles and a distant observer. To establish the formal conditions for\nthis limit, we first resort to a simplified shape of the 3D power spectrum,\nwhich allows us to obtain analytic results for both the full- and flat-sky\nangular power spectra. Using a saddle-point approximation, we find that the\nflat-sky results are obtained in the limit when the comoving distance and wave\nmodes $\\ell$ approach infinity at the same rate. This allows us to obtain an\nanalogous asymptotic expansion of the full-sky angular power spectrum for\ngeneral 3D power spectrum shapes, including the LCDM Universe. In this way, we\nfind a robust limit of correspondence between the full- and flat-sky results.\nThese results also establish a mathematical relation, i.e., an asymptotic\nexpansion of the ordinary hypergeometric function of a particular choice of\narguments that physically corresponds to the flat-sky approximation of a\ndistant observer. This asymptotic form of the ordinary hypergeometric function\nis obtained in two ways: relying on our saddle-point approximation and using\nsome of the known properties of the hypergeometric function.\n", "  The rapid development of gravitational wave astronomy provides the unique\nopportunity of exploring the dynamics of the Universe using clustering\nproperties of coalescing binary black hole mergers. Gravitational wave data,\nalong with information coming from future galaxy surveys, have the potential of\nshedding light about many open questions in Cosmology, including those\nregarding the nature of dark matter and dark energy. In this work we explore\nwhich combination of gravitational wave and galaxy survey datasets are able to\nprovide the best constraints both on modified gravity theories and on the\nnature of the very same binary black hole events. In particular, by using the\npublic Boltzmann code \\texttt{Multi\\_CLASS}, we compare cosmological\nconstraints on popular $\\Lambda$CDM extensions coming from gravitational waves\nalone and in conjunction with either deep and localized or wide and shallow\ngalaxy surveys. We show that constraints on extensions of General Relativity\nwill be at the same level of existing limits from gravitational waves alone or\none order of magnitude better when galaxy surveys are included. Furthermore,\ncross-correlating both kind of galaxy survey with gravitational waves datasets\nwill allow to confidently rule in or out primordial black holes as dark matter\ncandidate in the majority of the allowed parameter space.\n", "  The possible existence of primordial black holes (PBHs) is an open question\nin modern cosmology. Among the probes to test it, gravitational waves (GW)\ncoming from their mergers constitute a powerful tool. In this work, we study\nhow stellar mass PBH binaries could affect measurements of the clustering of\nmerger events in future GW surveys. We account for PBH binaries formed both in\nthe early and late Universe and show that the power spectrum modification they\nintroduce can be detected at $\\sim 2\\sigma-3\\sigma$ (depending on some\nassumptions) whenever PBH mergers make up at least $\\sim 60\\%$ of the overall\nnumber of detected events. By adding cross-correlations with galaxy surveys,\nthis threshold is lowered to $\\sim 40\\%$. In the case of a poor redshift\ndetermination of GW sources, constraints are degraded by about a factor of 2.\nAssuming a theoretical model for the PBH merger rate, we can convert our\nresults to constraints on the fraction of dark matter in PBHs, $f_{\\rm PBH}$.\nFinally, we perform a Bayesian model selection forecast and confirm that the\nanalysis we develop could be able to detect $\\sim30M_\\odot$ PBHs if they\naccount for $f_{\\rm PBH}\\sim 10^{-4}-10^{-3}$, depending on the model\nuncertainty considered, being thus competitive with other probes.\n", "  We calculate the redshift evolution of the global 21cm signal in the first\nbillion years using a semi-analytic galaxy formation model, DELPHI, that\njointly tracks the assembly of dark matter halos and their constituent baryons\nincluding the impact of supernova feedback and dust enrichment. Employing only\ntwo redshift- and mass-independent free parameters, our model predicts galaxy\npopulations in accord with data from both the James Webb Space Telescope (JWST)\nand the Atacama Large Millimetre Array (ALMA) at $z \\sim 5-12$. In addition to\nthis ``fiducial\" model, which fully incorporates the impact of dust\nattenuation, we also explore an unphysical ``maximal\" model wherein galaxies\ncan convert a 100\\% of their gas into stars instantaneously (and supernova\nfeedback is ignored) required to explain JWST data at $z >=13$. We also explore\na wide range of values for our {\\it 21cm} parameters that include the impact of\nX-ray heating ($f_{\\rm X,h} =0.02-2.0$) and the escape fraction of Lyman Alpha\nphotons ($f_\\alpha = 0.01-1.0$). Our key findings are: (i) the fiducial model\npredicts a global 21cm signal which reaches a minimum brightness temperature of\n$ T_{\\rm b, min}\\sim -215$ mK at a redshift $z_{\\rm min} \\sim 14$; (ii) since\nthe impact of dust on galaxy properties (such as the star formation rate\ndensity) only becomes relevant at $z <= 8$, dust does not have a sensible\nimpact on the global 21cm signal; (iii) the ``maximal\" model predicts $T_{\\rm\nb, min}= -210$ mK as early as $z_{\\rm min} \\sim 18$; (iv) galaxy formation and\n21cm parameters have a degenerate impact on the global 21cm signal. A\ncombination of the minimum temperature and its redshift will therefore be\ncrucial in constraining galaxy formation parameters and their coupling to the\n21cm signal at these early epochs.\n", "  We propose that observations of super-massive galaxies contain cosmological\nconstraining power similar to conventional cluster cosmology, and we provide\npromising indications that the associated systematic errors are comparably\neasier to control. We consider a fiducial spectroscopic and stellar mass\ncomplete sample of galaxies drawn from the Dark Energy Spectroscopic Survey\n(DESI) and forecast how constraints on Omega_m-sigma_8 from this sample will\ncompare with those from number counts of clusters based on richness. At fixed\nnumber density, we find that massive galaxies offer similar constraints to\ngalaxy clusters. However, a mass-complete galaxy sample from DESI has the\npotential to probe lower halo masses than standard optical cluster samples\n(which are typically limited to richness above 20 and halo mass above 10^13.5);\nadditionally, it is straightforward to cleanly measure projected galaxy\nclustering for such a DESI sample, which we show can substantially improve the\nconstraining power on Omega_m. We also compare the constraining power of\nstellar mass-limited samples to those from larger but mass-incomplete samples\n(e.g., the DESI Bright Galaxy Survey, BGS, Sample); relative to a lower number\ndensity stellar mass-limited samples, we find that a BGS-like sample improves\nstatistical constraints by 60% for Omega_m and 40% for sigma_8, but this uses\nsmall scale information which will be harder to model for BGS. Our initial\nassessment of the systematics associated with supermassive galaxy cosmology\nyields promising results. The proposed samples have a 10% satellite fraction,\nbut we show that cosmological constraints may be robust to the impact of\nsatellites. These findings motivate future work to realize the potential of\nsuper-massive galaxies to probe lower halo masses than richness-based clusters\nand to avoid persistent systematics associated with optical cluster finding.\n", "  We present the first results of one extremely high resolution, non-radiative\nmagnetohydrodynamical cosmological zoom-in simulation of a massive cluster with\na virial mass M$_\\mathrm{vir} = 2.0 \\times 10^{15}$ solar masses. We adopt a\nmass resolution of $4 \\times 10^5$ M$_{\\odot}$ with a maximum spatial\nresolution of around 250 pc in the central regions of the cluster. We follow\nthe detailed amplification process in a resolved small-scale turbulent dynamo\nin the Intracluster medium (ICM) with strong exponential growth until redshift\n4, after which the field grows weakly in the adiabatic compression limit until\nredshift 2. The energy in the field is slightly reduced as the system\napproaches redshift zero in agreement with adiabatic decompression. The field\nstructure is highly turbulent in the center and shows field reversals on a\nlength scale of a few 10 kpc and an anti-correlation between the radial and\nangular field components in the central region that is ordered by small-scale\nturbulent dynamo action. The large-scale field on Mpc scales is almost\nisotropic, indicating that the structure formation process in massive galaxy\ncluster formation is suppressing memory of both the initial field configuration\nand the amplified morphology via the turbulent dynamo in the central regions.\nWe demonstrate that extremely high-resolution simulations of the magnetized ICM\nare in reach that can resolve the small-scale magnetic field structure which is\nof major importance for the injection of and transport of cosmic rays in the\nICM. This work is a major cornerstone for follow-up studies with an on-the-fly\ntreatment of cosmic rays to model in detail electron-synchrotron and gamma-ray\nemissions.\n", "  Context. Whereas X-ray clusters are extensively used for cosmology, their\nidealistic modelling, through the hypotheses of spherical symmetry and\nhydrostatic equilibrium, are more and more being questioned. Along these lines,\nthe soft X-ray emission detected in tens of clusters with ROSAT was found to be\nhigher than what expected from the idealistic hot gas modelling, pointing to\nour incomplete understanding of these objects. Aims. Given that cluster\nenvironments are at the interface between the hot intra-cluster medium (ICM),\nwarm circum-galactic medium (WCGM) and warm-hot intergalactic medium (WHIM), we\naim to explore the relative soft X-ray emission of different gas phases in\ncircum-cluster environments. Method. By using the most massive halos in\nIllustrisTNG at z=0, we have predicted the hydrodynamical properties of the gas\nfrom cluster centers to their outskirts (5 R200), and modelled their X-ray\nradiation for various plasma phases. Results. First, we found that the radial\nprofile of temperature, density, metallicity and clumpiness of the ICM are in\ngood agreement with recent X-ray observations of clusters. Secondly, we have\ndeveloped a method to predict the radial profile of soft X-ray emission in\ndifferent bands, the column density of ions and the X-ray absorption lines (O\nVIII, O VII, Ne IX, and Ne IX) of warm-hot gas inside and around clusters.\nConclusion. The warm gas (in the form of both WCGM and WHIM gas) is a strong\nemitter in soft X-ray bands, and is qualitatively consistent with the\nobservational measurements. Our results suggest that the cluster soft excess is\ninduced by the thermal emission of warm gas in the circum-cluster environments.\n", "  To fully take advantage of the data provided by large-scale structure\nsurveys, we need to quantify the potential impact of baryonic effects, such as\nfeedback from active galactic nuclei (AGN) and star formation, on cosmological\nobservables. In simulations, feedback processes originate on scales that remain\nunresolved. Therefore, they need to be sourced via subgrid models that contain\nfree parameters. We use machine learning to calibrate the AGN and stellar\nfeedback models for the FLAMINGO cosmological hydrodynamical simulations. Using\nGaussian process emulators trained on Latin hypercubes of 32 smaller-volume\nsimulations, we model how the galaxy stellar mass function and cluster gas\nfractions change as a function of the subgrid parameters. The emulators are\nthen fit to observational data, allowing for the inclusion of potential\nobservational biases. We apply our method to the three different FLAMINGO\nresolutions, spanning a factor of 64 in particle mass, recovering the observed\nrelations within the respective resolved mass ranges. We also use the\nemulators, which link changes in subgrid parameters to changes in observables,\nto find models that skirt or exceed the observationally allowed range for\ncluster gas fractions and the stellar mass function. Our method enables us to\ndefine model variations in terms of the data that they are calibrated to rather\nthan the values of specific subgrid parameters. This approach is useful,\nbecause subgrid parameters are typically not directly linked to particular\nobservables, and predictions for a specific observable are influenced by\nmultiple subgrid parameters.\n", "  Bayesian Estimation Applied to Multiple Species (BEAMS) is implemented in the\nBEAMS with Bias Corrections (BBC) framework to produce a redshift-binned Hubble\ndiagram (HD) for Type Ia supernovae (SNe Ia). BBC corrects for selection\neffects and non-SNIa contamination, and systematic uncertainties are described\nby a covariance matrix with dimension matching the number of BBC redshift bins.\nFor spectroscopically confirmed SN Ia samples, a recent \"Binning is Sinning\"\narticle (BHS21, arxiv:2012.05900) showed that an unbinned HD and covariance\nmatrix reduces the systematic uncertainty by a factor of ~1.5 compared to the\nbinned approach. Here we extend their analysis to obtain an unbinned HD for a\nphotometrically identified sample processed with BBC. To test this new method,\nwe simulate and analyze 50 samples corresponding to the Dark Energy Survey\n(DES) witha low-redshift anchor; the simulation includes SNe Ia, and\ncontaminants from core-collapse SNe and peculiar SNe Ia. The analysis includes\nsystematic uncertainties for calibration, and measures the dark energy equation\nof state parameter (w). Compared to a redshift-binned HD, the unbinned HD with\nnearly 2000 events results in a smaller systematic uncertainty, in qualitative\nagreement with BHS21, and averaging results among the 50 samples we find no\nevidence for a w-bias. To reduce computation time for fitting an unbinned HD\nwith large samples, we propose an HD-rebinning method that defines the HD in\nbins of redshift, color, and stretch; the rebinned HD results in similar\nuncertainty as the unbinned case, and shows no evidence for a w-bias.\n", "  Data analysis from upcoming large galaxy redshift surveys, such as Euclid and\nDESI will significantly improve constraints on cosmological parameters. To\noptimally extract the information from these galaxy surveys, it is important to\ncontrol with a high level of confidence the uncertainty and bias arising from\nthe estimation of the covariance that affects the inference of cosmological\nparameters. In this work, we are addressing two different but closely related\nissues: (i) the sampling noise present in a covariance matrix estimated from a\nfinite set of simulations and (ii) the impact on cosmological constraints of\nthe non-Gaussian contribution to the covariance matrix of the power spectrum.\nWe focus on the parameter estimation obtained from fitting the matter power\nspectrum in real space, using the DEMNUni N-body simulations. Regarding the\nfirst issue, we adopt two different approaches to reduce the sampling noise in\nthe precision matrix that propagates in the parameter space: on the one hand\nusing an alternative estimator of the covariance matrix based on a non-linear\nshrinkage, NERCOME; and on the other hand employing a method of fast generation\nof approximate mock catalogs, COVMOS. We find that NERCOME can significantly\nreduce the noise induced on the posterior distribution of parameters, but at\nthe cost of a systematic overestimation of the error bars on the cosmological\nparameters. We show that using a COVMOS covariance matrix estimated from a\nlarge number of realisations (10~000) results in unbiased cosmological\nconstraints. Regarding the second issue, we quantify the impact on cosmological\nconstraints of the non-Gaussian part of the power spectrum covariance purely\ncoming from non-linear clustering. We find that when this term is neglected,\nboth the errors and central values of the estimated parameters are affected for\na scale cut $\\kmax > 0.2\\ \\invMpc$.\n", "  The cross correlation between the CMB Doppler mode and the 21 cm line\nbrightness temperature is calculated in the presence of a stochastic primordial\nmagnetic field. Potential detectability is estimated for Planck 2018 bestfit\nparameters in combination with configuration and survey design parameters of 21\ncm line radio telescopes such as LOFAR and the future SKAO. Homogeneous as well\nas inhomogeneous reionization has been considered. In particular the latter in\ncombination with SKA1-mid shows promising signal-over-noise ratios.\n", "  The Dark Energy Spectroscopic Instrument (DESI) completed its five-month\nSurvey Validation in May 2021. Spectra of stellar and extragalactic targets\nfrom Survey Validation constitute the first major data sample from the DESI\nsurvey. This paper describes the public release of those spectra, the catalogs\nof derived properties, and the intermediate data products. In total, the public\nrelease includes good-quality spectral information from 466,447 objects\ntargeted as part of the Milky Way Survey, 428,758 as part of the Bright Galaxy\nSurvey, 227,318 as part of the Luminous Red Galaxy sample, 437,664 as part of\nthe Emission Line Galaxy sample, and 76,079 as part of the Quasar sample. In\naddition, the release includes spectral information from 137,148 objects that\nexpand the scope beyond the primary samples as part of a series of secondary\nprograms. Here, we describe the spectral data, data quality, data products,\nLarge-Scale Structure science catalogs, access to the data, and references that\nprovide relevant background to using these spectra.\n", "  We present the one-dimensional Lyman-$\\alpha$ forest power spectrum\nmeasurement using the first data provided by the Dark Energy Spectroscopic\nInstrument (DESI). The data sample comprises $26,330$ quasar spectra, at\nredshift $z > 2.1$, contained in the DESI Early Data Release and the first two\nmonths of the main survey. We employ a Fast Fourier Transform (FFT) estimator\nand compare the resulting power spectrum to an alternative likelihood-based\nmethod in a companion paper. We investigate methodological and instrumental\ncontaminants associated to the new DESI instrument, applying techniques similar\nto previous Sloan Digital Sky Survey (SDSS) measurements. We use synthetic data\nbased on log-normal approximation to validate and correct our measurement. We\ncompare our resulting power spectrum with previous SDSS and high-resolution\nmeasurements. With relatively small number statistics, we successfully perform\nthe FFT measurement, which is already competitive in terms of the scale range.\nAt the end of the DESI survey, we expect a five times larger Lyman-$\\alpha$\nforest sample than SDSS, providing an unprecedented precise one-dimensional\npower spectrum measurement.\n", "  We present and validate the catalog of Lyman-$\\alpha$ forest fluctuations for\n3D analyses using the Early Data Release (EDR) from the Dark Energy\nSpectroscopic Instrument (DESI) survey. We used 88,511 quasars collected from\nDESI Survey Validation (SV) data and the first two months of the main survey\n(M2). We present several improvements to the method used to extract the\nLyman-$\\alpha$ absorption fluctuations performed in previous analyses from the\nSloan Digital Sky Survey (SDSS). In particular, we modify the weighting scheme\nand show that it can improve the precision of the correlation function\nmeasurement by more than 20%. This catalog can be downloaded from\nhttps://data.desi.lbl.gov/public/edr/vac/edr/lya/fuji/v0.3 and it will be used\nin the near future for the first DESI measurements of the 3D correlations in\nthe Lyman-$\\alpha$ forest.\n", "  We perform SubHalo Abundance Matching (SHAM) studies on UNIT simulations with\n\\{$\\sigma, V_{\\rm ceil}, v_{\\rm smear}$\\}-SHAM and \\{$\\sigma, V_{\\rm\nceil},f_{\\rm sat}$\\}-SHAM. They are designed to reproduce the clustering on\n5--30$\\,\\hmpc$ of Luminous Red Galaxies (LRGs), Emission Line Galaxies (ELGs)\nand Quasi-Stellar Objects (QSOs) at $0.4<z<3.5$ from DESI One Percent Survey.\n$V_{\\rm ceil}$ is the incompleteness of the massive host (sub)haloes and is the\nkey to the generalized SHAM. $v_{\\rm smear}$ models the clustering effect of\nredshift uncertainties, providing measurments consistent with those from repeat\nobservations. A free satellite fraction $f_{\\rm sat}$ is necessary to reproduce\nthe clustering of ELGs. We find ELGs present a more complex galaxy--halo mass\nrelation than LRGs reflected in their weak constraints on $\\sigma$. LRGs, QSOs\nand ELGs show increasing $V_{\\rm ceil}$ values, corresponding to the massive\ngalaxy incompleteness of LRGs, the quenched star formation of ELGs and the\nquenched black hole accretion of QSOs. For LRGs, a Gaussian $v_{\\rm smear}$\npresents a better profile for sub-samples at redshift bins than a Lorentzian\nprofile used for other tracers. The impact of the statistical redshift\nuncertainty on ELG clustering is negligible. The best-fitting satellite\nfraction for DESI ELGs is around 4 per cent, lower than previous estimations\nfor ELGs. The mean halo mass log$_{10}(\\langle M_{\\rm vir}\\rangle)$ in\n$\\Msun{}$ for LRGs, ELGs and QSOs are ${13.16\\pm0.01}$, ${11.90\\pm0.06}$ and\n${12.66\\pm0.45}$ respectively. Our generalized SHAM algorithms facilitate the\nproduction of mult-tracer galaxy mocks for cosmological tests.\n", "  We present the first comprehensive Halo Occupation Distribution (HOD)\nanalysis of the DESI One-Percent survey Luminous Red Galaxy (LRG) and\nQuasi-Stellar Object (QSO) samples. We constrain the HOD of each sample and\ntest possible HOD extensions by fitting the redshift-space galaxy 2-point\ncorrelation functions in 0.15 < r < 32 Mpc/h in a set of fiducial redshift\nbins. We use AbacusSummit cubic boxes at Planck 2018 cosmology as model\ntemplates and forward model galaxy clustering with the AbacusHOD package. We\nachieve good fits with a standard HOD model with velocity bias, and we find no\nevidence for galaxy assembly bias or satellite profile modulation at the\ncurrent level of statistical uncertainty. For LRGs in 0.4 < z < 0.6, we infer a\nsatellite fraction of fsat = 11+-1%, a mean halo mass of log10 Mh =\n13.40+0.02-0.02, and a linear bias of blin = 1.93+0.06-0.04. For LRGs in 0.6 <\nz < 0.8, we find fsat = 14+-1%, log10 Mh = 13.24+0.02-0.02, and blin =\n2.08+0.03-0.03. For QSOs, we infer fsat = 3+8-2%, log10 Mh = 12.65+0.09-0.04,\nand blin = 2.63+0.37-0.26 in redshift range 0.8 < z < 2.1. Using these fits, we\ngenerate a large suite of high-fidelity galaxy mocks. We also study the\nredshift-evolution of the DESI LRG sample from z = 0.4 up to z = 1.1, revealing\nsignificant and interesting trends in mean halo mass, linear bias, and\nsatellite fraction.\n", "  We present results from a set of high-fidelity simulated lightcones for the\nDESI One-Percent Survey, created from the Uchuu simulation. This 8 (Gpc/h)^3\nN-body simulation comprises 2.1 trillion particles and provides high-resolution\ndark matter (sub)haloes in the framework of the Planck base-LCDM cosmology.\nEmploying the subhalo abundance matching (SHAM) technique, we populate the\nUchuu (sub)haloes with all four DESI tracers (BGS, LRG, ELG and QSO) to z =\n2.1. Our method accounts for redshift evolution as well as the clustering\ndependence on luminosity and stellar mass. The two-point clustering statistics\nof the DESI One-Percent Survey align reasonably well with our predictions from\nUchuu across scales ranging from 0.1 Mpc/h to 100 Mpc/h. Some discrepancies\narise due to cosmic variance, incompleteness in the massive end of the stellar\nmass function, and a simplified galaxy-halo connection model. We find that the\nUchuu BGS and LRG samples are adequately described using the standard\n5-parameter halo occupation distribution model, while the ELGs and QSOs show\nagreement with an adopted Gaussian distribution for central halos with a power\nlaw for satellites. We observe a fair agreement in the large-scale bias\nmeasurements between data and mock samples, although the data exhibits smaller\nbias values, likely due to cosmic variance. The bias dependence on absolute\nmagnitude, stellar mass and redshift aligns with that of previous surveys.\nThese results improve simulated lightcone construction from cosmological models\nand enhance our understanding of the galaxy-halo connection, with pivotal\ninsights from the first DESI data for the success of the final survey.\n", "  The galactic component in clusters is commonly thought to be generally\nnonrotating and in a dynamical state different from that of a collisionally\nrelaxed system. In practice, a test of such a picture is often not available.\nWe consider the member galaxies of two clusters, Abell S1063 and MACS\nJ1206.2$-$0847, and study the possible presence of mean rotation and some\nproperties of their distribution in phase space. We look for empirical evidence\nof factors normally found in collisionally relaxed systems and others\ncharacteristic of violently-relaxed collisionless systems. Starting from the\nCLASH-VLT data, we obtain positions, stellar masses, and individual\nline-of-sight velocities for a large number of galaxies (N_{AS1063}=1200 and\nN_{M1206}=650) extending out to 1.6 (Abell) and 2.5 (MACS) times the radius\nr_{200}. We study the spatial distribution of the galaxy velocities and the\nproperties of the available galaxy sets when divided in stellar mass bins. To\ntest the presence of velocity dispersion anisotropy we compare the results\nbased on the Jeans equations with those obtained by assuming a specific form of\nthe galaxy distribution function incorporating the picture of violent\nrelaxation, where the total gravitational potential is imposed as set by the\navailable gravitational lensing observations. We find evidence of systematic\nrotation in both clusters, with significant rotation in each core (within 0.5'\nfrom the center) and no signatures of rotation at large radii. While no signs\nare found of energy equipartition, there is a clear indication of (stellar)\nmass segregation. Velocity dispersion anisotropy is present and qualitatively\nsimilar to that found in violently relaxed collisionless systems; this last\nconclusion is strengthened by the overall success in matching the observations\nwith the predictions of the physically justified distribution function.\n", "  We investigate the impact of a non-minimal coupling of the scalar field with\ngravity in inflationary models, where a small coupling is allowed. As a\nconcrete example, we consider the Witten-O'Raifeartaigh model, where, in line\nwith other models, the presence of a coupling strength $\\xi$ can recover\nconcordance of the inflationary parameters with cosmic microwave background\n(CMB) constraints, provided by the Planck collaboration. We go beyond the\nslow-roll regime and investigate the impact in the description of CMB\nanisotropies by performing a statistical analysis of the model with the most\nrecent Planck + Baryon Acoustic Oscillations (BAO) data to seek for any\nindication of a non-zero coupling by data within the model. We find that not\nonly the presence of a non-minimal coupling is seen, but the model has a slight\nstatistical preference when compared with the standard $\\Lambda$CDM one. We\nalso discuss the results on the minimally-coupled model, which in general,\nfavours the simple setting where the associated mass scale is equal to the\nreduced Planck mass $M_p$ while being, in general, disfavored concerning the\nstandard model.\n", "  The presence of axion strings in the Universe after recombination can leave\nan imprint on the polarization pattern of the cosmic microwave background\nradiation through the phenomenon of axion-string-induced birefringence via the\nhyperlight axion-like particle's coupling to electromagnetism. Across the sky,\nthe polarization rotation angle is expected to display a patchwork of uniform\nregions with sharp boundaries that arise as the `shadow' of axion string loops.\nThe statistics of such a birefringence sky map are therefore necessarily\nnon-Gaussian. In this article we quantify the non-Gaussianity in\naxion-string-induced birefringence using two techniques, kurtosis and\nbispectrum, which correspond to $4$- and $3$-point correlation functions. If\nanisotropic birefringence were detected in the future, a measurement of its\nnon-Gaussian properties would facilitate a discrimination across different new\nphysics sources generally, and in the context of axion strings specifically, it\nwould help to break degeneracies between the axion-photon coupling and\nproperties of the string network.\n", "  When the time difference quotients, or variational slopes, of quasar light\ncurves are plotted against their absolute magnitudes, there is a tight positive\ncorrelation of $\\sim 0.16$ dex in the variational slope direction or $\\sim 0.5$\ndex in the absolute magnitude direction. This finding resulted in suggestions\nthat a variational slope -- luminosity relation could be used as a distance\nindicator. However, I show that this relation can be explained almost entirely\nfrom self-correlation with luminosity. After properly accounting for the\nself-correlation component, the relation has a true scatter of $\\sim 1.5$ dex\nin luminosity, consistent with established correlations for quasar variability\namplitudes. Given this large scatter, correlation with variational slope or\nvariability amplitude and luminosity is not by itself a suitable distance\nindicator for quasars.\n", "  The scale-dependent bias of galaxy density contrasts is an important signal\nto be extracted in constraining local primordial non-Gaussianity ($f_{\\rm\nNL}^{\\text{local}}$) from observations of large-scale structure. Constraints so\nobtained rely on the assumption that horizon-scale features in the galaxy power\nspectrum are exclusively due to primordial physical mechanisms. Yet,\npost-inflationary effects can induce modulations to the galaxy number density\nthat appear as horizon-scale, scale-dependent bias. We investigate the effect\nof two such sources of scale-dependent bias - the free-streaming of light\nrelics and fluctuations in the background of ionising radiation - on precision\nmeasurements of local primordial non-Gaussianity $f_{\\rm NL}^{\\text{local}}$\nfrom galaxy power spectrum measurements. Using the SPHEREx survey as a test\ncase survey reaching $\\sigma(f_{\\rm NL}^{\\rm local}) \\lesssim 1$, we show that\nignoring the scale-dependent bias induced by free-streaming particles can\nnegatively bias the inferred value of $f_{\\rm NL}^{\\rm local}$ by $\\sim\n0.1-0.3\\sigma$. Ignoring the effect of ionising radiation fluctuations can\nnegatively bias the inferred value of $f_{\\rm NL}^{\\rm local}$ by $ \\sim\n1\\sigma$. The range of biases depends on the source populations and the ranges\nof scales used in the analysis, as well as the value of the neutrino mass and\nthe modelling of the impact of ionising radiation. If these sources of\nscale-dependent bias are included in the analysis, forecasts for $f_{\\rm\nNL}^{\\rm local}$ are unbiased but degraded.\n", "  Accuracy in the topology and statistics of a simulated Epoch of Reionization\n(EoR) are vital to draw connections between observations and physical\nprocesses. While full radiative transfer models produce the most accurate\nreionization models, they are highly computationally expensive, and are\ninfeasible for the largest cosmological simulations. Instead, large simulations\noften include EoR models that are pre-computed via the initial density field,\nor post-processed where feedback effects are ignored. We introduce Astrid-ES, a\nresimulation of the Astrid epoch of reionisation $20 > z > 5.5$ which includes\nan on-the-fly excursion-set reionization algorithm. Astrid-ES produces more\naccurate reionization histories without significantly impacting the\ncomputational time. This model directly utilises the star particles produced in\nthe simulation to calculate the EoR history and includes a UV background which\nheats the gas particles after their reionization. We contrast the reionization\ntopology and statistics in Astrid-ES with the previously employed parametric\nreionisation model, finding that in Astrid-ES, ionised regions are more\ncorrelated with galaxies, and the 21cm power-spectrum shows an increase in\nlarge scale power. We calculate the relation between the size of HII regions\nand the UV luminosity of the brightest galaxy within them. Prior to the overlap\nphase, we find a power-law fit of $\\mathrm{log} (R) = -0.314 M_\\mathrm{UV} -\n2.550 \\mathrm{log}(1+z) + 7.408$ with a standard deviation $\\sigma_R < 0.15\n\\mathrm{dex}$ across all mass bins. We also examine the properties of halos\nthroughout reionization, finding that while the properties of halos in the\nsimulation are correlated with the redshift of reionisation, they are not\ngreatly affected by reionisation itself.\n", "  The Cosmological Recombination Radiation (CRR) is one of the guaranteed\n$\\Lambda$CDM Spectral Distortion (SD) signals. Even if very small in amplitude,\nit provides a direct probe of the three recombination eras, opening the path\nfor testing one of the key pillars in our cosmological interpretation of the\nmeasured CMB anisotropies. Here we develop a new emulator, CRRfast, to quickly\nand accurately represent the CRR for a wide range of cosmologies, using the\nstate-of-the-art CosmoSpec code as a reference. CRRfast has been made publicly\navailable both as stand-alone code and as part of CLASS, thereby completing the\nset of $\\Lambda$CDM sources of SDs that can be modeled with CLASS. With this\nnewly-developed pipeline we investigate the full constraining power of SDs\nwithin $\\Lambda$CDM and highlight possible future applications to experimental\ndesign optimization. Furthermore, we show that the inhomogeneous evolution of\nthe recombination process imprints second-order contributions to the CRR\nspectrum, leading to a broadening and shifting of the CRR features. These\nsecond-order terms are naturally captured by the emulator and allow us to\nevaluate the $\\Lambda$CDM contributions to the average CRR as well as to\nillustrate the effect of perturbed recombination due to Primordial Magnetic\nFields (PMFs). As it turns out, while the $\\Lambda$CDM variance effects can be\nneglected, they could be significantly enhanced in the beyond-$\\Lambda$CDM\nmodels. In particular in the case of PMFs we demonstrate that through these\nnon-linear terms the parameter space relevant to the Hubble tension could be\ntested with future CMB spectrometers.\n", "  We consider the polarized Sunyaev-Zel'dovich (pSZ) effect for a tomographic\nprobe of cosmic birefringence, including all relevant terms of the pSZ effect\nin the cosmic microwave background (CMB) observables, some of which were\nignored in the previous works. The pSZ effect produces late-time polarization\nsignals from the scattering of the local temperature quadrupole seen by an\nelectron. We forecast the expected constraints on cosmic birefringence at the\nlate time of the universe with the pSZ effect. We find that the birefringence\nangles at $2\\lesssim z\\lesssim 5$ are constrained at a subdegree level by the\ncross-correlations between CMB $E$- and $B$-modes or between CMB $B$-modes and\nremote quadrupole $E$-modes using data from LiteBIRD, CMB-S4, and LSST. In\nparticular, the cross-correlation between large-scale CMB $B$-modes and\nremote-quadrupole $E$-modes has a much smaller bias from the Galactic\nforegrounds and is useful to cross-check the results from the $EB$ power\nspectrum.\n", "  We constrain the growth index $\\gamma$ by performing a full-shape analysis of\nthe power spectrum multipoles measured from the BOSS DR12 data. We adopt a\ntheoretical model based on the Effective Field theory of the Large Scale\nStructure (EFTofLSS) and focus on two different cosmologies: $\\gamma$CDM and\n$\\gamma \\nu$CDM, where we also vary the total neutrino mass. We explore\ndifferent choices for the priors on the primordial amplitude $A_s$ and spectral\nindex $n_s$, finding that informative priors are necessary to alleviate\ndegeneracies between the parameters and avoid strong projection effects in the\nposterior distributions. Our tightest constraints are obtained with 3$\\sigma$\nPlanck priors on $A_s$ and $n_s$: we obtain $\\gamma = 0.647 \\pm 0.085$ for\n$\\gamma$CDM and $\\gamma = 0.612^{+0.075}_{-0.090}$, $M_\\nu < 0.30$ for $\\gamma\n\\nu$CDM at 68\\% c.l., in both cases $\\sim 1\\sigma$ consistent with the\n$\\Lambda$CDM prediction $\\gamma \\simeq 0.55$. Additionally, we produce\nforecasts for a Stage-IV spectroscopic galaxy survey, focusing on a DESI-like\nsample. We fit synthetic data-vectors for three different galaxy samples\ngenerated at three different redshift bins, both individually and jointly.\nFocusing on the constraining power of the Large Scale Structure alone, we find\nthat forthcoming data can give an improvement of up to $\\sim 85\\%$ in the\nmeasurement of $\\gamma$ with respect to the BOSS dataset when no CMB priors are\nimposed. On the other hand, we find the neutrino mass constraints to be only\nmarginally better than the current ones, with future data able to put an upper\nlimit of $M_\\nu < 0.27~{\\rm eV}$. This result can be improved with the\ninclusion of Planck priors on the primordial parameters, which yield $M_\\nu <\n0.18~{\\rm eV}$.\n", "  Isocurvature perturbations with a blue power spectrum are one of the natural\ntargets for the future large scale structure observations which are probing\nshorter length scales with greater accuracy. We present a Fisher forecast for\nthe Euclid and MegaMapper (MM) experiments in their ability to detect blue\nisocurvature perturbations. We construct the theoretical predictions in the\nEFTofLSS and bias expansion formalisms at quartic order in overdensities which\nallows us to compute the power spectrum at one loop order and bispectrum at\ntree level and further include theoretical error at the next to leading order\nfor the covariance determination. We find that Euclid is expected to provide at\nleast a factor of few improvement on the isocurvature spectral amplitude\ncompared to the existing Planck constraints for large spectral indices while MM\nis expected to provide about 1 to 1.5 order of magnitude im provement for a\nbroad range of spectral indices. We find features that are specific to the blue\nisocurvature scenario including the leading parametric degeneracy being with\nthe Laplacian bias and a UV sensitive bare sound speed parameter.\n", "  The oscillating pressure of the ultralight scalar dark matter (DM) can induce\nthe oscillation of the local gravitational potential. Similar to the\ntime-dependent frequency shift for the pulse signals of pulsars, the\noscillation of the local gravitational potential can induce a time-dependent\nfrequency shift (or frequency modulation) for quasi-monochromatic gravitational\nwave (GW) signals from galactic white dwarf (WD) binaries. To make this effects\ndetectable, we suppose that some galactic WD binaries are located in the DM\nclumps/subhalos where the energy density of DM is about eight orders of\nmagnitude higher than that at the position of the Earth. Turn to the fisher\ninformation matrix, we find that the amplified GW frequency modulation induced\nby the ultralight scalar DM with mass\n$m=1.67\\times10^{-23}-4.31\\times10^{-23}[{\\rm eV}/c^2]$ can be detected by\nLISA.\n", "  As it is suggested in \\cite{Sakstein:2019fmf, CarrilloGonzalez:2020oac}, one\ncan dynamically introduce the coincidence time-scale for EDE in the framework\nof a particular mass-varying-neutrino-model as a time at which neutrinos\nconstituting the cosmic neutrino background enter the non-relativistic regime.\nThe model does not predict, however, the right amount of EDE density because of\nsmallness of neutrino masses. One may hope to adjust the parameters in such a\nway as to ensure that the two-loop contributions are kept small while at the\nsame time the effective mass for scalar field that enters the expression of\nzero-point-energy (for the field trapped in the minimum of effective potential)\nis sufficient for explaining the needed amount of EDE. Unfortunately, the\nanswer is not in the affirmative.\n", "  We present refined cosmological parameter constraints derived from a cosmic\nshear analysis of the fourth data release of the Kilo-Degree Survey\n(KiDS-1000). Our main improvements include enhanced galaxy shape measurements\nmade possible by an updated version of the lensfit code and improved shear\ncalibration achieved with a newly developed suite of multi-band image\nsimulations. Additionally, we incorporated recent advancements in cosmological\ninference from the joint Dark Energy Survey Year 3 and KiDS-1000 cosmic shear\nanalysis. Assuming a spatially flat standard cosmological model, we constrain\n$S_8\\equiv\\sigma_8(\\Omega_{\\rm m}/0.3)^{0.5} =\n0.776_{-0.027-0.003}^{+0.029+0.002}$, where the second set of uncertainties\naccounts for the systematic uncertainties within the shear calibration. These\nsystematic uncertainties stem from minor deviations from realism in the image\nsimulations and the sensitivity of the shear measurement algorithm to the\nmorphology of the galaxy sample. Despite these changes, our results align with\nprevious KiDS studies and other weak lensing surveys, and we find a\n${\\sim}2.3\\sigma$ level of tension with the Planck cosmic microwave background\nconstraints on $S_8$.\n", "  For over a decade there have been contradictory claims in the literature\nabout whether the local bulk flow motion of galaxies is consistent or in\ntension with the $\\Lambda$CDM model. While it has become evident that\nsystematics affect bulk flow measurements, systematics in the estimators have\nnot been widely investigated. In this work, we thoroughly evaluate the\nperformance of four estimator variants, including the Kaiser maximum likelihood\nestimator (MLE) and the minimum variance estimator (MVE). We find that these\nestimators are unbiased, however their precision may be strongly correlated\nwith the survey geometry. Small biases in the estimators can be present leading\nto underestimated bulk flows, which we suspect are due to the presence of\nnon-linear peculiar velocities. The uncertainty assigned to the bulk flows from\nthese estimators is typically underestimated, which leads to an overestimate of\nthe tension with $\\Lambda$CDM. We estimate the bulk flow for the CosmicFlows-4\ndata and use mocks to ensure the uncertainties are appropriately accounted for.\nUsing the MLE we find a bulk flow amplitude of $408\\pm165 \\mathrm{km s}^{-1}$\nat a depth of $49\\, \\mathrm{Mpc} h^{-1}$, in reasonable agreement with\n$\\Lambda$CDM. However using the MVE which can probe greater effective depths,\nwe find an amplitude of $428\\pm108 \\mathrm{km s}^{-1}$ at a depth of $173\\,\n\\mathrm{Mpc} h^{-1}$, in tension with the model, having only a 0.11%\nprobability of obtaining a larger $\\chi^2$. These measurements appear directed\ntowards the Great Attractor region where more data may be needed to resolve\ntensions.\n", "  Perturbations to the cosmic baryon density - and thus to the total-matter\ndensity - can be induced by magnetohydronamic forces if there are primordial\nmagnetic fields. The power spectrum for these density perturbations was first\nprovided in 1996, but without much in the way of detail in the derivation, and\nthere has been confusion in the intervening years about this calculation. In\nthis brief note, we re-derive this power spectrum using modern conventions,\nprovide a simplified result, and identify some of the discrepancies in the\nliterature.\n", "  We present a proof-of-principle determination of the Hubble parameter $H(z)$\nfrom photometric data, obtaining a determination at an effective redshift of\n$z=0.75$ ($0.65<z<0.85$) of $H(0.75) =105.0\\pm 7.9(stat)\\pm 7.3(sys)$ km\ns$^{-1}$ Mpc$^{-1}$, with 7.5\\% statistical and 7\\% systematic (10\\% with\nstatistical and systematics combined in quadrature) accuracy. This is obtained\nin a cosmology model-independent fashion, but assuming a linear age-redshift\nrelation in the relevant redshift range, as such, it can be used to constrain\narbitrary cosmologies as long as $H(z)$ can be considered slowly varying over\nredshift. In particular, we have applied a neural network, trained on a\nwell-studied spectroscopic sample of 140 objects, to the {\\tt COSMOS2015}\nsurvey to construct a set of 19 thousand near-passively evolving galaxies and\nbuild an age-redshift relation. The Hubble parameter is given by the derivative\nof the red envelope of the age-redshift relation. This is the first time the\nHubble parameter is determined from photometry at $\\lesssim 10$\\% accuracy.\nAccurate $H(z)$ determinations could help shed light on the Hubble tension;\nthis study shows that photometry, with a reduction of only a factor of two in\nthe uncertainty, could provide a new perspective on the tension.\n", "  Dark matter structures within strong gravitational lens galaxies and along\ntheir line of sight leave a gravitational imprint on the multiple images of\nlensed sources. Strong gravitational lensing provides, therefore, a key test of\ndifferent dark matter models in a way that is independent of the baryonic\ncontent of matter structures on subgalactic scales. In this chapter, we\ndescribe how galaxy-scale strong gravitational lensing observations are\nsensitive to the physical nature of dark matter. We provide a historical\nperspective of the field, and review its current status. We discuss the\nchallenges and advances in terms of data, treatment of systematic errors and\ntheoretical predictions, that will enable one to deliver a stringent and robust\ntest of different dark matter models in the near future. With the advent of the\nnext generation of sky surveys, the number of known strong gravitational lens\nsystems is expected to increase by several orders of magnitude. Coupled with\nhigh-resolution follow-up observations, these data will provide a key\nopportunity to constrain the properties of dark matter with strong\ngravitational lensing.\n", "  Modified theories of gravity encompass a class of $f(R)$-models that seek to\nelucidate the observed late time accelerated expansion of the universe. In this\nstudy, we examine a set of viable $f(R)$ models (Hu-Sawicki: two cases,\nSatrobinsky, Tsujikawa, exponential and arcTanh models) in metric formalism,\nusing recent cosmological data sets: type Ia supernovae data, cosmic\nchronometer observations, baryonic acoustic oscillations data, data from\nH\\textsc{ii} starburst galaxies, and local measurements of the Hubble parameter\n$H_0$. The model parameters are constrained using a Bayesian analysis with the\nMonte Carlo Markov Chain method. We employ statistical tools such as the Akaike\nInformation Criterion, Bayesian Information Criterion, and reduced chi-square\nstatistics to conduct a comparative investigation of these models. We determine\nthe transition redshift, the evolution of total equation-of-state (EoS)\nparameter, and the EoS for the component responsible for current accelerated\nexpansion to characterize the expansion's evolution. Taking into account the\n``Hubble tension,\" we perform the study with and without a Gaussian prior for\n$H_0$ from local measurements. Our findings are as follows: (i) in many cases\nthe $f(R)$ models are strongly favored over the standard $\\Lambda$CDM model,\n(ii) the deviation parameter ($b$) significantly deviates from zero in several\ncases, (iii) the inclusion of local $H_0$ not only increases the fitted value\nof $H_0$ (as expected) but also affects the gap between predictions of $f(R)$\nmodels and the $\\Lambda$CDM model, and (iv) the relevant quantities\ncharacterizing the (accelerated) expansion of the universe obtained in our\nmodels are consistent with those obtained in a model-independent way by others.\nOur investigation and results present a compelling case for pursuing further\nresearch on $f(R)$ models with future observations to come.\n", "  Galaxy cluster masses derived from observations of weak lensing suffer from a\nnumber of biases affecting the accuracy of mass-observable relations calibrated\nfrom such observations. In particular, the choice of the cluster center plays a\nprominent role in biasing inferred masses. In the past, empirical miscentring\ndistributions have been used to address this issue. Using hydro-dynamical\nsimulations, we aim to test the accuracy of weak lensing mass bias predictions\nbased on such miscentring distributions by comparing the results to mass biases\ncomputed directly using intra-cluster medium (ICM)-based centers from the same\nsimulation. We construct models for fitting masses to both centered and\nmiscentered Navarro-Frenk-White profiles of reduced shear, and model the\nresulting distributions of mass bias with normal and log-normal distributions.\nWe find that the standard approach of using miscentring distributions leads to\nan over-estimation of cluster masses at levels of between 2\\% and 6\\% when\ncompared to the analysis in which actual simulated ICM centers are used, even\nwhen the underlying miscentring distributions match in terms of the miscentring\namplitude. We find that neither log-normal nor normal distributions are\ngenerally reliable for approximating the shapes of the mass bias distributions,\nregardless of whether a centered or miscentered radial model is used.\n", "  Synthetic datasets generated from large-volume gravity-only simulations are\nan important tool in the calibration of cosmological analyses. Their creation\noften requires accurate inference of baryonic observables from the dark matter\nfield. We explore the effectiveness of a baryon pasting algorithm in providing\nprecise estimations of three-dimensional gas thermodynamic properties based on\ngravity-only simulations. We use the Borg Cube, a pair of simulations\noriginating from identical initial conditions, with one run evolved as a\ngravity-only simulation, and the other incorporating non-radiative\nhydrodynamics. Matching halos in both simulations enables comparisons of gas\nproperties on an individual halo basis. This comparative analysis allows us to\nfit for the model parameters that yield the closest agreement between the gas\nproperties in both runs. To capture the redshift evolution of these parameters,\nwe perform the analysis at five distinct redshift steps, spanning from $z=0$ to\n$2$. We find that the investigated algorithm, utilizing information solely from\nthe gravity-only simulation, achieves few-percent accuracy in reproducing the\nmedian intracluster gas pressure and density, albeit with a scatter of\napproximately 20%, for cluster-scale objects up to $z=2$. We measure the\nscaling relation between integrated Compton parameter and cluster mass\n($Y_{500c} | M_{500c}$), and find that the imprecision of baryon pasting adds\nless than 5% to the intrinsic scatter measured in the hydrodynamic simulation.\nWe provide best-fitting values and their redshift evolution, and discuss future\ninvestigations that will be undertaken to extend this work.\n", "  In this work we extend our earlier phenomenological model for a gravitational\nphase transition (GPT) and its generalization to early times by letting the\nmodifications in the linearly-perturbed Einstein equations be scale-dependent.\nThese modifications are characterized as deviations of the parameters\n$\\mu(z,k)$ and $\\gamma(z,k)$ from their values in general relativity (GR). The\nscale-dependent amplitudes of modified $\\mu(z,k)$ and $\\gamma(z,k)$ and the\nparameters defining the phase transition, along with the standard cosmological\nparameters, are measured by various data combinations. Out of the perturbation\nparameters, we construct gravity eigenmodes which represent patterns of\nperturbations best detectable by data. We detect no significant deviation from\nGR in these parameters. However, the larger parameter space produced due to the\nnew degrees of freedom allows for the reconciliation of various datasets which\nare in tension in $\\Lambda$CDM. In particular, we find $H_0=71.9\\pm 9.2$ from\nanisotropies of the Cosmic Microwave Background as measured by Planck and\nvarious measurements of the Baryonic Acoustic Oscillations, in agreement with\nlocal Hubble measurements. We also find that the $\\sigma_8$ tension between the\nmeasurements of Dark Energy Survey and Planck is reduced to less than\n$1\\sigma$.\n", "  One of the foundations of the Standard Model of Cosmology is statistical\nisotropy, which can be tested, among other probes, through the study of the\nCosmic Microwave Background (CMB). However, a hemispherical power asymmetry on\nlarge scales has been reported for WMAP and Planck data by different works. The\nstatistical significance is above 3${\\sigma}$ for temperature, suggesting a\ndirectional dependence of the local power spectrum, and thus a feature beyond\nthe ${\\Lambda}$CDM model. With the third release of the Planck data (PR3), a\nnew analysis was performed including the E-mode polarization maps, finding an\nasymmetry at a modest level of significance. In this work, we perform an\nasymmetry analysis in intensity and polarization maps for the latest Planck\nprocessing pipeline (PR4). We obtain similar results to those obtained with\nPR3, with a slightly lower significance (2.8% for the Sevem method) for the\namplitude of the E-mode local variance dipole as well as a significant\nvariability with the considered mask. In addition, a hint of a possible T-E\nalignment between the asymmetry axes is found at the level of $\\sim$ 5%. For\nthe analysis, we have implemented an alternative inpainting approach in order\nto get an accurate reconstruction of the E-modes. More sensitive all-sky CMB\npolarization data, such as those expected from the future LiteBIRD experiment,\nare needed to reach a more robust conclusion on the possible existence of\ndeviations from statistical isotropy in the form of a hemispherical power\nasymmetry.\n", "  Weak gravitational lensing induces flux dependent fluctuations in the\nobserved galaxy number density distribution. This cosmic magnification\n(magnification bias) effect in principle enables lensing reconstruction\nalternative to cosmic shear and CMB lensing. However, the intrinsic galaxy\nclustering, which otherwise overwhelms the signal, has hindered its\napplication. Through a scaling relation found by principal component analysis\nof the galaxy clustering in multi-band photometry space, we design a minimum\nvariance linear estimator to suppress the intrinsic galaxy clustering and to\nreconstruct the lensing convergence map. In combination of the CosmoDC2 galaxy\nmock and the CosmicGrowth simulation, we test this proposal for a LSST-like\ngalaxy survey with $ugrizY$ photometry bands. The scaling relation holds\nexcellently at multipole $\\ell<10^3$, and remains reasonably well to $\\ell\\sim\n3000$. The linear estimator efficiently suppresses the galaxy intrinsic\nclustering, by a factor of $\\sim 10^2$. For galaxies in the photo-z range\n$0.8<z_\\kappa<1.2$, the reconstructed convergence map is cosmic variance\nlimited per $\\ell$ mode at $\\ell<10^2$, and shot noise limited at $\\ell>= 200$.\nIts cross-correlation with cosmic shear of galaxies can achieve $S/N >= 200$.\nWhen the source redshift of cosmic shear galaxies $z_\\gamma<z_\\kappa$, the\nsystematic error is negligible at all investigated scales ($\\ell<3000$). When\n$z_\\gamma\\geq z_\\kappa$, the systematic error caused by the residual intrinsic\ngalaxy clustering becomes non-negligible. We discuss possible mitigation of the\nresidual intrinsic galaxy clustering required for accurate measurement at\n$\\ell>10^3$. This work further demonstrates the potential of lensing\nmeasurement through cosmic magnification to enhance the weak lensing cosmology.\n", "  We implement support for a cosmological parameter estimation algorithm as\nproposed by Racine et al. (2016) in Commander, and quantify its computational\nefficiency and cost. For a semi-realistic simulation similar to Planck LFI 70\nGHz, we find that the computational cost of producing one single sample is\nabout 20 CPU-hours and that the typical Markov chain correlation length is\n$\\sim$100 samples. The net effective cost per independent sample is $\\sim$2 000\nCPU-hours, in comparison with all low-level processing costs of 812 CPU-hours\nfor Planck LFI and WMAP in Cosmoglobe Data Release 1. Thus, although\ntechnically possible to run already in its current state, future work should\naim to reduce the effective cost per independent sample by one order of\nmagnitude to avoid excessive runtimes, for instance through multi-grid\npreconditioners and/or derivative-based Markov chain sampling schemes. This\nwork demonstrates the computational feasibility of true Bayesian cosmological\nparameter estimation with end-to-end error propagation for high-precision CMB\nexperiments without likelihood approximations, but it also highlights the need\nfor additional optimizations before it is ready for full production-level\nanalysis.\n", "  We revisit the evidence for CMB birefringence in the context of a rich\nAxiverse. Using probability density functions (PDFs) for various axion\nparameters, such as the mass and axion decay constant, we construct the PDF for\nthe cosmic birefringence angle and investigate its properties. By relating the\nobserved value of the birefringence angle to the mean or standard deviation of\nthe constructed PDF, we constrain the shape of the input PDFs, providing\ninsights into the statistical distribution of the Axiverse. We focus on three\ndifferent types of axion potentials: cosine, quadratic, and asymptotically\nlinear axion monodromy. Our analysis showcases the potential of cosmic\nbirefringence in constraining the distribution of axion parameters and\nuncovering possible correlations among them. We additionally offer predictions\nfor \"birefringence tomography,\" anticipating future measurements of\nbirefringence from lower multipoles, and show how it can be used to rule out\nsimpler versions of the Axiverse. Our findings contribute to the ongoing\nexploration of the Axiverse and its implications for cosmic birefringence.\n", "  Context: A non-linear relation between quasar monochromatic luminosities at\n2500A and 2 keV holds at all observed redshifts and luminosities, and it has\nbeen used to derive quasar distances and to build a Hubble Diagram of quasars.\nThe choice of the X-ray and UV indicators has so far been somewhat arbitrary,\nand has typically relied on photometric data. Aims: We want to determine the\nX-ray and UV proxies that provide the smallest dispersion of the relation, in\norder to obtain more precise distance estimates, and to confirm the reliability\nof the X-ray to UV relation as a distance indicator. Methods: We performed a\ncomplete UV spectroscopic analysis of a sample of $\\sim$1800 quasars with SDSS\noptical spectra and XMM- Newton X-ray serendipitous observations. In the\nX-rays, we analysed the spectra of all the sample objects at redshift z $>$1.9,\nwhile we relied on photometric measurements at lower redshifts. As done in\nprevious studies, we analysed the relation in small redshift bins, using fluxes\ninstead of luminosities. Results: We show that the monochromatic fluxes at 1\nkeV and 2500A are, respectively, the best X-ray and UV continuum indicators\namong those that are typically available. We also find a tight relation between\nsoft X-ray and Mg ii2800A line fluxes, and a marginal dependence of the X-ray\nto UV relation on the width of the Mg ii line. Conclusions: Our analysis\nsuggests that the physical quantities that are more tightly linked to one\nanother are the soft X-ray flux at $\\sim$1 keV and the ionizing UV flux\nblueward of the Lyman limit. However, the \"usual\" monochromatic fluxes at 2 keV\nand 2500A estimated from photometric data provide an almost as-tight X-ray to\nUV relation, and can be used to derive quasar distances. The Hubble diagram\nobtained using spectroscopic indicators is fully consistent with the one\npresented in previous papers, based on photometric data.\n", "  The local galaxy peculiar velocity field can be reconstructed from the\nsurrounding distribution of large-scale structure and plays an important role\nin calibrating cosmic growth and expansion measurements. In this paper, we\ninvestigate the effect of the stochasticity of these velocity reconstructions\non the statistical and systematic errors in cosmological inferences. By\nintroducing a simple statistical model between the measured and theoretical\nvelocities, whose terms we calibrate from linear theory, we derive the bias in\nthe model velocity. We then use lognormal realisations to explore the potential\nimpact of this bias when using a cosmic flow model to measure the growth rate\nof structure, and to sharpen expansion rate measurements from host galaxies for\ngravitational wave standard sirens with electromagnetic counterparts. Although\nour illustrative study does not contain fully realistic observational effects,\nwe demonstrate that in some scenarios these corrections are significant and\nresult in a measurable improvement in determinations of the Hubble constant\ncompared to standard forecasts.\n", "  The non-linear relationship between the monochromatic X-ray and UV\nluminosities in quasars offers the possibility of using high-z quasars as\nstandard candles for cosmological testing. In this paper, we use a high-quality\ncatalog of 1598 quasars extending to redshift 6, to compare the flat and\nuniformly expanding cosmological model, $R_h$ = ct and $\\Lambda$CDM\ncosmological models which are the most debated. The quasar samples are mainly\nfrom the XMM-Newton and the Sloan Digital Sky Survey (SDSS). The final result\nis that the Akaike Information Criterion favors $\\Lambda$CDM over $R_h$=ct with\na relative probability of 86.30% versus 13.70%.\n", "  We present a measurement of the cross-correlation between the MagLim galaxies\nselected from the Dark Energy Survey (DES) first three years of observations\n(Y3) and cosmic microwave background (CMB) lensing from the Atacama Cosmology\nTelescope (ACT) Data Release 4 (DR4), reconstructed over $\\sim 436$ sq.deg. of\nthe sky. Our galaxy sample, which covers $\\sim 4143$ sq.deg., is divided into\nsix redshift bins spanning the redshift range of $0.20<z<1.05$. We adopt a\nblinding procedure until passing all consistency and systematics tests. After\nimposing scale cuts for the cross-power spectrum measurement, we reject the\nnull hypothesis of no correlation at 9.1\\sigma. We constrain cosmological\nparameters from a joint analysis of galaxy and CMB lensing-galaxy power spectra\nconsidering a flat \\LCDM model, marginalized over 23 astrophysical and\nsystematic nuisance parameters. We find the clustering amplitude $S_8\\equiv\n\\sigma_8 (\\Omega_m/0.3)^{0.5} = 0.75^{+0.04}_{-0.05}$. In addition, we\nconstrain the linear growth of cosmic structure as a function of redshift. Our\nresults are consistent with recent DES Y3 analyses and suggest a preference for\na lower $S_8$ compared to results from measurements of CMB anisotropies by the\nPlanck satellite, although at a mild level ($< 2 \\sigma$) of statistical\nsignificance.\n", "  We develop a first-principles formalism to compute the distortion to the\nrelic neutrino density field caused by the peculiar motions of large-scale\nstructures. This distortion slows halos down due to dynamical friction, causes\na local anisotropy in the neutrino-CDM cross-correlation, and reduces the\nglobal cross-correlation between neutrinos and CDM. The local anisotropy in the\nneutrino-CDM cross-spectrum is imprinted in the three point cross-correlations\nof matter and galaxies, or the bispectrum in Fourier space, producing a signal\npeaking at squeezed triangle configurations. This bispectrum signature of\nneutrino masses is not limited by cosmic variance or potential inaccuracies in\nthe modeling of complicated nonlinear and galaxy formation physics, and it is\nnot degenerate with the optical depth to reionization. We show that future\nsurveys have the potential to detect the distortion bispectrum.\n", "  Field-level inference is emerging as a promising technique for optimally\nextracting information from cosmological datasets. Indeed, previous analyses\nhave shown field-based inference produces tighter parameter constraints than\npower spectrum analyses. However, estimates of the detailed quantitative gain\nin constraining power differ. Here, we demonstrate the gain in constraining\npower depends on the parameter space being constrained. As a specific example,\nwe find that field-based analysis of an LSST Y1-like mock data set only\nmarginally improves constraints relative to a 2-point function analysis in\n$\\Lambda$CDM, yet it more than doubles the constraining power of the data in\nthe context of $w$CDM models. This effect reconciles some, but not all, of the\ndiscrepant results found in the literature. Our results demonstrate the\nimportance of using a full systematics model when quantifying the information\ngain for realistic field-level analyses of future data sets.\n", "  Primordial black holes may arise through ultra slow-roll inflation. In this\nwork we study a toy model of ultra slow-roll inflation with a shallow dip. The\nultra slow-roll stage enhances the curvature perturbations and thus the\nprimordial scalar power spectrum. We analyze the features of the power spectrum\nnumerically and analytically, and then give a rough estimate of the lower and\nupper bound of the enhancement. These large perturbations also produce second\norder gravitational waves, which are in the scope of future observations.\n", "  During the Epoch of reionisation, the intergalactic medium is reionised by\nthe UV radiation from the first generation of stars and galaxies. One tracer of\nthe process is the 21 cm line of hydrogen that will be observed by the Square\nKilometre Array (SKA) at low frequencies, thus imaging the distribution of\nionised and neutral regions and their evolution. To prepare for these upcoming\nobservations, we investigate a deep learning method to predict from 21 cm maps\nthe reionisation time field (treion(r)), i.e. the time at which each location\nhas been reionised. treion(r) encodes the propagation of ionisation fronts in a\nsingle field, gives access to times of local reionisation or to the extent of\nthe radiative reach of early sources. Moreover it gives access to the time\nevolution of ionisation on the plane of sky, when such evolution is usually\nprobed along the line-of-sight direction. We trained a convolutional neural\nnetwork (CNN) using simulated 21 cm maps and reionisation times fields produced\nby the simulation code 21cmFAST . We also investigate the performance of the\nCNN when adding instrumental effects. Globally, we find that without\ninstrumental effects the 21 cm maps can be used to reconstruct the associated\nreionisation times field in a satisfying manner: the quality of the\nreconstruction is dependent on the redshift at which the 21 cm observation is\nbeing made and in general it is found that small scale (<10cMpc/h) features are\nsmoothed in the reconstructed field, while larger scale features are well\nrecovered. When instrumental effects are included, the scale dependance of\nreconstruction is even further pronounced, with significant smoothing on small\nand intermediate scales.\n", "  Observations of the millimeter sky contain valuable information on a number\nof signals, including the blackbody cosmic microwave background (CMB), Galactic\nemissions, and the Compton-$y$ distortion due to the thermal Sunyaev-Zel'dovich\n(tSZ) effect. Extracting new insight into cosmological and astrophysical\nquestions often requires combining multi-wavelength observations to spectrally\nisolate one component. In this work, we present a new arcminute-resolution\nCompton-$y$ map, which traces out the line-of-sight-integrated electron\npressure, as well as maps of the CMB in intensity and E-mode polarization,\nacross a third of the sky (around 13,000 sq.~deg.). We produce these through a\njoint analysis of data from the Atacama Cosmology Telescope (ACT) Data Release\n4 and 6 at frequencies of roughly 93, 148, and 225 GHz, together with data from\nthe \\textit{Planck} satellite at frequencies between 30 GHz and 545 GHz. We\npresent detailed verification of an internal linear combination pipeline\nimplemented in a needlet frame that allows us to efficiently suppress Galactic\ncontamination and account for spatial variations in the ACT instrument noise.\nThese maps provide a significant advance, in noise levels and resolution, over\nthe existing \\textit{Planck} component-separated maps and will enable a host of\nscience goals including studies of cluster and galaxy astrophysics, inferences\nof the cosmic velocity field, primordial non-Gaussianity searches, and\ngravitational lensing reconstruction of the CMB.\n", "  We study the cosmological effects of a Galileon term in scalar-tensor\ntheories of gravity. The subset of scalar-tensor theories considered are\ncharacterized by a non-minimal coupling $F(\\sigma) R$, a kinetic term with\narbitrary sign $Z (\\partial \\sigma)^2$ with $Z = \\pm 1$, a potential\n$V(\\sigma)$, and a Galileon term $G_3(\\sigma, (\\partial \\sigma)^2) \\square\n\\sigma$. In addition to the modified dynamics, the Galileon term provides a\nscreening mechanism to potentially reconcile the models with General Relativity\npredictions inside a Vainshtein radius. Thanks to the Galileon term, the\nstability conditions, namely ghost and Laplacian instabilities, in the branch\nwith a negative kinetic term ($Z = -1$) are fulfilled for a large volume of the\nparameter space. Solving numerically the background evolution and linear\nperturbations, we derive the constraints on the cosmological parameters in\npresence of a Galileon term for different combination of the cosmic microwave\nbackground (CMB) data from Planck, baryon acoustic oscillations (BAO)\nmeasurements from BOSS, and supernovae from the Pantheon compilation. We find\nthat the Galileon term alters the dynamics of all the studied cases. For a\nstandard kinetic term ($Z = 1$), we find that Planck data and a compilation of\nBAO data constrain the Galileon term to small values that allow screening very\ninefficiently. For a negative kinetic term ($Z = -1$), a Galileon term and a\nnon-zero potential lead to an efficient screening in a physically viable regime\nof the theory, with a value for the Hubble constant today which alleviates the\ntension between its CMB and local determinations. For a vanishing potential,\nthe case with $Z=-1$ and the Galileon term driving the late acceleration of the\nUniverse is ruled out by Planck data.\n", "  The Surface Brightness Fluctuation (SBF) method is a powerful tool for\ndetermining distances to early-type galaxies. The method measures the intrinsic\nvariance in a galaxy's surface brightness distribution to determine its\ndistance with an accuracy of about 5%. Here, we discuss the mathematical\nformalism behind the SBF technique, its calibration, and the practicalities of\nhow measurements are performed. We review the various sources of uncertainties\nthat affect the method and discuss how they can be minimized or controlled\nthrough careful observations and data analysis. The SBF technique has already\nbeen successfully applied to a large number of galaxies and used for deriving\naccurate constraints on the Hubble-Lema\\^itre constant $H_0$. An approved JWST\nprogram will greatly reduce the systematic uncertainties by establishing a firm\nzero-point calibration using tip of the red giant branch (TRGB) distances. We\nsummarize the existing results and discuss the excellent potential of the SBF\nmethod for improving the current constraints on $H_0$.\n", "  Upcoming imaging surveys will allow for high signal-to-noise measurements of\ngalaxy clustering at small scales. In this work, we present the results of the\nLSST bias challenge, the goal of which is to compare the performance of\ndifferent nonlinear galaxy bias models in the context of LSST Y10 data.\nSpecifically, we compare two perturbative approaches, Lagrangian perturbation\ntheory (LPT) and Eulerian PT (EPT) to two variants of Hybrid Effective Field\nTheory (HEFT), with our fiducial implementation of these models including terms\nup to second order in the bias expansion as well as nonlocal bias and\ndeviations from Poissonian stochasticity. We consider different simulated\ngalaxy samples and test the performance of the bias models in a tomographic\njoint analysis of LSST-Y10-like galaxy clustering, galaxy-galaxy-lensing and\ncosmic shear. We find both HEFT methods as well as LPT and EPT combined with\nnon-perturbative predictions for the matter power spectrum to yield unbiased\nconstraints on cosmological parameters up to at least a maximal scale of\n$k_{\\mathrm{max}}=0.4 \\; \\mathrm{Mpc}^{-1}$ for all samples considered, even in\nthe presence of assembly bias. While we find that we can reduce the complexity\nof the bias model for HEFT without compromising fit accuracy, this is not\ngenerally the case for the perturbative models. We find significant detections\nof non-Poissonian stochasticity in all cases considered, and our analysis shows\nevidence that small-scale galaxy clustering predominantly improves constraints\non galaxy bias rather than cosmological parameters. These results therefore\nsuggest that the systematic uncertainties associated with current nonlinear\nbias models are likely to be subdominant compared to other sources of error for\ntomographic analyses of upcoming photometric surveys, which bodes well for\nfuture galaxy clustering analyses using these high signal-to-noise data.\n[abridged]\n", "  Recent research has emphasized the benefits of accurately reconstructing the\ninitial Lagrangian positions of biased tracers from their positions at a later\ntime, to gain cosmological information. A weighted semi-discrete optimal\ntransport algorithm can achieve the required accuracy, provided the late-time\npositions are known, with minimal information about the background cosmology.\nThe algorithm's performance relies on knowing the masses of the biased tracers,\nand depends on how one models the distribution of the remaining mass that is\nnot associated with these tracers. We demonstrate that simple models of the\nremaining mass result in accurate retrieval of the initial Lagrangian\npositions, which we quantify using pair statistics and the void probability\nfunction. This is true even if the input positions are affected by\nredshift-space distortions. The most sophisticated models assume that the\nmasses of the tracers, and the amount and clustering of the missing mass are\nknown; we show that the method is robust to realistic errors in the masses of\nthe tracers and remains so as the model for the missing mass becomes\nincreasingly crude.\n", "  The HST treasury program BUFFALO provides extended wide-field imaging of the\nsix Hubble Frontier Fields galaxy clusters. Here we present the combined strong\nand weak-lensing analysis of Abell 370, a massive cluster at z=0.375. From the\nreconstructed total projected mass distribution in the 6arcmin x 6arcmin\nBUFFALO field-of-view, we obtain the distribution of massive substructures\noutside the cluster core and report the presence of a total of seven\ncandidates, each with mass $\\sim 5 \\times 10^{13}M_{\\odot}$. Combining the\ntotal mass distribution derived from lensing with multi-wavelength data, we\nevaluate the physical significance of each candidate substructure, and conclude\nthat 5 out of the 7 substructure candidates seem reliable, and that the mass\ndistribution in Abell 370 is extended along the North-West and South-East\ndirections. While this finding is in general agreement with previous studies,\nour detailed spatial reconstruction provides new insights into the complex mass\ndistribution at large cluster-centric radius. We explore the impact of the\nextended mass reconstruction on the model of the cluster core and in\nparticular, we attempt to physically explain the presence of an important\nexternal shear component, necessary to obtain a low root-mean-square separation\nbetween the model-predicted and observed positions of the multiple images in\nthe cluster core. The substructures can only account for up to half the\namplitude of the external shear, suggesting that more effort is needed to fully\nreplace it by more physically motivated mass components. We provide public\naccess to all the lensing data used as well as the different lens models.\n", "  The absorption features in spectra of high-redshift background radio sources,\ncaused by hyperfine structure lines of hydrogen atoms in the intervening\nstructures, are known collectively as the 21-cm forest. They provide a unique\nprobe of small-scale structures during the epoch of reionization, and can be\nused to constrain the properties of the dark matter (DM) thought to govern\nsmall-scale structure formation. However, the signals are easily suppressed by\nheating processes that are degenerate with a warm DM model. Here we propose a\nprobe of both the DM particle mass and the heating history of the Universe,\nusing the one-dimensional power spectrum of the 21-cm forest. The\none-dimensional power spectrum measurement not only breaks the DM model\ndegeneracy but also increases the sensitivity, making the probe actually\nfeasible. Making 21-cm forest observations with the upcoming Square Kilometre\nArray has the potential to simultaneously determine both the DM particle mass\nand the heating level in the early Universe, shedding light on the nature of DM\nand the first galaxies.\n", "  Recent observations from weak gravitational lensing (WL) surveys indicate a\nsmoother Universe compared to the predictions of the Cosmic Microwave\nBackground (CMB). This inconsistency is commonly referred to as the $\\sigma_8$\ntension or $S_8$ tension, where $\\sigma_8$ represents the present\nroot-mean-square matter fluctuation averaged over a sphere of radius $8 h^{-1}\n\\mathrm{Mpc}$, and $S_8 \\equiv \\sigma_8\\sqrt{\\Omega_m/0.3}$. In this article,\nwe investigate a kind of general Dirac-Born-Infeld (DBI) Lagrangian referred to\nas \\textit{surface-type DBI} (sDBI) model. We find that up to the linear order,\nthe constraints on the sDBI model with high-redshift probe (CMB) and\nlow-redshift probes (WL and Galaxy Clustering, GC) yield $S_8=\n0.7448_{-0.21}^{+0.031}$ and $0.7426_{-0.085}^{+0.054}$, respectively.\nRemarkably, these values not only demonstrate self-consistency but also align\nwith the values obtained from the majority of low-redshift probes. Furthermore,\nwe present a discussion on exploring the non-linear effects of this model,\nwhich holds the potential to address additional challenges associated with Cold\nDark Matter (CDM) on small scales.\n", "  [abridged] Recently, in Benetti et al. (Astrophys. J. 2023, 949, 65), we\nsuggested that the dark matter (DM) component in galaxies may originate\nfractional gravity. In such a framework, the DM component exists, but the\ngravitational potential associated to its density distribution is determined by\na modified Poisson equation including fractional derivatives, which are meant\nto describe nonlocal effects. In Benetti et al., we showed that fractional\ngravity worked very well for reproducing the kinematics of disk-dominated\ngalaxies, especially dwarfs; there is also preliminary evidence that the\nstrength of fractional effects tends to weaken toward more massive systems.\nHere, we aim to test fractional gravity in galaxy clusters, with a twofold aim:\n(i) perform an independent sanity check that it can accurately describe such\nlarge and massive structures; (ii) derive a clear-cut trend for its strength in\nsystems with different DM masses. To this purpose, we forward model the density\nand pressure distributions of the intracluster medium (ICM), working out the\nhydrostatic equilibrium equation in fractional gravity. Then, we perform a\nBayesian analysis of the X-COP galaxy cluster sample and infer constraints on\nthe fractional gravity parameters, for individual clusters as well as stacked\nclusters. We find that fractional gravity performs remarkably well in modeling\nthe ICM profiles for the X-COP sample. We also confirm the weakening of the\nfractional gravity effects toward more massive systems and derive the overall\nscaling of the fractional gravity parameters from dwarf galaxies to massive\nclusters, spanning six orders of magnitude in DM mass. Such an overall trend\nimplies that fractional gravity can substantially alleviate the small-scale\nissues of the standard DM paradigm, while remaining successful on large\ncosmological scales.\n", "  We present a numerical analysis of the cosmological evolution of scalar field\ndark matter (SFDM) in the Boltzmann code $\\texttt{CLASS}$, based on a dynamical\nsystem analysis of previous works. We show a detailed study of the evolution of\nthe different dynamical variables, and in particular of the energy density and\nits corresponding linear perturbations. The numerical results are in good\nagreement with those of the original SFDM equations of motion, and have better\naccuracy than other approaches. In addition, we calculate the temperature and\nmatter power spectra and discuss the reliability of their numerical results. We\nalso give simple examples in which we can put constraints on the field mass\nusing recent likelihoods incorporated in the Monte Carlo Markov Chain sampler\n$\\texttt{MontePython}$.\n", "  Time delays from strong gravitational lensing provide a one-step absolute\ndistance measurement. Thus, they measure $H_0$ independently of all other\nprobes. We first review the foundations and history of time-delay cosmography.\nThen, we illustrate the current state of the art by means of two recent case\nstudies that have been real breakthroughs: i) the quadruply imaged quasar\nlensed by a galaxy-scale deflector RXJ1131$-$1231, for which spatially resolved\nstellar kinematics is available; ii) the multiply imaged supernova \"Refsdal\",\nthe first with measured time delays, lensed by cluster MACS1149.5$+$2223. We\nconclude by discussing the exciting future prospects of time-delay cosmography\nin the coming decade.\n", "  Self-interacting dark matter (SIDM) has been proposed as an alternative to\nthe standard collisionless cold dark matter to explain the diversity of\ngalactic rotation curves and core-cusp problems seen at small scales. Here, we\nestimate the constraints on SIDM for a sample of 11 relaxed galaxy groups with\nX-ray observations from Chandra and XMM-Newton. We fit the dark matter density\ndistribution to the Einasto profile and use the estimated Einasto $\\alpha$\nparameter to constrain the SIDM cross-section, based on the empirical relation\nbetween the two, which was obtained in Eckert et al (2022). We obtain a\nnon-zero central estimate for the cross-section per unit mass ($\\sigma/m$) for\nseven groups, with the most precise estimate obtained for NGC 5044, given by\n$\\sigma/m=0.165 \\pm 0.025~\\rm{cm^2/g}$, for dark matter velocity dispersion of\nabout 300 km/sec. For the remaining four groups, we obtain 95% c.l. upper\nlimits on $\\sigma/m < 0.16-6.61~\\rm{cm^2/g}$ with dark matter velocity\ndispersions between 200-500 km/sec, with the most stringent limit for our\nsample obtained for the group MKW 4, given by $\\sigma/m< 0.16~\\rm{cm^2/g}$ for\ndark matter velocity dispersion of about 350 km/sec.\n", "  Samples of galaxy clusters allow us to better understand the physics at play\nin galaxy formation and to constrain cosmological models once their mass,\nposition (for clustering studies) and redshift are known. In this context,\nlarge optical data sets play a crucial role. We investigate the capabilities of\nthe Javalambre-Physics of the Accelerating Universe Astrophysical Survey\n(J-PAS) in detecting and characterizing galaxy groups and clusters. We analyze\nthe data of the miniJPAS survey, obtained with the JPAS-Pathfinder camera and\ncovering $1$ deg$^2$ centered on the AEGIS field to the same depths and with\nthe same 54 narrow band plus 2 broader band near-UV and near-IR filters\nanticipated for the full J-PAS survey. We use the Adaptive Matched Identifier\nof Clustered Objects (AMICO) to detect and characterize groups and clusters of\ngalaxies down to $S/N=2.5$ in the redshift range $0.05<z<0.8$. We detect 80, 30\nand 11 systems with signal-to-noise ratio larger than 2.5, 3.0 and 3.5,\nrespectively, down to $\\sim 10^{13}\\,M_{\\odot}/h$. We derive mass-proxy scaling\nrelations based on Chandra and XMM-Newton X-ray data for the signal amplitude\nreturned by AMICO, the intrinsic richness and a new proxy that incorporates the\ngalaxies' stellar masses. The latter proxy is made possible thanks to the J-PAS\nfilters and shows a smaller scatter with respect to the richness. We fully\ncharacterize the sample and use AMICO to derive a probabilistic membership\nassociation of galaxies to the detected groups that we test against\nspectroscopy. We further show how the narrow band filters of J-PAS provide a\ngain of up to 100% in signal-to-noise ratio in detection and an uncertainty on\nthe redshift of clusters of only $\\sigma_z=0.0037(1+z)$ placing J-PAS in\nbetween broadband photometric and spectroscopic surveys. The performances of\nAMICO and J-PAS with respect to mass sensitivity, mass-proxies quality\n", "  We consider the screening of the axio-dilaton fields when both the dilaton\nand the axion couple to matter with Yukawa couplings. We analyse the screening\nof the dilaton in the vicinity of a compact object and find that this can only\ntake place when special boundary conditions at infinity are imposed. We study\nthe cosmological dynamics of the axio-dilaton system when coupled to matter\nlinearly and find that the special boundary conditions at infinity, which\nguarantee the screening of compact objects, do not generically emerge from\ncosmology. We analyse the background cosmology and the cosmological\nperturbations at late time in these models and show that the Baryon Acoustic\nOscillations constrain the coupling of the dilaton to matter to be smaller than\nin its natural supergravity realisation. Moreover we find that the Hubble rate\nin the present Universe could deviate from the normalised Planck value,\nalthough by an amount too small to account for the $H_0$ tension, and that the\ngrowth of structure is generically reduced compared to $\\Lambda$CDM.\n", "  The inner slope (gammadm) of the dark matter (DM) density profile of\ncosmological halos carries information about the properties of DM and/or\nbaryonic processes affecting the halo gravitational potential. Cold DM\ncosmological simulations predict steep inner slopes, gammadm~1. We test this\nprediction on the MACS J1206.2-0847 cluster at redshift z=0.44, whose DM\ndensity profile was claimed to be cored at the center. We determine the cluster\nDM density profile from 2 kpc from the cluster center to the virial radius (~2\nMpc), using the velocity distribution of ~500 cluster galaxies and the internal\nvelocity dispersion profile of the Brightest Cluster Galaxy (BCG), obtained\nfrom VIMOS@VLT and MUSE@VLT data. We solve the Jeans equation of dynamical\nequilibrium using an upgraded version of the MAMPOSSt method. The total mass\nprofile is modeled as a sum of a generalized-NFW profile that describes the DM\ncomponent, allowing for a free inner slope of the density profile, a Jaffe\nprofile that describes the BCG stellar mass component, and a non-parametric\nbaryonic profile that describes the sum of the remaining galaxy stellar mass\nand of the hot intra-cluster gas mass. Our total mass profile is in remarkable\nagreement with independent determinations based on X-ray observations and\nstrong lensing. We find gammadm=0.7 (-0.1 +0.2) (68\\% confidence levels),\nconsistent with predictions from recent LambdaCDM cosmological numerical\nsimulations.\n", "  In this paper, we investigate the interaction between early dark energy (EDE)\nand scalar field dark matter, proposing a coupled scalar fields model to\naddress the Hubble tension and $S_8$ tension. While the EDE model successfully\nalleviates the Hubble tension, it exacerbates the $S_8$ tension. To mitigate\nthe negative impact of EDE, we introduce the interaction between EDE and dark\nmatter. Specifically, we replace cold dark matter with scalar field dark\nmatter, given its capability to suppress structure growth on small scales. We\nconstrained the new model using cosmological observations including the\ntemperature and polarization anisotropy power spectra data of cosmic microwave\nbackground radiation (CMB) from \\textit{Planck} 2018 results, baryon acoustic\noscillations (BAO) measurements extracted from 6dFGS, SDSS and BOSS, the\nPantheon sample of type Ia supernovae (SNIa), the local distance-ladder data\n(SH0ES), and the Dark Energy Survey Year-3 data. Employing Markov Chain Monte\nCarlo method, we find that this novel model yields best-fit values of $H_0$ and\n$S_8$ equal to $71.13$ km/s/Mpc and $0.8256$, respectively. Compared to the\n$\\Lambda$CDM model, the new model alleviates the Hubble tension but still fails\nto resolve the $S_8$ tension. However, we obtain a smaller value of $S_8$\ncompared to the result of $0.8316$ obtained for EDE model, which mitigates to\nsome extent the shortcoming of the EDE model.\n", "  We use simulated cluster member galaxies from Illustris TNG300-1 to develop a\ntechnique for measuring the galaxy cluster mass accretion rate (MAR) that can\nbe applied directly to observations. We analyze 1318 IllustrisTNG clusters of\ngalaxies with $M_{200c}>10^{14}$M$_\\odot$ and $0.01\\leq z \\leq 1.04$. The MAR\nwe derive is the ratio between the mass of a spherical shell located in the\ninfall region and the time for the infalling shell to accrete onto the\nvirialized region of the cluster. At fixed redshift, an $\\sim 1$ order of\nmagnitude increase in $M_{200c}$ results in a comparable increase in MAR. At\nfixed mass, the MAR increases by a factor of $\\sim 5$ from $z=0.01$ to\n$z=1.04$. The MAR estimates derived from the caustic technique are unbiased and\nlie within 20% of the MARs based on the true mass profiles. This agreement is\ncrucial for observational derivation of the MAR. The IllustrisTNG results are\nalso consistent with (i) previous merger tree approaches based on N-body dark\nmatter only simulations and with (ii) previously determined MARs of real\nclusters based on the caustic method. Future spectroscopic and photometric\nsurveys will provide MARs of enormous cluster samples with mass profiles\nderived from both spectroscopy and weak lensing. Combined with future larger\nvolume hydrodynamical simulations that extend to higher redshift, the MAR\npromises important insights into evolution of massive systems of galaxies.\n", "  We present a series of full-shape analyses of galaxy power spectrum multipole\nmeasurements from the 6dFGS, BOSS, and eBOSS galaxy surveys. We use an emulated\neffective field theory of large-scale structure (EFTofLSS) model to conduct\nthese analyses. We exploit the accelerated prediction speed of the\nneural-network-based emulator to explore various analysis setups for our\ncosmological inference pipeline. Via a set of mock full-shape analyses of\nsynthetic power spectrum multipoles, designed to approximate measurements from\nthe surveys above, we demonstrate that the use of alternative priors on\nnuisance parameters and restricted model complexity reduces many of the biases\npreviously observed in marginalised cosmological constraints coming from\nEFTofLSS analyses. The alternative priors take the form of a Jeffreys prior; a\nnon-informative prior that can mitigate against biases induced by marginalising\nover poorly constrained nuisance parameters. When performing a joint analysis\nof all synthetic multipoles, we see an improvement in the level of agreement\nbetween the marginalised $\\ln{\\left(10^{10}A_s\\right)}$ constraints and the\ntruth; from $\\sim2.0\\sigma$ to $\\sim0.42\\sigma$. Using our pipeline to analyse\nthe measured multipoles, we find an improvement in the level of agreement with\ncosmic microwave background (CMB) results; from $\\sim2.4\\sigma$ to\n$\\sim0.5\\sigma$. Therefore, we conclude that the spectroscopic galaxy survey\ndatasets listed above are consistent with constraints obtained from the CMB.\n", "  Cosmic voids identified in the spatial distribution of galaxies provide\ncomplementary information to two-point statistics. In particular, constraints\non the neutrino mass sum, $\\sum m_\\nu$, promise to benefit from the inclusion\nof void statistics. We perform inference on the CMASS NGC sample of\nSDSS-III/BOSS with the aim of constraining $\\sum m_\\nu$. We utilize the void\nsize function, the void galaxy cross power spectrum, and the galaxy auto power\nspectrum. To extract constraints from these summary statistics we use a\nsimulation-based approach, specifically implicit likelihood inference. We\npopulate approximate gravity-only, particle neutrino cosmological simulations\nwith an expressive halo occupation distribution model. With a conservative\nscale cut of kmax=0.15 h/Mpc and a Planck-inspired LCDM prior, we find upper\nbounds on $\\sum m_\\nu$ of 0.43 and 0.35 eV from the galaxy auto power spectrum\nand the full data vector, respectively (95% credible interval). We observe\nhints that the void statistics may be most effective at constraining $\\sum\nm_\\nu$ from below. We also substantiate the usual assumption that the void size\nfunction is Poisson distributed.\n", "  The Hubble constant ${H}_0$ is a crucial parameter in cosmology. However,\ndifferent cosmic observations have resulted in varying posterior results for\n${H}_0$, leading to what is known as the ${H}_0$ tension. In order to address\nthis issue, it is beneficial to use other dataset to constrain ${H}_0$. In this\npaper, via the cosmographic approach based on the\nFriedman-Lemaitre-Robertson-Walker (FLRW) metric to the dispersion measure of\nthe intergalactic medium ${\\rm{DM}}_{\\rm{IGM}}(z)$ of Fast Radio Bursts (FRBs),\nwe obtain the Taylor expansion of $\\langle{\\rm{DM}}_{\\rm{IGM}}(z)\\rangle$ in\nterms redshift $z$. The result for Hubble constant $H_0=65.5^{+6.4}_{-5.4}$\n${\\rm{km~s^{-1}~Mpc^{-1}}}$ $(68$$\\%$ ${\\rm{C.L.}}) $, cosmological\ndeceleration parameter $q_0=-0.50\\pm 0.20 $ and the jerk parameter\n$j_0=-0.1^{+2.0}_{-2.5}$ using uncalibrated Supernova Ia (SNe Ia) Pantheon\ndataset combined with 18 localized FRBs are obtained. To demonstrate the impact\nof parameter degeneracies on our analysis methods, we compare the results using\nthree different forms of $f_{\\rm{IGM}}(z)$ and two different prior\ndistributions for $\\Omega_{\\rm{b,0}}$. Then we find that the uncertainty in\n$H_0$ is not significantly affected by the prior range of $f_{\\rm{IGM}}(z)$ and\n$\\Omega_{\\rm{b,0}}$, but the mean value is influenced by the priors for\n$f_{\\rm{IGM}}(z)$ and $\\Omega_{\\rm{b,0}}$ due to parameter degeneracies with\n$H_0$. Employing $f_{\\rm{IGM}}(z)$ that evolves with redshift, we obtain the\nconstraints for $H_0=69.0^{+6.7}_{-5.7}$ ${\\rm{km~s^{-1}~Mpc^{-1}}}$.\nFurthermore, the mock analyses give a posterior estimation of $H_0$ with an\naccuracy of 4.6\\% and higher precision for $q_0$ and $j_0$ in the near future.\n", "  We present the Simple Intensity Map Producer for Line Emission (SIMPLE), a\npublic code for quickly simulating mock line-intensity maps, and an analytical\nframework for modeling intensity maps including observational effects. SIMPLE\ncan be applied to any spectral line sourced by galaxies. The SIMPLE code is\nbased on lognormal mock catalogs of galaxies including positions and velocities\nand assigns luminosities following the luminosity function. After applying a\nselection function to distinguish between detected and undetected galaxies, the\ncode generates an intensity map, which can be modified with anisotropic\nsmoothing, noise, a mask, and sky subtraction, and calculates the power\nspectrum multipoles. We show that the intensity autopower spectrum and the\ngalaxy-intensity cross-power spectrum agree well with the analytical estimates\nin real space. We derive and show that the sky subtraction suppresses the\nintensity autopower spectrum and the cross-power spectrum on scales larger than\nthe size of an individual observation. As an example application, we make\nforecasts for the sensitivity of an intensity mapping experiment similar to the\nHobby-Eberly Telescope Dark Energy Experiment (HETDEX) to the cross-power\nspectrum of Ly$\\alpha$-emitting galaxies and the Ly$\\alpha$ intensity. We\npredict that HETDEX will measure the galaxy-intensity cross-power spectrum with\na high signal-to-noise ratio on scales of $0.04\\, h\\,\\mathrm{Mpc}^{-1} < k <\n1\\, h\\,\\mathrm{Mpc}^{-1}$.\n", "  Massive neutrinos are expected to affect the large-scale structure formation,\nincluding the major component of solid substances, dark matter halos. How halos\nare influenced by neutrinos is vital and interesting, and angular momentum (AM)\nas a significant feature provides a statistical perspective for this issue.\nExploring halos from TianNu N-body cosmological simulation with the co-evolving\nneutrino particles, we obtain some concrete conclusions. First, by comparing\nthe same halos with and without neutrinos, in contrast to the neutrino-free\ncase, over 89.71\\% of halos have smaller halo moduli, over 71.06\\% have smaller\nparticle-mass-reduced (PMR) AM moduli, and over 95.44\\% change their\norientations of less than $0.65^\\circ$. Moreover, the relative variation of PMR\nmodulus is more visible for low-mass halos. Second, to explore the PMR moduli\nof halos in dense or sparse areas, we divide the whole box into big cubes, and\nsearch for halos within a small spherical cell in a single cube. From the\ntwo-level divisions, we discover that in denser cubes, the variation of PMR\nmoduli with massive neutrinos decreases more significantly. This distinction\nsuggests that neutrinos exert heavier influence on halos' moduli in compact\nregions. With massive neutrinos, most halos (86.60\\%) have lower masses than\nwithout neutrinos.\n", "  We present a forecast analysis on the feasibility of measuring the\ncosmological parameters with a large number of galaxy-galaxy scale strong\ngravitational lensing systems. Future wide area surveys are expected to\ndiscover and measure the properties of more than 10 000 strong lensing systems.\nWe develop a hierarchical model that can simultaneously constrain the lens\npopulation and cosmological parameters by combining Einstein radius\nmeasurements with stellar dynamical mass estimates for every lens.\nMarginalizing over the lens density profiles and stellar orbital anisotropies,\nwe find that $w$ can be constrained to a precision of $0.11$ with 10 000\ngalaxy-galaxy lens systems, which would be better than any existing\nsingle-probe constraint. We test our method on 161 existing lenses, finding\n$w=-0.96\\pm0.46$. We also show how to mitigate against the potential systematic\nof redshift evolution in the mean lens density profile of the population.\n", "  Twenty years after the discovery that the expansion of the Universe is\naccelerating, a new finding is now challenging our understanding of the cosmos.\nRecent studies have shown that the Hubble constant, the speed of expansion\nmeasured today, provides values in significant tension when measured from the\nCosmic Microwave Background in the primordial Universe or from Cepheids and\nSupernovae Type Ia in the local Universe. Whether this tension is hinting\ntowards new physics or some issue in the measurements, is still under debate;\nbut it is clearly calling for new independent cosmological probes to provide\nadditional pieces of evidence to solve this puzzle. This chapter introduces the\nmethod of cosmic chronometers, a new emerging cosmological probe that can\nprovide cosmology-independent estimates of the Universe's expansion history.\nThis method is based on the fact that the expansion rate of the Universe can be\ndirectly derived from measuring how much the Universe has changed in age\nbetween two different redshifts, i.e. by estimating the slope of the\nage--redshift relation. First, the main ingredients of the method will be\ndiscussed, presenting the main equations involved and how to estimate from the\nobservables the needed quantities. After, it will be presented how to reliably\nselect a sample of tracers to map the age evolution of the Universe coherently.\nNext, different methods to robustly measure the differential age of a\npopulation, the fundamental quantity involved in the method, will be reviewed.\nFinally, the main measurements obtained will be presented, providing forecasts\nfor future surveys and discussing how these data can provide useful feedback to\naddress the Hubble tension.\n", "  We implement and explore high-dimensional generalized dark matter (HDGDM)\nwith an arbitrary equation of state as a function of redshift as an extension\nto {\\Lambda}CDM.. Exposing this model to CMB, BAO, and supernova data, we\ndemonstrate that the use of marginalized posterior distributions can easily\nlead to misleading conclusions on the viability of a high-dimensional model\nsuch as this one. We discuss such pitfalls and corresponding mitigation\nstrategies, which can be used to search for an observationally favored region\nof the parameter space. We further show that the HDGDM model in particular does\nshow promise in terms of its ability to ease the Hubble tension once such\ntechniques are employed, and we find interesting features in the best-fitting\nequation of state that can serve as an inspiration for future model building.\n", "  We report the discovery of Mothra, an extremely magnified monster star,\nlikely a binary system of two supergiant stars, in one of the strongly lensed\ngalaxies behind the galaxy cluster MACS0416. The star is in a galaxy with\nspectroscopic redshift $z=2.091$ in a portion of the galaxy that is parsecs\naway from the cluster caustic. The binary star is observed only on the side of\nthe critical curve with negative parity but has been detectable for at least\neight years, implying the presence of a small lensing perturber.\n  Microlenses alone cannot explain the earlier observations of this object made\nwith the Hubble Space Telescope. A larger perturber with a mass of at least\n$10^4$\\,\\Msun\\ offers a more satisfactory explanation. Based on the lack of\nperturbation on other nearby sources in the same arc, the maximum mass of the\nperturber is $M< 2.5\\times10^6$\\,\\Msun, making it the smallest substructure\nconstrained by lensing above redshift 0.3. The existence of this millilens is\nfully consistent with the expectations from the standard cold dark matter\nmodel. On the other hand, the existence of such small substructure in a cluster\nenvironment has implications for other dark matter models. In particular, warm\ndark matter models with particle masses below 8.7\\,keV are excluded by our\nobservations. Similarly, axion dark matter models are consistent with the\nobservations only if the axion mass is in the range $0.5\\times10^{-22}\\, {\\rm\neV} < m_a < 5\\times10^{-22}\\, {\\rm eV}$.\n", "  This thesis explores the missing baryon problem in a computational context.\nAn overview of the problem is given, along with a discussion regarding the\nrelevance of the Circumgalactic Medium (CMG) and cosmological Zoom-in\nsimulations. The mechanisms underlying the N-body code ChaNGa (H. Menon, et\nal., Computational Astrophysics and Cosmology 2, 1 (2015), arXiv:1409.1929), as\nwell as the data visualization and analysis tools yt (M. J. Turk, et al., 192,\n9 (2011), arXiv:1011.3514) and trident (Hummels, et al., 847, 59 (2017),\narXiv:1612.03935) are presented at a conceptual level. Finally, a series of\nsynthetic quasar absorption spectra produced by using trident on a ChaNGa\ndataset from (S. Roca-Fabrega, et al., 917, 64 (2021), arXiv:2106.09738) at\nredshift of $z\\sim4$ are shown. The low relative flux exhibited by these\nspectra render absorption features indistinguishable from background noise, and\npossible explanations for this phenomena such as high redshift are discussed.\nThough the resulting spectra exhibit serious obstacles for both qualitative and\nquantitative interpretation, they provide a \"proof-of-concept\" for future work,\ndemonstrating trident's compatibility with ChaNGa's data format. Future\nprospects for using trident to analyze the CGM as simulated by ChaNGa are\ndiscussed, as well as possible extensions of this project.\n", "  We study two possible cosmological consequences of a first-order phase\ntransition in the temperature range of $1$ GeV to $10^3$ TeV: the generation of\na stochastic gravitational wave background (SGWB) within the sensitivity of the\nLaser Interferometer Space Antenna (LISA) and, simultaneously, primordial\nmagnetic fields that would evolve through the Universe's history and could be\ncompatible with the lower bound from $\\gamma$-ray telescopes on intergalactic\nmagnetic fields (IGMF) at present time. We find that, if even a small fraction\nof the kinetic energy in sound waves is converted into MHD turbulence, a first\norder phase transition occurring at temperature between $1$ and $10^6$ GeV can\ngive rise to an observable SGWB signal in LISA and, at the same time, an IGMF\ncompatible with the lower bound from the $\\gamma$-ray telescope MAGIC, for all\nproposed evolutionary paths of the magnetic fields throughout the radiation\ndominated era. For two values of the fraction of energy density converted into\nturbulence, $\\varepsilon_{\\rm turb}=0.1$ and $1$, we provide the range of\nfirst-order phase transition parameters (strength $\\alpha$, duration\n$\\beta^{-1}$, bubbles wall speed $v_w$, and temperature $T_*$), together with\nthe corresponding range of magnetic field strength $B$ and correlation length\n$\\lambda$, that would lead to the SGWB and IGMF observable with LISA and MAGIC.\nThe resulting magnetic field strength at recombination can also correspond to\nthe one that has been proposed to induce baryon clumping, previously suggested\nas a possible way to ease the Hubble tension. In the limiting case\n$\\varepsilon_{\\rm turb} \\ll 1$, the SGWB is only sourced by sound waves,\nhowever, an IGMF is still generated. We find that values as small as\n$\\varepsilon_{\\rm turb} \\sim O(10^{-13})$ (helical) and $O (10^{-9})$\n(non-helical) can provide IGMF compatible with MAGIC's lower bound.\n", "  Within the framework of investigating the link between central super massive\nblack holes in the core of galaxies and the galaxies themselves, we detected a\nvariable X-ray source in the center of CGCG 077-102 NED02, member of the CGCG\n077-102 galaxy pair within the Abell 2063 galaxy cluster. Our goal was then to\ncombine X-ray and optical data to demonstrate that this object harbors an\nactive super massive black hole in its core, and to relate this to the\ndynamical status of the galaxy pair within the Abell 2063 cluster. We used\nChandra and XMM-Newton archival data to derive the X-ray spectral shape and\nvariability. We also obtained optical spectroscopy to detect the expected\nemission lines that are typically found in Active Galactic Nuclei. And we\nfinally used public ZTF imaging data to investigate the optical variability.\nThere is no evidence of multiple X-ray sources or extended component within\nCGCG 077-102 NED02. Single X-ray spectral models fit well the source.\nNon-random significant X-ray flux inter-observation X-ray variabilities were\ndetected, between ~4days for short term variations and up to ~700days for long\nterm variations. Optical spectroscopy points toward a passive galaxy for CGCG\n077-102 NED01 and a Seyfert for CGCG 077-102 NED02. We did not detect\nshort-term variability in the optical ZTF light curves. However, we found a\nsignificant long-term stochastic variability in the g-band that can be well\ndescribed by the damped random walk model. Finally, the CGCG 077-102 galaxy\npair is deeply embedded within the Abell 2063 potential, and has underwent the\ncluster influence for a long time. Our observations point toward a moderatly\nmassive black hole in the center of CGCG 077-102 NED02, of ~10^6 Msol. CGCG\n077-102 NED02 is not heavily obscured, perhaps due to surrounding intra cluster\nmedium ram pressure stripping.\n", "  The Sunyaev-Zeldovich thermal (tSZ) and kinetic (kSZ) effects can be used to\nconstrain the thermodynamic properties of pressure and density, respectively,\nof galaxies and their surrounding regions. As SZ observations continue to\nimprove, it is important to understand any modeling systematics when inferring\nproperties from the data. Thus, a pipeline to forward model observed SZ\nprofiles was developed called Mop-c-GT. Previous studies have used this\nrepository to create modeled SZ profiles by selecting halos from the\nIllustrisTNG simulation and found significant differences between the simulated\nprofiles and those recently measured by the Atacama Cosmology Telescope. There\nare many uncertainties involved in modeling observed samples and in the forward\nmodeling process, so in this study, we explore methods implemented in Mop-c-GT\nand in the selection of the simulated halos to test the effects on the\nresulting modeled profiles. After testing several methods within the forward\nmodeling process and varying the halo selection from the simulation, we find\nminimal differences between the simulated tSZ profiles of the original\ncalculation and the updated methods, indicating that the observations still\npose a challenge for the numerical methods used to describe the astrophysics of\nthese systems.\n", "  We perform the weak lensing mass mapping analysis to identify troughs, which\nare defined as local minima in the mass map. Since weak lensing probes\nprojected matter along the line-of-sight, these troughs can be produced by\nsingle voids or multiple voids projected along the line-of-sight. To scrutinise\nthe origins of the weak lensing troughs, we systematically investigate the\nline-of-sight structure of troughs selected from the latest Subaru Hyper\nSuprime-Cam (HSC) Year 3 weak lensing data covering $433.48 \\, \\mathrm{deg}^2$.\nFrom a curved sky mass map constructed with the HSC data, we identify 15\ntroughs with the signal-to-noise ratio higher than $5.7$ and address their\nline-of-sight density structure utilizing redshift distributions of two galaxy\nsamples, photometric luminous red galaxies observed by HSC and spectroscopic\ngalaxies detected by Baryon Oscillation Spectroscopic Survey. While most of\nweak lensing signals due to the troughs are explained by multiple voids aligned\nalong the line-of-sight, we find that two of the 15 troughs potentially\noriginate from single voids at redshift $\\sim 0.3$. The single void\ninterpretation appears to be consistent with our three-dimensional mass mapping\nanalysis. We argue that single voids can indeed reproduce observed weak lensing\nsignals at the troughs if these voids are not spherical but are highly\nelongated along the line-of-sight direction.\n", "  In this followup analysis, we update previous constraints on the Transitional\nPlanck Mass (TPM) modified gravity model using the latest version of EFTCAMB\nand provide new constraints using SPT and Planck anisotropy data along with\nPlanck CMB lensing, BAO, SNe Ia, and an $H_0$ prior from local measurements. We\nfind that large shifts in the Planck mass lead to large suppression of power on\nsmall scales that is disfavored by both SPT and Planck. Using only SPT TE-EE\ndata, this suppression of power can be compensated for by an upward shift of\nthe scalar index to $n_s = 1.003 \\pm 0.016$ resulting in $H_0 =\n71.94^{+0.86}_{-0.85}$ kms$^{-1}$Mpc$^{-1}$ and a $\\sim7\\%$ shift in the Planck\nmass. Including Planck TT $\\ell \\leq 650$ and Planck TE-EE data restricts the\nshift to be $<5\\%$ at $2\\sigma$ with $H_0 = 70.65 \\pm 0.66$\nkms$^{-1}$Mpc$^{-1}$. Excluding the $H_0$ prior, SPT and Planck data constrain\nthe shift in the Planck mass to be $<3\\%$ at $2\\sigma$ with a best-fit value of\n$0.04\\%$, consistent with the $\\Lambda$CDM limit. In this case $H_0 =\n69.09^{+0.69}_{-0.68}$ kms$^{-1}$Mpc$^{-1}$, which is partially elevated by the\ndynamics of the scalar-field in the late universe. This differs from EDE models\nthat prefer higher values of $H_0$ when high $\\ell$ Planck TT data are\nexcluded. We additionally constrain TPM using RSD data from BOSS DR 12 and\ncosmic shear, galaxy-galaxy lensing, and galaxy clustering data from DES Y1\nfinding both disfavor transitions close to recombination, but earlier Planck\nmass transitions are allowed.\n", "  Primordial black hole (PBH) binaries forming in the early Universe may\ncontribute to the merger events observed by the LIGO-Virgo-KAGRA\ncollaborations. Moreover, the inferred merger rate constraints the fraction of\nPBH with masses $m \\sim 10 \\, M_{\\odot}$ in the dark matter (DM) to $f_{PBH}\n\\lesssim 10^{-3}$. This constraint assumes that after the formation of PBH\nbinaries, they do not get destroyed or their parameters are not perturbed until\nthe merger. However, PBHs themselves contribute to the formation of early DM\nstructures in which the interactions between PBHs take place actively. This\nleads to the fact that the binaries can be perturbed in such a way that their\nlifetime becomes longer than the Hubble time $t_H$. In this work, we consider\nthe effect of the initial spatial Poisson distribution of PBHs on the structure\nformation at the high redshifts $z \\gtrsim 10$. Next, we explore the evolution\nof such halos due to the interaction of PBHs with each other and with DM\nparticles. We show that the early halos evolve on timescales much shorter than\nthe age of the Universe. Furthermore, for fractions of PBHs $f_{PBH} < 1$, the\ninternal dynamics of a halo is significantly accelerated due to the dynamical\nfriction of PBHs against DM particles. As a result, a significant fraction of\nbinaries will be perturbed in such structures, and the gravitational waves\nconstraints on PBHs with masses $m \\sim 10 \\, M_{\\odot}$ can be weakened to\n$f_{PBH} \\sim 0.1$.\n", "  We study the time evolution of the mutual information between the mass\ndistributions in spatially separated but casually connected regions in an\nexpanding universe. The evolution of the mutual information is primarily\ndetermined by the configuration entropy rate which depends on the dynamics of\nthe expansion and the growth of the density perturbations. The joint entropy\nbetween the distributions from the two regions plays a negligible role in such\nevolution. The mutual information decreases with time in a matter dominated\nUniverse whereas it stays constant in a $\\Lambda$-dominated Universe. The\n$\\Lambda$CDM model and some other models of dark energy predict a minimum in\nthe mutual information beyond which the dark energy dominates the dynamics of\nthe Universe. The mutual information may have deeper connections to the dark\nenergy and the accelerated expansion of the universe.\n", "  The cosmic microwave background (CMB) offers a unique window into the early\nuniverse, providing insights into cosmological parameters like the Hubble\nconstant. Recent precise measurements of the CMB by experiments like Planck\nseem to point to a lower value for the Hubble constant compared to some other\nmeasurements like those from Type Ia supernovae. This discrepancy, known as the\nHubble tension, currently lacks a definitive explanation. In this chapter, we\nprovide an overview of how the Hubble constant is determined from detailed\nmeasurements of the CMB power spectrum. We explain the physics underlying key\nfeatures of the CMB spectrum and their connection to cosmological parameters.\nWe then examine the consistency of Planck's Hubble constant determination, both\ninternally within the data itself and externally with other astrophysical\nprobes. While largely consistent, some anomalies like the lensing amplitude\nparameter $A_L$ remain unresolved. We also explore various theoretical\nextensions to the standard ${\\Lambda}$CDM cosmological model and assess their\npotential to resolve the Hubble tension. No clear resolution emerges,\nindicating significant tensions remain between early and late universe probes\nwithin simple extensions to ${\\Lambda}$CDM. Upcoming CMB experiments promise\nimproved precision and should provide further insights into this cosmic\nconundrum. A coherent picture bridging measurements across cosmic time remains\nan open challenge at the forefront of modern cosmology.\n", "  The Fred Young Submillimeter Telescope (FYST) and the Simons Observatory\nLarge Aperture Telescope (SO\\ LAT) will deliver unprecedented high-resolution\nmeasurements of microwave sky emissions. Notably, one of those microwave sky\nemissions, the thermal Sunyaev-Zeldovich (tSZ) signal, is an essential probe\nfor cluster astrophysics and cosmology. However, an obstacle to its measurement\nis contamination by the cosmic infrared background (CIB), especially at high\nfrequencies. Our goal is to assess the detection and purity of tSZ power\nspectrum measurements from these two telescopes. We demonstrate that FYST's\nhigh-frequency coverage helps lower CIB contamination and improves signal\ndetection. We simulated the various components of the microwave sky at the\nfrequencies, sensitivities, and beam sizes of the upcoming SO LAT and FYST\ntelescopes using full-sky Hierarchical Equal Area isoLatitude Pixelisation\n(HEALPix) map templates from the Websky simulations and the Python Sky Model\n(PySM). We used a map-based internal linear combination (ILC) and a constrained\nILC (CILC) to extract the tSZ signal and compute residual noises to assess CIB\ncontamination and signal recovery. We find that the CIB's residual noise power\nspectrum in the ILC-recovered tSZ is lowered by $\\sim 35\\%$ on average over the\nscales $\\ell \\in [500,5000]$ when SO LAT and FYST are combined compared to when\nSO LAT is used alone. We find that when using CILC to deproject CIB, the\ncombined abilities of SO LAT and FYST offer a large $\\ell \\in [1800,3500]$\nwindow in which the recovered tSZ power spectrum is not noise dominated.\n", "  We revisit the flat-sky approximation for evaluating the angular power\nspectra of projected random fields by retaining information about the\ncorrelations along the line of sight. With broad, overlapping radial window\nfunctions, these line-of-sight correlations are suppressed and are ignored in\nthe Limber approximation. However, retaining the correlations is important for\nnarrow window functions or unequal-time spectra but introduces significant\ncomputational difficulties due to the highly oscillatory nature of the\nintegrands involved. We deal with the integral over line-of-sight wave-modes in\nthe flat-sky approximation analytically, using the FFTlog expansion of the 3D\npower spectrum. This results in an efficient computational method, which is a\nsubstantial improvement compared to any full-sky approaches. We apply our\nresults to galaxy clustering (with and without redshift-space distortions), CMB\nlensing and galaxy lensing observables. For clustering, we find excellent\nagreement with the full-sky results on large (percent-level agreement) and\nintermediate or small (subpercent agreement) scales, dramatically\nout-performing the Limber approximation for both wide and narrow window\nfunctions, and in equal- and unequal-time cases. In the case of lensing, we\nshow on the full sky that the angular power spectrum of the convergence can be\nvery well approximated by projecting the 3D Laplacian (rather than the correct\nangular Laplacian) of the gravitational potential, even on large scales.\nCombining this approximation with our flat-sky techniques provides an efficient\nand accurate evaluation of the CMB lensing angular power spectrum on all\nscales.\n", "  We demonstrate and measure the impact of source galaxy clustering on\nhigher-order summary statistics of weak gravitational lensing data. By\ncomparing simulated data with galaxies that either trace or do not trace the\nunderlying density field, we show this effect can exceed measurement\nuncertainties for common higher-order statistics for certain analysis choices.\nSource clustering effects are larger at small scales and for statistics applied\nto combinations of low and high redshift samples, and diminish at high\nredshift. We evaluate the impact on different weak lensing observables, finding\nthat third moments and wavelet phase harmonics are more affected than peak\ncount statistics. Using Dark Energy Survey Year 3 data we construct null tests\nfor the source-clustering-free case, finding a $p$-value of $p=4\\times10^{-3}$\n(2.6 $\\sigma$) using third-order map moments and $p=3\\times10^{-11}$ (6.5\n$\\sigma$) using wavelet phase harmonics. The impact of source clustering on\ncosmological inference can be either be included in the model or minimized\nthrough \\textit{ad-hoc} procedures (e.g. scale cuts). We verify that the\nprocedures adopted in existing DES Y3 cosmological analyses (using map moments\nand peaks) were sufficient to render this effect negligible. Failing to account\nfor source clustering can significantly impact cosmological inference from\nhigher-order gravitational lensing statistics, e.g. higher-order N-point\nfunctions, wavelet-moment observables (including phase harmonics and scattering\ntransforms), and deep learning or field level summary statistics of weak\nlensing maps. We provide recipes both to minimise the impact of source\nclustering and to incorporate source clustering effects into forward-modelled\nmock data.\n", "  As the scale of cosmological surveys increases, so does the complexity in the\nanalyses. This complexity can often make it difficult to derive the underlying\nprinciples, necessitating statistically rigorous testing to ensure the results\nof an analysis are consistent and reasonable. This is particularly important in\nmulti-probe cosmological analyses like those used in the Dark Energy Survey and\nthe upcoming Legacy Survey of Space and Time, where accurate uncertainties are\nvital. In this paper, we present a statistically rigorous method to test the\nconsistency of contours produced in these analyses, and apply this method to\nthe Pippin cosmological pipeline used for Type Ia supernova cosmology with the\nDark Energy Survey. We make use of the Neyman construction, a frequentist\nmethodology that leverages extensive simulations to calculate confidence\nintervals, to perform this consistency check. A true Neyman construction is too\ncomputationally expensive for supernova cosmology, so we develop a method for\napproximating a Neyman construction with far fewer simulations. We find that\nfor a simulated data-set, the 68% contour reported by the Pippin pipeline and\nthe 68% confidence region produced by our approximate Neyman construction\ndiffer by less than a percent near the input cosmology, however show more\nsignificant differences far from the input cosmology, with a maximal difference\nof 0.05 in $\\Omega_{M}$, and 0.07 in $w$. This divergence is most impactful for\nanalyses of cosmological tensions, but its impact is mitigated when combining\nsupernovae with other cross-cutting cosmological probes, such as the Cosmic\nMicrowave Background.\n", "  Together with larger spectroscopic surveys such as the Dark Energy\nSpectroscopic Instrument (DESI), the precision of large scale structure studies\nand thus the constraints on the cosmological parameters are rapidly improving.\nTherefore, one must build realistic simulations and robust covariance matrices.\n  We build galaxy catalogues by applying a Halo Occupation Distribution (HOD)\nmodel upon the \\textsc{FastPM} simulations, such that the resulting galaxy\nclustering reproduces high resolution $N$-body simulations. While the\nresolution and halo finder are different from the reference simulations, we\nreproduce the reference galaxy two-point clustering measurements -- monopole\nand quadrupole -- to a precision required by the DESI Year 1 Emission Line\nGalaxy sample down to non-linear scales, i.e. $k<0.5\\,h\\mathrm{Mpc}$ or\n$s>10\\,\\mathrm{Mpc}/h$.\n  Furthermore, we compute covariance matrices based on the resulting\n\\textsc{FastPM} galaxy clustering -- monopole and quadrupole. We study for the\nfirst time the effect of fitting on Fourier conjugate [e.g. power spectrum] on\nthe covariance matrix of the Fourier counterpart [e.g. correlation function].\nWe estimate the uncertainties of the two parameters of a simple clustering\nmodel and observe a maximum variation of 20 per cent for the different\ncovariance matrices. Nevertheless, for most studied scales the scatter is\nbetween two to ten per cent\n  Consequently, using the current pipeline we can precisely reproduce the\nclustering of $N$-body simulations and the resulting covariance matrices\nprovide robust uncertainty estimations against HOD fitting scenarios. We expect\nour methodology will be useful for the coming DESI data analyses and their\nextension for other studies.\n", "  The Universe has evolved from an initial diffuse, uniform gas to a complex\nstructure that includes both voids and high-density galaxy clusters connected\nby gaseous filaments, known as the Cosmic Web, and traced by 3D surveys of\ngalaxies. The filamentary structure contains a significant fraction of the\nbaryonic matter and is predicted to be mostly in the form of a moderately high\ntemperature plasma, the Warm Hot Intergalactic Medium. Plasma at this\ntemperature and ionization level emits mostly in soft X-rays. The filamentary\nstructure, however, is hard to detect because the other sources contributing to\nthe Diffuse X-ray Background are much brighter and, currently, there are very\nfew reported detections of emission from the filaments. We report the first\nhigh-confidence level indirect detection of X-ray emission from the Warm Hot\nIntergalactic Medium. Applying the Power Spectrum Analysis to XMM-Newton and\neROSITA data, we separated its contribution from other sources modeled in\nprevious studies. Our result is in good agreement with numerical simulations\nand fills a critical gap in the picture of the large-scale structure of the\nUniverse, in which filamentary gas, galaxies and dark matter interact and\nco-evolve.\n", "  The study of massive neutrinos and their interactions is a critical aspect of\ncontemporary cosmology. Recent advances in parallel computation and\nhigh-performance computing provide new opportunities for accurately\nconstraining Large-Scale Structures (LSS). In this paper, we introduce the\nTianNu cosmological N-body simulation during the co-evolution of massive\nneutrino and cold dark matter components via the CUBEP$^3$M code running on the\nsupercomputer Tianhe-2 and TianNu's connected works. We start by analyzing\n$2.537\\times10^7$ dark halos from the scientific data of TianNu simulation, and\ncompare their angular momentum with the matched halos from neutrino-free\nTianZero, revealing a dependence of angular momentum modulus on neutrino\ninjection at scales below 50 Mpc and around 10 Mpc.\n", "  As a fundamental parameter for modern cosmology, the Hubble constant $H_0$ is\nexperiencing a serious crisis. In this paper, we explore an independent\napproach to measure $H_0$ based on the time-delay cosmography with strong\ngravitational lensing of a quasar by a galaxy cluster. Specifically we focus on\nthe strong lensing system SDSS J1004+4112 with the maximum image separation of\n14.62$''$, the first system of a quasar lensed by a galaxy cluster with five\nmultiple images. Incorporating the latest time-delay measurements, we\ninvestigate the lens model dependence from the combination of 16 different lens\nmass models. We find that the lens model dependence is indeed large, with the\ncombined measurement of the Hubble constant of\n$H_0=67.5^{+14.5}_{-8.9}km/s/Mpc$ that is obtained by summing posteriors of the\nHubble constant from the 16 models with equal weighting. Interestingly, our\nresults show that the value of Hubble constant decreases as the complexity of\nthe perturbation around the lens increases, although weighting based on\npositional errors of quasar images does not significantly improve the $H_0$\nconstraint. We find that the 16 different mass models predict largely different\nshapes of the lensed quasar host galaxy as well as other lensed galaxies behind\nthe cluster. By selecting two mass models that best reproduces those shapes,\nthe constraint on the Hubble constant is significantly tightened to\n$H_0=59.1^{+3.6}_{-3.5}km/s/Mpc$. While we caution that our analysis still does\nnot fully explore all the possible mass model uncertainty, our results\nhighlight the importance of including as many constraints as possible such as\nextended shapes of lensed galaxies for obtaining tight constraints on the\nHubble constant from cluster-lensed quasar lens systems.\n", "  The 21-cm brightness temperature fluctuation from the Dark Ages ($z \\simeq\n30-100$) will allow us to probe the inflationary epoch on very small scales\n($>0.1 \\, \\mbox{Mpc}^{-1}$), inaccessible to cosmic microwave background\nexperiments. Combined with the possibility to collect information from\ndifferent redshift slices, the 21-cm bispectrum has the potential to\nsignificantly improve constraints on primordial non-Gaussianity. However,\nrecent work has shown secondary effects source off-diagonal terms in the\ncovariance matrix which can significantly affect forecasted constraints,\nespecially in signals that peak in the squeezed configuration, such as the\nlocal bispectrum. In this paper we propose the three-point $\\langle 21-21-\\rm\nCMB \\rangle$ bispectrum cross-correlation as a new independent observational\nchannel sensitive to local primordial non-Gaussianity. We find that, contrary\nto the 21-cm bispectrum, secondary contributions are subdominant to the\nprimordial signal for values $f_{\\rm NL}^{\\rm loc} \\sim 1$, resulting in\nnegligible effects from off-diagonal terms in the covariance matrix. We\nforecast that CMB $T$ and $E$ modes cross-correlated with an ideal cosmic\nvariance-limited 21-cm experiment with a $0.1$ MHz frequency and $0.1$\narc-minute angular resolution could reach $f_{\\rm NL}^{\\rm loc} \\sim 6 \\times\n10^{-3}$. This forecast suggests cross-correlation between CMB and 21-cm\nexperiments could provide a viable alternative to 21-cm auto-spectra in\nreaching unprecedented constraints on primordial local non-Gaussianities.\n", "  High-resolution JWST observations can test confusion-limited HST observations\nfor a photometric bias that could affect extragalactic Cepheids and the\ndetermination of the Hubble constant. We present JWST NIRCAM observations in\ntwo epochs and three filters of >330 Cepheids in NGC4258 (which has a 1.5%\nmaser-based geometric distance) and in NGC5584 (host of SNIa 2007af), near the\nmedian distance of the SH0ES HST SNIa host sample and with the best leverage\namong them to detect such a bias. JWST provides far superior source separation\nfrom line-of-sight companions than HST in the NIR to largely negate confusion\nor crowding noise at these wavelengths, where extinction is minimal. The result\nis a remarkable >2.5x reduction in the dispersion of the Cepheid P-L relations,\nfrom 0.45 to 0.17 mag, improving individual Cepheid precision from 20% to 7%.\nTwo-epoch photometry confirmed identifications, tested JWST photometric\nstability, and constrained Cepheid phases. The P-L relation intercepts are in\nvery good agreement, with differences (JWST-HST) of 0.00+/-0.03 and 0.02+/-0.03\nmag for NGC4258 and NGC5584, respectively. The difference in the determination\nof H_0 between HST and JWST from these intercepts is 0.02+/-0.04 mag,\ninsensitive to JWST zeropoints or count-rate non-linearity thanks to error\ncancellation between rungs. We explore a broad range of analysis variants\n(including passband combinations, phase corrections, measured detector offsets,\nand crowding levels) indicating robust baseline results. These observations\nprovide the strongest evidence yet that systematic errors in HST Cepheid\nphotometry do not play a significant role in the present Hubble Tension.\nUpcoming JWST observations of >12 SNIa hosts should further refine the local\nmeasurement of the Hubble constant.\n", "  Hubble tension is a problem in one-dimensional (1D) posteriors, since local\n$H_0$ determinations are only sensitive to a single parameter. Projected 1D\nposteriors for $\\Lambda$CDM cosmological parameters become more non-Gaussian\nwith increasing effective redshift when the model is fitted to redshift binned\ndata in the late Universe. We explain mathematically why this non-Gaussianity\narises and show using observational Hubble data (OHD) that Markov Chain Monte\nCarlo (MCMC) marginalisation leads to 1D posteriors that fail to track the\n$\\chi^2$ minimum at $68\\%$ confidence level in high redshift bins. To remedy\nthis limitation of MCMC, we resort to profile distributions as a complementary\ntechnique. Doing so, we observe that $z \\gtrsim 1$ cosmic chronometer (CC) data\ncurrently prefers a non-evolving (constant) Hubble parameter over a\nPlanck-$\\Lambda$CDM cosmology at $\\sim 2 \\sigma$. Within the Hubble tension\ndebate, it is imperative that subsamples of data sets with differing redshifts\nyield similar $H_0$ values. In addition, we confirm that MCMC degeneracies\nobserved in 2D posteriors are not due to curves of constant $\\chi^2$. Finally,\non the assumption that the Planck-$\\Lambda$CDM cosmological model is correct,\nusing profile distributions we confirm a $>2 \\sigma$ discrepancy with\nPlanck-$\\Lambda$CDM in a combination of CC and baryon acoustic oscillations\n(BAO) data beyond $ z \\sim 1.5$. This confirms a discrepancy reported earlier\nwith fresh methodology.\n", "  Phenomenological models are widely used in cosmology in relation to\nconstraining different cosmological models, with two common examples being\ncosmographic expansions and modeling the equation-of-state parameter of dark\nenergy. This work presents a study of how using different phenomenological\nexpressions for observables and physical quantities versus using physically\nmotivated, derived expressions affects cosmological parameter constraints. The\nstudy includes the redshift-distance relation and Hubble parameter as\nobservables, and the dark energy equation-of-state parameter as a physical\nquantity, and focuses on constraining the cosmological parameter\n$\\Omega_{\\Lambda}$. The observables and equation-of-state parameter are all\nmodeled both using the physical, derived expressions and a variety of\nphenomenological models with different levels of accuracy and complexity. The\nresults suggest that the complexity of phenomenological expressions only has\nminor impact on the parameter constraints unless the complexity is very high.\nThe results also indicate that statistically significantly different results\ncan be expected from parameter constraints using different phenomenological\nmodels if the models do not have very similar accuracy. This suggests that a\ngood practice is to use multiple phenomenological models when possible, in\norder to assess the model dependence of results. Straightforward examples of\nthis is that results obtained using cosmographic expansions should always be\nchecked against similar results obtained with expansions of other order, and\nwhen using phenomenological models such as for the equation-of-state\nparameters, robustness of results could be assessed using fitted models from\nsymbolic regression, similar to what is done in this study.\n", "  In this study, we perform a halo-finder code comparison between Rockstar and\nCompaSO. Based on our previous analysis aiming at quantifying resolution of\n$N$-body simulations by exploiting large (up to $N=4096^3$) simulations of\nscale-free cosmologies run using Abacus, we focus on convergence of the HMF,\n2PCF and mean radial pairwise velocities of halo centres selected with the\naforementioned two algorithms. We establish convergence, for both Rockstar and\nCompaSO, of mass functions at the $1\\%$ precision level and of the mean\npairwise velocities (and also 2PCF) at the $2\\%$ level. At small scales and\nsmall masses, we find that Rockstar exhibits greater self-similarity, and we\nalso highlight the role played by the merger-tree post-processing of CompaSO\nhalos on their convergence. Finally, we give resolution limits expressed as a\nminimum particle number per halo in a form that can be directly extrapolated to\nLCDM.\n", "  El Gordo (ACT-CL J0102-4915) is an extraordinarily large and bright galaxy\ncluster collision. In a previous study, we found that El Gordo is in\n$6.2\\sigma$ tension with the $\\Lambda$CDM standard model when assuming the\nnominal mass and infall velocity values from the hydrodynamical simulations of\nZhang et al. ($M_{200} = 3.2 \\times 10^{15} M_{\\odot}$ and $V_{\\textrm{infall}}\n= 2500~\\textrm{km~s}^{-1}$, respectively). The recent weak lensing study of Kim\net al. showed that the mass of El Gordo is actually $2.13^{+0.25}_{-0.23}\n\\times 10^{15} M_{\\odot}$. Here we explore the level of tension between El\nGordo and $\\Lambda$CDM for the new mass estimate, assuming several\n$V_{\\textrm{infall}}$ values. We find that in order to reduce the tension below\nthe $5\\sigma$ level, the El Gordo subclusters should have $V_{\\textrm{infall}}\n< 2300~\\textrm{km~s}^{-1}$ ($V_{\\textrm{infall}} < 1800~\\textrm{km~s}^{-1}$\nwhen considering the combined tension with the Bullet Cluster). To the best of\nour knowledge, the El Gordo hydrodynamical simulations conducted so far require\n$V_{\\textrm{infall}} \\geq 2500~\\textrm{km~s}^{-1}$ to simultaneously reproduce\nits morphology and its high X-ray luminosity and temperature. We therefore\nconclude that El Gordo still poses a significant challenge to $\\Lambda$CDM\ncosmology. Whether the properties of El Gordo can be reconciled with a lower\n$V_{\\textrm{infall}}$ should be tested with new hydrodynamical simulations that\nexplore different configurations of the interaction.\n", "  We present an analysis of Type Ia Supernovae (SNe~Ia) from both the Carnegie\nSupernova Project~I (CSP-I) and II (CSP-II), and extend the Hubble diagram from\nthe optical to the near-infrared wavelengths ($uBgVriYJH$). We calculate the\nHubble constant, $H_0$, using various distance calibrators: Cepheids, Tip of\nthe Red Giant Branch (TRGB), and Surface Brightness Fluctuations (SBF).\nCombining all methods of calibrations, we derive $\\rm H_0=71.76 \\pm 0.58 \\\n(stat) \\pm 1.19 \\ (sys) \\ km \\ s^{-1} \\ Mpc^{-1}$ from $B$-band, and $\\rm\nH_0=73.22 \\pm 0.68 \\ (stat) \\pm 1.28 \\ (sys) \\ km \\ s^{-1} \\ Mpc^{-1}$ from\n$H$-band. By assigning equal weight to the Cepheid, TRGB, and SBF calibrators,\nwe derive the systematic errors required for consistency in the first rung of\nthe distance ladder, resulting in a systematic error of $1.2\\sim 1.3 \\rm \\ km \\\ns^{-1} \\ Mpc^{-1}$ in $H_0$. As a result, relative to the statistics-only\nuncertainty, the tension between the late-time $H_0$ we derive by combining the\nvarious distance calibrators and the early-time $H_0$ from the Cosmic Microwave\nBackground is reduced. The highest precision in SN~Ia luminosity is found in\nthe $Y$ band ($0.12\\pm0.01$ mag), as defined by the intrinsic scatter\n($\\sigma_{int}$). We revisit SN~Ia Hubble residual-host mass correlations and\nrecover previous results that these correlations do not change significantly\nbetween the optical and the near-infrared wavelengths. Finally, SNe~Ia that\nexplode beyond 10 kpc from their host centers exhibit smaller dispersion in\ntheir luminosity, confirming our earlier findings. Reduced effect of dust in\nthe outskirt of hosts may be responsible for this effect.\n", "  In the absence of numerous gravitational-wave detections with confirmed\nelectromagnetic counterparts, the \"dark siren\" method has emerged as a leading\ntechnique of gravitational-wave cosmology. The method allows redshift\ninformation of such events to be inferred statistically from a catalogue of\npotential host galaxies. Due to selection effects, dark siren analyses\nnecessarily depend on the mass distribution of compact objects and the\nevolution of their merger rate with redshift. Informative priors on these\nquantities will impact the inferred posterior constraints on the Hubble\nconstant ($H_0$). It is thus crucial to vary these unknown distributions during\nan $H_0$ inference. This was not possible in earlier analyses due to the high\ncomputational cost, restricting them to either excluding galaxy catalogue\ninformation, or fixing the gravitational-wave population mass distribution and\nrisking introducing bias to the $H_0$ measurement. This paper introduces a\nsignificantly enhanced version of the Python package GWCOSMO, which allows\njoint estimation of cosmological and compact binary population parameters. This\nthereby ensures the analysis is now robust to a major source of potential bias.\nThe gravitational-wave events from the Third Gravitational-Wave Transient\nCatalogue are reanalysed with the GLADE+ galaxy catalogue, and an updated, more\nreliable measurement of $H_0=69^{+12}_{-7}$ km s$^{-1}$ Mpc$^{-1}$ is found\n(maximum a posteriori probability and 68% highest density interval). This\nimproved method will enable cosmological analyses with future\ngravitational-wave detections to make full use of the information available\n(both from galaxy catalogues and the compact binary population itself), leading\nto promising new independent bounds on the Hubble constant.\n", "  Cepheids have been the cornerstone of the extragalactic distance scale for a\ncentury. With high-quality data, these luminous supergiants exhibit a small\ndispersion in their Leavitt (period-luminosity) relation, particularly at\nlonger wavelengths, and few methods rival the precision possible with Cepheid\ndistances. In these proceedings, we present an overview of major observational\nprograms pertaining to the Cepheid extragalactic distance scale, its progress\nand remaining challenges. In addition, we present preliminary new results on\nCepheids from the James Webb Space Telescope (JWST). The launch of JWST has\nopened a new chapter in the measurement of extragalactic distances and the\nHubble constant. JWST offers a resolution three times that of the Hubble Space\nTelescope (HST) with nearly 10 times the sensitivity. It has been suggested\nthat the discrepancy in the value of the Hubble constant based on Cepheids\ncompared to that inferred from measurements of the cosmic microwave background\nrequires new and additional physics beyond the standard cosmological model.\nJWST observations will be critical in reducing remaining systematics in the\nCepheid measurements and for confirming if new physics is indeed required.\nEarly JWST data for the galaxy, NGC 7250 show a decrease in scatter in the\nCepheid Leavitt law by a factor of two relative to existing HST data and\ndemonstrate that crowding/blending effects are a significant issue in a galaxy\nas close as 20 Mpc.\n", "  Hydrodynamical cosmological simulations are a powerful tool for accurately\npredicting the properties of the intergalactic medium (IGM) and for producing\nmock skies that can be compared against observational data. However, the need\nto resolve density fluctuation in the IGM puts a stringent requirement on the\nresolution of such simulations which in turn limits the volumes which can be\nmodelled, even on most powerful supercomputers. In this work, we present a\nnovel modeling method which combines physics-driven simulations with\ndata-driven generative neural networks to produce outputs that are\nqualitatively and statistically close to the outputs of hydrodynamical\nsimulations employing 8 times higher resolution. We show that the Ly-$\\alpha$\nflux field, as well as the underlying hydrodynamic fields, have greatly\nimproved statistical fidelity over a low-resolution simulation. Importantly,\nthe design of our neural network allows for sampling multiple realizations from\na given input, enabling us to quantify the model uncertainty. Using test data,\nwe demonstrate that this model uncertainty correlates well with the true error\nof the Ly-$\\alpha$ flux prediction. Ultimately, our approach allows for\ntraining on small simulation volumes and applying it to much larger ones,\nopening the door to producing accurate Ly-$\\alpha$ mock skies in volumes of\nHubble size, as will be probed with DESI and future spectroscopic sky surveys.\n", "  More precise measurements of galaxy clustering will be provided by the next\ngeneration of galaxy surveys such as DESI, WALLABY and SKA. To utilize this\ninformation to improve our understanding of the Universe, we need to accurately\nmodel the distribution of galaxies in their host dark matter halos. In this\nwork we present a new galaxy number density profile of haloes, which makes\npredictions for the positions of galaxies in the host halo, different to the\nwidely adopted Navarro-Frenk-White (NFW) profile, since galaxies tend to be\nfound more in the outskirts of halos (nearer the virial radius) than an NFW\nprofile. The parameterised galaxy number density profile model of haloes is fit\nand tested using the DARKSAGE semi-analytic model of galaxy formation. We find\nthat our galaxy number density profile model of haloes can accurately reproduce\nthe halo occupation distribution and galaxy two-point correlation function of\nthe DARKSAGE simulation. We also derive the analytic expressions for the\ncircular velocity and gravitational potential energy for this profile model. We\nuse the SDSS DR10 galaxy group catalogue to validate this galaxy number density\nprofile model of haloes. Compared to the NFW profile, we find that our model\nmore accurately predicts the positions of galaxies in their host halo and the\ngalaxy two-point correlation function.\n", "  Widefield surveys of the sky probe many clustered scalar fields -- such as\ngalaxy counts, lensing potential, gas pressure, etc. -- that are sensitive to\ndifferent cosmological and astrophysical processes. Our ability to constrain\nsuch processes from these fields depends crucially on the statistics chosen to\nsummarize the field. In this work, we explore the cumulative distribution\nfunction (CDF) at multiple scales as a summary of the galaxy lensing\nconvergence field. Using a suite of N-body lightcone simulations, we show the\nCDFs' constraining power is modestly better than that of the 2nd and 3rd\nmoments of the field, as they approximately capture the information from all\nmoments of the field in a concise data vector. We then study the practical\naspects of applying the CDFs to observational data, using the first three years\nof the Dark Energy Survey (DES Y3) data as an example, and compute the impact\nof different systematics on the CDFs. The contributions from the point spread\nfunction are 2-3 orders of magnitude below the cosmological signal, while those\nfrom reduced shear approximation contribute $\\lesssim 1\\%$ to the signal.\nSource clustering effects and baryon imprints contribute $1-10\\%$. Enforcing\nscale cuts to limit systematics-driven biases in parameter constraints degrades\nthese constraints a noticeable amount, and this degradation is similar for the\nCDFs and the moments. We also detect correlations between the observed\nconvergence field and the shape noise field at $13\\sigma$. We find that the\nnon-Gaussian correlations in the noise field must be modeled accurately to use\nthe CDFs, or other statistics sensitive to all moments, as a rigorous cosmology\ntool.\n", "  It is natural to wonder how far the flat pattern in the distribution of\ngalaxies and clusters of galaxies around the de Vaucoueurs Local Supercluster\nextends, and whether there are other similarly extended flat patterns in cosmic\nstructure. I present evidence of two extended flat sheet-like patterns in the\ndistributions of galaxies and clusters detected at redshifts less than 0.021.\nSheet A contains our position and is tilted 11 degrees from the supergalactic\npole, meaning the Local Supercluster is a moderately bent part of the more\nextended Sheet A. The continuation of this sheet is detected in the disjoint\nsample of galaxies at redshifts 0.021 to 0.041 and of galaxies and clusters of\ngalaxies at redshifts 0.042 to 0.085. Sheet B is 15 Mpc from us at its closest\npoint. It is detected at redshift less than 0.021 and at redshift 0.021 to\n0.041. These results make a serious case for the reality of signatures of close\nto flat extended sheet-like patterns.\n", "  We study how the bounds on the abundance of Primordial Black Holes (PBHs) and\nthe constraints to the power spectrum (PS) are modified if a non-standard\nevolution phase takes place between the end of inflation and the Standard Big\nBang (SBB). The constraints on PBH abundance and PS are computed using the new,\nfreely available, PBHBeta library, which accounts for the effects of\nnon-standard expansion and specific criteria for PBH formation. As working\nexamples, we consider three different scenarios: a pure matter-dominated (MD)\nphase, a scalar field-dominated (SFD) universe, and a stiff fluid-dominated\n(SD) scenario. While the background expansion is the same for the MD and SFD\nscenarios, the PBH formation criteria lead to different constraints to the PS.\nAdditionally, the duration of the non-standard expansion phase alters the\nbounds, with longer MD periods resulting in weaker constraints on the PS, and\nlonger SD scenarios leading to an enhanced abundance due to the dust-like\nredshifting of PBHs. The modifications to the constraints are reported in all\ncases, and we highlight those where the PS may be significantly more\nconstrained.\n", "  Inspired by the discussion in the community on possible hidden systematic\nerrors in late universe cosmological probes and non-trivial physical models\ndeveloped to reduce the Hubble tension, we investigate the Pantheon and\nPantheon+ SNe samples for possible deviations from the original $\\Lambda$CDM\nanalysis. To simultaneously account for possible systematics or deviations from\n$\\Lambda$CDM, we adopt Gaussian processes to model additional covariance while\nmaking no further assumptions on their origin. We explore both stationary and\nnon-stationarity corrections to the covariance. While small changes in the\ninferred cosmological parameters $H_0$ and $\\Omega_{m}$ can occur, we find no\nstatistically significant evidence for missing covariance. We find an upper\nlimit for the Gaussian processes amplitude $\\sigma < 0.031$ mag with $95\\%$\nconfidence, which corresponds to $20\\%$ of the average statistical error in the\nPantheon+ sample. The strongest effect we find on the inferred cosmological\nparameter posterior can reduce the statistical significance of the Hubble\ntension between Pantheon+ and Planck estimates from 5.3$\\sigma$ to 4.5$\\sigma$.\nTherefore, we conclude that the SN cosmological parameter inference is robust\nagainst the analysis modifications studied in this work.\n", "  In this paper, we investigate a potential departure in the standard dark\nmatter density evolution law, $\\rho_{dm} = \\rho_{dm,0}(1+z)^3$. The method\ninvolves considering a deformed evolution model, denoted as $\\rho_{dm} =\n\\rho_{dm,0}(1+z)^3f(z)$, and searching the presence of any deviation ($f(z)\\neq\n1$). As one may see, $f(z)$ is a general function that parametrizes a\ndigression from the standard law. We use data of baryon acoustic oscillations,\ntype I Supernovae luminosity distances, and galaxy cluster gas mass fraction\nobservations to reconstruct $f(z)$ by Gaussian process regression. Unlike\nprevious works, it enables us to investigate a possible deviation without using\na specific function to describe it. We have obtained $f(z)=1$, the standard\nmodel scenario, within $2\\sigma$ c.l. in all the considered cases.\n", "  We constrain the $\\Lambda$CDM cosmological parameter $\\sigma_{8}$ by applying\nthe extreme value statistics for galaxy cluster mass on the AMICO KiDS-DR3\ncatalog. We sample the posterior distribution of the parameters by considering\nthe likelihood of observing the largest cluster mass value in a sample of\n$N_{\\textrm{obs}} = 3644$ clusters with intrinsic richness $\\lambda^{*} > 20$\nin the redshift range $z\\in[0.10, 0.60]$. We obtain\n$\\sigma_{8}=0.90_{-0.18}^{+0.20}$, consistent within $1\\sigma$ with the\nmeasurements obtained by the Planck collaboration and with previous results\nfrom cluster cosmology exploiting AMICO KiDS-DR3. The constraints could improve\nby applying this method to forthcoming missions, such as $\\textit{Euclid}$ and\nLSST, which are expected to deliver thousands of distant and massive clusters.\n", "  We derive a minimal basis of kernels furnishing the perturbative expansion of\nthe density contrast and velocity divergence in powers of the initial density\nfield that is applicable to cosmological models with arbitrary expansion\nhistory, thereby relaxing the commonly adopted Einstein-de-Sitter (EdS)\napproximation. For this class of cosmological models, the non-linear kernels\nare at every order given by a sum of terms, each of which factorizes into a\ntime-dependent growth factor and a wavenumber-dependent basis function. We show\nhow to reduce the set of basis functions to a minimal amount, and give explicit\nexpressions up to order $n=5$. We find that for this minimal basis choice, each\nbasis function individually displays the expected scaling behaviour due to\nmomentum conservation, being non-trivial at $n\\geq 4$. This is a highly\ndesirable property for numerical evaluation of loop corrections. In addition,\nit allows us to match the density field to an effective field theory (EFT)\ndescription for cosmologies with an arbitrary expansion history, which we\nexplicitly derive at order four. We evaluate the differences to the EdS\napproximation for $\\Lambda$CDM and $w_0w_a$CDM, paying special attention to the\nirreducible cosmology dependence that cannot be absorbed into EFT terms for the\none-loop bispectrum. Finally, we provide algebraic recursion relations for a\nspecial generalization of the EdS approximation that retains its simplicity and\nis relevant for mixed hot and cold dark matter models.\n", "  We use the spherical collapse model to demonstrate that the observable\naverage density of virialized clusters depends on the properties of dark energy\nalong with the properties of gravity on cluster scales and can therefore be\nused as a probe of these properties. As an application of this approach we\nderive the predicted virialized densities and radii of cluster mass structures\nfor a wide range of values of the cosmological constant (including negative\nvalues) as a function of the turnaround redshift. For the value of\n$\\Omega_{\\Lambda,0}=-0.7$ (with $\\Omega_{m,0}=0.3$) preferred by $\\Lambda$\nsign-switching models ($\\Lambda_s\\text{CDM}$) proposed for the resolution of\nthe Hubble and $S_8$ tensions, we find an amplification of the density of\nvirialized clusters which can be as large as $80\\%$ compared to \\plcdm for a\nturnaround redshift $z_{\\text{max}} \\gtrsim 2$. Such an amplification may lead\nto more efficient early galaxy formation in this class of models in accordance\nwith the recent findings of JWST.\n", "  The exploration of the redshift drift, a direct measurement of cosmological\nexpansion, is expected to take several decades of observation with stable,\nsensitive instruments. We introduced a new method to probe cosmology which\nbypasses the long-period observation by observing the redshift difference, an\naccumulation of the redshift drift, in multiple-image gravitational lens\nsystems. With this, the photons observed in each image will have traversed\nthrough different paths between the source and the observer, and so the lensed\nimages will show different redshifts when observed at the same instance. Here,\nwe consider the impact of the underlying cosmology on the observed redshift\ndifference in gravitational lens systems, generating synthetic data for\nrealistic lens models and exploring the accuracy of determined cosmological\nparameters. We show that, whilst the redshift difference is sensitive to the\ndensities of matter and dark energy within a universe, it is independent of the\nHubble constant. Finally, we determine the observational considerations for\nusing the redshift difference as a cosmological probe, finding that one\nthousand lensed sources are enough to make robust determinations of the\nunderlying cosmological parameters. Upcoming cluster lens surveys, such as the\nEuclid, are expected to detect a sufficient number of such systems.\n", "  The non-Gaussian part of the covariance matrix of the galaxy power spectrum\ninvolves the connected four-point correlation in Fourier space, i.e.\ntrispectrum. This paper introduces a fast method to compute the non-Gaussian\npart of the covariance matrix of the galaxy power spectrum multipoles in\nredshift space at tree-level standard perturbation theory. For the tree-level\ngalaxy trispectrum, the angular integral between two wavevectors can be\nevaluated analytically by employing an FFTLog. The new implementation computes\nthe non-Gaussian covariance of the power spectrum monopole, quadrupole,\nhexadecapole and their cross-covariance in $O(10)$ seconds, for an effectively\narbitrary number of instances of cosmological and galaxy bias parameters and\nredshift, without any parallelization or acceleration. It is a large advantage\nover conventional numerical integration. We demonstrate that the computation of\nthe covariance at $k = 0.005 - 0.4\\,h\\,\\mathrm{Mpc}^{-1}$ gives results with\n$0.1 - 1\\%$ accuracy. The efficient computation of the analytic covariance can\nbe useful for future galaxy surveys, especially utilizing multi-tracer\nanalysis.\n", "  The detection of large angular scale $B$-mode in the Cosmic Microwave\nBackground (CMB) polarization signal will open a direct window into not only\nthe primary CMB anisotropies caused by the primordial gravitational waves (PGW)\noriginating in the epoch of inflation, but also the secondary anisotropies\nimprinted during the epoch of cosmic reionization. The existence of patchiness\nin the electron density during reionization produces a unique distortion in the\nCMB $B$-mode polarization, which can be distinguished from the PGW signal with\nthe aid of spatial frequency modes. In this work, we employ an $EB$ estimator\nby combining $E$-mode and $B$-mode polarization for the $\\tau$ power spectrum\nsignal generated in a photon-conserving semi-numerical reionization model\ncalled SCRIPT. We developed a Bayesian framework for the joint detection of the\nPGW and reionization signal from CMB observations and show the efficacy of this\ntechnique for upcoming CMB experiments. We find that, for our model, the $\\tau$\npower spectrum signal effectively tracks the inhomogeneous electron density\nfield, allowing for robust constraints on the patchy $B$-mode signal. Further,\nour results indicate that employing the $EB$ estimator for the $\\tau$ signal\nwill facilitate ground-based CMB-S4 to detect the patchy $B$-mode signal at\napproximately $\\geq 2\\sigma$ confidence level while observations with\nspace-based PICO will improve this detection to $\\geq 3\\sigma$ going as high as\n$\\geq 7\\sigma$ for extreme reionization models. These findings not only\nhighlight the future potential of these experiments to provide an improved\npicture of the reionization process but also have important implications\ntowards an unbiased measurement of $r$.\n", "  Weak lensing of the cosmic microwave background is rapidly emerging as a\npowerful probe of neutrinos, dark energy, and new physics. We present a fast\ncomputation of the non-linear CMB lensing power spectrum which combines\nnon-linear perturbation theory at early times with power spectrum emulation\nusing cosmological simulations at late times. Comparing our calculation with\nlightcones from the FLAMINGO 5.6 Gpc cube dark-matter-only simulation, we\nconfirm its accuracy to 1% (2%) up to multipoles L = 3000 (L = 5000) for a\nnuLambdaCDM cosmology consistent with current data. Clustering suppression due\nto small-scale baryonic phenomena such as feedback from active galactic nuclei\ncan reduce the lensing power by of order 10%. To our perturbation theory and\nemulator-based calculation we add SP(k), a new fitting function for this\nsuppression, and confirm its accuracy compared to the FLAMINGO hydrodynamic\nsimulations to 4% at L = 5000, with similar accuracy for massive neutrino\nmodels. We further demonstrate that scale-dependent suppression due to\nneutrinos and baryons approximately factorize, implying that a careful\ntreatment of baryonic feedback can limit biasing neutrino mass constraints.\n", "  We present cosmological constraints derived from peak counts, minimum counts,\nand the angular power spectrum of the Subaru Hyper Suprime-Cam first-year (HSC\nY1) weak lensing shear catalog. Weak lensing peak and minimum counts contain\nnon-Gaussian information and hence are complementary to the conventional\ntwo-point statistics in constraining cosmology. In this work, we forward-model\nthe three summary statistics and their dependence on cosmology, using a suite\nof $N$-body simulations tailored to the HSC Y1 data. We investigate systematic\nand astrophysical effects including intrinsic alignments, baryon feedback,\nmultiplicative bias, and photometric redshift uncertainties. We mitigate the\nimpact of these systematics by applying cuts on angular scales, smoothing\nscales, statistic bins, and tomographic redshift bins. By combining peaks,\nminima, and the power spectrum, assuming a flat-$\\Lambda$CDM model, we obtain\n$S_{8} \\equiv \\sigma_8\\sqrt{\\Omega_m/0.3}= 0.810^{+0.022}_{-0.026}$, a 35\\%\ntighter constraint than that obtained from the angular power spectrum alone.\nOur results are in agreement with other studies using HSC weak lensing shear\ndata, as well as with Planck 2018 cosmology and recent CMB lensing constraints\nfrom the Atacama Cosmology Telescope and the South Pole Telescope.\n", "  A major question in $\\Lambda$CDM is what this theory actually predicts for\nthe properties of subhalo populations. Subhalos are difficult to simulate and\nto find within simulations, and this propagates into uncertainty in theoretical\npredictions for satellite galaxies. We present Symfind, a new\nparticle-tracking-based subhalo finder, and demonstrate that it can track\nsubhalos to orders-of-magnitude lower masses than commonly used halo-finding\ntools, with a focus on Rockstar and consistent-trees. These longer survival\nmean that at a fixed peak subhalo mass, we find $\\approx 15\\%{-}40\\%$ more\nsubhalos within the virial radius, $R_\\textrm{vir}$, and $\\approx 35\\%-120\\%$\nmore subhalos within $R_\\textrm{vir}/4$ in the Symphony dark-matter-only\nsimulation suite. More subhalos are found as resolution is increased. We\nperform extensive numerical testing. In agreement with idealized simulations,\nwe show that the $v_{\\rm max}$ of subhalos is only resolved at high resolutions\n($n_\\textrm{peak}\\gtrsim3\\times 10^4$), but that mass loss itself can be\nresolved at much more modest particle counts ($n_\\textrm{peak}\\gtrsim4\\times\n10^3$). We show that Rockstar converges to false solutions for the mass\nfunction, radial distribution, and disruption masses of subhalos. We argue that\nour new method can trace resolved subhalos until the point of typical galaxy\ndisruption without invoking ``orphan'' modeling. We outline a concrete set of\nsteps for determining whether other subhalo finders meet the same criteria. We\npublicly release Symfind catalogs and particle data for the Symphony simulation\nsuite at \\url{http://web.stanford.edu/group/gfc/symphony}.\n", "  We present the first measurements of Lyman-$\\alpha$ (Ly$\\alpha$) forest\ncorrelations using early data from the Dark Energy Spectroscopic Instrument\n(DESI). We measure the auto-correlation of Ly$\\alpha$ absorption using 88,509\nquasars at $z>2$, and its cross-correlation with quasars using a further\n147,899 tracer quasars at $z\\gtrsim1.77$. Then, we fit these correlations using\na 13-parameter model based on linear perturbation theory and find that it\nprovides a good description of the data across a broad range of scales. We\ndetect the BAO peak with a signal-to-noise ratio of $3.8\\sigma$, and show that\nour measurements of the auto- and cross-correlations are fully-consistent with\nprevious measurements by the Extended Baryon Oscillation Spectroscopic Survey\n(eBOSS). Even though we only use here a small fraction of the final DESI\ndataset, our uncertainties are only a factor of 1.7 larger than those from the\nfinal eBOSS measurement. We validate the existing analysis methods of\nLy$\\alpha$ correlations in preparation for making a robust measurement of the\nBAO scale with the first year of DESI data.\n", "  Weak gravitational lensing of the Cosmic Microwave Background (CMB) changes\nCMB statistics in a nontrivial way, allowing for reconstruction of the lensing\npotential and the use of these reconstructed maps in determining cosmological\nparameters that affect the formation of intervening large-scale structures.\nAlthough in principle there are correlations between the primary CMB and the\nreconstructed lensing potential due to the lensing procedure itself, in\npractice CMB analyses treat these as negligible when combining these band\npowers in likelihoods. In this paper we quantify explicitly the impact on\nparameter constraints due to these cross-covariances between the lensed CMB and\nreconstructed lensing power, and we compare to the effect of including all\nlensing-induced non-Gaussian covariances, which have previously shown to impact\nparameter constraints on the order of 10%. We perform our analysis for a range\nof experimental setups, scanning over instrumental noise levels of 0.5 to 10.0\n$\\mu$K-arcmin in temperature assuming fully polarized detectors, and using a\nfixed beam size of 1.4 arcmin. When the correlations between the lensed CMB and\nlensing power are neglected, we find that forecasted constraints shift by at\nmost 3% of the error bar for a 6-parameter $\\Lambda$CDM model, and for the\nnoise levels considered in this paper. For some of the $\\Lambda$CDM extensions\nconsidered here, however, these correlations have a nontrivial impact, in some\ncases more than 10% of the error bar, even for current experimental noise\nlevels.\n", "  In the process of producing the roughly three ionizing photons per atom\nrequired to reionize the IGM, the same massive stars explode and eject metals\ninto their surroundings. While the overly sensitive Lya transition makes\nGunn-Peterson absorption of background quasar light an ineffective probe of\nreionization at z > 6, strong low-ionization transitions like the MgII doublet\nwill give rise to a detectable \"metal-line forest\", if metals pollute the\nneutral IGM. We measure the auto-correlation of the MgII forest transmission\nusing a sample of ten ground based z >= 6.80 quasar spectra probing the\nredshift range 5.96 < z_MgII < 7.42 (z_MgII,median = 6.47). The correlation\nfunction exhibits strong small-scale clustering and a pronounced peak at the\ndoublet velocity (768 km/s) arising from strong absorbers in the CGM of\ngalaxies. After these strong absorbers are identified and masked the signal is\nconsistent with noise. Our measurements are compared to a suite of models\ngenerated by combining a large hydrodynamical simulation with a semi-numerical\nreionization topology, assuming a simple uniform enrichment model. We obtain a\n95% credibility upper limit of [Mg/H] < -3.73 at z_MgII,median = 6.47, assuming\nuninformative priors on [Mg/H] and the IGM neutral fraction x_HI. Splitting the\ndata into low-z (5.96 < z_MgII < 6.47; z_MgII,median = 6.235) and high-z (6.47\n< z_MgII < 7.42; z_MgII,median = 6.72) subsamples again yields null-detections\nand 95% upper limits of [Mg/H] < -3.75 and [Mg/H] < -3.45, respectively. These\nfirst measurements set the stage for an approved JWST Cycle 2 program (GO 3526)\ntargeting a similar number of quasars that will be an order of magnitude more\nsensitive, making the Mgii forest an emerging powerful tool to deliver\nprecision constraints on the reionization and enrichment history of the\nUniverse.\n", "  In order to address fundamental questions related to the expansion history of\nthe Universe and its primordial nature with the next generation of galaxy\nexperiments, we need to model reliably large-scale structure observables such\nas the correlation function and the power spectrum. Cosmological $N$-body\nsimulations provide a reference through which we can test our models, but their\noutput suffers from sample variance on large scales. Fortunately, this is the\nregime where accurate analytic approximations exist. To reduce the variance,\nwhich is key to making optimal use of these simulations, we can leverage the\naccuracy and precision of such analytic descriptions using Control Variates\n(CV). The power of control variates stems from utilizing inexpensive but highly\ncorrelated surrogates of the statistics one wishes to measure. The stronger the\ncorrelation between the surrogate and the statistic of interest, the larger the\nvariance reduction delivered by the method. We apply two control variate\nformulations to mock catalogs generated in anticipation of upcoming data from\nthe Dark Energy Spectroscopic Instrument (DESI) to test the robustness of its\nanalysis pipeline. Our CV-reduced measurements offer a factor of 5-10\nimprovement in the measurement error compared with the raw measurements. We\nexplore the relevant properties of the galaxy samples that dictate this\nreduction and comment on the improvements we find on some of the derived\nquantities relevant to Baryon Acoustic Oscillation (BAO) analysis. We also\nprovide an optimized package for computing the power spectra and other\ntwo-point statistics of an arbitrary galaxy catalog as well as a pipeline for\nobtaining CV-reduced measurements on any of the AbacusSummit cubic box outputs.\nWe make our scripts publicly available and report a speed improvement of\n$\\sim$10 for a grid size of $N_{\\rm mesh} = 256^3$ compared with\n\\texttt{nbodykit}.\n", "  We demonstrate how a changing and negative equation-of-state (EoS) for dark\nmatter can alleviate cosmic tensions and explain the integrated Sachs-Wolfe\n(ISW) void anomaly. We discuss the effect of the model on the cosmic expansion\nhistory, growth of structure and the ISW. We show that a negative EoS at late\ntimes is able to produce a larger Hubble constant and smaller $\\sigma_{8}$,\nwhich can explain both cosmological tensions. Furthermore, the model uniquely\npredicts larger ISW at low redshift, a prediction which is in agreement with\nobservations of larger ISW from voids. The preference for a negative EoS for\ndark matter at late times is indicative of a unified dark sector and degenerate\nwith models of dark matter and dark energy interaction. Future measurements of\nthe ISW from cosmic voids can provide a unique test for this solution to\ntensions in cosmology, should they continue to persist.\n", "  At $z \\lesssim 1$, shock heating caused by large-scale velocity flows and\npossibly violent feedback from galaxy formation, converts a significant\nfraction of the cool gas ($T\\sim 10^4$ K) in the intergalactic medium (IGM)\ninto warm-hot phase (WHIM) with $T >10^5$K, resulting in a significant\ndeviation from the previously tight power-law IGM temperature-density\nrelationship, $T=T_0 (\\rho / {\\bar{\\rho}})^{\\gamma -1}$. This study explores\nthe impact of the WHIM on measurements of the low-$z$ IGM thermal state,\n$[T_0,\\gamma]$, based on the $b$-$N_{H I}$ distribution of the Lyman-$\\alpha$\nforest. Exploiting a machine learning-enabled simulation-based inference method\ntrained on Nyx hydrodynamical simulations, we demonstrate that [$T_0$,\n$\\gamma$] can still be reliably measured from the $b$-$N_{H I}$ distribution at\n$z=0.1$, notwithstanding the substantial WHIM in the IGM. To investigate the\neffects of different feedback, we apply this inference methodology to mock\nspectra derived from the IllustrisTNG and Illustris simulations at $z=0.1$. The\nresults suggest that the underlying $[T_0,\\gamma]$ of both simulations can be\nrecovered with biases as low as $|\\Delta \\log(T_0/\\text{K})| \\lesssim 0.05$\ndex, $|\\Delta \\gamma | \\lesssim 0.1$, smaller than the precision of a typical\nmeasurement. Given the large differences in the volume-weighted WHIM fractions\nbetween the three simulations (Illustris 38\\%, IllustrisTNG 10\\%, Nyx 4\\%) we\nconclude that the $b$-$N_{H I}$ distribution is not sensitive to the WHIM under\nrealistic conditions. Finally, we investigate the physical properties of the\ndetectable Lyman-$\\alpha$ absorbers, and discover that although their $T$ and\n$\\Delta$ distributions remain mostly unaffected by feedback, they are\ncorrelated with the photoionization rate used in the simulation.\n", "  Massive halos hosting groups and clusters of galaxies imprint coherent,\narcminute-scale features across the spectrophotometric sky, especially\noptical-IR clusters of galaxies, distortions in the sub-mm CMB, and extended\nsources of X-ray emission. Statistical modeling of such features often rely\nupon the evolving space-time density of dark matter halos -- the halo mass\nfunction (HMF) -- as a common theoretical ground for cosmological,\nastrophysical and fundamental physics studies. We propose a compact (eight\nparameter) representation of the HMF with readily interpretable parameters that\nstem from polynomial expansions, first in terms of log-mass, then expanding\nthose coefficients similarly in redshift. We demonstrate good ($\\sim \\! 5\\%$)\nagreement of this form, referred to as the dual-quadratic (DQ-HMF), with\nMira-Titan N-body emulator estimates for halo masses above $10^{13.7} h^{-1}\n{\\rm M}_\\odot$ over the redshift range $0.1 < z < 1.5$, present best-fit\nparameters for a Planck 2018 cosmology, and present parameter variation in the\n$\\sigma_8 - \\Omega_{\\rm m}$ plane. Convolving with a minimal mass-observable\nrelation (MOR) yields closed-form expressions for counts, mean mass, and mass\nvariance of cluster samples characterized by some observable property.\nPerforming information-matrix forecasts of potential parameter constraints from\nexisting and future surveys under different levels of systematic uncertainties,\nwe demonstrate the potential for percent-level constraints on model parameters\nby an LSST-like optical cluster survey of 300,000 clusters and a richness-mass\nvariance of $0.3^2$. Even better constraints could potentially be achieved by a\nsurvey with one-tenth the sample size but with a reduced selection property\nvariance of $0.1^2$. Potential benefits and extensions to the basic MOR\nparameterization are discussed.\n", "  Measurements of the peculiar velocities of large samples of galaxies enable\nnew tests of the standard cosmological model, including determination of the\ngrowth rate of cosmic structure that encodes gravitational physics. With the\nsize of such samples now approaching hundreds of thousands of galaxies, complex\nstatistical analysis techniques and models are required to extract cosmological\ninformation. In this paper we summarise how correlation functions between\ngalaxy velocities, and with the surrounding large-scale structure, may be\nutilised to test cosmological models. We present new determinations of the\nanalytical covariance between such correlation functions, which may be useful\nfor cosmological likelihood analyses. The statistical model we use to determine\nthese covariances includes the sample selection functions, observational noise,\ncurved-sky effects and redshift-space distortions. By comparing these\ncovariance determinations with corresponding estimates from large suites of\ncosmological simulations, we demonstrate that these analytical models recover\nthe key features of the covariance between different statistics and\nseparations, and produce similar measurements of the growth rate of structure.\n", "  The cosmic web consists of a nested hierarchy of structures: voids, walls,\nfilaments, and clusters. These structures interconnect and can encompass one\nanother, collectively shaping an intricate network. Here we introduce the\nHierarchical Spine (H-Spine) method, a framework designed to hierarchically\nidentify and characterize voids, walls, and filaments. Inspired by the\ngeometrical and dynamical constraints imposed by anisotropic gravitational\ncollapse, the H-Spine method captures the geometry and interconnectivity\nbetween cosmic structures as well as their nesting relations, offering a more\ncomplete description of the cosmic web compared to single-scale or multi-scale\napproaches.\n  To illustrate the method's utility, we present the distribution of densities\nand sizes of voids, walls and filaments identified in a 3-level hierarchical\nspace. This analysis demonstrates how each level within the hierarchy unveils\ndistinctive densities and scales inherent to cosmic web elements.\n", "  In this work, we explore the possibility that Early Dark Energy (EDE) is\ndynamical in nature and study its effect on cosmological observables. We\nintroduce a parameterization of the equation of state allowing for an equation\nof state $w$ differing considerably from cosmological constant (cc, $w={-1}$)\nand vary both the initial $w_i$ as well final $w_f$ equation of state of the\nEDE fluid. This idea is motivated by the fact that in many models of EDE, the\nscalar field may have some kinetic energy when it starts to behave like EDE\nbefore the CMB decoupling. We find that the present data have a mild preference\nfor non-cc early dark energy $( w_i= -0.78)$ using Planck+BAO+Pantheon+S$H_0$ES\ndata sets, leading to $\\Delta \\chi^2_{\\rm min}$ improvement of -2.5 at the\nexpense of one more parameter. However, $w_i$ is only weakly constrained, with\n$w_i < -0.56$ at $1\\sigma$. We argue that allowing for $w_i\\neq -1$ can play a\nrole in decreasing the $\\sigma_8$ parameter. Yet, in practice the decrease is\nonly $\\sim0.4\\sigma$ and $\\sigma_8$ is still larger than weak lensing\nmeasurements. We conclude that while promising, a dynamical EDE cannot resolve\nboth $H_0$ and $\\sigma_8$ tensions simultaneously.\n", "  Theory of the physics of the early hot universe leads to a prediction of\nbaryon acoustic oscillations that has received confirmation from the pair-wise\nseparations of galaxies in samples of hundreds of thousands of objects.\nEvidence is presented here for the discovery of a remarkably strong individual\ncontribution to the baryon acoustic oscillation (BAO) signal at z=0.068, an\nentity that is given the name Ho'oleilana. The radius of the 3D structure is\n155/h_{75} Mpc. At its core is the Bootes supercluster. The Sloan Great Wall,\nCfA Great Wall, and Hercules complex all lie within the BAO shell. The\ninterpretation of Ho'oleilana as a BAO structure with our preferred analysis\nimplies a value of the Hubble constant of 76.9+8.2-4.8 km/s/Mpc.\n", "  Using a set of high-resolution N-body simulations, we extend the unified\ndistribution model of cold dark matter (CDM) subhaloes to the warm dark\nmatter(WDM) case. The same model framework combining the unevolved mass\nfunction, unevolved radial distribution, and tidal stripping can predict the\nmass function and spatial distribution of subhaloes in both CDM and WDM\nsimulations. The dependence of the model on the DM particle property is\nuniversally parameterized through the half-mode mass of the initial power\nspectrum. Compared with the CDM model, the WDM model differs most notably in\ntwo aspects. 1) In contrast to the power-law form in CDM, the unevolved subhalo\nmass function for WDM is scale-dependent at the low mass end due to the cut-off\nin the initial power spectrum. 2) WDM subhaloes are more vulnerable to tidal\nstripping and disruption due to their lower concentrations at accretion time.\nTheir survival rate is also found to depend on the infall mass. Accounting for\nthese differences, the model predicts a final WDM subhalo mass function that is\nalso proportional to the unevolved subhalo mass function. The radial\ndistribution of WDM subhaloes is predicted to be mass-dependent. For low mass\nsubhaloes, the radial distribution is flatter in the inner halo and steeper in\nthe outer halo compared to the CDM counterpart, due to the scale-dependent\nunevolved mass function and the enhanced tidal stripping. The code for sampling\nsubhaloes according to our generalized model is available at\nhttps://github.com/fhtouma/subgen2 .\n", "  Combining cosmological probes has consolidated the standard cosmological\nmodel with percent precision, but some tensions have recently emerged when\ncertain parameters are estimated from the local or primordial Universe. The\norigin of this behaviour is still under debate, however, it is crucial to study\nas many probes as possible to cross-check the results with independent methods\nand provide additional pieces of information to the cosmological puzzle. In\nthis work, by combining several late-Universe probes (0$<z<$10), namely, Type\nIa SuperNovae, Baryon Acoustic Oscillations, Cosmic Chronometers and Gamma-Ray\nBursts, we aim to derive cosmological constraints independently of local or\nearly-Universe anchors. To test the standard cosmological model and its various\nextensions, considering an evolving Dark Energy Equation of State and the\ncurvature as a free parameter, we analyse each probe individually and all their\npossible permutations. Assuming a flat $\\Lambda$CDM model, the full combination\nof probes provides $H_0=67.2^{+3.4}_{-3.2}$ km s$^{-1}$ Mpc$^{-1}$ and\n$\\Omega_m=0.325\\pm0.015$ (68$\\%$ C.L.). Considering a flat $w$CDM model, we\nmeasure $w_0=-0.91^{+0.07}_{-0.08}$ (68$\\%$ C.L.), while by relaxing the\nflatness assumption ($\\Lambda$CDM model, 95$\\%$ C.L.) we obtain\n$\\Omega_k=0.125^{+0.167}_{-0.165}$. Finally, we analytically characterize the\ndegeneracy directions and the relative orientation of the probes' contours. By\ncalculating the Figure-of-Merit, we quantify the synergies among independent\nmethods, estimate the constraining power of each probe and identify which\nprovides the best contribution to the inference process. Pending the new\ncosmological surveys, this study confirms the exigency for new emerging probes\nin the landscape of modern cosmology.\n", "  Temperature profiles of the hot galaxy cluster intracluster medium (ICM) have\na complex non-linear structure that traditional parametric modelling may fail\nto fully approximate. For this study, we made use of neural networks, for the\nfirst time, to construct a data-driven non-parametric model of ICM temperature\nprofiles. A new deconvolution algorithm was then introduced to uncover the true\n(3D) temperature profiles from the observed projected (2D) temperature\nprofiles. An auto-encoder-inspired neural network was first trained by learning\na non-linear interpolatory scheme to build the underlying model of 3D\ntemperature profiles in the radial range of [0.02-2] R$_{500}$, using a sparse\nset of hydrodynamical simulations from the THREE HUNDRED PROJECT. A\ndeconvolution algorithm using a learning-based regularisation scheme was then\ndeveloped. The model was tested using high and low resolution input temperature\nprofiles, such as those expected from simulations and observations,\nrespectively. We find that the proposed deconvolution and deprojection\nalgorithm is robust with respect to the quality of the data, the morphology of\nthe cluster, and the deprojection scheme used. The algorithm can recover\nunbiased 3D radial temperature profiles with a precision of around 5\\% over\nmost of the fitting range. We apply the method to the first sample of\ntemperature profiles obtained with XMM{\\it -Newton} for the CHEX-MATE project\nand compared it to parametric deprojection and deconvolution techniques. Our\nwork sets the stage for future studies that focus on the deconvolution of the\nthermal profiles (temperature, density, pressure) of the ICM and the dark\nmatter profiles in galaxy clusters, using deep learning techniques in\nconjunction with X-ray, Sunyaev Zel'Dovich (SZ) and optical datasets.\n", "  We show that the recently reported cosmic gravitational wave background by\nthe NANOGrav 15-year collaboration may be the result of resonant particle\ncreation during inflation. For the appropriate amplitude and particle mass an\nenhancement of the primordial scalar power spectrum could induce Secondary\nInduced Gravitational Waves (SIGW) which will appear on a scale corresponding\nto the frequency of the NANOGrav detection. Since the resonant creation will\nhave an effect comparable to that of a delta function increment as studied by\nthe NANOGrav 15-year collaboration, our study indicates that the low-frequency\nPulsar Timing Array (PTA) data could reveal the aspects of the physics during\ninflation through the detection of a cosmic background of Gravitational Waves\n(GW).\n", "  The SPT-3G 2018 TT/TE/EE cosmic microwave background (CMB) data set\n(temperature and polarization) is used to place constraints on an axion-like\nmodel of early dark energy (EDE). These data do not favor axion-like EDE and\nplace an upper limit on the maximum fraction of the total energy density\n$f_{\\rm EDE}< 0.172$ (at the 95% confidence level, CL). This is in contrast\nwith ACT DR4 which gives $f_{\\rm EDE}=0.150^{+0.050}_{-0.078}$. When combining\nCMB measurements with measurements of the baryon acoustic oscillations and\nluminosity distance to Type Ia supernovae, we show that the tension with the\nS$H_0$ES measurement of the Hubble parameter goes up from 2.6$\\sigma$ with\nPlanck to 2.9$\\sigma$ with Planck+SPT-3G 2018. The additional inclusion of ACT\nDR4 data leads to a reduction of the tension to $1.6\\sigma$, but the\ndiscrepancy between ACT DR4 and Planck+SPT-3G 2018 casts some doubt on the\nstatistical consistency of this joint analysis. The importance of improved\nmeasurements of the CMB at both intermediate and small scales (in particular\nthe shape of the damping tail) as well as the interplay between temperature and\npolarization measurements in constraining EDE are discussed. Upcoming\nground-based measurements of the CMB will play a crucial role in determining\nwhether EDE remains a viable model to address the Hubble tension.\n", "  Galaxy peculiar velocities are excellent cosmological probes provided that\nbiases inherent to their measurements are contained before any study. This\npaper proposes a new algorithm based on an object point process model whose\nprobability density is built to statistically reduce the effects of Malmquist\nbiases and uncertainties due to lognormal errors in radial peculiar velocity\ncatalogs. More precisely, a simulated annealing algorithm permits maximizing\nthe probability density describing the point process model. The resulting\nconfigurations are bias-minimized catalogs. Tests are conducted on synthetic\ncatalogs mimicking the second and third distance modulus catalogs of the\nCosmicflows project from which peculiar velocity catalogs are derived. By\nreducing the local peculiar velocity variance in catalogs by an order of\nmagnitude, the algorithm permits recovering the expected one while preserving\nthe small-scale velocity correlation. It also permits retrieving the expected\nclustering. The algorithm is then applied to the observational catalogs. The\nlarge-scale structure reconstructed with the Wiener-filter technique applied to\nthe bias-minimized observational catalogs matches with great success the local\ncosmic web as depicted by redshift surveys of local galaxies. These new\nbias-minimized versions of peculiar velocity catalogs can be used as a starting\npoint for several studies from possibly estimating the most probable Hubble\nconstant, H0, value to the production of simulations constrained to reproduce\nthe local Universe.\n", "  Cross-correlation between weak lensing of the Cosmic Microwave Background\n(CMB) and weak lensing of galaxies offers a way to place robust constraints on\ncosmological and astrophysical parameters with reduced sensitivity to certain\nsystematic effects affecting individual surveys. We measure the angular\ncross-power spectrum between the Atacama Cosmology Telescope (ACT) DR4 CMB\nlensing and the galaxy weak lensing measured by the Dark Energy Survey (DES) Y3\ndata. Our baseline analysis uses the CMB convergence map derived from ACT-DR4\nand $\\textit{Planck}$ data, where most of the contamination due to the thermal\nSunyaev Zel'dovich effect is removed, thus avoiding important systematics in\nthe cross-correlation. In our modelling, we consider the nuisance parameters of\nthe photometric uncertainty, multiplicative shear bias and intrinsic alignment\nof galaxies. The resulting cross-power spectrum has a signal-to-noise ratio $=\n7.1$ and passes a set of null tests. We use it to infer the amplitude of the\nfluctuations in the matter distribution ($S_8 \\equiv \\sigma_8 (\\Omega_{\\rm\nm}/0.3)^{0.5} = 0.782\\pm 0.059$) with informative but well-motivated priors on\nthe nuisance parameters. We also investigate the validity of these priors by\nsignificantly relaxing them and checking the consistency of the resulting\nposteriors, finding them consistent, albeit only with relatively weak\nconstraints. This cross-correlation measurement will improve significantly with\nthe new ACT-DR6 lensing map and form a key component of the joint 6x2pt\nanalysis between DES and ACT.\n", "  One of the most exciting and pressing issues in cosmology today is the\ndiscrepancy between some measurements of the local Hubble constant and other\nvalues of the expansion rate inferred from the cosmic microwave background\n(CMB) radiation. Resolving these differences holds the potential for the\ndiscovery of new physics beyond the standard model of cosmology: Lambda Cold\nDark Matter (LCDM), a successful model that has been in place for more than 20\nyears. Given both the fundamental significance of this outstanding discrepancy,\nand the many-decades-long effort to increase the accuracy of the extragalactic\ndistance scale, it is critical to demonstrate that the local measurements are\nconvincingly free from residual systematic errors. We review the progress over\nthe past quarter century in measurements of the local value of the Hubble\nconstant, and discuss remaining challenges. Particularly exciting are new data\nfrom the James Webb Space Telescope (JWST). JWST is delivering high-resolution\nnear-infrared imaging data to both test for and to address directly several of\nthe systematic uncertainties that have historically limited the accuracy of the\nextragalactic distance scale. We present an overview of our new JWST program to\nobserve Cepheids, TRGB and JAGB stars. For the first galaxy in our program, NGC\n7250, the high-resolution JWST images demonstrate that many of the Cepheids\nobserved with the Hubble Space Telescope (HST) are significantly crowded by\nnearby neighbors. Avoiding the more significantly crowded variables, the\nscatter in the JWST near-infrared (NIR) Cepheid period-luminosity relation is\ndecreased by a factor of two compared to those from HST, illustrating the power\nof JWST for improvements to local measurements of Ho. Ultimately, these data\nwill either confirm the standard model, or provide robust evidence for the\ninclusion of additional new physics.\n", "  Future constraints of cosmological parameters from Type Ia supernovae (SNe\nIa) will depend on the use of photometric samples, those samples without\nspectroscopic measurements of the SNe Ia. There is a growing number of analyses\nthat show that photometric samples can be utilised for precision cosmological\nstudies with minimal systematic uncertainties. To investigate this claim, we\nperform the first analysis that combines two separate photometric samples, SDSS\nand Pan-STARRS, without including a low-redshift anchor. We evaluate the\nconsistency of the cosmological parameters from these two samples and find they\nare consistent with each other to under $1\\sigma$. From the combined sample,\nnamed Amalgame, we measure $\\Omega_M = 0.328 \\pm 0.024$ with SN alone in a flat\n$\\Lambda$CDM model, and $\\Omega_M = 0.330 \\pm 0.018$ and $w =\n-1.016^{+0.055}_{-0.058}$ when combining with a Planck data prior and a flat\n$w$CDM model. These results are consistent with constraints from the Pantheon+\nanalysis of only spectroscopically confirmed SNe Ia, and show that there are no\nsignificant impediments to analyses of purely photometric samples of SNe Ia.\n", "  All lens modeling methods, simply-parametrized, hybrid, and free-form, use\nassumptions to reconstruct galaxy clusters with multiply imaged sources, though\nthe nature of these assumptions (priors) can differ considerably between\nmethods. This raises an important question in strong lens modeling: how much\ninformation about the mass model comes from the lensed images themselves, and\nhow much is a consequence of model priors. One way to assess the relative\ncontributions of the lensing data vs. model priors is to estimate global lens\nproperties through images alone, without any prior assumptions about the mass\ndistribution. This is our approach. We use 200 mock cluster lenses, half of\nwhich have substructures which vary from clumpy and compact to smooth and\nextended; a simulated cluster Ares; and real clusters Abell 1689 and\nRXJ1347.5-1145 to show that the center, ellipticity, and position angle can be\nestimated quite well, and nearly perfectly for weakly substructured clusters,\nimplying that the recovery of these properties is largely driven by the images,\nnot priors. However, the correlation between the true and image-estimated\namount of substructure has a lot of scatter, suggesting that multiple images do\nnot uniquely constrain substructure. Therefore in general, lens model priors\nhave a stronger effect on smaller scales. Our analysis partly explains why\nreconstructions using different methodologies can produce qualitatively\ndifferent mass maps on substructure scales. Our analysis is not meant to aide\nor replace lens inversion methods, but only to investigate what cluster\nproperties are constrained with multiple images.\n", "  Previous studies have revealed that the estimated probability of\ngalaxy-galaxy strong lensing in observed galaxy clusters exceeds the\nexpectations from the $\\Lambda$ Cold Dark Matter cosmological model by one\norder of magnitude. We aim to understand the origin of this excess by analyzing\na larger set of simulated galaxy clusters and investigating how the theoretical\nexpectations vary under different adopted prescriptions and numerical\nimplementations of star formation and feedback in simulations. We perform a\nray-tracing analysis of 324 galaxy clusters from the Three Hundred project,\ncomparing the Gadget-X and Gizmo-Simba runs. These simulations, which start\nfrom the same initial conditions, are performed with different implementations\nof hydrodynamics and galaxy formation models tailored to match different\nobservational properties of the Intra-Cluster-Medium and cluster galaxies. We\nfind that galaxies in the Gizmo-Simba simulations develop denser stellar cores\nthan their Gadget-X counterparts. Consequently, their probability for\ngalaxy-galaxy strong lensing is higher by a factor of $\\sim 3$. This increment\nis still insufficient to fill the gap with observations, as a discrepancy by a\nfactor $\\sim 4$ still persists. In addition, we find that several simulated\ngalaxies have Einstein radii that are too large compared to observations. We\nconclude that a persistent excess of galaxy-galaxy strong lensing exists in\nobserved galaxy clusters. The origin of this discrepancy with theoretical\npredictions is still unexplained in the framework of the cosmological\nhydrodynamical simulations. This might signal a hitherto unknown issue with\neither the simulation methods or our assumptions regarding the standard\ncosmological model.\n", "  Upcoming emission-line spectroscopic surveys, such as Euclid and the Roman\nSpace Telescope, will be affected by systematic effects due to the presence of\ninterlopers: galaxies whose redshift and distance from us are miscalculated due\nto line confusion in their emission spectra. Particularly pernicious are\ninterlopers involving the confusion between two lines with close emitted\nwavelengths, like H$\\beta$ emitters confused as \\oiii, since those are strongly\nspatially correlated with the target galaxies. They introduce a particular\npattern in the 3D distribution of the observed galaxy catalog that can shift\nthe position of the BAO peak in the galaxy correlation function and bias any\ncosmological analysis performed with that sample. Here we present a novel\nmethod to predict the fraction of interlopers in a galaxy catalog, using Graph\nNeural Networks (GNNs) to learn the posterior distribution of the interloper\nfraction while marginalizing over cosmology and galaxy bias. The method is\ndeveloped using simulations with halos acting as a proxy for galaxies. The GNN\ncan infer the mean and standard deviation of the posterior distribution of\ninterloper fraction using small-scale information that is usually not\nconsidered in cosmological analyses. The injection of large-scale information\ninto the graph as a global attribute improves the performance of the GNN when\nmarginalizing over cosmology.\n", "  Superclusters are the largest massive structures in the cosmic web on tens to\nhundreds of megaparsecs (Mpc) scales. They are the largest assembly of galaxy\nclusters in the Universe. Apart from a few detailed studies of such structures,\ntheir evolutionary mechanism is still an open question. In order to address and\nanswer the relevant questions, a statistically significant, large catalog of\nsuperclusters covering a wide range of redshifts and sky areas is essential.\nHere, we present a large catalog of 662 superclusters identified using a\nmodified $\\textit{ Friends of Friends}$ algorithm applied on the WHL\n(Wen-Han-Liu) cluster catalog within a redshift range of $0.05 \\le z \\le 0.42$.\nWe name the most massive supercluster at $z \\sim 0.25$ as $\\textit{Einasto\nSupercluster}$. We find that the median mass of superclusters is $\\sim 5.8\n\\times 10^{15}$ M$_{\\odot}$ and median size $\\sim 65$ Mpc. We find that the\nsupercluster environment slightly affects the growth of clusters. We compare\nthe properties of the observed superclusters with the mock superclusters\nextracted from the Horizon Run 4 cosmological simulation. The properties of\nsuperclusters in mocks and observations are in broad agreement. We find that\nthe density contrast of a supercluster is correlated with its maximum extent\nwith a power law index, $\\alpha \\sim -2$. The phase-space distribution of mock\nsuperclusters shows that, on average, $\\sim 90\\%$ part of a supercluster has a\ngravitational influence on its constituents. We also show mock halos' average\nnumber density and peculiar velocity profiles in and around the superclusters.\n", "  We present two galaxy samples, selected from DESI Legacy Imaging Surveys (LS)\nDR9, with approximately 20,000 square degrees of coverage and spectroscopic\nredshift distributions designed for cross-correlations such as with CMB\nlensing, galaxy lensing, and the Sunyaev-Zel'dovich effect. The first sample is\nidentical to the DESI Luminous Red Galaxy (LRG) sample, and the second sample\nis an extended LRG sample with 2-3 times the DESI LRG density. We present the\nimproved photometric redshifts, tomographic binning and their spectroscopic\nredshift distributions and imaging systematics weights, and magnification bias\ncoefficients. The catalogs and related data products will be made publicly\navailable. The cosmological constraints using this sample and Planck lensing\nmaps are presented in a companion paper. We also make public the new set of\ngeneral-purpose photometric redshifts trained using DESI spectroscopic\nredshifts, which are used in this work, for all galaxies in LS DR9.\n", "  The clustering of matter, as measured by the matter power spectrum, informs\nus about dark matter and cosmology, as well as baryonic effects on the\ndistribution of matter in the universe. Using cosmological hydrodynamical\nsimulations from the cosmo-OWLS and BAHAMAS simulation projects, we investigate\nthe contribution of power in haloes with various masses, defined by particles\nwithin some overdensity region, to the full power spectrum, as well as the\npower ratio between baryonic and dark matter only (DMO) simulations for a\nmatched (between simulations) and an unmatched set of haloes. We find that the\npresence of AGN feedback suppresses the power on all scales for haloes of all\nmasses examined ($10^{11.25}\\leq M_{500,\\mathrm{crit}}\\leq\n10^{14.75}\\,\\mathrm{M_\\odot}/h$), by ejecting matter from within\n$r_{500,\\mathrm{c}}$ to $r_{200,\\mathrm{m}}$ and potentially beyond in massive\nhaloes ($M_{500,\\mathrm{crit}}\\gtrsim 10^{13}\\,\\mathrm{M_\\odot}/h$), and likely\nimpeding the growth of lower-mass haloes as a consequence. A lower AGN feedback\ntemperature drastically changes the behaviour of high-mass haloes\n($M_{500,\\mathrm{crit}}\\geq 10^{13.25}\\,\\mathrm{M_\\odot}/h$), damping the\neffects of AGN feedback at small scales, $k\\,\\gtrsim\\,4\\,h\\mathrm{\\,Mpc^{-1}}$.\nFor $k\\,\\lesssim\\,3\\,h\\mathrm{\\,Mpc^{-1}}$, group-sized haloes\n($10^{14\\pm0.25}\\, \\mathrm{M_\\odot}/h$) dominate the power spectrum, while on\nsmaller scales the combined contributions of lower-mass haloes to the full\npower spectrum rise above that of the group-sized haloes. Finally, we present a\nmodel for the power suppression due to feedback, which combines observed mean\nhalo baryon fractions with halo mass fractions and halo-matter cross-spectra\nextracted from dark matter only simulations to predict the power suppression to\npercent-level accuracy down to $k\\,\\approx\\,10\\,h\\mathrm{\\,Mpc^{-1}}$ without\nany free parameters.\n", "  Upcoming imaging surveys will use weak gravitational lensing to study the\nlarge-scale structure of the Universe, demanding sub-percent accuracy for\nprecise cosmic shear measurements. We present a new differentiable\nimplementation of our perturbation-based shear estimator (FPFS), using JAX,\nwhich is publicly available as part of a new suite of analytic shear algorithms\ncalled AnaCal. This code can analytically calibrate the shear response of any\nnonlinear observable constructed with the FPFS shapelets and detection modes\nutilizing auto-differentiation (AD), generalizing the formalism to include a\nfamily of shear estimators with corrections for detection and selection biases.\nUsing the AD capability of JAX, it calculates the full Hessian matrix of the\nnon-linear observables, which improves the previously presented second-order\nnoise bias correction in the shear estimation. As an illustration of the power\nof the new AnaCal framework, we optimize the effective galaxy number density in\nthe space of the generalized shear estimators using an LSST-like galaxy image\nsimulation for the ten-year LSST. For the generic shear estimator, the\nmagnitude of the multiplicative bias $|m|$ is below $3\\times 10^{-3}$ (99.7%\nconfidence interval), and the effective galaxy number density is improved by\n5%. We also discuss some planned future additions to the AnaCal software suite\nto extend its applicability beyond the FPFS measurements.\n", "  The $\\sim 5\\sigma$ mismatch between the value of the Hubble parameter\nmeasured by SH0ES and the one inferred from the inverse distance ladder (IDL)\nconstitutes the biggest tension afflicting the standard model of cosmology,\nwhich could be pointing to the need of physics beyond $\\Lambda$CDM. In this\npaper we study the background history required to solve the $H_0$ tension if we\nconsider standard prerecombination physics, paying special attention to the\nrole played by the data on baryon acoustic oscillations (BAO) employed to build\nthe IDL. We show that the anisotropic BAO data favor an ultra-late-time\n(phantom-like) enhancement of $H(z)$ at $z\\lesssim 0.2$, accompanied by a\ntransition in the absolute magnitude of supernovae of Type Ia $M(z)$ in the\nsame redshift range. This agrees with previous findings in the literature. The\neffective dark energy (DE) density must be smaller than in the standard model\nat higher redshifts. Instead, when angular BAO data (claimed to be less subject\nto model dependencies) is employed in the analysis, we find that the increase\nof $H(z)$ starts at much higher redshifts, typically in the range $z\\sim\n0.5-0.8$. In this case, $M(z)$ could experience also a transition (although\nmuch smoother) and the effective DE density becomes negative at $z\\gtrsim 2$.\nBoth scenarios require a violation of the weak energy condition (WEC), but\nleave an imprint on completely different redshift ranges and might also have a\ndifferent impact on the perturbed observables. They allow for the effective\ncrossing of the phantom divide. Finally, we employ two alternative methods to\nshow that current data from cosmic chronometers do not exclude the violation of\nthe WEC, but do not add any strong evidence in its favor neither. Our work puts\nthe accent on the utmost importance of the choice of the BAO data set in the\nstudy of the possible solutions to the $H_0$ tension.\n", "  A number of recent studies have found evidence for a tension between\nobservations of large-scale structure (LSS) and the predictions of the standard\nmodel of cosmology with the cosmological parameters fit to the cosmic microwave\nbackground (CMB). The origin of this '$S_8$ tension' remains unclear, but\npossibilities include new physics beyond the standard model, unaccounted for\nsystematic errors in the observational measurements and/or uncertainties in the\nrole that baryons play. Here we carefully examine the latter possibility using\nthe new FLAMINGO suite of large-volume cosmological hydrodynamical simulations.\nWe project the simulations onto observable harmonic space and compare with\nobservational measurements of the power and cross-power spectra of cosmic\nshear, CMB lensing, and the thermal Sunyaev-Zel'dovich (tSZ) effect. We explore\nthe dependence of the predictions on box size and resolution, cosmological\nparameters including the neutrino mass, and the efficiency and nature of\nbaryonic 'feedback'. Despite the wide range of astrophysical behaviours\nsimulated, we find that baryonic effects are not sufficiently large to remove\nthe $S_8$ tension. Consistent with recent studies, we find the CMB lensing\npower spectrum is in excellent agreement with the standard model, whilst the\ncosmic shear power spectrum, tSZ effect power spectrum, and the cross-spectra\nbetween shear, CMB lensing, and the tSZ effect are all in varying degrees of\ntension with the CMB-specified standard model. These results suggest that some\nmechanism is required to slow the growth of fluctuations at late times and/or\non non-linear scales, but that it is unlikely that baryon physics is driving\nthis modification.\n", "  Third-order lensing statistics contain a wealth of cosmological information\nthat is not captured by second-order statistics. However, the computational\neffort for estimating such statistics on forthcoming stage IV surveys is\nprohibitively expensive. We derive and validate an efficient estimation\nprocedure for the three-point correlation function (3PCF) of polar fields such\nas weak lensing shear. We then use our approach to measure the shear 3PCF and\nthe third-order aperture mass statistics on the KiDS-1000 survey. We construct\nan efficient estimator for third-order shear statistics which builds on the\nmultipole decomposition of the 3PCF. We then validate our estimator on mock\nellipticity catalogs obtained from $N$-body simulations. Finally, we apply our\nestimator to the KiDS-1000 data and present a measurement of the third-order\naperture statistics in a tomographic setup. Our estimator provides a speedup of\na factor of $\\sim$ 100-1000 compared to the state-of-the-art estimation\nprocedures. It is also able to provide accurate measurements for squeezed and\nfolded triangle configurations without additional computational effort. We\nreport a significant detection of the tomographic third-order aperture mass\nstatistics in the KiDS-1000 data $(\\mathrm{S/N}=6.69)$. Our estimator will make\nit computationally feasible to measure third-order shear statistics in\nforthcoming stage IV surveys. Furthermore, it can be used to construct\nempirical covariance matrices for such statistics.\n", "  A key challenge in the search for primordial B-modes is the presence of\npolarized Galactic foregrounds, especially thermal dust emission.\nPower-spectrum-based analysis methods generally assume the foregrounds to be\nGaussian random fields when constructing a likelihood and computing the\ncovariance matrix. In this paper, we investigate how non-Gaussianity in the\ndust field instead affects CMB and foreground parameter inference in the\ncontext of inflationary B-mode searches, capturing this effect via\nmodifications to the dust power-spectrum covariance matrix. For upcoming\nexperiments such as the Simons Observatory, we find no dependence of the\ntensor-to-scalar ratio uncertainty $\\sigma(r)$ on the degree of dust\nnon-Gaussianity or the nature of the dust covariance matrix. We provide an\nexplanation of this result, noting that when frequency decorrelation is\nnegligible, dust in mid-frequency channels is cleaned using high-frequency data\nin a way that is independent of the spatial statistics of dust. We show that\nour results hold also for non-zero levels of frequency decorrelation that are\ncompatible with existing data. We find, however, that neglecting the impact of\ndust non-Gaussianity in the covariance matrix can lead to inaccuracies in\ngoodness-of-fit metrics. Care must thus be taken when using such metrics to\ntest B-mode spectra and models, although we show that any such problems can be\nmitigated by using only cleaned spectrum combinations when computing\ngoodness-of-fit statistics.\n", "  The flux ratios of gravitationally lensed quasars provide a powerful probe of\nthe nature of dark matter. Importantly, these ratios are sensitive to\nsmall-scale structure, irrespective of the presence of baryons. This\nsensitivity may allow us to study the halo mass function even below the scales\nwhere galaxies form observable stars. For accurate measurements, it is\nessential that the quasar's light is emitted from a physical region of the\nquasar with an angular scale of milli-arcseconds or larger; this minimizes\nmicrolensing effects by stars within the deflector. The warm dust region of\nquasars fits this criterion, as it has parsec-size physical scales and\ndominates the spectral energy distribution of quasars at wavelengths greater\nthan 10$\\mu$m. The JWST Mid-Infrared Instrument (MIRI) is adept at detecting\nredshifted light in this wavelength range, offering both the spatial resolution\nand sensitivity required for accurate gravitational lensing flux ratio\nmeasurements. Here, we introduce our survey designed to measure the warm dust\nflux ratios of 31 lensed quasars. We discuss the flux-ratio measurement\ntechnique and present results for the first target, DES J0405-3308. We find\nthat we can measure the quasar warm dust flux ratios with 3% precision. Our\nsimulations suggest that this precision makes it feasible to detect the\npresence of 10$^7$ M$_\\odot$ dark matter halos at cosmological distances. Such\nhalos are expected to be completely dark in Cold Dark Matter models.\n", "  We propose a new framework for the analysis of current and future\ncosmological surveys, which combines perturbative methods (PT) on large scales\nwith conditional simulation-based implicit inference (SBI) on small scales.\nThis enables modeling of a wide range of statistics across all scales using\nonly small-volume simulations, drastically reducing computational costs, and\navoids the assumption of an explicit small-scale likelihood. As a\nproof-of-principle for this hybrid simulation-based inference (HySBI) approach,\nwe apply it to dark matter density fields and constrain cosmological parameters\nusing both the power spectrum and wavelet coefficients, finding promising\nresults that significantly outperform classical PT methods. We additionally lay\nout a roadmap for the next steps necessary to implement HySBI on actual survey\ndata, including consideration of bias, systematics, and customized simulations.\nOur approach provides a realistic way to scale SBI to future survey volumes,\navoiding prohibitive computational costs.\n", "  Relative astrometric shifts between multiply lensed images provide a valuable\ntool to investigate haloes in the intergalactic space. In strong lens systems\nin which a single lens plays the primary role in producing multiple images, the\ngravitational force exerted by line-of-sight (LOS) haloes can slightly change\nthe relative positions of multiply lensed images produced by the dominant lens.\nIn such cases, a LOS halo positioned sufficiently far from the dominant lens\nalong the LOS can create a pattern in the reduced deflection angle that\ncorresponds to the B-mode (magnetic or divergence-free mode). By measuring both\nthe B-mode and E-mode (electric or rotation-free mode), we can determine the\nLOS distance ratios, as well as the 'bare' convergence and shear perturbations\nin the absence of the dominant lens. However, scale variations in the distance\nratio lead to mass-sheet transformations in the background lens plane,\nintroducing some uncertainty in the distance ratio estimation. This uncertainty\ncan be significantly reduced by measuring the time delays between the lensed\nimages. Additionally, if we obtain the redshift values of both the dominant and\nperturbing haloes, along with the time delays between the multiply lensed\nimages that are affected by the haloes, the B-mode can break the degeneracy\nrelated to mass-sheet transformations in both the foreground and background\nlens planes. Therefore, measuring the astrometric lensing B-mode has the\npotential to substantially decrease the uncertainty in determining the Hubble\nconstant.\n", "  Galaxy cluster mergers are natural consequences of the structure formation in\nthe Universe. Such events involve a large amount of energy ($\\sim 10^{63}$ erg)\ndissipated during the process. Part of this energy can be channelled in\nparticle acceleration and magnetic field amplification, enhancing non-thermal\nemission of the intra- and inter-cluster environment. Recently, low-frequency\nobservations have detected a bridge of diffuse synchrotron emission connecting\ntwo merging galaxy clusters, Abell 399 and Abell 401. Such a result provides\nclear observational evidence of relativistic particles and magnetic fields\nin-between clusters. In this work, we have used LOw Frequency ARray (LOFAR)\nobservations at 144 MHz to study for the first time the polarized emission in\nthe A399-A401 bridge region. No polarized emission was detected from the bridge\nregion. Assuming a model where polarization is generated by multiple shocks,\ndepolarization can be due to Faraday dispersion in the foreground medium with\nrespect to the shocks. We constrained its Faraday dispersion to be greater than\n0.10 rad m$^{-2}$ at 95% confidence level, which corresponds to an average\nmagnetic field of the bridge region greater than 0.46 nG (or 0.41 nG if we\ninclude regions of the Faraday spectrum that are contaminated by Galactic\nemission). This result is largely consistent with the predictions from\nnumerical simulations for Mpc regions where the gas density is $\\sim 300$ times\nlarger than the mean gas density.\n", "  We investigate the possible anisotropy of the universe using the most\nup-to-date type Ia supernovae, i.e. the Pantheon+ compilation. We fit the full\nPantheon+ data with the dipole-modulated $\\Lambda$CDM model, and find that it\nis well consistent with a null dipole. We further divide the full sample into\nseveral subsamples with different high-redshift cutoff $z_c$. It is shown that\nthe dipole appears at $2\\sigma$ confidence level only if $z_c\\leq 0.1$, and in\nthis redshift region the dipole is very stable, almost independent of the\nspecific value of $z_c$. For $z_c=0.1$, the dipole amplitude is\n$D=1.0_{-0.4}^{+0.4}\\times 10^{-3}$, pointing towards $(l,b)=(334.5_{\\\n-21.6^{\\circ}}^{\\circ +25.7^{\\circ}},16.0_{\\ -16.8^{\\circ}}^{\\circ\n+27.1^{\\circ}})$, which is about $65^{\\circ}$ away from the CMB dipole. This\nimplies that the full Pantheon+ is consistent with a large-scale isotropic\nuniverse, but the low-redshift anisotropy couldn't be purely explained by the\npeculiar motion of the local universe.\n", "  We use the distance sum rule (DSR) method to constrain the spatial curvature\nof the Universe with a large sample of 161 strong gravitational lensing (SGL)\nsystems, whose distances are calibrated from the Pantheon compilation of type\nIa supernovae (SNe Ia) using deep learning. To investigate the possible\ninfluence of mass model of the lens galaxy on constraining the curvature\nparameter $\\Omega_k$, we consider three different lens models. Results show\nthat a flat Universe is supported in the singular isothermal sphere (SIS) model\nwith the parameter $\\Omega_k=0.049^{+0.147}_{-0.125}$. While in the power-law\n(PL) model, a closed Universe is preferred at $\\sim 3\\sigma$ confidence level,\nwith the parameter $\\Omega_k=-0.245^{+0.075}_{-0.071}$. In extended power-law\n(EPL) model, the 95$\\%$ confidence level upper limit of $\\Omega_k$ is $<0.011$.\nAs for the parameters of the lens models, constrains on the three models\nindicate that the mass profile of the lens galaxy could not be simply described\nby the standard SIS model.\n", "  We carry out a statistical analysis of the spatial distribution of galaxies\nat cosmological redshifts $0.16 \\leq z \\leq 0.47$ based on the SDSS\\ DR12\\ LOWZ\ncatalogue. Our aim is to search and study possible large-scale quasi-regular\nstructures embedded in the {\\it cosmic web}. We calculate projections of the\nCartesian galaxy coordinates on different axes (directions) densely covering\ncertain regions in the sky to look for special directions along which\none-dimensional distributions of the projections contain significant\nquasi-periodic components. These components appear as peaks in the power\nspectra and lie in a narrow range of wave numbers $0.05 < k < 0.07$. Particular\nattention is paid to the evaluation of the significance of the peaks. It is\nfound that the significance of the dominant peaks for some selected directions\nexceeds $(4 - 5)\\sigma$. In order to reduce possible selection effects, we\ncreate a mock homogeneous catalogue of spatial distribution of galaxies by\nadding a random set of artificial objects (points) to the real galaxies under\nstudy. The power spectrum of this cumulative model data also demonstrates\nsignificant peak corresponding to approximately the same scale. As a result we\nassume the existence of an anisotropic cosmological quasi-periodic structure\nwith characteristic scale $(116 \\pm 10)~h^{-1}$~Mpc.\n", "  We explore the relationship between the thermal Sunyaev-Zel'dovich (tSZ)\npower spectrum amplitude and the halo mass and redshift of galaxy clusters in\nSouth Pole Telescope (SPT) data, in comparison with three $N$-body simulations\ncombined with semi-analytical gas models of the intra-cluster medium.\nSpecifically, we calculate both the raw and fractional power contribution to\nthe full tSZ power spectrum amplitude at $\\ell = 3000$ from clusters as a\nfunction of halo mass and redshift. We use nine mass bins in the range $1\n\\times 10^{14}\\ M_\\odot\\ h^{-1} < M_{500} < 2 \\times 10^{15}\\ M_\\odot\\ h^{-1}$,\nand two redshift bins defined by $0.25 < z < 0.59$ and $0.59 < z < 1.5$. We\nadditionally divide the raw power contribution in each mass bin by the number\nof clusters in that bin, as a metric for comparison of different gas models. At\nlower masses, the SPT data prefers a model that includes a mass-dependent bound\ngas fraction component and relatively high levels of AGN feedback, whereas at\nhigher masses there is a preference for a model with a lower amount of feedback\nand a complete lack of non-thermal pressure support. The former provides the\nbest fit to the data overall, in regards to all metrics for comparison. Still,\ndiscrepancies exist and the data notably exhibits a steep mass-dependence which\nall of the simulations fail to reproduce. This suggests the need for additional\nmass- and redshift-dependent adjustments to the gas models of each simulation,\nor the potential presence of contamination in the data at halo masses below the\ndetection threshold of SPT-SZ. Furthermore, the data does not demonstrate\nsignificant redshift evolution in the per-cluster tSZ power spectrum\ncontribution, in contrast to self-similar model predictions.\n", "  We present cosmology results obtained from a blind joint analysis of the\nabundance, projected clustering, and weak lensing of galaxy clusters measured\nfrom the Sloan Digital Sky Survey (SDSS) redMaPPer cluster catalog and the\nHyper-Suprime Cam (HSC) Year3 shape catalog. We present a full-forward model\nfor the cluster observables, which includes empirical modeling for the\nanisotropic boosts on the lensing and clustering signals of optical clusters.\nWe validate our analysis via mock cluster catalogs which include observational\nsystematics, such as the projection effect and the effect of baryonic feedback,\nand find that our analysis can robustly constrain cosmological parameters in an\nunbiased manner without any informative priors on our model parameters. The\njoint analysis of our observables in the context of the flat $\\Lambda$CDM model\nresults in cosmological constraints for $S_8\\equiv \\sigma_8 \\sqrt{\\Omega_{\\rm\nm} / 0.3}=0.816^{+0.041}_{-0.039}$. Our result is consistent with the $S_8$\ninference from other cosmic microwave background- and large scale\nstructure-based cosmology analyses, including the result from the \\emph{Planck}\n2018 primary CMB analysis.\n", "  We present a free-form lens model for the multiply lensed quasar in the\ngalaxy cluster SDSS J$1004+4112$. Our lens model makes minimal assumptions\nabout the distribution of mass in the lens plane. We pay particular attention\nto the model uncertainties on the predicted time delay, originating from the\nparticular configuration of model variables. Taking into account this\nuncertainty, we obtain a value of the Hubble constant of $H_0= 74^{+9}_{-13}$km\ns$^{-1}$ Mpc$^{-1}$, consistent with independent recent estimates. The\npredicted time delay between the central image E and image C (the first to\narrive), is $\\Delta T_{E-C}=3200\\pm 200$ days. Future measurements of $\\Delta\nT_{E-C}$ will allow to impose a tighter constrain on $H_0$ from this\ncluster-QSO system.\n", "  Simulation-based inference (SBI) is a promising approach to leverage high\nfidelity cosmological simulations and extract information from the\nnon-Gaussian, non-linear scales that cannot be modeled analytically. However,\nscaling SBI to the next generation of cosmological surveys faces the\ncomputational challenge of requiring a large number of accurate simulations\nover a wide range of cosmologies, while simultaneously encompassing large\ncosmological volumes at high resolution. This challenge can potentially be\nmitigated by balancing the accuracy and computational cost for different\ncomponents of the the forward model while ensuring robust inference. To guide\nour steps in this, we perform a sensitivity analysis of SBI for galaxy\nclustering on various components of the cosmological simulations: gravity\nmodel, halo-finder and the galaxy-halo distribution models (halo-occupation\ndistribution, HOD). We infer the $\\sigma_8$ and $\\Omega_m$ using galaxy power\nspectrum multipoles and the bispectrum monopole assuming a galaxy number\ndensity expected from the luminous red galaxies observed using the Dark Energy\nSpectroscopy Instrument (DESI). We find that SBI is insensitive to changing\ngravity model between $N$-body simulations and particle mesh (PM) simulations.\nHowever, changing the halo-finder from friends-of-friends (FoF) to Rockstar can\nlead to biased estimate of $\\sigma_8$ based on the bispectrum. For galaxy\nmodels, training SBI on more complex HOD leads to consistent inference for less\ncomplex HOD models, but SBI trained on simpler HOD models fails when applied to\nanalyze data from a more complex HOD model. Based on our results, we discuss\nthe outlook on cosmological simulations with a focus on applying SBI approaches\nto future galaxy surveys.\n", "  We analyze the formation of the redshifted hyperfine structure line 21-cm of\nhydrogen atom in the Dark Ages, Cosmic Dawn, and Reionization epochs. The\nevolution of the global differential brightness temperature in this line was\ncomputed to study its dependence on the values of cosmological parameters and\nphysical conditions in the intergalactic medium. Variations of the depth of the\nDark Ages absorption line at $z\\sim80$ with variations of the cosmological\nparameters $\\Omega_b$, $\\Omega_{cdm}$, $\\Omega_{\\Lambda}$, $\\Omega_K$ and $H_0$\nare studied. The standard model with post-Planck parameters predicts a value of\nthe differential brightness temperature in the center of the absorption line\n$\\sim$30-50 mK. The profile of this line can be quite another in the\nnon-standard cosmological models, which include the annihilating or decaying\ndark matter, a primordial stochastic magnetic field, etc. It can be shallower\nor be an emission bump instead of an absorption trough. It is also shown that\nthe position and depth of the Cosmic Dawn absorption line formed at 10<z<30,\ndue to the Wouthuysen-Field effect, is mainly defined by the spectral energy\ndistribution of the first sources of light. If reionization occurs at\n$z_{ri}=7\\pm1$, then the differential brightness temperature in the center of\nthis line is $\\sim$80 mK. During the reionization, the emission with an\namplitude of $\\sim$20 mK is possible. It is also shown that the temperature,\ndensity, and degree of ionization of the baryonic component are decisive in\ncalculating the intensity of the 21-cm absorption/emission line from these\nepochs.\n", "  Searches for primordial non-Gaussianity in cosmological perturbations are a\nkey means of revealing novel primordial physics. However, robustly extracting\nsignatures of primordial non-Gaussianity from non-linear scales of the\nlate-time Universe is an open problem. In this paper, we apply k-Nearest\nNeighbor cumulative distribution functions, kNN-CDFs, to the\n\\textsc{quijote-png} simulations to explore the sensitivity of kNN-CDFs to\nprimordial non-Gaussianity. An interesting result is that for halo samples with\n$M_h<10^{14}$ M$_\\odot$/h, the kNN-CDFs respond to \\textit{equilateral} PNG in\na manner distinct from the other parameters. This persists in the galaxy\ncatalogs in redshift space and can be differentiated from the impact of galaxy\nmodelling, at least within the halo occupation distribution (HOD) framework\nconsidered here. kNN-CDFs are related to counts-in-cells and, through mapping a\nsubset of the kNN-CDF measurements into the count-in-cells picture, we show\nthat our results can be modeled analytically. A caveat of the analysis is that\nwe only consider the HOD framework, including assembly bias. It will be\ninteresting to validate these results with other techniques for modeling the\ngalaxy--halo connection, e.g., (hybrid) effective field theory or\nsemi-analytical methods.\n", "  The relationship between the integrated H$\\beta$ line luminosity and the\nvelocity dispersion of the ionized gas of HII galaxies and giant HII regions\nrepresents an exciting standard candle that presently can be used up to\nredshifts $z\\sim~4$. Locally it is used to obtain precise measurements of the\nHubble constant by combining the slope of the relation obtained from nearby\n($z<0.2$) HII galaxies with the zero point determined from giant HII regions\nbelonging to an `anchor sample' of galaxies for which accurate\nredshift-independent distance moduli are available (e.g Cepheids, TRGBs).\nThrough this chapter, we present a general description of the method and\nresults obtained so far in the determination of the local value of the Hubble\nconstant and cosmological constraints. We account for the main systematic\neffects associated with the method and the possibility of improvement in the\nfuture. The discussion presented here is the product of an independent approach\nto the standard methods used in the literature to measure distances and,\nalthough at present less precise than the latest SNIa results, it is amenable\nto substantial improvement.\n", "  Context. The Doppler shift predicted by general relativity for light escaping\na gravitational potential has been observed on Earth as well as in the\ndirection of various stars and galaxy clusters at optical wavelengths. Aims.\nObserving the gravitational redshift in the X-ray band within galaxy clusters\ncould provide information on their properties and, in particular, their\ngravitational potential. We present a feasibility study of such a measurement,\nusing the capabilities of the next-generation European X-ray observatory\nAthena. Methods. We used a simple generalized Navarro-Frenk-White potential\nmodel along with a beta-model for the density of baryonic matter, which sets\nthe emission to provide an estimation of the observed redshift in the simplest\nof cases. We generated mock observations with the Athena X-ray Integral Field\nUnit (X-IFU) for a nearby massive cluster, while seeking to recover the\ngravitational redshift along with other properties of the toy model cluster.\nResults. We investigated the observability of the gravitational redshift in an\nidealized test case of a nearby massive cluster with the Athena X-IFU\ninstrument, as well as its use in probing the properties of the potential well.\nWe were also able to constrain the mass to a 20 % level of precision and the\ncosmological redshift to less than 1%, within a simplified and idealized\nobservational framework. More refined simulations accounting for further\neffects such as the internal gas motions and the actual shape of the potential\nwell are required to fully investigate the feasibility of measuring the\ngravitational redshift for a single target or statistically over a sample of\ngalaxy clusters.\n", "  We present constraints on the amplitude of local Primordial Non-Gaussianities\n(PNG), $f_{\\rm NL}$, using the quasar sample in the Sloan Digital Sky Survey IV\nextended Baryon Oscillation Spectroscopic Survey Data Release 16. We analyze\nthe power spectrum monopole, testing for the presence of scale dependent galaxy\nbias induced by local PNG. Our analysis makes use of optimal redshift weights\nthat maximize the response of the quasar sample to the possible presence of non\nzero PNG. We find $-4<f_{\\rm NL}<27$ at $68\\%$ confidence level, which is among\nthe strongest bounds with Large Scale Structure data. The optimal analysis\nreduces the error bar by about 10% compared to the standard one, an amount\nwhich is smaller than what was expected from a Fisher matrix analysis. This,\nand the reduced improvement over previous releases of the same catalog, suggest\nthe presence of still unknown systematic effects in the data. If the quasars\nhave a lower response to local PNG, our optimal constraint becomes $-23<f_{\\rm\nNL}<21$ at $68\\%$, with an improvement of $30\\%$ over standard analyses. We\nalso show how to use the optimal weights to put data-driven priors on the\nsample's response to local PNG.\n", "  The statistics of thermal gas pressure are a new and promising probe of\ncosmology and astrophysics. The large-scale cross-correlation between galaxies\nand the thermal Sunyaev-Zeldovich effect gives the bias-weighted mean electron\npressure, $\\langle b_\\mathrm{h}P_e\\rangle$. In this paper, we show that\n$\\langle b_\\mathrm{h}P_e\\rangle$ is sensitive to the amplitude of fluctuations\nin matter density, for example $\\langle b_\\mathrm{h}P_e\\rangle\\propto\n\\left(\\sigma_8\\Omega_\\mathrm{m}^{0.81}h^{0.67}\\right)^{3.14}$ at redshift\n$z=0$. We find that at $z<0.5$ the observed $\\langle b_\\mathrm{h}P_e\\rangle$ is\nsmaller than that predicted by the state-of-the-art hydrodynamical simulations\nof galaxy formation, MillenniumTNG, by a factor of $0.93$. This can be\nexplained by a lower value of $\\sigma_8$ and $\\Omega_\\mathrm{m}$, similar to\nthe so-called \"$S_8$ tension'' seen in the gravitational lensing effect,\nalthough the influence of astrophysics cannot be completely excluded. The\ndifference between Magneticum and MillenniumTNG at $z<2$ is small, indicating\nthat the difference in the galaxy formation models used by these simulations\nhas little impact on $\\langle b_\\mathrm{h}P_e\\rangle$ at this redshift range.\nAt higher $z$, we find that both simulations are in a modest tension with the\nexisting upper bounds on $\\langle b_\\mathrm{h}P_e\\rangle$. We also find a\nsignificant difference between these simulations there, which we attribute to a\nlarger sensitivity to the galaxy formation models in the high redshift regime.\nTherefore, more precise measurements of $\\langle b_\\mathrm{h}P_e\\rangle$ at all\nredshifts will provide a new test of our understanding of cosmology and galaxy\nformation.\n", "  Combining galaxy clustering information from regions of different\nenvironmental densities can help break cosmological parameter degeneracies and\naccess non-Gaussian information from the density field that is not readily\ncaptured by the standard two-point correlation function (2PCF) analyses.\nHowever, modelling these density-dependent statistics down to the non-linear\nregime has so far remained challenging. We present a simulation-based model\nthat is able to capture the cosmological dependence of the full shape of the\ndensity-split clustering (DSC) statistics down to intra-halo scales. Our models\nare based on neural-network emulators that are trained on high-fidelity mock\ngalaxy catalogues within an extended-$\\Lambda$CDM framework, incorporating the\neffects of redshift-space, Alcock-Paczynski distortions and models of the\nhalo-galaxy connection. Our models reach sub-percent level accuracy down to\n$1\\,h^{-1}{\\rm Mpc}$ and are robust against different choices of galaxy-halo\nconnection modelling. When combined with the galaxy 2PCF, DSC can tighten the\nconstraints on $\\omega_{\\rm cdm}$, $\\sigma_8$, and $n_s$ by factors of 2.9,\n1.9, and 2.1, respectively, compared to a 2PCF-only analysis. DSC additionally\nputs strong constraints on environment-based assembly bias parameters. Our code\nis made publicly available on Github.\n", "  We present a clustering analysis of the BOSS DR12 CMASS galaxy sample,\ncombining measurements of the galaxy two-point correlation function and\ndensity-split clustering down to a scale of $1\\,h^{-1}{\\rm Mpc}$. Our\ntheoretical framework is based on emulators trained on high-fidelity mock\ngalaxy catalogues that forward model the cosmological dependence of the\nclustering statistics within an extended-$\\Lambda$CDM framework, including\nredshift-space and Alcock-Paczynski distortions. Our base-$\\Lambda$CDM analysis\nfinds $\\omega_{\\rm cdm} = 0.1201\\pm 0.0022$, $\\sigma_8 = 0.792\\pm 0.034$, and\n$n_s = 0.970\\pm 0.018$, corresponding to $f\\sigma_8 = 0.462\\pm 0.020$ at $z\n\\approx 0.525$, which is in agreement with Planck 2018 predictions and various\nclustering studies in the literature. We test single-parameter extensions to\nbase-$\\Lambda$CDM, varying the running of the spectral index, the dark energy\nequation of state, and the density of massless relic neutrinos, finding no\ncompelling evidence for deviations from the base model. We model the\ngalaxy-halo connection using a halo occupation distribution framework, finding\nsignatures of environment-based assembly bias in the data. We validate our\npipeline against mock catalogues that match the clustering and selection\nproperties of CMASS, showing that we can recover unbiased cosmological\nconstraints even with a volume 84 times larger than the one used in this study.\n", "  This research explores the correlation between the absolute magnitude and the\nredshift of Type Ia supernovae (SNe Ia) with a model-independent approach. The\nPantheon sample of SNe Ia and strong gravitational lensing systems (SGLS) are\nused. With the cosmic distance-duality relation (CDDR), the evolution parameter\nof the magnitude, the light curve parameters of SNe Ia, and the parameters of\nthe SGLS geometric model are constrained simultaneously. Considering the\nconsistency of the redshifts, we selected a subsample of SNe Ia in which the\nredshift of each SNe Ia is close to the corresponding redshift of the SGLS\nsample. Two parametric models are used to describe this evolution, which can be\nwritten as $\\delta_M=\\varepsilon z$ and $\\delta_M=\\varepsilon\\log(1+z)$,\nrespectively. Our analysis reveals that $\\varepsilon=-0.036^{+0.357}_{-0.339}$\nin the first parametric model and $\\varepsilon=-0.014^{+0.588}_{-0.630}$ in the\nsecond model, indicating that no significant evolution ($\\varepsilon=0$) is\nsupported at the 1$\\sigma$ confidence level in this study. These results\nrepresent a significant advancement in our understanding of the intrinsic\nproperties of SNe Ia and provide important constraints for future SNe Ia study.\n", "  This work tests if the large-scale galaxy distribution can be characterized\nas a fractal system. The $\\Lambda$CDM cosmology with $H_0=(70\\pm 5)$ km/s/Mpc\nis adopted to study the UltraVISTA DR1, COSMOS2015 and SPLASH surveys,\nalongside the number density equations of these galaxy distribution systems as\nfractals with dimension D. The relativistic distance definitions $d_L$, $d_Z$\nand $d_G$ are used to estimate the galaxy number densities in the redshift\ninterval $0.1 \\leq z \\leq 4$ at volume limited subsamples. Applying the\nappropriate relations for the description of galaxy fractal structures with\nsingle dimension $D$ in the relativistic settings to these surveys datasets it\nis possible to state that for $z<1$ the UltraVISTA DR1 galaxies presented an\naverage of $D=(1.58\\pm 0.20)$, the COSMOS2015 galaxies produced $D=(1.39\\pm\n0.19)$ and the SPLASH galaxies generated $D=(1.00\\pm 0.12)$. For $1 \\leq z \\leq\n4$ the dimensions respectively decreased to $D=(0.59\\pm 0.28)$,\n$D=0.54^{+0.27}_{-0.26}$ and $D=0.83^{+0.36}_{-0.37}$. These results are robust\nunder the Hubble constant uncertainty assumed here. Analysis of blue and red\ngalaxies subsamples in the COSMOS2015 and SPLASH surveys show that the fractal\ndimensions of blue galaxies present essentially no alteration from the values\nabove, although the ones for the red galaxies changed mostly to smaller values,\nmeaning that D may be assumed as a more intrinsic property of the distribution\nof objects in the Universe, thus allowing for the fractal dimension to be used\nas a tool to study different populations of galaxies. All results confirm the\ndecades old theoretical prediction of a decrease in the fractal dimension for\n$z>1$ suggesting that either there are yet unclear observational biases causing\nsuch decrease in the fractal dimension, or the galaxy clustering was possibly\nmore sparse and the universe void dominated in a not too distant past.\n", "  Recent data released by James Webb Space Telescope (JWST) and, somewhat\nearlier, the data presented by Hubble Space Telescope (HST) are commonly\nunderstood as a strong indication for breaking of the canonical $\\Lambda$CDM\ncosmology. It is argued in the presented work that massive primordial black\nholes (PBH) could seed galaxy and quasar formation in the very young universe\nas it has been conjectured in our paper of 1993 and resolve the tension induced\nby the JWST and the HST data with the standard cosmology. This point of view is\npresently supported by several recent works. The proposed mechanism of PBH\nformation leads to the log-normal mass spectrum of PBHs and predicts abundant\nantimatter population of our Galaxy, Milky Way. Both these predictions are in\nexcellent agreement with astronomical observations.\n", "  During cosmic recombination, charged particles bind into neutral atoms and\nthe mean free path of photons rapidly increases, resulting in the familiar\ndiffusion damping of primordial radiation temperature variations. An additional\neffect is a small photon spectrum distortion, because photons arriving from a\nparticular sky direction were originally in thermal equilibrium at various\nspatial locations with different temperatures; the combination of these\ndifferent blackbody temperature distributions results in a spectrum with a\nCompton $y$-distortion. Using the approximation that photons had zero mean free\npath prior to their second-to-last scattering, we derive an expression for the\nresulting $y$-distortion, and compute the angular correlation function of the\ndiffusion $y$-distortion and its cross-correlation with the square of the\nphoton temperature fluctuation. Detection of the cross-correlation is within\nreach of existing arcminute-resolution microwave background experiments such as\nthe Atacama Cosmology Telescope and the South Pole Telescope.\n", "  Upcoming deep optical surveys such as the Vera C. Rubin Observatory Legacy\nSurvey of Space and Time will scan the sky to unprecedented depths and detect\nbillions of galaxies. This amount of detections will however cause the apparent\nsuperposition of galaxies on the images, called blending, and generate a new\nsystematic error due to the confusion of sources. As consequences, the\nmeasurements of individual galaxies properties such as their redshifts or\nshapes will be impacted, and some galaxies will not be detected. However,\ngalaxy shapes are key quantities, used to estimate masses of large scale\nstructures, such as galaxy clusters, through weak gravitational lensing. This\nwork presents a new catalog matching algorithm, called friendly, for the\ndetection and characterization of blends in simulated LSST data for the DESC\nData Challenge 2. By identifying a specific type of blends, we show that\nremoving them from the data may partially correct the amplitude of the\n$\\Delta\\Sigma$ weak lensing profile that could be biased low by around 20% due\nto blending. This would result in impacting clusters weak lensing mass estimate\nand cosmology.\n", "  We release photometric redshifts, reaching $\\sim$0.7, for $\\sim$14M galaxies\nat $r\\leq 20$ in the 11,500 deg$^2$ of the SDSS north and south galactic caps.\nThese estimates were inferred from a convolution neural network (CNN) trained\non $ugriz$ stamp images of galaxies labelled with a spectroscopic redshift from\nthe SDSS, GAMA and BOSS surveys. Representative training sets of $\\sim$370k\ngalaxies were constructed from the much larger combined spectroscopic data to\nlimit biases, particularly those arising from the over-representation of\nLuminous Red Galaxies. The CNN outputs a redshift classification that offers\nall the benefits of a well-behaved PDF, with a width efficiently signaling\nunreliable estimates due to poor photometry or stellar sources. The dispersion,\nmean bias and rate of catastrophic failures of the median point estimate are of\norder $\\sigma_{\\rm MAD}=0.014$, <$\\Delta z_{\\rm norm}$>$=0.0015$, $\\eta(|\\Delta\nz_{\\rm norm}|>0.05)=4\\%$ on a representative test sample at $r<19.8$,\nout-performing currently published estimates. The distributions in narrow\nintervals of magnitudes of the redshifts inferred for the photometric sample\nare in good agreement with the results of tomographic analyses. The inferred\nredshifts also match the photometric redshifts of the redMaPPer galaxy clusters\nfor the probable cluster members. The CNN input and output are available at:\nhttps://deepdip.iap.fr/treyer+2023.\n", "  Photometric redshift estimation plays a crucial role in modern cosmological\nsurveys for studying the universe's large-scale structures and the evolution of\ngalaxies. Deep learning has emerged as a powerful method to produce accurate\nphotometric redshift estimates from multi-band images of galaxies. Here, we\nintroduce a multimodal approach consisting of the parallel processing of\nseveral subsets of image bands prior, the outputs of which are then merged for\nfurther processing through a convolutional neural network (CNN). We evaluate\nthe performance of our method using three surveys: the Sloan Digital Sky Survey\n(SDSS), The Canada-France-Hawaii Telescope Legacy Survey (CFHTLS) and Hyper\nSuprime-Cam (HSC). By improving the model's ability to capture information\nembedded in the correlation between different bands, our technique surpasses\nthe state-of-the-art photometric redshift precision. We find that the positive\ngain does not depend on the specific architecture of the CNN and that it\nincreases with the number of photometric filters available.\n", "  The Square Kilometer array is expected to measure the 21cm signal from the\nEpoch of Reionization (EoR) in the coming decade, and its pathfinders may\nprovide a statistical detection even earlier. The currently reported upper\nlimits provide tentative constraints on the astrophysical parameters of the\nmodels of the EoR.\n  In order to interpret such data with 3D radiative hydrodynamics simulations\nusing Bayesian inference, we present the latest developments of the\n\\textsc{Licorice} code. Relying on an implementation of the halo conditional\nmass function to account for unresolved star formation, this code now allows\naccurate simulations of the EoR at $256^3$ resolution. We use this version of\n\\textsc{Licorice} to produce the first iteration of \\textsc{LoReLi}, a public\ndataset now containing hundreds of 21cm signals computed from radiative\nhydrodynamics simulations. We train a neural network on \\textsc{LoReLi} to\nprovide a fast emulator of the \\textsc{Licorice} power spectra,\n\\textsc{LorEMU}, which has $\\sim 5\\%$ rms error relative to the simulated\nsignals. \\textsc{LorEMU} is used in a Markov Chain Monte Carlo framework to\nperform Bayesian inference, first on a mock observation composed of a simulated\nsignal and thermal noise corresponding to 100h observations with the SKA. We\nthen apply our inference pipeline to the latest measurements from the HERA\ninterferometer. We report constraints on the X-ray emissivity, and confirm that\ncold reionization scenarios are unlikely to accurately represent our Universe.\n", "  We present a tentative constraint on cosmological parameters $\\Omega_m$ and\n$\\sigma_8$ from a joint analysis of galaxy clustering and galaxy-galaxy lensing\nfrom DESI Legacy Imaging Surveys Data Release 9 (DR9), covering approximately\n10000 square degrees and spanning the redshift range of 0.1 to 0.9. To study\nthe dependence of cosmological parameters on lens redshift, we divide lens\ngalaxies into seven approximately volume-limited samples, each with an equal\nwidth in photometric redshift. To retrieve the intrinsic projected correlation\nfunction $w_{\\rm p}(r_{\\rm p})$ from the lens samples, we employ a novel method\nto account for redshift uncertainties. Additionally, we measured the\ngalaxy-galaxy lensing signal $\\Delta\\Sigma(r_{\\rm p})$ for each lens sample,\nusing source galaxies selected from the shear catalog by applying our\n\\texttt{Fourier\\_Quad} pipeline to DR9 images. We model these observables\nwithin the flat $\\Lambda$CDM framework, employing the minimal bias model. To\nensure the reliability of the minimal bias model, we apply conservative scale\ncuts: $r_{\\rm p} > 8$ and $12 ~h^{-1}{\\rm Mpc}$, for $w_{\\rm p}(r_{\\rm p})$ and\n$\\Delta\\Sigma(r_{\\rm p})$, respectively. Our findings suggest a mild tendency\nthat $S_8 \\equiv \\sigma_8 \\sqrt{\\Omega_m/0.3} $ increases with lens redshift,\nalthough this trend is only marginally significant. When we combine low\nredshift samples, the value of $S_8$ is determined to be $0.84 \\pm 0.02$,\nconsistent with the Planck results but significantly higher than the 3$\\times$\n2pt analysis by 2-5$\\sigma$. Despite the fact that further refinements in\nmeasurements and modeling could improve the accuracy of our results, the\nconsistency with standard values demonstrates the potential of our method for\nmore precise and accurate cosmology in the future.\n", "  We revisit the lensing anomaly in the Planck 2018 temperature (TT) data and\nexamine its robustness to frequency selection and additional sky masking. Our\nmain findings are: (1) The phenomenological lensing amplitude parameter, $A_L$,\nvaries with ecliptic latitude, with a $2.9\\sigma$ preference for $A_L>1$ near\nthe ecliptic, and $1.0\\sigma$ preference near the ecliptic poles, compared to\n$2.5\\sigma$ on the original masks. This behavior is largely or solely from 217\nGHz and suggestive of some non-random effect given the Planck scan strategy.\n(2) The 217 GHz TT data also show a stronger preference for $A_L>1$ than the\nlower frequencies. The shifts in $A_L$ from 217 GHz with additional Galactic\ndust masking are too large to be explained solely by statistical fluctuations,\nindicating some connection with the foreground treatment. Overall, the Planck\n$A_L$ anomaly does not have a single simple cause. Removing the 217 GHz TT data\nleaves a $1.8\\sigma$ preference for $A_L>1$. The low-multipole ($\\ell<30$) TT\ndata contribute to the preference for $A_L>1$ through correlations with\n$\\Lambda$CDM parameters. The 100 and 143 GHz data at $\\ell\\geq30$ prefer\n$A_L>1$ at $1.3\\sigma$, and this appears robust to the masking tests we\nperformed. The lensing anomaly may impact fits to alternative cosmological\nmodels. Marginalizing over $A_L$, optionally applied only to Planck TT spectra,\ncan check this. Models proposed to address cosmological tensions should be\nrobust to removal of the Planck 217 GHz TT data.\n", "  In this work, we investigated the interplay between the X-ray and radio\nemission of the cluster PSZ2G113.91-37.01 (z = 0.371) using the high-quality\nXMM-Newton observations of the CHEX-MATE project, and the images of the\nLoTSS-DR2. The cluster is undergoing a merger along the north-south axis, and\nshows a central radio halo and two radio relics, one in the southern and one in\nthe northern regions. The analysis of the intracluster medium distribution\nrevealed the presence of a northern surface brightness jump associated to the\nmerger event. By extracting spectra across this discontinuity, we classified\nthe edge as a cold front. Furthermore, we made use of upgraded Giant Metrewave\nRadio Telescope observations that allowed us to perform a spectral analysis of\nthe G113 radio emission. We found evidence of re-acceleration of particles in\nthe northern relic, and we measured an associated Mach number of M = 1.95 $\\pm$\n0.01, as inferred from radio observations. We then performed a point-to-point\nanalysis of the X-ray and radio emission both in the halo and in the northern\nrelic regions. We found a strong correlation for the halo and an\nanti-correlation for the relic. The former behaviour is in agreement with\nprevious studies. The relic anti-correlation is likely related to the reverse\nradial distribution of the X-ray (increasing towards the cluster centre) and\nradio (decreasing towards the cluster centre) emissions. Finally, we performed\na point-to-point analysis of the radio emission and the residuals obtained by\nsubtracting a double beta model to the X-ray emission. We found a strong\ncorrelation between the two quantities. This behaviour suggests the presence of\na connection between the process responsible for the radio emission and the one\nthat leaves fluctuations in the X-ray observations.\n", "  The recent Dark Energy Survey Year 1 (DES-Y1) analysis of galaxy cluster\nabundances and weak lensing produced $\\Omega_{\\rm m}$ and $\\sigma_8$\nconstraints in 5.6$\\sigma$ tension with Planck. It is suggested in that work\nthat this tension is driven by unmodelled systematics in optical cluster\nselection. We present a novel simulation-based forward modeling framework that\nexplicitly incorporates cluster selection into its model predictions. Applying\nthis framework to the DES-Y1 data we find consistency with Planck, resolving\nthe tension found in the DES-Y1 analysis. An extension of this approach to the\nfinal DES data set will produce robust constraints on $\\Lambda$CDM parameters\nand correspondingly strong tests of cosmological models.\n", "  The aim of this work is to study the anisotropic weak lensing signal\nassociated with the mass distribution of massive clusters of galaxies using the\nCosmic Microwave Background (CMB) data. For this purpose, we stack patches of\nthe Planck Collaboration 2018 CMB lensing convergence map centered on SDSS DR8\nredMaPPer clusters within the redshift range [0.4, 0.5]. We obtain mean radial\nprofiles of the convergence parameter k finding strong signals at scales as\nlarge as 40 Mpc/h. By orienting the clusters along their major axis defined\nthrough the galaxy member distribution, we find a significant difference\nbetween the parallel and perpendicular oriented convergence profiles. The\namplitude of the profile along the parallel direction is about 50% larger than\nthat along the perpendicular direction, indicating that the clusters are well\naligned with the surrounding mass distribution. From a model with an\nanisotropic surface mass density, we obtain a suitable agreement for both mass\nand ellipticities of clusters compared to results derived from weak lensing\nshear estimates, finding strong evidence of the correlation between the galaxy\ncluster member distribution and the large--scale mass distribution.\n", "  We report the discovery of PSJ2107-1611, a fold-configuration 4.3\"-separation\nquadruply lensed quasar with a bright lensed arc. It was discovered using a\nconvolutional neural network on Pan-STARRS gri images of pre-selected quasar\ncandidates with multiple nearby Pan-STARRS detections. Spectroscopic follow-up\nwith EFOSC2 on the ESO 3.58m New Technology Telescope reveals the source to be\na quasar at z = 2.673, with the blended fold image pair showing deformed broad\nlines relative to the other images. The flux ratios measured from optical to\nnear-infrared imaging in the Canada-France-Hawaii Telescope Legacy Survey,\nPan-STARRS, the Legacy Surveys, and the Vista Hemisphere Survey are\ninconsistent with a smooth mass model as the fold pair images are about 15\ntimes too faint. Variability, time delay effects, and reddening are ruled out\nthrough multiple-epoch imaging and color information. The system is marginally\nresolved in the radio in the Very Large Array Sky Survey S-band, where it has a\n10 mJy detection. The radio flux ratios are compatible with the smooth mass\nmacromodel. This system offers a unique tool for future studies of quasar\nstructure with strong and microlensing. A more detailed analysis of follow-up\nwith JWST/MIRI, VLT/MUSE, VLT/ERIS, and data from the European Very Long\nBaseline Interferometer will be presented in an upcoming paper.\n", "  We present the methodology for deriving accurate and reliable cosmological\nconstraints from non-linear scales (<50Mpc/h) with k-th nearest neighbor (kNN)\nstatistics. We detail our methods for choosing robust minimum scale cuts and\nvalidating galaxy-halo connection models. Using cross-validation, we identify\nthe galaxy-halo model that ensures both good fits and unbiased predictions\nacross diverse summary statistics. We demonstrate that we can model kNNs\neffectively down to transverse scales of rp ~ 3Mpc/h and achieve precise and\nunbiased constraints on the matter density and clustering amplitude, leading to\na 2% constraint on sigma_8. Our simulation-based model pipeline is resilient to\nvaried model systematics, spanning simulation codes, halo finding, and\ncosmology priors. We demonstrate the effectiveness of this approach through an\napplication to the Beyond-2p mock challenge. We propose further explorations to\ntest more complex galaxy-halo connection models and tackle potential\nobservational systematics.\n", "  We investigate the transition scale to homogeneity, $R_H$, using as cosmic\ntracer the spectroscopic sample of blue galaxies from the Sloan Digital Sky\nSurvey (SDSS). Considering the spatial distribution of the galaxy sample we\ncompute the two point correlation function $\\xi(r)$, the scaled counts in\nspheres $\\mathcal{N}(<r)$, and the fractal dimension $\\mathcal{D}_2(r)$ to\nquantify the homogeneity scale in the Local Universe ($0.04 < z < 0.20$). The\nsample in analysis is compared with {\\it random} and {\\it mock} catalogues with\nthe same geometry, and the same number of synthetic cosmic objects as the\ndataset, to calculate the covariance matrix for the errors determination. The\ncriteria adopted for the transition-to-homogeneity follows the literature, it\nis attained when $\\mathcal{D}_2(r)$ reaches the $1$ per cent level of the limit\nvalue $3$ (i.e., where it reaches $2.97$) as the scale increases. We obtain\n$R_H = 70.33 \\pm 10.74$ Mpc$/h$, at the effective redshift\n$z_{\\text{eff}}=0.128$, for a sample containing $150\\,302$ SDSS blue galaxies\nwith $0.04 < z < 0.20$. Additionally, we perform robustness tests by analysing\nthe homogeneity scale in sub-volumes of the original one, obtaining coherent\nresults; we also check for a possible artefact in our procedure examining a\nhomogeneous synthetic dataset as a pseudo-data, verifying that such systematic\nis absent. Because our analyses concentrate in data at low redshifts, $z <\n0.20$, we find interesting to use cosmography to calculate the radial comoving\ndistances; therefore in this subject our analyses do not use fiducial\ncosmological model. For completeness, we evaluate the difference of the\ncomoving distances estimation using cosmography and fiducial cosmology.\n", "  [abridged] We propose a model of the Universe (dubbed $\\eta$CDM) featuring a\nstochastic evolution of the cosmological quantities, that is meant to render\nsmall deviations from homogeneity/isotropy on scales of $30-50\\, h^{-1}$ Mpc at\nlate cosmic times, associated to the emergence of the cosmic web. Specifically,\nwe prescribe that the behavior of the matter/radiation energy densities in\ndifferent patches of the Universe with such a size can be effectively described\nby a stochastic version of the mass-energy evolution equation. The latter\nincludes an appropriate noise term that statistically accounts for local\nfluctuations due to inhomogeneities, anisotropic stresses and matter flows. The\nevolution of the different patches as a function of cosmic time is rendered via\nthe diverse realizations of the noise term; meanwhile, at any given cosmic\ntime, sampling the ensemble of patches will originate a nontrivial spatial\ndistribution of the cosmological quantities. The overall behavior of the\nUniverse will be obtained by averaging over the patch ensemble. We assume a\nphysically reasonable parameterization of the noise term, gauging it against a\nwealth of cosmological datasets. We find that, with respect to standard\n$\\Lambda$CDM, the ensemble-averaged cosmic dynamics in the $\\eta$CDM model is\nsubstantially altered in three main respects: (i) an accelerated expansion is\nenforced at late cosmic times without the need for any additional exotic\ncomponent (e.g., dark energy); (ii) the spatial curvature can stay small even\nin a low-density Universe; (iii) matter can acquire an effective negative\npressure at late times. We provide predictions for the variance of the\ncosmological quantities among different patches of the Universe at late cosmic\ntimes. Finally, we show that in $\\eta$CDM the Hubble-tension is solved, and the\ncosmic coincidence problem is relieved without invoking the anthropic\nprinciple.\n", "  A measurement of the 21-cm global signal would be a revealing probe of the\nDark Ages, the era of first star formation, and the Epoch of Reionization. It\nhas remained elusive owing to bright galactic and extra-galactic foreground\ncontaminants, coupled with instrumental noise, ionospheric effects, and beam\nchromaticity. The simultaneous detection of a consistent 21-cm dipole signal\nalongside the 21-cm global signal would provide confidence in a claimed\ndetection. We use simulated data to investigate the possibility of using\ndrift-scan dipole antenna experiments to achieve a detection of both monopole\nand dipole. We find that at least two antennae located at different latitudes\nare required to localise the dipole. In the absence of foregrounds, a total\nintegration time of $\\sim 10^4$ hours is required to detect the dipole. With\ncontamination by simple foregrounds, we find that the integration time required\nincreases to $\\sim 10^5$ hours. We show that the extraction of the 21-cm dipole\nfrom more realistic foregrounds requires a more sophisticated foreground\nmodelling approach. Finally, we motivate a global network of dipole antennae\nthat could reasonably detect the dipole in $\\sim 10^3$ hours of integration\ntime.\n", "  The Hubble Constant observed at high redshift and low redshift are\ninconsistent, representing one of the urgent issues to be resolved in the field\nof cosmology. The discovery of gravitational waves opens a new window for\naddressing this problem. For instance, the GW170817 event, through the\ncoordinated observation of electromagnetic and gravitational wave signals,\nallows for constraints to be imposed from a completely new perspective.\nHowever, the number of gravitational wave events where both electromagnetic and\ngravitational wave signals are observed simultaneously is too small, making it\ndifficult to enhance the precision through statistical methods. In this paper,\nwe use dark sirens as the subjects of study. Through the standard gravitational\nwave data simulation and the analysis process, we analyze the constraints a\ntypical binary neutron star merger event can place on the Hubble Constant. We\nsimulated a random event and found that it an provide an error of +0.04-0.05\nfor the Hubble Constant. By combining multiple events, this constraint can be\nimproved.\n", "  Three galaxy clusters selected from the XXL X-ray survey at high redshift and\nlow mass ($z\\sim1$ and $M_{500} \\sim 1-2 \\times 10^{14}$ M$_{\\odot}$) were\nobserved with NIKA2 to image their Sunyaev-Zel'dovich effect (SZ) signal. They\nall present an SZ morphology, together with the comparison with X-ray and\noptical data, that indicates dynamical activity related to merging events.\nDespite their disturbed intracluster medium, their high redshifts, and their\nlow masses, the three clusters follow remarkably well the pressure profile and\nthe SZ flux-mass relation expected from standard evolution. This suggests that\nthe physics that drives cluster formation is already in place at $z \\sim 1$\ndown to $M_{500} \\sim 10^{14}$ M$_{\\odot}$.\n", "  The current discrepancy between the CMB and weak lensing measurements of the\namplitude of matter fluctuations, the so-called $S_8$ tension, has attracted a\ngreat deal of recent attention, as it may show a crack in the $\\Lambda$CDM\nmodel of cosmology. We review the evidence for this tension and describe\npotential solutions, focusing on extensions of the standard cosmological model,\nincluding interacting dark energy and modified gravity. We present a likelihood\nanalysis of the BOSS DR12 data, probing these alternative models as well as\n$\\Lambda$CDM. From this analysis, we show hints of non-standard cosmology\ncompatible with those seen in weak lensing observations, demonstrating that\ninteracting dark energy or modified gravity can explain them successfully. We\nthen discuss the robustness of these results to analysis choices, as well as\nfuture paths to confirm them with additional data and further distinguish\nbetween models.\n", "  High-resolution mapping of the hot gas in galaxy clusters is a key tool for\ncluster-based cosmological analyses. Taking advantage of the NIKA2 millimeter\ncamera operated at the IRAM 30-m telescope, the NIKA2 SZ Large Program seeks to\nget a high-resolution follow-up of 38 galaxy clusters covering a wide mass\nrange at intermediate to high redshift. The measured SZ fluxes will be\nessential to calibrate the SZ scaling relation and the galaxy clusters mean\npressure profile, needed for the cosmological exploitation of SZ surveys. We\npresent in this study a method to infer a mean pressure profile from cluster\nobservations. We have designed a pipeline encompassing the map-making and the\nthermodynamical properties estimates from maps. We then combine all the\nindividual fits, propagating the uncertainties on integrated quantities, such\nas $R_{500}$ or $P_{500}$, and the intrinsic scatter coming from the deviation\nto the standard self-similar model. We validate the proposed method on\nrealistic LPSZ-like cluster simulations.\n", "  The study of the morphology of 2D projected maps of galaxy clusters is a\nsuitable approach to infer, from real data, the dynamical state of those\nsystems. We recently developed a new method to recover the morphological\nfeatures in galaxy cluster maps which consists of an analytical modelling\nthrough the Zernike polynomials. After the first validation of this approach on\na set of high-resolution mock maps of the Compton parameter, $y$, from\nhydrodynamically simulated galaxy clusters in THE THREE HUNDRED project, we\napply the Zernike modelling on $y$-maps of local ($z < 0.1$) galaxy clusters\nobserved by the $Planck$ satellite. With a single parameter collecting the main\ninformation of the Zernike modelling, we classify their morphology. A set of\nmock $Planck$-like $y$-maps, generated from THE THREE HUNDRED clusters, is also\nused to validate our indicator with a proper dynamical state classification.\nThis approach allows us to test the efficiency of the Zernike morphological\nmodelling in evaluating the dynamical population in the real $Planck$ sample.\n", "  The increasing statistical precision of photometric redshift surveys requires\nimproved accuracy of theoretical predictions for large-scale structure\nobservables to obtain unbiased cosmological constraints. In $\\Lambda$CDM\ncosmologies, massive neutrinos stream freely at small cosmological scales,\nsuppressing the small-scale power spectrum. In massive neutrino cosmologies,\ngalaxy bias modeling needs to accurately relate the scale-dependent growth of\nthe underlying matter field to observed galaxy clustering statistics. In this\nwork, we implement a computationally efficient approximation of the\nneutrino-induced scale-dependent bias (NISDB). Through simulated likelihood\nanalyses of Dark Energy Survey Year 3 (DESY3) and Legacy Survey of Space and\nTime Year 1 (LSSTY1) synthetic data that contain an appreciable NISDB, we\nexamine the impact of linear galaxy bias and neutrino mass modeling choices on\ncosmological parameter inference. We find model misspecification of the NISDB\napproximation and neutrino mass models to decrease the constraining power of\nphotometric galaxy surveys and cause parameter biases in the cosmological\ninterpretation of future surveys. We quantify these biases and devise\nmitigation strategies.\n", "  Weak gravitational lensing is an important tool to estimate the masses of\ngalaxy clusters, as it allows us to directly access their projected surface\nmass density along the line-of-sight (LOS) in a manner largely independent of\ntheir dynamical state. Moreover, we can extract information on the projected\nshape of the cluster mass distribution. In this work, we generate mock catalogs\nof lensed background galaxies to measure the individual lensing properties of\ngalaxy clusters from the simulation project The Three Hundred. By repeating the\nanalysis for different projections of the same cluster, we find that the use of\nshear multipoles provides constraints on the ellipticity of the cluster\nprojected mass density but does not have a significant impact on the cluster\nmass reconstruction compared to the standard approach.\n", "  We provide a complementary nested sampling analysis for the Atacama Cosmology\nTelescope lensing data release 6. This allows the quantification of global\nconsistency statistics between ACT lensing and alternative datasets. In the\ncontext of flat $\\Lambda$CDM, we find no inconsistency between ACT, Baryonic\nAcoustic Oscillations, Planck anisotropies, weak lensing datasets, or NPIPE\nlensing. As part of our analysis, we also investigate the effect of the prior\nwidths used in the ACT analysis and find that the headline results are\nquantitatively but not qualitatively affected by the chosen priors. We use both\nBayes factors and the suspiciousness statistic to quantify the possibility of\ntension, and find suspiciousness unsuitable in the case of strong agreement\nbetween ACT DR6 and NPIPE. Nested sampling provides a competitive alternative\nto Metropolis Hastings and we recommend it be used alongside existing analyses.\nWe release the chains and plotting source for the analysis using anesthetic.\n", "  We present an analytical model for cosmological Lyman-limit systems (LLSs)\nthat successfully reproduces the observed evolution of the mean free path (L)\nof ionizing photons. The evolution of the co-moving mean free path is\npredominantly a consequence of the changing meta galactic photo-ionization rate\nand the increase with cosmic time of the minimum mass below which halos lose\ntheir gas due to photo-heating. In the model, Lyman-limit absorption is caused\nby highly ionized gas in the outskirt of dark matter halos. We exploit the\nassociation with halos to compute statistical properties of LLSs and of their\nbias, b. The latter increases from 1.5 to 2.6 from redshifts 2 to 6. Combined\nwith the rapid increase with redshift of the bias of the halos that host a\nquasar, the model predicts a rapid drop in the value of L when measured in\nquasar spectra from z=5 to 6, whereas the actual value of L falls more\nsmoothly. We derive an expression for the effective optical depth due to Lyman\nlimit absorption as a function of wavelength and show that it depends\nsensitively on the poorly constrained number density of LLSs as a function of\ncolumn density. The optical depth drops below unity for all wavelengths below a\nredshift of 2.5, which is therefore the epoch when the Universe first became\ntransparent to ionizing photons.\n", "  The Hubble constant problem is that the values of Hubble constant from the\nobservation of cosmic microwave background assuming the LambdaCDM model\ndisagrees with the values from direct measurements. This problem suggests some\nnew physics beyond the LambdaCDM model. Typically there are two ways of\nreconciliation: one is the realization of smaller value of sound horizon at\nrecombination, and the other is the modification of the way of expansion of the\nuniverse after recombination. In this letter we examine the latter possibility\nby comparing two typical phenomenological dark energy models with the\ndistance-redshift relation provided by Pantheon catalogue of supernova\nobservations and galaxy surveys by BOSS and eBOSS collaborations. Though these\nphenomenological dark energy models globally fit observations better than the\nLambdaCDM model, they are strongly disfavored by the distance-redshift relation\nas almost the same level as the LambdaCDM model defined by cosmic microwave\nbackground observations. The distance-redshift relation strongly suggests some\nnew physics which realize smaller value of sound horizon at recombination.\n", "  Dark matter-dominated cores have long been claimed for the well-studied local\ngroup dwarf galaxies. More recently, extended stellar halos have been uncovered\naround several of these dwarfs through deeper imaging and spectroscopy. Such\ncore-halo structures are not a feature of conventional cold dark matter (CDM),\nbased on collisionless particles where smooth, scale-free profiles are\npredicted. In contrast, smooth and prominent dark matter cores are predicted\nfor Warm and Fuzzy/Wave Dark Matter (WDM/$\\psi$DM) respectively. The question\narises to what extent the visible stellar profiles should reflect this dark\nmatter core structure. Here we compare cosmological hydrodynamical simulations\nof CDM, WDM $\\&$ $\\psi$DM, aiming to predict the stellar profiles for these\nthree DM scenarios. We show that cores surrounded by extended halos are\ndistinguishable for WDM and $\\psi$DM, with the most prominent cores in the case\nof $\\psi$DM, where the stellar density is enhanced in the core due to the\npresence of the relatively dense soliton. Our analysis demonstrates that such\nbehavior does not appear in CDM, implying that the small-scale cut-off in the\npower spectrum present for WDM and $\\psi$DM provides a core-halo transition.\nConsequently, we estimate the mass of the $\\psi$DM particle at this core-halo\ntransition point. Furthermore, we observe the anticipated asymmetry for\n$\\psi$DM due to the soliton's random walk, a distinctive characteristic not\nfound in the symmetric distributions of stars in Warm and CDM models.\n", "  The standard cosmological model predicts statistically isotropic cosmic\nmicrowave background (CMB) fluctuations. However, several summary statistics of\nCMB isotropy have anomalous values, including: the low level of large-angle\ntemperature correlations, $S_{1/2}$; the excess power in odd versus even\nlow-$\\ell$ multipoles, $R^{TT}$; the (low) variance of large-scale temperature\nanisotropies in the ecliptic north, but not the south, $\\sigma^2_{16}$; and the\nalignment and planarity of the quadrupole and octopole of temperature,\n$S_{QO}$. Individually, their low $p$-values are weak evidence for violation of\nstatistical isotropy. The correlations of the tail values of these statistics\nhave not to this point been studied. We show that the joint probability of all\nfour of these happening by chance in $\\Lambda$CDM is likely\n$\\leq3\\times10^{-8}$. This constitutes more than $5\\sigma$ evidence for\nviolation of statistical isotropy.\n", "  We use Dark Energy Survey Year 3 (DES Y3) clusters with archival X-ray data\nfrom XMM-Newton and Chandra to assess the centering performance of the\nredMaPPer cluster finder and to measure key richness observable scaling\nrelations. In terms of centering, we find that 10-20% of redMaPPer clusters are\nmiscentered with no significant difference in bins of low versus high richness\n($20<\\lambda<40$ and $\\lambda>40$) or redshift ($0.2<z<0.4$ and $0.4 <z <\n0.65$). We also investigate the richness bias induced by miscentering. The\ndominant reasons for miscentering include masked or missing data and the\npresence of other bright galaxies in the cluster; for half of the miscentered\nclusters the correct central was one of the other possible centrals identified\nby redMaPPer, while for $\\sim 40$% of miscentered clusters the correct central\nis not a redMaPPer member with most of these cases due to masking. In addition,\nwe fit the scaling relations between X-ray temperature and richness and between\nX-ray luminosity and richness. We find a T$_X$-$\\lambda$ scatter of $0.21 \\pm\n0.01$. While the scatter in T$_X$-$\\lambda$ is consistent in bins of redshift,\nwe do find modestly different slopes with high-redshift clusters displaying a\nsomewhat shallower relation. Splitting based on richness, we find a marginally\nlarger scatter for our lowest richness bin, $20 < \\lambda < 40$. The X-ray\nproperties of detected, serendipitous clusters are generally consistent with\nthose for targeted clusters, but the depth of the X-ray data for undetected\nclusters is insufficient to judge whether they are X-ray underluminous in all\nbut one case.\n", "  The growth of large-scale structure, together with the geometrical\ninformation of cosmic expansion history and cosmological distances, can be used\nto obtain constraints on the spatial curvature of the universe that probes the\nearly universe physics, whereas modeling the nonlinear growth in a nonflat\nuniverse is still challenging due to computational expense of simulations in a\nhigh-dimensional cosmological parameter space. In this paper, we develop an\napproximate method to compute the halo-matter and halo-auto power spectra for\nnonflat $\\Lambda$CDM model, from quantities representing the nonlinear\nevolution of the corresponding flat $\\Lambda$CDM model, based on the separate\nuniverse (SU) method. By utilizing the fact that the growth response to\nlong-wavelength fluctuations (equivalently the curvature), $T_{\\delta_{\\rm\nb}}(k)$, is approximated by the response to the Hubble parameter, $T_h(k)$, our\nmethod allows one to estimate the nonlinear power spectra in a nonflat universe\nefficiently from the power spectra of the flat universe. We use $N$-body\nsimulations to show that the estimator can provide the halo-matter (halo-auto)\npower spectrum at $\\sim 1\\%$ ($\\sim 2\\%$ ) accuracy up to $k \\simeq 3 (1) \\, h\n{\\rm Mpc}^{-1}$ even for a model with large curvature $\\Omega_K = \\pm 0.1$.\nUsing the estimator we can extend the prediction of the existing emulators such\nas Dark Emulator to nonflat models without degrading their accuracy. Since the\nresponse to long-wavelength fluctuations is also a key quantity for estimating\nthe super sample covariance (SSC), we discuss that the approximate identity\n$T_{\\delta_{\\rm b}}(k) \\approx T_h(k)$ can be used to calculate the SSC terms\nanalytically.\n", "  The non-Gaussian Cold Spot (CS) surrounded by its hot ring is one of the most\nstriking features of the CMB. It has been speculated that either new physics or\nISW effect induced by the presence of a cosmic void at high redshift can\naccount for the observations. Here we investigate if the systematic decrease in\nCMB temperature in the neighbourhood of nearby galaxies may create such a\nstrong temperature depression. In particular, we note that the Eridanus\nsupergroup and its neighbouring groups, is in the CS area. Our goal is to\nanalyse observational galaxy data to characterise the neighbourhood of the CS,\nexplore the properties of these galaxies and thereby make a prediction of the\nCMB temperature decrement in this region. We use the Planck SMICA maps and the\ngalaxy catalogues 2MRS, 6dF and HIPASS as foreground tracers. We apply mean\ntemperature profiles to model the temperature decrement from the galaxies in\nthe CS area. Even after correcting for the mean low temperature of the CS\nregion, we find that the temperature decrement around galaxies is significantly\nstronger than the mean decrement in other parts of the sky. We discuss whether\nthis could be attributed to the fact that the CS area coincides with one of the\nregions populated by the most HI deficient galaxies. Modelling the foreground\ntemperature profile, we find a particularly strong temperature decrement due to\nthe presence of the late-type overabundant largest group complex in the nearby\nuniverse. A CS shape, which to a large degree overlaps with the CMB CS, is\nobserved. We conclude that the coincidence of the only nearby spiral rich group\ncomplex located in the CS region, and the success of the modelling performed,\nadds strong evidence to the existence of a local extragalactic foreground which\ncould account for the observed temperature depression, alleviating the tension\nwith an otherwise Gaussian field expected in the CMB.\n", "  Minkowski functionals are summary statistics that capture the geometric and\nmorphological properties of fields. They are sensitive to all higher order\ncorrelations of the fields and can be used to complement more conventional\nstatistics, such as the power spectrum of the field. We develop a Minkowski\nfunctional-based approach for a full likelihood analysis of mildly non-Gaussian\nsky maps with partial sky coverage. Applying this to the inference of\ncosmological parameters from the Planck mission's map of the Cosmic Microwave\nBackground's lensing convergence, we find an excellent agreement with results\nfrom the power spectrum-based lensing likelihood. While the non-Gaussianity of\ncurrent CMB lensing maps is dominated by reconstruction noise, a Minkowski\nfunctional-based analysis may be able to extract cosmological information from\nthe non-Gaussianity of future lensing maps and thus go beyond what is\naccessible with a power spectrum-based analysis. We make the numerical code for\nthe calculation of a map's Minkowski functionals, skewness and kurtosis\nparameters available for download from GitHub.\n", "  The determination of the spatial geometry of the universe plays an important\nrole in modern cosmology. Any deviation from the cosmic curvature $\\Omega_K=0$\nwould have a profound impact on the primordial inflation paradigm and\nfundamental physics. In this paper, we carry out a systematic study of the\nprospect of measuring cosmic curvature with the inspiral signal of supermassive\nblack hole binaries (SMBHBs) that could be detected with TianQin. The study is\nbased on a cosmological-model-independent method that extended the application\nof gravitational wave (GW) standard sirens in cosmology. By comparing the\ndistances from future simulated GW events and simulated $H(z)$ data, we\nevaluate if TianQin would produce robust constraints on the cosmic curvature\nparameter $\\Omega_{k}$. More specifically, we consider 3-yr to 10-yr\nobservations of supermassive black hole binaries with total masses ranging from\n$10^{3}M_\\odot$ to $10^{7}M_\\odot$. Our results show that in the future, with\nthe synergy of 10-yr high-quality observations, we can tightly constrain the\ncurvature parameter at the level of $1\\sigma$ $\\Omega_k=-0.002\\pm0.061$.\nMoreover, our findings indicate that the total mass of SMBHB does influence the\nestimation of cosmic curvature, implied by the analysis performed on different\nsubsamples of gravitational wave data. Therefore, TianQin is expected to\nprovide a powerful and competitive probe of the spatial geometry of the\nuniverse, compared to future spaced-based detectors such as DECIGO.\n", "  Alternative to weak lensing measurements through cosmic shear, we present a\nweak lensing convergence $\\hat{\\kappa}$ map reconstructed through cosmic\nmagnification effect in DECaLS galaxies of the DESI imaging surveys DR9. This\nis achieved by linearly weighing $12$ maps of galaxy number overdensity in\ndifferent magnitude bins of $grz$ photometry bands. The weight is designed to\neliminate the mean galaxy deterministic bias, minimize galaxy shot noise while\nmaintaining the lensing convergence signal. We also perform corrections of\nimaging systematics in the galaxy number overdensity. The $\\hat{\\kappa}$ map\nhas $8365$ deg$^2$ sky coverage. Given the low number density of DECaLS\ngalaxies, the $\\hat{\\kappa}$ map is overwhelmed by shot noise and the map\nquality is difficult to evaluate using the lensing auto-correlation.\nAlternatively, we measure its cross-correlation with the cosmic shear catalogs\nof DECaLS galaxies of DESI imaging surveys DR8, which has $8365$ deg$^2$\noverlap in sky coverage with the $\\hat{\\kappa}$ map. We detect a\nconvergence-shear cross-correlation signal with $S/N\\simeq 10$. The analysis\nalso shows that the galaxy intrinsic clustering is suppressed by a factor\n$\\mathcal{O}(10^2)$ and the residual galaxy clustering contamination in the\n$\\hat{\\kappa}$ map is consistent with zero. Various tests with different galaxy\nand shear samples, and the Akaike information criterion analysis all support\nthe lensing detection. So is the imaging systematics corrections, which enhance\nthe lensing signal detection by $\\sim 30\\%$. We discuss various issues for\nfurther improvement of the measurements.\n", "  We present the first cosmological constraints from analyzing higher-order\ngalaxy clustering on non-linear scales. We use ${\\rm S{\\scriptsize IM}BIG}$, a\nforward modeling framework for galaxy clustering analyses that employs\nsimulation-based inference to perform highly efficient cosmological inference\nusing normalizing flows. It leverages the predictive power of high-fidelity\nsimulations and robustly extracts cosmological information from regimes\ninaccessible with current standard analyses. In this work, we apply ${\\rm\nS{\\scriptsize IM}BIG}$ to a subset of the BOSS galaxy sample and analyze the\nredshift-space bispectrum monopole, $B_0(k_1, k_2, k_3)$, to $k_{\\rm\nmax}=0.5\\,h/{\\rm Mpc}$. We achieve 1$\\sigma$ constraints of\n$\\Omega_m=0.293^{+0.027}_{-0.027}$ and $\\sigma_8= 0.783^{+0.040}_{-0.038}$,\nwhich are more than 1.2 and 2.4$\\times$ tighter than constraints from standard\npower spectrum analyses of the same dataset. We also derive 1.4, 1.4,\n1.7$\\times$ tighter constraints on $\\Omega_b$, $h$, $n_s$. This improvement\ncomes from additional cosmological information in higher-order clustering on\nnon-linear scales and, for $\\sigma_8$, is equivalent to the gain expected from\na standard analysis on a $\\sim$4$\\times$ larger galaxy sample. Even with our\nBOSS subsample, which only spans 10% of the full BOSS volume, we derive\ncompetitive constraints on the growth of structure: $S_8 =\n0.774^{+0.056}_{-0.053}$. Our constraint is consistent with results from both\ncosmic microwave background and weak lensing. Combined with a $\\omega_b$ prior\nfrom Big Bang Nucleosynthesis, we also derive a constraint on\n$H_0=67.6^{+2.2}_{-1.8}\\,{\\rm km\\,s^{-1}\\,Mpc^{-1}}$ that is consistent with\nearly universe constraints.\n", "  The 3D distribution of galaxies encodes detailed cosmological information on\nthe expansion and growth history of the Universe. We present the first\ncosmological constraints that exploit non-Gaussian cosmological information on\nnon-linear scales from galaxy clustering, inaccessible with current standard\nanalyses. We analyze a subset of the BOSS galaxy survey using ${\\rm\nS{\\scriptsize IM}BIG}$, a new framework for cosmological inference that\nleverages high-fidelity simulations and deep generative models. We use two\nclustering statistics beyond the standard power spectrum: the bispectrum and a\nconvolutional neural network based summary of the galaxy field. We infer\nconstraints on $\\Lambda$CDM parameters, $\\Omega_b$, $h$, $n_s$, $\\Omega_m$, and\n$\\sigma_8$, that are 1.6, 1.5, 1.7, 1.2, and 2.3$\\times$ tighter than power\nspectrum analyses. With this increased precision, we derive constraints on the\nHubble constant, $H_0$, and $S_8 = \\sigma_8 \\sqrt{\\Omega_m/0.3}$ that are\ncompetitive with other cosmological probes, even with a sample that only spans\n10% of the full BOSS volume. Our $H_0$ constraints, imposing the Big Bang\nNucleosynthesis prior on the baryon density, are consistent with the early time\nconstraints from the cosmic microwave background (CMB). Meanwhile, our $S_8$\nconstraints are consistent with weak lensing experiments and similarly lie\nbelow CMB constraints. Lastly, we present forecasts to show that future work\nextending ${\\rm S{\\scriptsize IM}BIG}$ to upcoming spectroscopic galaxy surveys\n(DESI, PFS, Euclid) will produce leading $H_0$ and $S_8$ constraints that\nbridge the gap between early and late time measurements and shed light on\ncurrent cosmic tensions.\n", "  The dark ages 21-cm signal is a powerful tool for precision cosmology and\nprobing new physics. We study two non-standard models: an excess radio\nbackground (ERB) model (possibly generated by dark matter decay) and the\nmillicharged dark matter (mDM) model. These models were inspired by the\npossible EDGES detection of a strong global 21-cm absorption during cosmic\ndawn, but more generally they provide a way to anticipate the potential\ndiscovery space. During the dark ages the 21-cm global signal in the ERB model\nreaches a saturated form for an amplitude $A_{\\rm r}=0.4$, where $A_{\\rm r}$ is\nthe radio background intensity at cosmic dawn relative to the cosmic microwave\nbackground. This amplitude is one-fifth of the minimum required to explain the\nEDGES signal, and corresponds to just 0.1% of the observed extragalactic\nbackground; it would give a signal that can be detected at 5.9$\\sigma$\nsignificance (compared to $4.1\\,\\sigma$ for the standard signal) and can be\ndistinguished from the standard (no ERB) signal at $8.5\\,\\sigma$, all with a\n1,000 hr global signal measurement. The 21-cm power spectrum has potentially\nmore information, but far greater resources would be required for comparable\nconstraints. For the mDM model, over a range of viable parameters, the global\nsignal detection significance would be $4.7-7.2\\,\\sigma$, and it could be\ndistinguished from the standard at $2.2-9.3\\,\\sigma$. With an array of global\nsignal antennas achieving an effective 100,000 hr integration, the significance\nwould be $10\\,\\times$ better. Our analysis helps motivate the development of\nlunar and space-based dark ages experiments.\n", "  Deviations from Gaussianity in the distribution of the fields probed by\nlarge-scale structure surveys generate additional terms in the data covariance\nmatrix, increasing the uncertainties in the measurement of the cosmological\nparameters. Super-sample covariance (SSC) is among the largest of these\nnon-Gaussian contributions, with the potential to significantly degrade\nconstraints on some of the parameters of the cosmological model under study --\nespecially for weak lensing cosmic shear. We compute and validate the impact of\nSSC on the forecast uncertainties on the cosmological parameters for the Euclid\nphotometric survey, obtained with a Fisher matrix analysis, both considering\nthe Gaussian covariance alone and adding the SSC term -- computed through the\npublic code PySSC. The photometric probes are considered in isolation and\ncombined in the `3$\\times$2pt' analysis. We find the SSC impact to be\nnon-negligible -- halving the Figure of Merit of the dark energy parameters\n($w_0$, $w_a$) in the 3$\\times$2pt case and substantially increasing the\nuncertainties on $\\Omega_{{\\rm m},0}, w_0$, and $\\sigma_8$ for cosmic shear;\nphotometric galaxy clustering, on the other hand, is less affected due to the\nlower probe response. The relative impact of SSC does not show significant\nchanges under variations of the redshift binning scheme, while it is smaller\nfor weak lensing when marginalising over the multiplicative shear bias nuisance\nparameters, which also leads to poorer constraints on the cosmological\nparameters. Finally, we explore how the use of prior information on the shear\nand galaxy bias changes the SSC impact. Improving shear bias priors does not\nhave a significant impact, while galaxy bias must be calibrated to sub-percent\nlevel to increase the Figure of Merit by the large amount needed to achieve the\nvalue when SSC is not included.\n", "  The observed radial velocity of a galaxy consists of two main components: the\nrecession velocity caused by the smooth Hubble expansion and the peculiar\nvelocity resulting from the gravitational attraction of growing structures due\nto matter density fluctuations. To isolate the recession velocity component and\ncalculate the Hubble constant, accurate measurements of true distances are\nneeded. The Tully-Fisher relation is an empirical correlation between the\nluminosity and rotational velocity of spiral galaxies that serves as a distance\nindicator to measure distances independent of redshift. The Tully-Fisher\nrelation has played an important role in Hubble constant measurements since its\ninception. This chapter delves into the significance of the Tully-Fisher\nrelation in such measurements and explores its implications. We begin by\ndiscussing the definition and historical background of the Tully-Fisher\nrelation. We also explore the observational evidence supporting this relation\nand discuss its advantages and limitations. The chapter then focuses on the\nmethodology of using the Tully-Fisher relation for Hubble constant\nmeasurements. This includes detailed explanations of calibration techniques and\nbiases. We emphasize the advantages of utilizing the Tully-Fisher relation,\nsuch as its ability to provide accurate distance measurements even at\nsignificant redshift where other methods may encounter challenges.\n", "  We present the first test of coasting cosmological models with\ngravitational-wave standard sirens observed in the first three observing runs\nof the LIGO-Virgo-KAGRA detector network. We apply the statistical galaxy\ncatalog method adapted to coasting cosmologies and infer constraints on the\n$H_0$ Hubble constant for the three fixed values of the curvature parameter\n$k=\\left\\{ -1,0,+1 \\right\\}$ in $H_0^2 c^{-2}$ units. The maximum posteriors\nand $68.3\\%$ highest density intervals we obtained from a combined analysis of\n$46$ dark siren detections and a single bright siren detection are\n$H_0=\\left\\{68.1^{+8.5}_{-5.6},67.5^{+8.3}_{-5.2},67.1^{+6.6}_{-5.8}\n\\right\\}~\\mathrm{km\\ s^{-1}\\ Mpc^{-1}}$, respectively. All our constraints on\n$H_0$ are consistent within one sigma with the $H_0$ measured with the\ndifferential age method, which provides a constraint on $H_0$ in coasting\ncosmologies independently from $k$. Our results constrain all cosmological\nmodels with $a(t)\\propto t$ linear expansion in the luminosity distance and\nredshift range of the $47$ LIGO-Virgo detections, i.e. $d_\\mathrm{L}\\lesssim\n5~\\mathrm{Gpc}$ and $z\\lesssim 0.8$, which practically include all (both\nstrictly linear and quasi-linear) models in the coasting model family. As we\nhave found, the coasting models and the $\\Lambda$CDM model fit equally well to\nthe applied set of gravitational-wave detections.\n", "  Beyond-two-point statistics contain additional information on cosmological as\nwell as astrophysical and observational (systematics) parameters. In this\nmethodology paper we provide an end-to-end simulation-based analysis of a set\nof Gaussian and non-Gaussian weak lensing statistics using detailed mock\ncatalogues of the Dark Energy Survey. We implement: 1) second and third\nmoments; 2) wavelet phase harmonics (WPH); 3) the scattering transform (ST).\nOur analysis is fully based on simulations, it spans a space of seven $\\nu\nw$CDM cosmological parameters, and it forward models the most relevant sources\nof systematics of the data (masks, noise variations, clustering of the sources,\nintrinsic alignments, and shear and redshift calibration). We implement a\nneural network compression of the summary statistics, and we estimate the\nparameter posteriors using a likelihood-free-inference approach. We validate\nthe pipeline extensively, and we find that WPH exhibits the strongest\nperformance when combined with second moments, followed by ST. and then by\nthird moments. The combination of all the different statistics further enhances\nconstraints with respect to second moments, up to 25 per cent, 15 per cent, and\n90 per cent for $S_8$, $\\Omega_{\\rm m}$, and the Figure-Of-Merit ${\\rm\nFoM_{S_8,\\Omega_{\\rm m}}}$, respectively. We further find that non-Gaussian\nstatistics improve constraints on $w$ and on the amplitude of intrinsic\nalignment with respect to second moments constraints. The methodological\nadvances presented here are suitable for application to Stage IV surveys from\nEuclid, Rubin-LSST, and Roman with additional validation on mock catalogues for\neach survey. In a companion paper we present an application to DES Year 3 data.\n", "  Recently, a new wave of full modeling analyses have emerged within the\nLarge-Scale Structure community, leading mostly to tighter constraints on the\nestimation of cosmological parameters, when compared with standard approaches\nused over the last decade by collaboration analyses of stage III experiments.\nHowever, the majority of these full-shape analyses have primarily been\nconducted in Fourier space, with limited emphasis on exploring the\nconfiguration space. Investigating n-point correlations in configuration space\ndemands a higher computational cost compared to Fourier space because it\ntypically requires an additional integration step. This can pose a limitation\nwhen using these approaches, especially when considering higher-order\nstatistics. One avenue to mitigate the high computation time is to take\nadvantage of neural network acceleration techniques. In this work, we present a\nfull shape analysis of Sloan Digital Sky Survey III/BOSS in configuration space\nusing a neural network accelerator. We show that the efficacy of the pipeline\nis enhanced by a time factor $10^{3}$ without sacrificing precision, making it\npossible to reduce the error associated with the surrogate modeling to below\n$10^{-2}$ percent which is compatible with the precision required for current\nstage IV experiments such as DESI. We find $\\Omega_m=0.286\\pm 0.009$,\n$H_0=68.8\\pm 1.2$ $\\mathrm{km} \\mathrm{s^{-1}}\\mathrm{Mpc^{-1}}$ and $A_s\n\\times 10^9 =2.09 ^{+0.25}_{-0.29}$. Our results on public BOSS data are in\ngood agreement with BOSS official results and compatible with other independent\nfull modeling analyses. We explore relaxing the prior on $\\omega_b$ and varying\n$n_s$, without significant changes in the mean values of the cosmological\nparameters posterior distributions, but enlarging their widths. Finally, we\nexplore the information content of the multipoles when constraining\ncosmological parameters.\n", "  As demonstrated by Planck, SPT, and ACT, the abundance of\nSunyaev-Zeldovich-detected galaxy clusters across mass and redshift is a\npowerful cosmological probe. Upcoming experiments such as the Simons\nObservatory (SO) will detect over an order of magnitude more objects than what\nprevious experiments have found, thereby providing an unprecedented\nconstraining potential. However, in order for this potential to be realised,\nthe cluster detection and analysis pipelines will have to be built and\nunderstood to a much higher level of accuracy than has been demonstrated to\ndate. Here we discuss ongoing efforts towards the accurate modelling of tSZ\ncluster counts, focusing on several improvements regarding optimisation bias,\ncovariance estimation, and foreground deprojection, which are implemented in\nthe publicly-available SZiFi package. Next, we briefly discuss the application\nof these improved cluster detection methods to Planck data. Finally, we\nintroduce cosmocnc, a new cluster number count likelihood code that will be\npublicly available soon.\n", "  Halo Occupation Distribution (HOD) models help us to connect observations and\ntheory, by assigning galaxies to dark matter haloes. In this work we study one\nof the components of HOD models: the probability distribution function (PDF),\nwhich is used to assign a discrete number of galaxies to a halo, given a mean\nnumber of galaxies. For satellite galaxies, the most commonly used PDF is a\nPoisson Distribution. PDFs with super-Poisson variances have also been studied,\nallowing for continuous values of variances. This has not been the case for\nsub-Poisson variances, for which only the Nearest Integer distribution, with a\nsingle variance, has been used in the past. In this work we propose a\ndistribution based on the binomial one, which provides continuous sub-Poisson\nvariances. We have generated mock galaxy catalogues from two dark-matter only\nsimulations, UNIT and OUTERIM, with HOD models assuming different PDFs. We show\nthat the variance of the PDF for satellite galaxies affects the one-halo term\nof the projected correlation function, and the Count-In-Cells (CIC) one point\nstatistics. We fit the clustering of eBOSS Emission Line Galaxies, finding a\npreference for a sub-poissonian PDF, when we only vary the parameter\ncontrolling the PDF variance and the fraction of satellites. Using a mock\ncatalogue as a reference, we have also included both the clustering and CIC to\nconstrain the parameters of the HOD model. CIC can provide strong constraints\nto the PDF variance of satellite galaxies.\n", "  Through observational tests of strong lensing galaxy clusters, we can test\nsimulation derived structure predictions that follow from $\\Lambda$ Cold Dark\nMatter ($\\Lambda$CDM) cosmology. The shape and centroid deviations between the\ntotal matter distribution, stellar matter distributions, and hot intracluster\ngas distribution serve as an observational test of these theoretical structure\npredictions. We measure the position angles, ellipticities, and\nlocations/centroids of the brightest cluster galaxy (BCG), intracluster light\n(ICL), the hot intracluster medium (ICM), and the core lensing mass for a\nsample of strong lensing galaxy clusters from the SDSS Giant Arcs Survey\n(SGAS). We utilize HST WFC3/IR imaging data to measure the shapes/centroids of\nthe ICL and BCG distributions and use Chandra ACIS-I X-ray data to measure the\nshapes/centroids of ICM. Additionally, we measure the concentration parameter c\nand asymmetry parameter A to incorporate cluster dynamical state into our\nanalysis. Using this multicomponent approach, we attempt to constrain the\nastrophysics of our strong lensing cluster sample and evaluate the different\ncomponents in terms of their ability to trace out the DM halo of clusters in\nvarious dynamical states.\n", "  This paper examines a power law solution under $f(R,T)$ gravity for an\nisotropic and homogeneous universe by considering its functional form as\n$f(R,T) = R + \\xi RT$, where $\\xi$ is a positive constant. In $f(R,T)$ gravity,\nwe have built the field equation for homogeneous and isotropic spacetime. The\ndeveloped model's solution is $a = \\alpha t^{\\beta}$. We have used the redshift\nin the range $0 \\leq z \\leq 1.965$ and obtained the model parameters $\\alpha$,\n$\\beta$, $H_0$ by using the Markov Chain Monte Carlo (MCMC) method. The\nconstrained values of the model parameter are as follows: $H_0 =\n67.098^{+2.148}_{-1.792}$ km s$^{-1}$ Mpc$^{-1}$, $H_0 =\n67.588^{+2.229}_{-2.170}$ km s$^{-1}$ Mpc$^{-1}$, $H_0 =\n66.270^{+2.215}_{-2.181}$ km s$^{-1}$ Mpc$^{-1}$, $H_0 =\n65.960^{+2.380}_{-1.834}$ km s$^{-1}$ Mpc$^{-1}$, $H_0 =\n66.274^{+2.015}_{-1.864}$ km s$^{-1}$ Mpc$^{-1}$ which have been achieved by\nbounding the model with the Hubble parameter ($H(z)$) dataset, Baryon Acoustic\nOscillations (BAO) dataset, Pantheon dataset, joint $H(z)$ + Pantheon dataset\nand collective $H(z)$ + BAO + Pantheon dataset, respectively. These computed\n$H_o$ observational values agree well with the outcomes from the Plank\ncollaboration group. Through an analysis of the energy conditions' behaviour on\nour obtained solution, the model has been examined and analysed. Using the Om\ndiagnostic as the state finder diagnostic tool and the jerk parameter, we have\nalso investigated the model's validity. Our results show that, within a certain\nrange of restrictions, the proposed model agrees with the observed signatures.\n", "  The large-scale distribution of matter, as mapped by photometric surveys like\nthe Dark Energy Survey (DES), serves as a powerful probe into cosmology. It is\nespecially sensitive to both the amplitude of matter clustering ($\\sigma_8$)\nand the total matter density ($\\Omega_m$). The fiducial analysis of the\ntwo-point clustering statistics of these surveys is invariably done in\nconfiguration space where complex masking scheme is easier to handle. However,\nsuch an analysis inherently mixes different scales together, requiring special\ncare in modeling. In this study, we present an analysis of DES Y3 3x2\nclustering data in harmonic space where small and large scales are better\nseparated and can be neatly modeled using perturbative techniques. Using\nconservative scale cuts together with Limber approximation and a Gaussian\ncovariance assumption in a first study, we model the clustering data under a\nlinear bias model for galaxies, incorporating comprehensive treatment for\nastrophysical effects. We subsequently extend this fiducial analysis to explore\na third-order biasing prescription. For our fiducial analysis, we get\n$S_8=0.789\\pm0.020$, consistent with the configuration space analysis presented\nby the DES collaboration, although under our different modeling choices, we\nfind a preference for a lower $\\Omega_m$ and a higher $\\sigma_8$. The analysis\nsets the stage for a future search for signatures of primordial non-Gaussianity\nand blue-tilted isocurvature perturbations from photometric surveys.\n", "  The near infrared background (NIRB) is the collective light from unresolved\nsources observed in the band 1-10 $\\mu$m. The measured NIRB angular power\nspectrum on angular scales $\\theta \\gtrsim 1$ arcmin exceeds by roughly two\norder of magnitudes predictions from known galaxy populations. The nature of\nthe sources producing these fluctuations is still unknown. Here we test\nprimordial black holes (PBHs) as sources of the NIRB excess. Considering PBHs\nas a cold dark matter (DM) component, we model the emission of gas accreting\nonto PBHs in a cosmological framework. We account for both accretion in the\nintergalactic medium (IGM) and in DM haloes. We self consistently derive the\nIGM temperature evolution, considering ionization and heating due to X-ray\nemission from PBHs. Besides $\\Lambda$CDM, we consider a model that accounts for\nthe modification of the linear matter power spectrum due to the presence of\nPBHs; we also explore two PBH mass distributions, i.e. a $\\delta$-function and\na lognormal distribution. For each model, we compute the mean intensity and the\nangular power spectrum of the NIRB produced by PBHs with mass\n1-$10^3~\\mathrm{M}_{\\odot}$. In the limiting case in which the entirety of DM\nis made of PBHs, the PBH emission contributes $<1$ per cent to the observed\nNIRB fluctuations. This value decreases to $<0.1$ per cent if current\nconstraints on the abundance of PBHs are taken into account. We conclude that\nPBHs are ruled out as substantial contributors to the NIRB.\n", "  The era of precision cosmology allows us to test the composition of the dark\nmatter. Mixed ultralight or fuzzy dark matter (FDM) is a cosmological model\nwith dark matter composed of a combination of particles of mass $m\\leq\n10^{-20}\\;\\mathrm{eV}$, with an astrophysical de Broglie wavelength, and\nparticles with a negligible wavelength sharing the properties of cold dark\nmatter (CDM). In this work, we simulate cosmological volumes with a dark matter\nwave function for the ultralight component coupled gravitationally to CDM\nparticles. We investigate the impact of a mixture of CDM and FDM in various\nproportions $(0\\%,\\;1\\%,\\;10\\%,\\;50\\%,\\;100\\%)$ and for ultralight particle\nmasses ranging over five orders of magnitude $(2.5\\times\n10^{-25}\\;\\mathrm{eV}-2.5\\times 10^{-21}\\;\\mathrm{eV})$. To track the evolution\nof density perturbations in the non-linear regime, we adapt the simulation code\nAxioNyx to solve the CDM dynamics coupled to a FDM wave function obeying the\nSchr\\\"odinger-Poisson equations. We obtain the non-linear power spectrum and\nstudy the impact of the wave effects on the growth of structure on different\nscales. We confirm that the steady-state solution of the Schr\\\"odinger-Poisson\nsystem holds at the center of halos in the presence of a CDM component when it\ncomposes $50\\%$ or less of the dark matter but find no stable density core when\nthe FDM accounts for $10\\%$ or less of the dark matter. We implement a modified\nfriends-of-friends halo finder and find good agreement between the observed\nhalo abundance and the predictions from the adapted halo model axionHMCode.\n", "  This paper is a parametrization of the equation of state (EoS) parameter of\ndark energy (DE), which is parameterized using Square-Root (SR) form i.e.\n$\\omega _{SR}=\\text{$\\omega _{0}$}+\\text{$\\omega\n_{1}$}\\frac{z}{\\sqrt{z^{2}+1}}$, where $\\omega _{0}$ and $\\omega _{1}$ are free\nconstants. This parametrization will be examined in the context of the recently\nsuggested $f(Q)$ gravity theory as an alternative to General Relativity (GR),\nin which gravitational effects are attributed to the non-metricity scalar $Q$\nwith the functional form $f(Q)=Q+\\alpha Q^{n}$, where $\\alpha$ and $n$ are\narbitrary constants. We derived observational constraints on model parameters\nusing the Hubble dataset with 31 data points and the Supernovae (SNe) dataset\nfrom the Pantheon samples compilation dataset with 1048 data points. For the\ncurrent model, the evolution of the deceleration parameter, density parameter,\nEoS for DE, and $Om(z)$ diagnostic have all been investigated. It has been\nshown that the deceleration parameter favors the current accelerated expansion\nphase. It has also been shown that the EoS parameter for DE has a quintessence\nnature at this time.\n", "  Constrained cosmological simulations play an important role in modelling the\nlocal Universe, enabling investigation of the dark matter content of local\nstructures and their formation histories. We introduce a method for determining\nthe extent to which individual haloes are reliably reconstructed between\nconstrained simulations, and apply it to the Constrained Simulations in BORG\n(CSiBORG) suite of $101$ high-resolution realisations across the posterior\nprobability distribution of initial conditions from the Bayesian Origin\nReconstruction from Galaxies (BORG) algorithm. The method is based on the\noverlap of the initial Lagrangian patch of a halo in one simulation with those\nin another, and therefore measures the degree to which the haloes' particles\nare initially coincident. By this metric we find consistent reconstructions of\n$M\\gtrsim10^{14}~M_\\odot / h$ haloes across the CSiBORG simulations, indicating\nthat the constraints from the BORG algorithm are sufficient to pin down the\nmasses, positions and peculiar velocities of clusters to high precision. The\neffect of the constraints tapers off towards lower mass however, and the halo\nspins and concentrations are largely unconstrained at all masses. We document\nthe advantages of evaluating halo consistency in the initial conditions,\ndescribe how the method may be used to quantify our knowledge of the halo field\ngiven galaxy survey data analysed through the lens of probabilistic inference\nmachines such as BORG, and describe applications to matched but unconstrained\nsimulations.\n", "  Deep learning (DL) has recently been proposed as a novel approach for 21cm\nforeground removal. Before applying DL to real observations, it is essential to\nassess its consistency with established methods, its performance across various\nsimulation models and its robustness against instrumental systematics. This\nstudy develops a commonly used U-Net and evaluates its performance for\npost-reionisation foreground removal across three distinct sky simulation\nmodels based on pure Gaussian realisations, the Lagrangian perturbation theory,\nand the Planck sky model. Stable outcomes across the models are achieved\nprovided that training and testing data align with the same model. On average,\nthe residual foreground in the U-Net reconstructed data is $\\sim$10% of the\nsignal across angular scales at the considered redshift range. Comparable\nresults are found with traditional approaches. However, blindly using a network\ntrained on one model for data from another model yields inaccurate\nreconstructions, emphasising the need for consistent training data. The study\nthen introduces frequency-dependent Gaussian beams and gain drifts to the test\ndata. The network struggles to denoise data affected by \"unexpected\"\nsystematics without prior information. However, after re-training consistently\nwith systematics-contaminated data, the network effectively restores its\nreconstruction accuracy. This highlights the importance of incorporating prior\nsystematics knowledge during training for successful denoising. Our work\nprovides critical guidelines for using DL for 21cm foreground removal, tailored\nto specific data attributes. Notably, it is the first time that DL has been\napplied to the Planck sky model being most realistic foregrounds at present.\n", "  This paper introduces a technique called NKL, which cleans both polarized and\nunpolarized foregrounds from HI intensity maps by applying a Karhunen-Lo\\`eve\ntransform on the needlet coefficients. In NKL, one takes advantage of\ncorrelations not only along the line of sight, but also between different\nangular regions, referred to as ``chunks\". This provides a distinct advantage\nover many of the standard techniques applied to map-space that one finds in the\nliterature, which do not consider such spatial correlations. Moreover, the NKL\ntechnique does not require any priors on the nature of the foregrounds, which\nis important when considering polarized foregrounds. We also introduce a\nmodified version of GNILC, referred to as MGNILC, which incorporates an\napproximation of the foregrounds to improve performance. The NKL and MGNILC\ntechniques are tested on simulated maps which include polarized foregrounds.\nTheir performance is compared to the GNILC, GMCA, ICA and PCA techniques. Two\nseparate tests were performed. One at $1.84 < z < 2.55$ and the other at $0.31\n< z < 0.45$. NKL was found to provide the best performance in both tests,\nproviding a factor of 10 to 50 improvement over GNILC at $k < 0.1\\,{\\rm\nhMpc^{-1}}$ in the higher redshift case and $k < 0.03 \\,{\\rm hMpc^{-1}}$ in the\nlower redshift case. However, none of the methods were found to recover the\npower spectrum satisfactorily at all BAO scales.\n", "  The reconstruction of the large scale velocity field from the grouped\nCosmicflows-4 (CF4) database is presented. The lognormal bias of the inferred\ndistances and velocities data is corrected by the Bias Gaussianization\ncorrection (BGc) scheme, and the linear density and velocity fields are\nreconstructed by means of the Wiener filter (WF) and constrained realizations\n(CRs) algorithm. These tools are tested against a suite of random and\nconstrained Cosmicflows-3-like mock data. The CF4 data consists of 3 main\nsubsamples - the 6dFGS and the SDSS data - and the `others'. The individual\ncontributions of the subsamples have been studied. The quantitative analysis of\nthe velocity field is done mostly by the mean overdensity ($\\Delta_L(R)$) and\nthe bulk velocity ($V_{\\mathrm{bulk}}(R)$) profiles of the velocity field out\nto $300\\, h^{-1}{\\rm Mpc}$.\n  The $V_{\\mathrm{bulk}}(R)$ and $\\Delta_{\\mathrm L}(R)$ profiles of the CF4\ndata without its 6dFGS component are consistent with the cosmic variance to\nwithin $1\\sigma$. The 6dFGS sample dominates the $V_{\\mathrm{bulk}}$\n($\\Delta_{\\mathrm L}$) profile beyond $\\sim120\\, h^{-1}{\\rm Mpc}$, and drives\nit to roughly a $3.4\\sigma$ ($-1.9\\sigma$) excess (deficiency) relative to the\ncosmic variance at $R\\sim250\\ (190)\\ \\, h^{-1}{\\rm Mpc}$. The excess in the\namplitude of $V_{\\mathrm{bulk}}$ is dominated by its Supergalactic X component,\nroughly in the direction of the Shapley Concentration. The amplitude and\nalignment of the inferred velocity field from the CF4 data is at\n$\\sim(2\\,-\\,3)\\,\\sigma$ discrepancy with respect to the $\\Lambda$CDM model.\nNamely, it is somewhat atypical but yet there is no compelling tension with the\nmodel.\n", "  Aims. We study the possibility that the gas in cool-core clusters of galaxies\nhas non-negligible rotation support, the impact of gas rotation on mass\nestimates from current X-ray observations, and the ability of forthcoming X-ray\nobservatories to detect such rotation.\n  Methods. We present three representative models of massive cool-core clusters\nwith rotating intracluster medium (ICM) in equilibrium in cosmologically\nmotivated spherical, oblate or prolate dark matter halos. In the models, the\ngas follows a composite-polytropic distribution, and has rotation velocity\nprofiles consistent with current observational constraints. We show that the\nmodels are consistent with the available measurements of the ICM properties of\nthe massive cluster population: thermodynamic profiles, shape of\nsurface-brightness distribution, hydrostatic mass bias and broadening of X-ray\nemitting lines. Using the configuration for the microcalorimeter onboard the\nXRISM satellite, we generate a set of mock X-ray spectra of our cluster models,\nwhich we then analyze to make predictions on the estimates of the rotation\nspeed that will be obtained with such an instrument. We then assess what\nfraction of the hydrostatic mass bias of our models could be accounted for by\ndetecting rotation speed with XRISM spectroscopy over the range (0.1-1)r500.\n  Results. Current data leave room for rotating ICM in cool-core clusters with\npeaks of rotation speed as high as 600 km/s. We have shown that such rotation,\nif present, will be detected with upcoming X-ray facilities such as XRISM and\nthat 60-70% of the hydrostatic mass bias due to rotation can be accounted for\nusing the line-of-sight velocity measured from X-ray spectroscopy with XRISM,\nwith a residual bias smaller than 3% at an overdensity of 500. In this way,\nXRISM will allow us to pin down any mass bias of origin different from\nrotation.\n", "  In the quest for the faint primordial B-mode polarization of the Cosmic\nMicrowave Background, three are the key requirements for any present or future\nexperiment: an utmost sensitivity, excellent control over instrumental\nsystematic effects and over Galactic foreground contamination. Bolometric\nInterferometry (BI) is a novel technique that matches them all by combining the\nsensitivity of bolometric detectors, the control of instrumental systematics\nfrom interferometry and a software-based, tunable, in-band spectral resolution\ndue to its ability to perform band-splitting during data analysis (spectral\nimaging). In this paper, we investigate how the spectral imaging capability of\nBI can help in detecting residual contamination in case an over-simplified\nmodel of foreground emission is assumed in the analysis. To mimic this\nsituation, we focus on the next generation of ground-based CMB experiment,\nCMB-S4, and compare its anticipated sensitivities, frequency and sky coverage\nwith a hypothetical version of the same experiment based on BI, CMB-S4/BI,\nassuming that line-of-sight (LOS) frequency decorrelation is present in dust\nemission but is not accounted for during component separation. We show results\nfrom a Monte-Carlo analysis based on a parametric component separation method\n(FGBuster), highlighting how BI has the potential to diagnose the presence of\nforeground residuals in estimates of the tensor-to-scalar ratio $r$ in the case\nof unaccounted Galactic dust LOS frequency decorrelation.\n", "  The Hubble diagram (HD) is a plot that contains luminous distance modulus\npresented with respect to the redshift. The distance modulus--redshift relation\nof the most well-known ``standard candles'', the type Ia supernovae (SN), is a\ncrucial tool in cosmological model testing. In this work, we use the SN Ia data\nfrom the Pantheon catalogue to calibrate the Swift long gamma-ray bursts\n(LGRBs) as ``standard candles'' via the Amati relation. Thus, we expand the HD\nfrom supernovae to the area of the Swift LGRBs up to $z\\sim8$. To improve the\nquality of estimation of the parameters and their errors, we implement the\nMonte-Carlo uncertainty propagation method. We also compare the results of\nestimation of the Amati parameters calibrated by the SN Ia, and by the standard\n$\\Lambda$CDM model and find no statistically significant distinguish between\nthem. Although the size of our LGRB sample is relatively small and the errors\nare high, we find this approach of expanding the cosmological distance scale\nperspective for future cosmological tests.\n", "  This study proposes a novel parametrization approach for the dimensionless\nHubble parameter i.e. $E^2(z)=A(z)+\\beta (1+\\gamma B(z))$ in the context of\nscalar field dark energy models. The parameterization is characterized by two\nfunctions, $A(z)$ and $B(z)$, carefully chosen to capture the behavior of the\nHubble parameter at different redshifts. We explore the evolution of\ncosmological parameters, including the deceleration parameter, density\nparameter, and equation of state parameter. Observational data from Cosmic\nChronometers (CC), Baryonic Acoustic Oscillations (BAO), and the Pantheon+\ndatasets are analyzed using MCMC methodology to determine model parameters. The\nresults are compared with the standard $\\Lambda$CDM model using the Planck\nobservations. Our approach provides a model-independent exploration of dark\nenergy, contributing to a comprehensive understanding of late-time cosmic\nacceleration.\n", "  In this paper we investigate the impact of lensing magnification on the\nanalysis of Euclid's spectroscopic survey, using the multipoles of the 2-point\ncorrelation function for galaxy clustering. We determine the impact of lensing\nmagnification on cosmological constraints, and the expected shift in the\nbest-fit parameters if magnification is ignored. We consider two cosmological\nanalyses: i) a full-shape analysis based on the $\\Lambda$CDM model and its\nextension $w_0w_a$CDM and ii) a model-independent analysis that measures the\ngrowth rate of structure in each redshift bin. We adopt two complementary\napproaches in our forecast: the Fisher matrix formalism and the Markov chain\nMonte Carlo method. The fiducial values of the local count slope (or\nmagnification bias), which regulates the amplitude of the lensing\nmagnification, have been estimated from the Euclid Flagship simulations. We use\nlinear perturbation theory and model the 2-point correlation function with the\npublic code coffe. For a $\\Lambda$CDM model, we find that the estimation of\ncosmological parameters is biased at the level of 0.4-0.7 standard deviations,\nwhile for a $w_0w_a$CDM dynamical dark energy model, lensing magnification has\na somewhat smaller impact, with shifts below 0.5 standard deviations. In a\nmodel-independent analysis aiming to measure the growth rate of structure, we\nfind that the estimation of the growth rate is biased by up to $1.2$ standard\ndeviations in the highest redshift bin. As a result, lensing magnification\ncannot be neglected in the spectroscopic survey, especially if we want to\ndetermine the growth factor, one of the most promising ways to test general\nrelativity with Euclid. We also find that, by including lensing magnification\nwith a simple template, this shift can be almost entirely eliminated with\nminimal computational overhead.\n", "  We propose a novel approach to parameterize the equation of state for Scalar\nField Dark Energy (SFDE) and use it to derive analytical solutions for various\ncosmological parameters. Using statistical MCMC with Bayesian techniques, we\nobtain constraint values for the model parameters and analyze three\nobservational datasets. We find a quintessence-like behavior for Dark Energy\n(DE) with positive values for both model parameters $\\alpha$ and $\\beta$. Our\nanalysis of the $CC$+$BAO$+$SNe$ datasets reveals that the transition redshift\nand the current value of the deceleration parameter are\n$z_{tr}=0.73_{-0.01}^{+0.03}$ and $q_{0}=-0.44_{-0.02}^{+0.03}$, respectively.\nWe also investigate the fluid flow of accretion SFDE around a Black Hole (BH)\nand analyze the nature of the BH's dynamical mass during accretion, taking into\naccount Hawking radiation and BH evaporation. Our proposed model offers insight\ninto the nature of DE in the Universe and the behavior of BHs during accretion.\n", "  Recently, pulsar timing array (PTA) collaborations, including NANOGrav, have\nreported evidence of a stochastic gravitational wave background within the nHz\nfrequency range.\\ It can be interpreted by gravitational waves from preheating\nera. In this context, we demonstrate that the emission of this stochastic\ngravitational wave background can be attributed to fluctuations occurring at\nthe end of inflation, thus giving rise to the Hubble tension issue. At the\nonset of inflation, the value of the frequency of the gravitational wave signal\nstood at $f=0.08nHz$, but it rapidly transitioned to $f=1nHz$ precisely at the\nend of inflation. However, just before the end of inflation, a phase\ncharacterized by curvature perturbation is known to occur, causing a swift\nincrease in the frequency.\n", "  Fuzzy Dark Matter (FDM) has recently emerged as an interesting alternative\nmodel to the standard Cold Dark Matter (CDM). In this model, dark matter\nconsists of very light bosonic particles with quantum mechanical effects on\ngalactic scales. Using the N-body code AX-GADGET, we perform cosmological\nsimulations of FDM that fully model the dynamical effects of the quantum\npotential throughout cosmic evolution. Through the combined analysis of FDM\nvolume and high-resolution zoom-in simulations of different FDM particle masses\n($m_{\\chi}$ $\\sim$ $10^{-23} - 10^{-21}$ eV/c$^2$), we study how FDM impacts\nthe abundance of substructure and the inner density profiles of dark matter\nhaloes. For the first time, using our FDM volume simulations, we provide a\nfitting formula for the FDM-to-CDM subhalo abundance ratio as a function of the\nFDM mass.\n  More importantly, our simulations clearly demonstrate that there exists an\nextended FDM particle mass interval able to reproduce the observed substructure\ncounts and, at the same time, create substantial cores ($r_{c} \\sim 1$ kpc) in\nthe density profile of dwarf galaxies ($\\approx 10^{9}-10^{10}$ M$_{\\odot}$),\nwhich stands in stark contrast with CDM predictions even with baryonic effects\ntaken into account. The dark matter distribution in the faintest galaxies\noffers then a clear way to discriminate between FDM and CDM.\n", "  The cosmological model with an interaction between dynamical quintessence\ndark energy and cold dark matter is considered. Evolution of a dark energy\nequation of state parameter is defined by a dark energy adiabatic sound speed\nand a dark sector interaction parameter, which must be more physically correct\nmodel then a previously used in which such evolution was given by some fixed\ndependence on scale factor. The constraints on interaction parameter and other\nparameters of the model was obtained using a cosmic microwave background,\nbaryon acoustic oscillations and supernova SN Ia data.\n", "  We present a first measurement of the galaxy-galaxy-CMB lensing bispectrum.\nThe signal is detected at $26\\sigma$ and $22\\sigma$ significance using two\nsamples from the unWISE galaxy catalog at mean redshifts $\\bar{z}=0.6$ and\n$1.1$ and lensing reconstructions from Planck PR4. We employ a compressed\nbispectrum estimator based on the cross-correlation between the square of the\ngalaxy overdensity field and CMB lensing reconstructions. We present a series\nof consistency tests to ensure the cosmological origin of our signal and rule\nout potential foreground contamination. We compare our results to model\npredictions from a halo model previously fit to only two-point spectra, finding\nreasonable agreement when restricting our analysis to large scales. Such\nmeasurements of the CMB lensing galaxy bispectrum will have several important\ncosmological applications, including constraining the uncertain higher-order\nbias parameters that currently limit lensing cross-correlation analyses.\n", "  We search for narrow-line optical emission from dark matter decay by stacking\ndark-sky spectra from the Dark Energy Spectroscopic Instrument (DESI) at the\nredshift of nearby galaxies from DESI's Bright Galaxy and Luminous Red Galaxy\nsamples. Our search uses regions separated by 5 to 20 arcsecond from the\ncenters of the galaxies, corresponding to an impact parameter of approximately\n$50\\,\\rm kpc$. No unidentified spectral line shows up in the search, and we\nplace a line flux limit of\n$10^{-19}\\,\\rm{ergs}/\\rm{s}/\\rm{cm}^{2}/\\rm{arcsec}^{2}$ on emissions in the\noptical band ($3000\\lesssim\\lambda\\lesssim9000 \\,\\mathring{\\rm A}$), which\ncorresponds to $34$ in AB magnitude in a normal broadband detection. This\ndetection limit suggests that the line surface brightness contributed from all\ndark matter along the line of sight is two orders of magnitude lower than the\nmeasured extragalactic background light (EBL), which rules out the possibility\nthat narrow optical-line emission from dark matter decay is a major source of\nthe EBL.\n", "  Intensity mapping of 21cm emission from neutral hydrogen (HI) promises to be\na powerful probe of large-scale structure in the post-reionisation epoch.\nHowever, HI intensity mapping (IM) experiments will suffer the loss of\nlong-wavelength line-of-sight HI modes in the galactic foreground subtraction\nprocess. The loss of these modes is particularly problematic for detecting HI\nIM cross-correlations with projected large-scale structure tracers, such as CMB\nsecondary anisotropies. Here, we propose a cross-bispectrum estimator to\nrecover the cross-correlation of the HI IM field, $\\delta T_{21},$ with the CMB\nlensing field, $\\kappa,$ constructed by correlating the position-dependent HI\npower spectrum with the mean overdensity traced by CMB lensing.\n  We study the cross-bispectrum estimator, $B^{\\bar \\kappa \\delta T_{21} \\delta\nT_{21}},$ in the squeezed limit and forecast its detectability based on HI IM\nmeasurements from HIRAX and CMB lensing measurements from AdvACT. The\ncross-bispectrum improves constraints on cosmological parameters; in\nparticular, the constraint on the dark energy equation-of-state parameter,\n$w_0,$ improves on the HI IM auto-power spectra constraint by 44\\% (to 0.014),\nwhile the constraint on $w_a$ improves by 33\\% (to 0.08), assuming Planck\npriors in each case. These results are robust to HI IM foreground removal\nbecause they largely derive from small-scale HI modes. The HI-HI-$\\kappa$\ncross-bispectrum thus provides a novel way to recover HI correlations with CMB\nlensing and constrain cosmological parameters at a level that is competitive\nwith next-generation galaxy redshift surveys. As a striking example of this, we\nfind that the combined constraint on the sum of the neutrino masses, while\nvarying all redshift and standard cosmological parameters within a\n$w_0w_a\\Omega_K$CDM model, is 5.5 meV.\n", "  The large-angular-scale falloff in the autocorrelation function for the\ncosmic microwave background (CMB) temperature has long intrigued cosmologists\nand fueled speculation about suppressed superhorizon power. Here we highlight\nan inconsistency between the temperature quadrupole and the more recently\nobtained E-mode polarization quadrupole from Planck PR3. The temperature\nquadrupole arises primarily at the CMB surface of last scatter, while the\npolarization primarily from the epoch of reionization, but the two still probe\ncomparable distance scales. Although the temperature quadrupole is intriguingly\nlow (much greater than a $1\\sigma$ fluctuation) compared with that expected in\nthe standard $\\Lambda$CDM cosmological model, the polarization quadrupole turns\nout to be somewhat high, at the $1\\sigma$ level. We calculate the joint\nprobability distribution function for both and find a slight tension: the\nobserved pair of quadrupoles is inconsistent at a $2.3\\sigma$ confidence level.\nThe problem is robust to simple changes to the cosmological model. If the high\npolarization quadrupole survives further scrutiny, then this result disfavors,\nat comparable significance, new superhorizon physics. The full-sky coverage and\npristine foreground subtraction of the LiteBIRD satellite will be ideal to help\nresolve this question.\n", "  Studies of the Universe's transition to smoothness in the context of LCDM\nhave all pointed to a transition radius no larger than ~300 Mpc. These are\nbased on a broad array of tracers for the matter power spectrum, including\ngalaxies, clusters, quasars, the Ly-alpha forest and anisotropies in the cosmic\nmicrowave background. It is therefore surprising, if not anomalous, to find\nmany structures extending out over scales as large as ~2 Gpc, roughly an order\nof magnitude greater than expected. Such a disparity suggests that new physics\nmay be contributing to the formation of large-scale structure, warranting a\nconsideration of the alternative FLRW cosmology known as the $R_h=ct$ universe.\nThis model has successfully eliminated many other problems in LCDM. In this\npaper, we calculate the fractal (or Hausdorff) dimension in this cosmology as a\nfunction of distance, showing a transition to smoothness at ~2.2 Gpc, fully\naccommodating all of the giant structures seen thus far. This outcome adds\nfurther observational support for R_h=ct over the standard model.\n", "  The warm inflationary scenario is investigated in the context of affine\ngravity formalism. A general framework is provided for studying different\nsingle-field potentials. Using the sphaleron mechanism we explain the\ncontinuous dissipation of the inflaton field into radiation, leading to the\n$\\Gamma=\\Gamma_0 T^3$ dissipation coefficient. The treatment is performed in\nthe weak and strong dissipation limits. We consider the quartic potential as a\ncase study to provide a detailed study. Moreover, in this study, we discuss\nvarious constraints on inflationary models in general. We compare the\ntheoretical results of the quartic potential model within warm inflation with\nthe observational constraints from Planck $2018$ and BICEP/Keck 2018, as\npresented by the tensor-to-scalar ratio, spectral index and the perturbation\nspectrum.\n", "  The Axion Dark Matter eXperiment (ADMX) has previously excluded\nDine-Fischler-Srednicki-Zhitnisky (DFSZ) axions between 680-790 MHz under the\nassumption that the dark matter is described by the isothermal halo model.\nHowever, the precise nature of the velocity distribution of dark matter is\nstill unknown, and alternative models have been proposed. We report the results\nof a non-virialized axion search over the mass range 2.81-3.31 {\\mu}eV,\ncorresponding to the frequency range 680-800 MHz. This analysis marks the most\nsensitive search for non-virialized axions sensitive to Doppler effects in the\nMilky Way Halo to date. Accounting for frequency shifts due to the detector's\nmotion through the Galaxy, we exclude cold flow relic axions with a velocity\ndispersion of order 10^-7 c with 95% confidence.\n", "  We constrain cosmology and baryonic feedback scenarios with a joint analysis\nof weak lensing, galaxy clustering, cosmic microwave background (CMB) lensing,\nand their cross-correlations (so-called 6$\\times$2) using data from the Dark\nEnergy Survey (DES) Y1 and the Planck satellite mission. Noteworthy features of\nour 6$\\times$2 pipeline are: We extend CMB lensing cross-correlation\nmeasurements to a band surrounding the DES Y1 footprint (a $\\sim 25\\%$ gain in\npairs), and we develop analytic covariance capabilities that account for\ndifferent footprints and all cross-terms in the 6$\\times$2 analysis. We also\nmeasure the DES Y1 cosmic shear two-point correlation function (2PCF) down to\n$0.^\\prime 25$, but find that going below $2.^\\prime 5$ does not increase\ncosmological information due to shape noise. We model baryonic physics\nuncertainties via the amplitude of Principal Components (PCs) derived from a\nset of hydro-simulations. Given our statistical uncertainties, varying the\nfirst PC amplitude $Q_1$ is sufficient to model small-scale cosmic shear 2PCF.\nFor DES Y1+Planck 6$\\times$2 we find $S_8=0.799\\pm0.016$, comparable to the\n5$\\times$2 result of DES Y3+SPT/Planck $S_8=0.773\\pm0.016$. Combined with our\nmost informative cosmology priors -- baryon acoustic oscillation (BAO), big\nbang nucleosynthesis (BBN), type Ia supernovae (SNe Ia), and Planck 2018\nEE+lowE, we measure $S_8=0.817\\pm 0.011$. Regarding baryonic physics\nconstraints, our 6$\\times$2 analysis finds $Q_1=2.8\\pm1.8$. Combined with the\naforementioned priors, it improves the constraint to $Q_1=3.5\\pm1.3$. For\ncomparison, the strongest feedback scenario considered in this paper, the\ncosmo-OWLS AGN ($\\Delta T_\\mathrm{heat}=10^{8.7}$ K), corresponds to\n$Q_1=5.84$.\n", "  With the detection of black hole mergers by the LIGO gravitational wave\ntelescope, there has been increasing interest in the possibility that dark\nmatter may be in the form of solar mass primordial black holes. One of the\npredictions implicit in this idea is that compact clouds in the broad emission\nline regions of high redshift quasars will be microlensed, leading to changes\nin line structure and the appearance of new emission features. In this paper\nthe effect of microlensing on the broad emission line region is reviewed by\nreference to gravitationally lensed quasar systems where microlensing of the\nemission lines can be unambiguously identified. It is then shown that although\nchanges in Seyfert galaxy line profiles occur on timescales of a few years,\nthey are too nearby for a significant chance that they could be microlensed,\nand are plausibly attributed to intrinsic changes in line structure. In\ncontrast, in a sample of 53 high redshift quasars, 9 quasars show large changes\nin line profile at a rate consistent with microlensing. These changes occur on\na timescale an order of magnitude too short for changes associated with the\ndynamics of the emission line region. The main conclusion of the paper is that\nthe observed changes in quasar emission line profiles are consistent with\nmicrolensing by a population of solar mass compact bodies making up the dark\nmatter, although other explanations like intrinsic variability are possible.\nSuch bodies are most plausibly identified as primordial black holes.\n", "  The main purpose of this work is to investigate the properties of the\nnon-thermal emission in the interacting clusters pairs Abell 0399-Abell 0401\nand Abell 21-PSZ2 G114.9, found in an interacting state. In both cases their\nconnection along a filament is supported by SZ effect detected by the Planck\nsatellite and, in the special case of Abell 0399-Abell 0401, the presence of a\nradio bridge has been already confirmed by LOFAR observations at 140MHz. Here,\nwe analyse new high sensitivity wideband (250-500MHz) uGMRT data of these two\nsystems and describe an injection procedure to place limits on the spectrum of\nAbell 0399-Abell 0401 and on the radio emission between Abell 21-PSZ2 G114.9.\nFor the A399-A401 pair, we are able to constrain the steep spectral index of\nthe bridge emission to be alpha>2.2 with a 95% confidence level between 140MHz\nand 400MHz. For the A21-PSZ2 G114.9 pair, we are able to place an upper limit\non the flux density of the bridge emission with two different methods, finding\nat the central frequency of 383MHz a conservative value of fu_1<260mJy at 95%\nconfidence level, and a lower value of fu_2<125mJy at 80% confidence level,\nbased on visual inspection and a morphological criterion. Our work provides a\nconstraint on the spectrum in the bridge A399-A401 which disfavours\nshock-acceleration as the main mechanism for the radio emission.\n", "  We present the first detailed analysis of the ultra-steep spectrum radio halo\nin the merging galaxy cluster Abell 521, based on upgraded Giant Metrewave\nRadio telescope (uGMRT) observations. The combination of radio observations\n(300-850 MHz) and archival X-ray data provide a new window into the complex\nphysics occurring in this system. When compared to all previous analyses, our\nsensitive radio images detected the centrally located radio halo emission to a\ngreater extent of $\\sim$ 1.3 Mpc. A faint extension of the southeastern radio\nrelic has been discovered. We detected another relic, recently discovered by\nMeerKAT, and coincident with a possible shock front in the X-rays, at the\nnorthwest position of the center. We find that the integrated spectrum of the\nradio halo is well-fitted with a spectral index of $-1.86 \\pm 0.12$. A\nspatially resolved spectral index map revealed the spectral index fluctuations,\nas well as an outward radial steepening of the average spectral index. The\nradio and X-ray surface brightness are well correlated for the entire and\ndifferent sub-parts of the halo, with sub-linear correlation slopes\n(0.50$-$0.65). We also found a mild anti-correlation between the spectral index\nand X-ray surface brightness. Newly detected extensions of the SE relic and the\ncounter relic are consistent with the merger in the plane of the sky.\n", "  In this work, we study the evolution of Betti curves obtained by\npersistent-homological analysis of pointclouds formed by halos in different\ncosmological $N$-body simulations. We show that they can be approximated with a\nscaled log-normal distribution function with reasonable precision. Our analysis\nshows that the shapes and maximums of Betti curves exhibit dependence on the\nmass range of the selected subpopulation of halos, but at the same time, the\nresolution of a simulation does not play any significant role, provided that\nthe mass distribution of simulated halos is complete down to a given mass\nscale. Besides, we study how Betti curves change with the evolution of the\nUniverse, i.e., their dependence on redshift. Sampling subpopulations of halos\nwithin certain mass ranges up to redshift $z=2.5$ yields a surprisingly small\ndifference between corresponding Betti curves. We propose that this may be an\nindicator of the existence of a new specific topological invariant in the\nstructure of the Universe.\n", "  The warm-hot plasma in cosmic web filaments is thought to comprise a large\nfraction of the gas in the local Universe. So far, the search for this gas has\nfocused on mapping its emission, or detecting its absorption signatures against\nbright, point-like sources. Future, non-dispersive, high spectral resolution\nX-ray detectors will, for the first time, enable absorption studies against\nextended objects. Here, we use the Hydrangea cosmological hydrodynamical\nsimulations to predict the expected properties of intergalactic gas in and\naround massive galaxy clusters, and investigate the prospects of detecting it\nin absorption against the bright cores of nearby, massive, relaxed galaxy\nclusters. We probe a total of $138$ projections from the simulation volumes,\nfinding $16$ directions with a total column density $N_{O VII} > 10^{14.5}$\ncm$^{-2}$. The strongest absorbers are typically shifted by $\\pm 1000$ km/s\nwith respect to the rest frame of the cluster they are nearest to. Realistic\nmock observations with future micro-calorimeters, such as the Athena X-ray\nIntegral Field Unit or the proposed Line Emission Mapper (LEM) X-ray probe,\nshow that the detection of cosmic web filaments in O VII and O VIII absorption\nagainst galaxy cluster cores will be feasible. An O VII detection with a\n$5\\sigma$ significance can be achieved in $10-250$ ks with Athena for most of\nthe galaxy clusters considered. The O VIII detection becomes feasible only with\na spectral resolution of around $1$ eV, comparable to that envisioned for LEM.\n", "  Simulation based inference has seen increasing interest in the past few years\nas a promising approach to model the non linear scales of galaxy clustering.\n  The common approach using Gaussian process is to train an emulator over the\ncosmological and galaxy-halo connection parameters independently for every\nscales. We present a new Gaussian process model allowing to extend the input\nparameter space dimensions and to use non-diagonal noise covariance matrix.\n  We use our new framework to emulate simultaneously every scales of the\nnon-linear clustering of galaxies in redshift space from the AbacusSummit\nN-body simulations at redshift $z=0.2$. The model includes nine cosmological\nparameters, five halo occupation distribution (HOD) parameters and one scale\ndimension. Accounting for the limited resolution of the simulations, we train\nour emulator on scales from $0.3~h^{-1}\\mathrm{Mpc}$ to $60~h^{-1}\\mathrm{Mpc}$\nand compare its performance with the standard approach of building one\nindependent emulator for each scales. The new model yields more accurate and\nprecise constraints on cosmological parameters compared to the standard\napproach.\n  As the new model is able to interpolate over the scales space, we are also\nable to account for the Alcock-Paczynski distortion effect leading more\naccurate constraints on the cosmological parameters.\n", "  In the present work, we apply consistency relation tests to several\ncosmological models, including the flat and non-flat $\\Lambda$CDM models, as\nwell as the flat XCDM model. The analysis uses a non-parametric Gaussian\nProcesses method to reconstruct various cosmological quantities of interest,\nsuch as the Hubble parameter $H(z)$ and its derivatives from $H(z)$ data, as\nwell as the comoving distance and its derivatives from SNe Ia data. We\nconstruct consistency relations from these quantities which should be valid\nonly in the context of each model and test them with the current data. We were\nable to find a general method of constructing such consistency relations in the\ncontext of $H(z)$ reconstruction. In the case of comoving distance\nreconstruction, there were not a general method of constructing such relations\nand this work had to write an specific consistency relation for each model.\nFrom $H(z)$ data, we have analyzed consistency relations for all the three\nabove mentioned models, while for SNe Ia data we have analyzed consistency\nrelations only for flat and non-flat $\\Lambda$CDM models. Concerning the flat\n$\\Lambda$CDM model, some inconsistency was found, at more than $2\\sigma$ c.l.,\nwith the $H(z)$ data in the interval $1.8\\lesssim z\\lesssim2.4$, while the\nother models were all consistent at this c.l. Concerning the SNe Ia data, the\nflat $\\Lambda$CDM model was consistent in the $0<z<2.5$ interval, at $1\\sigma$\nc.l., while the nonflat $\\Lambda$CDM model was consistent in the same interval,\nat 2$\\sigma$ c.l.\n", "  Upcoming Large Scale Structure surveys aim to achieve an unprecedented level\nof precision in measuring galaxy clustering. However, accurately modeling these\nstatistics may require theoretical templates that go beyond second-order\nperturbation theory, especially for achieving precision at smaller scales. In\nour previous work, we introduced a hybrid model for the redshift space power\nspectrum of galaxies. This model combines second-order templates with N-body\nsimulations to capture the influence of scale-independent parameters on the\ngalaxy power spectrum. However, the impact of scale-dependent parameters was\naddressed by precomputing a set of input statistics derived from\ncomputationally expensive N-body simulations. As a result, exploring the\nscale-dependent parameter space was not feasible in this approach. To address\nthis challenge, we present an accelerated methodology that utilizes Gaussian\nprocesses, a machine learning technique, to emulate these input statistics. Our\nemulators exhibit remarkable accuracy, achieving reliable results with just 13\nN-body simulations for training. We reproduce all necessary input statistics\nfor a set of test simulations with an error of approximately 0.1 per cent in\nthe parameter space within $5\\sigma$ of the Planck predictions, specifically\nfor scales around $k > 0.1$ $h$Mpc$^{-1}$. Following the training of our\nemulators, we can predict all inputs for our hybrid model in approximately\n0.2,seconds at a specified redshift. Given that performing 13 N-body\nsimulations is a manageable task, our present methodology enables us to\nconstruct efficient and highly accurate models of the galaxy power spectra\nwithin a manageable time frame.\n", "  Cosmology is poised to measure the neutrino mass sum $M_\\nu$ and has\nidentified several smaller-scale observables sensitive to neutrinos,\nnecessitating accurate predictions of neutrino clustering over a wide range of\nlength scales. The FlowsForTheMasses non-linear perturbation theory for the\nmassive neutrino power spectrum, $\\Delta^2_\\nu(k)$, agrees with its companion\nN-body simulation at the $10\\%-15\\%$ level for $k \\leq 1~h/$Mpc. Building upon\nthe Mira-Titan IV emulator for the cold matter, we use FlowsForTheMasses to\nconstruct an emulator for $\\Delta^2_\\nu(k)$ covering a large range of\ncosmological parameters and neutrino fractions $\\Omega_{\\nu,0} h^2 \\leq 0.01$,\nwhich corresponds to $M_\\nu \\leq 0.93$~eV. Consistent with FlowsForTheMasses at\nthe $3.5\\%$ level, it returns a power spectrum in milliseconds. Ranking the\nneutrinos by initial momenta, we also emulate the power spectra of momentum\ndeciles, providing information about their perturbed distribution function.\nComparing a $M_\\nu=0.15$~eV model to a wide range of N-body simulation methods,\nwe find agreement to $3\\%$ for $k \\leq 3 k_\\mathrm{FS} = 0.17~h/$Mpc and to\n$19\\%$ for $k \\leq 0.4~h/$Mpc. We find that the enhancement factor, the ratio\nof $\\Delta^2_\\nu(k)$ to its linear-response equivalent, is most strongly\ncorrelated with $\\Omega_{\\nu,0} h^2$, and also with the clustering amplitude\n$\\sigma_8$. Furthermore, non-linearities enhance the free-streaming-limit\nscaling $\\partial \\log(\\Delta^2_\\nu / \\Delta^2_{\\rm m}) / \\partial \\log(M_\\nu)$\nbeyond its linear value of 4, increasing the $M_\\nu$-sensitivity of the\nsmall-scale neutrino density.\n", "  Type Ia supernovae (SNe Ia) were instrumental in establishing the\nacceleration of the universe's expansion. By virtue of their combination of\ndistance reach, precision, and prevalence, they continue to provide key\ncosmological constraints, complementing other cosmological probes. Individual\nSN surveys cover only over about a factor of two in redshift, so compilations\nof multiple SN datasets are strongly beneficial. We assemble an updated \"Union\"\ncompilation of 2087 cosmologically useful SNe Ia from 24 datasets (\"Union3\").\nWe take care to put all SNe on the same distance scale and update the\nlight-curve fitting with SALT3 to use the full rest-frame optical. Over the\nnext few years, the number of cosmologically useful SNe Ia will increase by\nmore than a factor of ten, and keeping systematic uncertainties subdominant\nwill be more challenging than ever. We discuss the importance of treating\noutliers, selection effects, light-curve shape and color populations and\nstandardization relations, unexplained dispersion, and heterogeneous\nobservations simultaneously. We present an updated Bayesian framework, called\nUNITY1.5 (Unified Nonlinear Inference for Type-Ia cosmologY), that incorporates\nsignificant improvements in our ability to model selection effects,\nstandardization, and systematic uncertainties compared to earlier analyses. As\nan analysis byproduct, we also recover the posterior of the SN-only\npeculiar-velocity field, although we do not interpret it in this work. We\ncompute updated cosmological constraints with Union3 and UNITY1.5, finding weak\n1.7--2.6sigma tension with LambdaCDM and possible evidence for thawing dark\nenergy. We release our binned SN distances to the community.\n", "  Minkowski functionals quantify the morphology of smooth random fields. They\nare widely used to probe statistical properties of cosmological fields.\nAnalytic formulae for ensemble expectations of Minkowski functionals are well\nknown for Gaussian and mildly non-Gaussian fields. In this paper we extend the\nformulae to composite fields which are sums of two fields and explicitly derive\nthe expressions for the sum of uncorrelated mildly non-Gaussian and Gaussian\nfields. These formulae are applicable to observed data which is usually a sum\nof the true signal and one or more secondary fields that can be either noise,\nor some residual contaminating signal. Our formulae provide explicit\nquantification of the effect of the secondary field on the morphology and\nstatistical nature of the true signal. As examples, we apply the formulae to\ndetermine how the presence of Gaussian noise can bias the morphological\nproperties and statistical nature of Gaussian and non-Gaussian CMB temperature\nmaps.\n", "  In this paper, we study the evolutions of a self-gravitating cloud of bosonic\ndark matter with finite angular momentum and self-interaction. This is achieved\nby using the sixth-order pseudospectral operator splitting method to solve the\nsystem of nonlinear Schr\\\"odinger and Poisson equations. The initial cloud is\nassumed to have mass density randomly distributed throughout three-dimensional\nspace. The dark matter particles in the initial cloud are in the kinetic\nregime, i.e., their de Broglie wavelength is much smaller than the halo size.\n  It is shown that Bose stars are indeed formed in the numerical simulation\npresented here. The presence of angular momentum and self-interaction in the\ninitial cloud can significantly influence the star formation time in a\nnon-trivial fashion. Furthermore, the plots of the vorticity magnitude profile\nafter the star formation time indicate that the formed star may not have any\nintrinsic angular momentum for the cases when the self-interaction among the\nparticles is either negligible or attractive. These results are in agreement\nwith the earlier analytical studies of an isolated rotating Bose star. However,\nfor the case of repulsive self-interaction, the vorticity magnitude analysis\nshows a possibility that the star formed in the numerical simulations may\npossess intrinsic angular momentum. It is also shown that the average mass and\nradius diagrams of the star are strongly influenced by the presence of angular\nmomentum in the initial cloud.\n", "  We compare the reduced void probability function (VPF) inside and outside of\ncosmic voids in the TNG300-1 simulation, both in real and simulated redshift\nspace. The VPF is a special case of the counts-in-cells approach for extracting\ninformation of high-order clustering that is crucial for a full understanding\nof the distribution of galaxies. Previous studies have validated the\nhierarchical scaling paradigm of galaxy clustering moments, in good agreement\nwith the \"negative binomial\" model, in redshift surveys, but have also reported\nthat this paradigm is not valid in real space. However, in this work we find\nthat hierarchical scaling can indeed be found in real space inside cosmic\nvoids. This is well fitted by the negative binomial model. We find this result\nto be robust against changes in void identification, galaxy mass, random\ndilutions, and redshift. We also obtain that the VPF in real space at high\nredshift approaches the negative binomial model, and therefore it is similar to\nthe VPF inside voids at the present time. This study points, for the first\ntime, towards evidence of hierarchical scaling of high-order clustering of\ngalaxies in real space inside voids, preserving the pristine structure\nformation processes of the Universe.\n", "  The cosmological 21-cm signal from neutral hydrogen, which is considered as a\npromising tool, is being used to observe and study the cosmic dawn (CD) and\nepoch of reionization (EoR). A significant part of this thesis focuses on the\nsemi-analytical modeling of the global HI 21-cm signal from CD considering\nseveral physical processes. Further, it investigates the nature of galaxies\nthat dominate during CD and EoR using current available observations. In our\nwork, we study the redshift evolution of the primordial magnetic field (PMF)\nduring the dark ages and cosmic dawn, and prospects of constraining it in light\nof EDGES 21-cm signal in the `colder IGM' background. We find that the IGM\nheating rate due to the PMF enhances compared to the standard scenario.\nHowever, PMF is an unlikely candidate for explaining the rise of the EDGES\nabsorption signal at lower redshift. We further consider, in detail, the\nheating of the IGM owing to cosmic ray protons generated by the supernovae from\nboth early Pop~III and Pop~II stars. We show that the EDGES signal can be well\nfitted by the cosmic ray heating along with the Lyman-$\\alpha$ coupling and the\ndark matter-baryon interaction. We, further, explore the conditions by which\nthe EDGES detection is consistent with current reionization and\npost-reionization observations. By coupling a physically motivated source model\nderived from radiative transfer hydrodynamic simulations of reionization to a\nMCMC sampler, we find that high contribution from low-mass halos along with\nhigh photon escape fractions are required to simultaneously reproduce the\nexisting constraints. With the extreme effort in building more advanced and\nsophisticated telescopes, the future 21-cm signal detection would be able to\nprovide better constraints on the amplitude of PMF and the efficiencies on\ncosmic ray protons, and consequently on early star formation rates.\n", "  The bispectrum is an important statistics helpful for measuring the\nprimordial non-Gaussianity parameter $f_{\\mathrm{NL}}$ to less than order unity\nin error, which would allow us to distinguish between single and multi-field\ninflation models. The Spectro-Photometer for the History of the Universe, Epoch\nof Reionization and Ices Explorer (SPHEREx) mission is particularly well-suited\nfor making this measurement with its $\\sim$100-band all-sky observations in the\nnear-infrared. Consequently, the SPHEREx data will contain galaxies with\nspectroscopic-like redshift measurements as well as those with much larger\nerrors. In this paper, we evaluate the impact of photometric redshift errors on\n$f_{\\mathrm{NL}}$ constraints in the context of an updated multi-tracer\nforecast for SPHEREx, finding that the azimuthal averages of the first three\neven bispectrum multipoles are no longer sufficient for capturing most of the\ninformation (as opposed to the case of spectroscopic surveys shown in the\nliterature). The final SPHEREx result with all five galaxy samples and six\nredshift bins is however not severely impacted because the total result is\ndominated by the samples with the best redshift errors, while the worse samples\nserve to reduce cosmic variance. Our fiducial result of\n$\\sigma_{f_{\\mathrm{NL}}} = 0.7$ from bispectrum alone is increased by $18\\%$\nand $3\\%$ when using $l_{\\mathrm{max}}=0$ and 2 respectively. We also explore\nthe impact on parameter constraints when varying the fiducial redshift errors,\nas well as using subsets of multi-tracer combinations or triangles with\ndifferent squeezing factors. Note that the fiducial result here is not the\nfinal SPHEREx capability, which is still on target for being\n$\\sigma_{f_{\\mathrm{NL}}} = 0.5$ once the power spectrum will be included.\n", "  The Hubble parameter $H_0$, is not a univocally-defined quantity: it relates\nredshifts to distances in the near Universe, but is also a key parameter of the\n$\\Lambda$CDM standard cosmological model. As such, $H_0$ affects several\nphysical processes at different cosmic epochs, and multiple observables. We\nhave counted more than a dozen $H_0$'s which are expected to agree if a) there\nare no significant systematics in the data and their interpretation and b) the\nadopted cosmological model is correct.\n  With few exceptions (proverbially confirming the rule) these determinations\ndo not agree at high statistical significance; their values cluster around two\ncamps: the low (68 km/s/Mpc) and high (73 km/s/Mpc) camp. It appears to be a\nmatter of anchors: the shape of the Universe expansion history agrees with the\nmodel, it is the normalizations that disagree.\n  Beyond systematics in the data/analysis, if the model is incorrect there are\nonly two viable ways to \"fix\" it: by changing the early time ($z\\gtrsim 1100$)\nphysics and thus the early time normalization, or by a global modification,\npossibly touching the model's fundamental assumptions (e.g., homogeneity,\nisotropy, gravity). None of these three options has the consensus of the\ncommunity.\n  The research community has been actively looking for deviations from\n$\\Lambda$CDM for two decades; the one we might have found makes us wish we\ncould put the genie back in the bottle.\n", "  In this work, we analyze a power-law inflationary potential enhanced with a\nstep that can introduce features in the primordial power spectrum. We focus on\nthe computation of the Spectral Distortions (SD) induced by these features\nobtained from the inflationary dynamics. In this scenario, we explore the\npotential of upcoming experimental missions like PIXIE to detect the SD of the\nmodel within a power of $n = 2/3$, a power that agrees with recent\ntensor-to-scalar ratio constraints. The model offers insights into models with\ncosmological phases and different scalar field dynamics. Introducing a step in\nthe inflaton potential leads to distinct features in the primordial power\nspectrum, such as oscillations and localized enhancements/suppressions at\nspecific scales. We analyze the impact of three primary parameters$-\\beta$,\n$\\delta$, and $\\phi_{\\text{step}}-$on the amplitude and characteristics of the\nSD. The $\\phi_{\\rm step}$ places the onset of the oscillations in the\nprimordial power spectrum. The $\\beta$ parameter significantly influences the\nmagnitude of the $\\mu$-SD, with its increase leading to larger SD and vice\nversa. Similarly, the $\\delta$ parameter affects the smoothness of the step in\nthe potential, with larger values resulting in smaller SD. Our findings\nindicate a distinct parameter space defined by $0.02 <\\delta/{\\rm M_{pl}}\n\\lesssim 0.026$, $0.10 \\lesssim \\beta < 0.23$, and $ 7.53 \\lesssim \\phi_{\\rm\nstep}/{\\rm M_{pl}} \\lesssim 7.55$, which produces SD potentially detectable by\nPIXIE. This region also corresponds to the maximum observed values of $\\mu$ and\n$y$ SD, which in special cases are an order of magnitude larger than the\nexpected for $\\Lambda$CDM. However, we also identify parameter ranges where\n$\\mu$ and $y$ SD may not be detectable due to the limitations of current\nobservational technology.\n", "  We present the first direct constraints on a Degenerate Higher Order Scalar\nTensor (DHOST) inflation model using the Planck 2018 Cosmic Microwave\nBackground (CMB) results on non-Gaussianities. We identify that the bispectrum\nconsists of a fixed contribution following from the power spectrum and a linear\ncombination of terms depending on five free parameters defining the cubic\nperturbations to the DHOST model. The former peaks in the squeezed limit, while\nthe latter is maximised in the equilateral limit. We directly confront the\nmodel predictions to the CMB bispectrum statistics via the public code CMB-BEST\nand marginalize over the free parameters. We explicitly show that there are\nviable DHOST inflationary models satisfying both power spectrum and bispectrum\nconstraints from Planck. However, rather surprisingly, the constraints exclude\ncertain models at the $6\\sigma$-level even though they pass the conventional\nfudge factor tests. In this case and despite having a handful of free\nparameters, the model's large squeezed bispectrum cannot be cancelled out\nwithout introducing a large bispectrum in other limits which are strongly\nconstrained by Planck's non-detection of primordial non-Gaussianity. We\nemphasize that first-order approximations such as fudge factors, albeit\ncommonly used in the literature, may be misleading and provide weaker\nconstraints. A proper analysis of the constraints from Planck requires a more\nrobust approach, such as the one provided by the CMB-BEST code.\n", "  Baryon Acoustic Oscillation (BAO) observations offer a robust method for\nmeasuring cosmological expansion. However, the BAO signal in a sample of\ngalaxies can be diluted and shifted by interlopers - galaxies that have been\nassigned the wrong redshifts. Because of the slitless spectroscopic method\nadopted by the Roman and Euclid space telescopes, the galaxy samples resulting\nfrom single line detections will have relatively high fractions of interloper\ngalaxies. Interlopers with a small displacement between true and false redshift\nhave the strongest effect on the measured clustering. In order to model the BAO\nsignal, the fraction of such interlopers and their clustering need to be\naccurately known. We introduce a new method to self-calibrate these quantities\nby shifting the contaminated sample towards or away from us along the line of\nsight by the interloper offset, and measuring the cross-correlations between\nthese shifted samples. The contributions from the different components are\nshifted in scale in this cross-correlation compared to the auto-correlation of\nthe contaminated sample, enabling the decomposition and extraction of the\ncomponent terms. We demonstrate the application of the method using numerical\nsimulations and show that an unbiased BAO measurement can be extracted. Unlike\nprevious attempts to model the effects of contaminants, self-calibration allows\nus to make fewer assumptions about the form of the contaminants such as their\nbias.\n", "  In this work, we present a study of the void lensing signal or the excess\nsurface mass density (ESMD) around cosmic voids. First, we propose a new\nvoid-finder algorithm that is designed to capture the ESMD around voids. We\ncompare our algorithm applied to projected slices with the ZOBOV void finder\nand find significantly deeper weak-lensing profiles for voids defined by our\nalgorithm in the context of a realistic galaxy mock. Then we test the\nconsistency between the measurements of the ESMD as measured through the shear\nof background galaxies and directly calculated through the dark matter density\nprofiles of the same voids. We found inconsistencies for voids with diameter\n$\\geq 100h^{-1}\\mathrm{Mpc}$ along the line-of-sight, but the consistency holds\nfor smaller voids, meaning that we are indeed probing the underlying dark\nmatter field by measuring the shear around these voids. Moreover, we show that\nvoids found in the projected slices, which are highly sensitive to lensing, are\ncorrelated to $3$D voids exhibiting intrinsic alignments between them.\n", "  The Universe at the present epoch is found to be a network of matter\nover-dense and under-dense regions. To date, this picture of the Universe is\nbest revealed through cosmological large-volume simulations and large-scale\ngalaxy redshift surveys, in which, the most important step is the appropriate\nidentification of structures. So far, these structures are identified using\nvarious group finding codes, mostly based on the friends-of-friends (FoF) or\nspherical over-density (SO) algorithms. Although, the main purpose is to\nidentify gravitationally bound structures, surprisingly, the mass information\nhas hardly been used effectively by these codes. Moreover, the methods used so\nfar either constrain the over-density or use the real unstructured geometry\nonly. Even though these are key factors in the accurate determination of\nstructures-mass information, hardly any attempt has been made as yet to\nconsider these important parameters together while formulating the grouping\nalgorithms. In this paper, we present our proposed algorithm which takes care\nof all the above-mentioned relevant features and ensures the bound structures\nby means of physical quantities, mainly mass and the total energy information.\nWe introduced a novel concept of physically relevant arm-length for each\nelement depending on their individual gravity leading to a distinct linking\nlength for each unique pair of elements. This proposed algorithm is thus\nfundamentally new that, not only able to catch the gravitationally bound, real\nunstructured geometry, it does identify it roughly within a predefined\nphysically motivated density threshold. Such a thing could not be\nsimultaneously achieved before by any of the usual FoF or SO-based methods. We\nalso demonstrate the unique ability of the code in the appropriate\nidentification of structures, both from large volume cosmological simulations\nas well as from galaxy redshift surveys.\n", "  Cosmological observations, e.g., cosmic microwave background, have precisely\nmeasured the spectrum of primordial curvature perturbation on larger scales,\nbut smaller scales are still poorly constrained. Since primordial black holes\n(PBHs) could form in the very early Universe through the gravitational collapse\nof primordial density perturbations, constrains on the PBH could encodes much\ninformation on primordial fluctuations. In this work, we first derive a simple\nformula for lensing effect to apply PBH constraints with the monochromatic mass\ndistribution to an extended mass distribution. Then, we investigate the latest\nfast radio burst observations with this relationship to constrain two kinds of\nprimordial curvature perturbation models on the small scales. It suggests that,\nfrom the null search result of lensed fast radio burst in currently available\nobservations, the amplitude of primordial curvature perturbation should be less\nthan $8\\times 10^{-2}$ at the scale region of $10^5-10^6~\\rm Mpc^{-1}$. This\ncorresponds to an interesting mass range relating to binary black holes\ndetected by LIGO-Virgo-KAGRA and future Einstein Telescope or Cosmic Explorer.\n", "  Understanding the entire history of the ionization state of the intergalactic\nmedium (IGM) is at the frontier of astrophysics and cosmology. A promising\nmethod to achieve this is by extracting the damping wing signal from the\nneutral IGM. As hundreds of redshift $z>6$ quasars are observed, we anticipate\ndetermining the detailed time evolution of the ionization fraction with\nunprecedented fidelity. However, traditional approaches to parameter inference\nare not sufficiently accurate. We assess the performance of a simulation-based\ninference (SBI) method to infer the neutral fraction of the universe from\nquasar spectra. The SBI method adeptly exploits the shape information of the\ndamping wing, enabling precise estimations of the neutral fraction\n$\\left<x_{\\rm HI}\\right>_{\\rm v}$ and the wing position $w_p$. Importantly, the\nSBI framework successfully breaks the degeneracy between these two parameters,\noffering unbiased estimates of both. This makes the SBI superior to the\ntraditional method using a pseudo-likelihood function. We anticipate that SBI\nwill be essential to determine robustly the ionization history of the Universe\nthrough joint inference from the hundreds of high-$z$ spectra we will observe.\n", "  Nonlinear gravitational evolution induces strong nonlinearities in the\nobserved cosmological density fields, leading to positive off-diagonal\ncorrelations in the power spectrum covariance. This has caused the information\nsaturation in the power spectrum, e.g., the neutrino mass constraints from the\nnonlinear power spectra are lower than their linear counterparts by a factor of\n$\\sim2$ at $z=0$. In this paper, we explore how nonlinear reconstruction\nmethods improve the cosmological information from nonlinear cosmic fields. By\napplying nonlinear reconstruction to cold dark matter fields from the Quijote\nsimulations, we find that nonlinear reconstruction can improve the constraints\non cosmological parameters significantly, nearly reaching the linear theory\nlimit. For neutrino mass, the result is only $12\\%$ lower than the linear power\nspectrum, i.e., the theoretical best result. This makes nonlinear\nreconstruction an efficient and useful method to extract neutrino information\nfrom current and upcoming galaxy surveys.\n", "  In the conventional / most studied local distance ladder measurements, Type\nIa supernovae (SNe Ia) are used in two of the three rungs. In the second rung,\ntheir luminosities are calibrated by standard candles like Cepheids or Tip of\nthe Red Giant Branch (TRGB). In the third rung, the high luminosities and\nstandardizability allow SNe to be used to calibrate the `Hubble' relation\nbetween distances and redshifts. Locally, the majority of distance ladder\nanalyses find a high value of the Hubble Constant $H_0$ of $>70$ km/s/Mpc.\nGiven the discrepancy with the inferred value using CMB observations, great\nscrutiny must be given to the role supernovae play in measuring $H_0$. Here, we\nreview the main methodology, the many crosschecks for the supernova component\nof the distance ladder, and the various systematics studied. We review the\nimportant role supernovae play to explain the small disagreements seen from\nvarious local analyses. We also discuss analyses that employ an inverse\ndistance ladder, which use similar sets of supernovae, but in the reverse\ndirection, and yield a low value of $H_0$. We conclude given all available\nevidence, it is difficult to find a way that a systematic in supernovae\nmeasurements, or a non-$\\Lambda$CDM component of the universe which could be\nmeasured with supernovae, can help explain the Hubble tension.\n", "  The current expansion rate of the Universe, the Hubble constant $H_0$, is an\nimportant cosmological quantity. However, two different ways to measure its\nvalue do not agree -- building a low-redshift distance ladder leads to a higher\nvalue of $H_0$ than inferring it from high-redshift observations in a\n$\\Lambda$CDM cosmology. Most approaches to solve this tension either act at\nvery low redshift by modifying the local distance ladder, or at high redshift\nby introducing new physics that changes the normalization of the inverse\ndistance ladder. Here we discuss a way to address the Hubble tension at\nintermediate redshifts instead. By keeping the low- and high-redshift\nnormalizations unchanged, we find a violation of the distance duality in the\nredshift range where luminosity and angular diameter distances overlap. We\n'solve' this problem by introducing a redshift-dependent systematic effect that\nbrings the luminosity distance into agreement with the angular diameter\ndistance. The resulting expansion history is no longer compatible with\n$\\Lambda$CDM, but this can be fixed with a dynamical dark energy component. In\nthis way, we are able to solve the Hubble tension at intermediate redshifts.\n", "  We study preheating via kinetic couplings after dilaton-axion\n$\\alpha$-attractor inflation. We focus on E-model $\\alpha$-attractor driven\ninflation where the inflaton is kinetically coupled to an ultralight axion. In\nthis class of models, the kinetic coupling is related to the form of the\npotential, and once the amplitude of the scalar curvature spectrum as well as\nthe tensor-to-scalar ratio are specified, the model has no free parameters. We\nfind that kinetic preheating can be extremely efficient, with stronger\npreheating occurring at parameter values corresponding to smaller values of the\ntensor-to-scalar ratio. Preheating becomes extremely efficient below $r\n\\lesssim 1.6\\times 10^{-5}$.\n", "  This study aims to improve the photometric redshifts (photo-$z$s) of galaxies\nby integrating two contemporary methods: template-fitting and machine learning.\nFinding the synergy between these two methods was not a high priority in the\npast, but now that our computer processing power and observational accuracy\nhave increased, we deem it worth investigating. We compared two methods to\nimprove galaxy photometric redshift estimations by using the algorithms ANNz2\nand BPz on different photometric and spectroscopic samples from the Sloan\nDigital Sky Survey (SDSS). We find that the photometric redshift performance of\nANNz2 (machine learning) is better than that of BPz (galactic templates), and\nwith the utilisation of the merging technique we introduced, we see that there\nis an improvement in photo-$z$ when the two strategies are consolidated,\nproviding improvements in $\\sigma_{RMS}$ and $\\sigma_{68}$ up to [0.0265,\n0.0222] in the LRG sample and [0.0471, 0.0471] in the Stripe-82 Sample. This\nsimple demonstration can be used for photo-$z$s of galaxies in fainter and\ndeeper sky surveys, and future work is required to prove its viability in these\nsamples.\n", "  Particle-mesh simulations trade small-scale accuracy for speed compared to\ntraditional, computationally expensive N-body codes in cosmological\nsimulations. In this work, we show how a data-driven model could be used to\nlearn an effective evolution equation for the particles, by correcting the\nerrors of the particle-mesh potential incurred on small scales during\nsimulations. We find that our learnt correction yields evolution equations that\ngeneralize well to new, unseen initial conditions and cosmologies. We further\ndemonstrate that the resulting corrected maps can be used in a simulation-based\ninference framework to yield an unbiased inference of cosmological parameters.\nThe model, a network implemented in Fourier space, is exclusively trained on\nthe particle positions and velocities.\n", "  In order to investigate the potential Hubble tension, we compile a catalogue\nof 216 measurements of the Hubble--Lema\\^itre constant $H_0$ between 2012 and\n2022, which includes 109 model-independent measurements and 107 $\\Lambda$CDM\nmodel-based measurements. Statistical analyses of these measurements show that\nthe deviations of the results with respect to the average $H_0$ are far larger\nthan expected from their error bars if they follow a Gaussian distribution. We\nfind that $x\\sigma $ deviation is indeed equivalent in a Gaussian distribution\nto $x_{\\rm eq}\\sigma$ deviation in the frequency of values, where $x_{\\rm\neq}=0.72x^{0.88}$. Hence, a tension of 5$\\sigma$, estimated between the\nCepheid-calibrated type Ia supernovae and cosmic microwave background (CMB)\ndata, is indeed a 3$\\sigma$ tension in equivalent terms of a Gaussian\ndistribution of frequencies. However, this recalibration should be independent\nof the data whose tension we want to test. If we adopt the previous analysis of\ndata of 1976-2019, the equivalent tension is reduced to $2.25\\sigma$.\nCovariance terms due to correlations of measurements do not significantly\nchange the results. Nonetheless, the separation of the data into two blocks\nwith $H_0<71$ and $H_0\\ge 71$ km s$^{-1}$ Mpc$^{-1}$ finds compatibility with a\nGaussian distribution for each of them without removing any outlier. These\nstatistical results indicate that the underestimation of error bars for $H_0$\nremains prevalent over the past decade, dominated by systematic errors in the\nmethodologies of CMB and local distance ladder analyses.\n", "  Continuing work presented in Li et al. (2021), we performed a series of tests\nto our high-resolution three-dimensional mass map reconstruction algorithm\n\\splinv{}. We test the mass reconstruction accuracy against realistic mock\ncatalogs generated using shear field produced by triaxial halos with the inner\ndensity profile of $\\rho \\propto r^{-1}$ and of $\\rho \\propto r^{-1.5}$. The\ngalaxy shape noise is modeled based on the Year-1 Subaru Hyper Suprime-Cam\n(HSC) Survey. After reviewing mathematical details of our algorithm and dark\nmatter halo models, we determine an optimal value of the coefficient of the\nadaptive LASSO regression penalty term for single halo reconstruction. We\nsuccessfully measure halo masses for massive triaxial halos; the mass\ndetermination accuracy is 5 percent for halos with $M = 10^{14.6}~M_\\odot$ at\n$0.0625\\leq z \\leq 0.2425$, and 5 percent for those with $10^{14.8}~M_\\odot$ at\n$0.0625\\leq z \\leq 0.4675$, and 20 percent for $M= 10^{15.0} ~M_\\odot$ and\n$M=10^{15.2}~M_\\odot$ in the redshift range $0.0625\\leq z \\leq 0.4675$. The\nredshift estimate accuracy is consistently below $\\Delta z /z \\leq 0.05$ for\nthe above halo masses in the range $0.1525\\leq z \\leq 0.4675$. We also\ndemonstrate that the orientation of triaxial halos and systematic error in our\nhalo model do not affect reconstruction result significantly. Finally, we\npresent results from reconstruction of mass distribution using shear catalogs\nproduced by multiple halos, to show \\splinv{}'s capability using realistic\nshear maps from ongoing and future galaxy surveys.\n", "  We investigate the stochastic gravitational waves background arising from the\nfirst-order QCD chiral phase transition, considering three distinct sources:\nbubble collisions, sound waves, and fluid turbulence. Within the framework of\nthe Polyakov-Nambu-Jona-Lasinio (PNJL) model, we calculate the parameters\ngoverning the intensity of the gravitational wave phase transition and\ndetermine their magnitudes along the adiabatic evolutionary path. We introduce\nthe effective bag constant $B_{\\mathrm{eff}}$ related to the dynamical\nevolution of quarks to evaluate the intensity of the phase transition. By\ncalculating expanded potential at the point of false vacuum, we find that all\nthe bubbles are in the mode of runaway, leading the velocity of the bubble wall\nto the speed of light. The resulting gravitational wave energy spectrum is\nestimated, revealing a characteristic amplitude of the generated gravitational\nwaves within the centihertz frequency range. We present the gravitational wave\nspectrum and compare it with the sensitivity range of detectors, and find that\nthe gravitational wave spectra generated by these sources have the potential to\nbe detected by future detectors such as BBO and $\\mu$ARES.\n", "  The role of unresolved structures (\"mini-halos\") in determining the\nconsumption of ionizing photons during cosmic reionization remains an unsolved\nproblem in modeling cosmic reionization, despite recent extensive studies with\nsmall-box high-resolution simulations by Park et al. and Chan et al., because\nthe small-box studies are not able to fully sample all environments. In this\npaper these simulations are combined with large-box simulations from the\n\"Cosmic Reionization On Computers\" (CROC) project, allowing one to account for\nthe full range of environments and to produce an estimate for the number of\nrecombinations per hydrogen atom that are missed in large-scale simulations\nlike CROC or Thesan. I find that recombinations in unresolved mini-halos are\ncompletely negligible compared to recombinations produced in large-scale cosmic\nstructures and inside more massive, fully resolved halos. Since both Park et\nal. and Chan et al. studies have severe limitations, the conclusions of this\npaper may need to be verified with more representative sets of small-box\nhigh-resolution simulations.\n", "  The epoch of hydrogen reionization is complete by $z=5$, but its progression\nat higher redshifts is uncertain. Measurements of Ly$\\alpha$ forest opacity\nshow large scatter at $z<6$, suggestive of spatial fluctuations in neutral\nfraction ($x_\\mathrm{HI}$), temperature, or ionizing background, either\nindividually or in combination. However, these effects are degenerate,\nnecessitating modeling these physics in tandem in order to properly interpret\nthe observations. We begin this process by developing a framework for modeling\nthe reionization history and associated temperature fluctuations, with the\nintention of incorporating ionizing background fluctuations at a later time. To\ndo this, we generate several reionization histories using semi-numerical code\nAMBER, selecting histories with volume-weighted neutral fractions that adhere\nto the observed CMB optical depth and dark pixel fractions. Implementing these\nhistories in the \\texttt{Nyx} cosmological hydrodynamics code, we examine the\nevolution of gas within the simulation, and the associated metrics of the\nLy$\\alpha$ forest opacity. We find that the pressure smoothing scale within the\nIGM is strongly correlated with the adiabatic index of the temperature-density\nrelation. We find that while models with 20,000 K photoheating at reionization\nare better able to reproduce the shape of the observed $z=5$ 1D flux power\nspectrum than those with 10,000 K, they fail to match the highest wavenumbers.\nThe simulated autocorrelation function and optical depth distributions are\nsystematically low and narrow, respectively, compared to the observed values,\nbut are in better agreement when the reionization history is longer in\nduration, more symmetric in its distribution of reionization redshifts, or if\nthere are remaining neutral regions at $z<6$. The systematically low variance\nlikely requires the addition of a fluctuating UVB.\n", "  The latest improvements in the scale and calibration of Type Ia supernovae\ncatalogues allow us to constrain the specific nature and evolution of dark\nenergy through its effect on the expansion history of the universe. We present\nthe results of Bayesian cosmological model comparison on the SNe~Ia catalogue\nPantheon+, where Flat $\\Lambda$CDM is preferred by the data over all other\nmodels and we find moderate evidence ($\\Delta \\log \\mathcal{Z} \\sim 2.5$) to\nreject a number of the alternate dark energy models. The effect of peculiar\nvelocity corrections on model comparison is analysed, where we show that\nremoving the peculiar velocity corrections results in a varying fit on\nnon-$\\Lambda$CDM parameters. As well as comparing cosmological models, the\nBayesian methodology is extended to comparing the scatter model of the data,\ntesting for non-gaussianity in the Pantheon+ Hubble residuals. We find that\nadding a scale parameter to the Pantheon+ covariances, or alternately using a\nmultivariate Student's t-distribution fits the data better than the fiducial\nanalysis, producing a cosmology independent evidence increase of $\\Delta \\log\n\\mathcal{Z} = 2.29 $ and $2.46$ respectively. This improved treatment of the\nscatter decreases the uncertainty in the constraint on the Hubble constant,\nfinding $H_0 = 73.67 \\pm 0.99 $ km s$^{-1}$ Mpc$^{-1}$, in $ 5.7 \\sigma$\ntension with Planck. We also explore $M_B$ transition models as a potential\nsolution for the Hubble tension, finding no evidence to support these models\namong the SNe data.\n", "  This is a model-independent analysis that investigates the statistical\nisotropy in the Local Universe using the ALFALFA survey data ($0 < z < 0.06$).\nWe investigate the angular distribution of HI extra-galactic sources from the\nALFALFA catalogue and study whether they are compatible with the statistical\nisotropy hypothesis using the two-point angular correlation function (2PACF).\nAware that the Local Universe is plenty of clustered structures and large\nvoids, we compute the 2PACF with the Landy-Szalay estimator performing\ndirectional analyses to inspect 10 sky regions. We investigate these 2PACF\nusing power-law best-fit analyses, and determine the statistical significance\nof the best-fit parameters for the 10 ALFALFA regions by comparison with the\nones obtained through the same procedure applied to a set of mock catalogues\nproduced under the homogeneity and isotropy hypotheses. Our conclusion is that\nthe Local Universe, as mapped by the HI sources of the ALFALFA survey, is in\nagreement with the hypothesis of statistical isotropy within $2\\,\\sigma$\nconfidence level, for small and large angle analyses, with the only exception\nof one region -- located near the Dipole Repeller -- which appears slightly\noutlier ($2.4\\,\\sigma$). Interestingly, regarding the large angular\ndistribution of the HI sources, we found 3 regions where the presence of cosmic\nvoids reported in the literature left their signature in our 2PACF, suggesting\nprojected large underdensities there, with number-density contrast $\\delta\n\\simeq -0.7$. According to the current literature these regions correspond,\npartially, to the sky position of the void structures known as Local Cosmic\nVoid and Dipole Repeller.\n", "  Large-scale structure (LSS) surveys will increasingly provide stringent\nconstraints on our cosmological models. Recently, the density-marked\ncorrelation function (MCF) has been introduced, offering an easily computable\ndensity-correlation statistic. Simulations have demonstrated that MCFs offer\nadditional, independent constraints on cosmological models beyond the standard\ntwo-point correlation (2PCF). In this study, we apply MCFs for the first time\nto SDSS CMASS data, aiming to investigate the statistical information regarding\nclustering and anisotropy properties in the Universe and assess the performance\nof various weighting schemes in MCFs. Upon analyzing the CMASS data, we observe\nthat, by combining different weights ($\\alpha = [-0.2, 0, 0.2, 0.6]$), the MCFs\nprovide a tight and independent constraint on the cosmological parameter\n$\\Omega_m$, yielding $\\Omega_m = 0.293 \\pm0.006$ at the $1\\sigma$ level, which\nrepresents a significant reduction in the statistical error by a factor of 3.4\ncompared to that from 2PCF. Our constraint is consistent with recent findings\nfrom the small-scale clustering of BOSS galaxies \\cite{arXiv:2203.08999v2}\nwithin the 1$\\sigma$ level. However, we also find that our estimate is lower\nthan the Planck measurements by about 2.6$\\sigma$, indicating the potential\npresence of new physics beyond the standard cosmological model if all the\nsystematics are fully corrected. The method outlined in this study can be\nextended to other surveys and datasets, allowing for the constraint of other\ncosmological parameters. Additionally, it serves as a valuable tool for\nforthcoming emulator analysis on the Chinese Space Station Telescope (CSST).\n", "  We study the dynamics of the quintom dark energy model using state-of-the-art\ncosmological observations. The set of equations has been converted into an\nautonomous system using suitable transformations of the variables. We have\ndiscussed the fixed points of the model and the general phase-space behavior,\nin particular, in finding the existence of the tracker solutions for this\nmodel. The observations suggest that at late times the phantom field should\ndominate the dark energy sector with an approximately 15% share to the\nquintessence counterpart, and with both fields tracking the background at early\ntimes. A Bayesian model comparison with LambdaCDM has also been done by\ncomputing the Bayes factor and a positive preference has been obtained for the\nquintom model. Although not fully resolved, the Hubble tension can be reduced\nto 2.6{\\sigma} when compared with the value of H0 reported in [1] and to\n1.6{\\sigma} when compared with that of [2].\n", "  Cosmological studies have now entered Stage IV according to the Dark Energy\nTask Force prescription, thanks to new missions (Euclid, Rubin Observatory,\nSRG/eROSITA) that are expected to provide the required ultimate accuracy in the\ndark energy (DE) equation of state (EoS). However, none of these projects have\nthe power to systematically unveil the galaxy cluster population at $z>1$.\nThere therefore remains the need for an ATHENA-like mission to run independent\ncosmological investigations and scrutinise the consistency between the results\nfrom the $0<z<1$ and $1<z<2$ epochs. We study the constraints on the DE EoS and\non primordial non-Gaussanities for typical X-ray cluster surveys executed by\nATHENA. We consider two survey designs: 50 deg$^2$ at 80ks (survey A) and 200\ndeg$^2$ at 20ks (survey B). We analytically derive cluster counts in a space of\nobservable properties, and predict the cosmological potential of the\ncorresponding samples with a Fisher analysis. The achieved depth allows us to\nunveil the halo mass function down to the group scale out to $z=2$. We predict\nthe detection of thousands of clusters down to a few 10$^{13} h^{-1}\nM_{\\odot}$, in particular 940 and 1400 clusters for surveys A and B,\nrespectively, at $z>1$. Such samples will allow a detailed modelling of the\nevolution of cluster physics along with a standalone cosmological analysis. Our\nresults suggest that survey B has the optimal design as it provides greater\nstatistics. Remarkably, high-$z$ clusters, despite representing 15% or less of\nthe full samples, allow a significant reduction of the uncertainty on the\ncosmological parameters: $\\Delta w_a$ is reduced by a factor of 2.3 and $\\Delta\nf_{NL}^{loc}$ by a factor of 3. Inventorying the high-$z$ X-ray cluster\npopulation can play a crucial role in ensuring overall cosmological\nconsistency. This will be the major aim of future new-generation ATHENA-like\nmissions.\n", "  Orphan galaxies that have lost a large fraction of the dark matter subhaloes\nhave often been invoked in semi-analytical as well as empirical models of\ngalaxy formation. We run a mock cluster finder that mimics the optical cluster\nfinding technique of the redMaPPer algorithm on a catalogue of galaxies with\nquenched star formation from one such empirical model, the UniverseMachine, and\nobtain the prevalence of orphan galaxies in these clusters as a function of\ntheir cluster-centric distance. We compare the fraction of orphan galaxies with\nthe upper limits derived based on our prior observations of the weak lensing\nsignals around satellite galaxies from SDSS redMaPPer clusters. Although the\norphan fraction from the UniverseMachine is marginally consistent with the\nupper limits in the innermost regions of galaxy clusters spanning [0.1, 0.3]\n$h^{-1}$ Mpc, we observe that the orphan fractions substantially violate the\nupper limits in the outer regions of galaxy clusters beyond 0.3 $h^{-1}$ Mpc.\nWe discuss the reasons, plausible improvements to the model and how\nobservations can be used to constrain such models further.\n", "  Weak gravitational lensing simulations serve as indispensable tools for\nobtaining precise cosmological constraints. In particular, it is crucial to\naddress the systematic uncertainties in theoretical predictions, given the\nrapid increase in galaxy numbers and the reduction in observational noise. Both\non-the-fly and post-processing methods for constructing lensing light-cones\nencounter limitations due to the finite simulated volume, necessitating the\nreplication of the simulation box to encompass the volume to high redshifts. To\naddress this issue, our primary focus lies on investigating and quantifying the\nimpact of box replication on the convergence power spectrum and higher-order\nmoments of lensing fields. By combining the KS test with these statistics, we\nconfirm that there is a probability exceeding 99\\% to observe the significant\nstatistical deviation from the correct measurements for all investigated\nspecial line-of-sight directions, e.g., x-axis direction. Additionally, we have\ndeveloped a code that facilitates the identification of optimal viewing angles\nfor the light-cone construction. This code has been made publicly accessible.\n", "  We estimate the efficiency of mitigating the lensing $B$-mode polarization,\nthe so-called delensing, for the $LiteBIRD$ experiment with multiple external\ndata sets of lensing-mass tracers. The current best bound on the\ntensor-to-scalar ratio, $r$, is limited by lensing rather than Galactic\nforegrounds. Delensing will be a critical step to improve sensitivity to $r$ as\nmeasurements of $r$ become more and more limited by lensing. In this paper, we\nextend the analysis of the recent $LiteBIRD$ forecast paper to include multiple\nmass tracers, i.e., the CMB lensing maps from $LiteBIRD$ and CMB-S4-like\nexperiment, cosmic infrared background, and galaxy number density from\n$Euclid$- and LSST-like survey. We find that multi-tracer delensing will\nfurther improve the constraint on $r$ by about $20\\%$. In $LiteBIRD$, the\nresidual Galactic foregrounds also significantly contribute to uncertainties of\nthe $B$-modes, and delensing becomes more important if the residual foregrounds\nare further reduced by an improved component separation method.\n", "  The structure of the sound waves generated in baryonic gas during the\nevolution of dark matter halos with masses less than the Jeans mass is\ncalculated. In this case, the source of the gravitational field that creates\nthe wave can be either at a linear stage (an evolving perturbation in dark\nmatter) or at a nonlinear stage (detached and virialized objects). The peculiar\nvelocity of baryons in the sound wave in the second order of velocity cause\nabsorption of the relic radiation in the 21 cm line. It is shown that this\nadditional absorption at sound waves ranges from fractions of a percent (at the\nredshifts z~15-20) to about percent (at z~7-15) of the absorption value in a\nhomogeneous Universe, however, additional absorption may be larger in the case\nof a non-standard spectrum of small scale cosmological perturbations.\n", "  We present the first measurement of the Weyl potential at four redshifts bins\nusing data from the first three years of observations of the Dark Energy Survey\n(DES). The Weyl potential, which is the sum of the spatial and temporal\ndistortions of the Universe's geometry, provides a direct way of testing the\ntheory of gravity and the validity of the $\\Lambda$CDM model. We find that the\nmeasured Weyl potential is 2.3$\\sigma$, respectively 3.1$\\sigma$, below the\n$\\Lambda$CDM predictions in the two lowest redshift bins. We show that these\nlow values of the Weyl potential are at the origin of the $\\sigma_8$ tension\nbetween Cosmic Microwave Background (CMB) measurements and weak lensing\nmeasurements. Interestingly, we find that the tension remains if no information\nfrom the CMB is used. DES data on their own prefer a high value of the\nprimordial fluctuations, followed by a slow evolution of the Weyl potential. A\nremarkable feature of our method is that the measurements of the Weyl potential\nare model-independent and can therefore be confronted with any theory of\ngravity, allowing efficient tests of models beyond General Relativity.\n", "  The small-scale structure of baryons in the intergalactic medium is\nintimately linked to their past thermal history. Prior to the $\\gtrsim10^4$ K\nphotoheating during the epoch of reionization, cold baryons may have closely\ntraced the clumpy cosmic web of dark matter down to scales as low as\n$\\lesssim1$ comoving kpc, depending on the degree of heating by the X-ray\nbackground. After the passage of the ionization front, this clumpy structure\ncan persist for $\\sim10^{8}$ years. The strong Ly$\\alpha$ damping wings\ndetected towards a few of the highest redshift quasars, in addition to their\nsmaller-than-expected Ly$\\alpha$-transmissive proximity zones, suggest that\nthey have ionized and heated the foreground intergalactic medium less than\n$10^7$ years ago. Signatures of the pre-reionization small-scale structure\nshould thus persist in their intergalactic surroundings. Here we explore how\nthe persistence of this clumpy structure can affect the statistics of\nLy$\\alpha$ transmission inside the transparent proximity zones of $z\\gtrsim7$\nquasars by post-processing a suite of small-volume hydrodynamical simulations\nwith 1D ionizing radiative transfer. We find that the Ly$\\alpha$ flux power\nspectrum and flux PDF statistics of ten $z=7.5$ proximity zones, with realistic\nobservational parameters, could distinguish the gaseous structure of a $T_{\\rm\nIGM}\\sim2$ K CDM model from warm dark matter models with particle masses\n$m_{\\rm WDM}>10$ keV and X-ray heated models with $f_{\\rm X}f_{\\rm abs}>0.1$\n($T_{\\rm IGM}(z=7.5)\\gtrsim275$ K) at the $2\\sigma$ level.\n", "  Recently, the emergence of cosmological tension has raised doubts about the\nconsistency of the $\\Lambda$CDM model. In order to constrain the neutrino mass\nwithin a consistent cosmological framework, we investigate three massive\nneutrinos with normal hierarchy (NH) and inverted hierarchy (IH) in both the\naxion-like EDE (Axi-EDE) model and the AdS-EDE model. We use the joint datasets\nincluding cosmic microwave background (CMB) power spectrum from Planck 2018,\nPantheon of type Ia supernova, baryon acoustic oscillation (BAO) and $H_0$ data\nfrom SH0ES. For the $\\nu$Axi-EDE model, we obtain $\\sum m_{\\nu,\\mathrm{NH}} <\n0.152$ eV and $\\sum m_{\\nu,\\mathrm{IH}} < 0.178$ eV, while for the $\\nu$AdS-EDE\nmodel, we find $\\sum m_{\\nu,\\mathrm{NH}} < 0.135$ eV and $\\sum\nm_{\\nu,\\mathrm{IH}} < 0.167$ eV. Our results exhibit a preference for the\nnormal hierarchy in both the $\\nu$Axi-EDE model and the $\\nu$AdS-EDE model.\n", "  Big Bang Nucleosynthesis provides us with an observational insight into the\nvery early Universe. Since this mechanism of light element synthesis comes out\nof the standard model of particle cosmology which follows directly from General\nRelativity, it is expected that any modifications to GR will result in\ndeviations in the predicted observable parameters which are mainly, the\nneutron-to-proton ratio and the baryon-to-photon ratio. We use the measured\nneutron-to-proton ratio and compare the theoretically obtained expressions to\nconstrain two models in the framework of $ f(T,\\mathcal{T}) $ gravity. The\ntheoretically constrained models are then tested against observational data\nfrom the Hubble dataset and the $ \\Lambda $CDM model to explain the accelerated\nexpansion of the Universe.\n", "  We study the dipole signal in the spectral index (x) of the differential\nnumber counts using quasars in the CatWISE2020 catalog of infrared sources. The\nindex is extracted by using the log-likelihood method. We obtain the value\n$x=1.579 \\pm 0.001$ for a quasar sample of 1355352 sources. We extract the\ndipole signal in this parameter by employing $\\chi^{2}$ minimization, assuming\na sky model of x up to the quadrupole term. We find that the dipole amplitude\n|D| is 0.005 \\pm 0.002 and dipole direction (l, b) in Galactic coordinate\nsystem equal to $(201.50^{\\circ} \\pm 27.87^{\\circ}, -29.37^{\\circ} \\pm\n19.86^{\\circ})$. The direction of dipole anisotropy is found to be very close\nto the hemispherical power asymmetry $(l,b)=(221^\\circ,-27^{\\circ})$ in the\nCosmic Microwave Background (CMB). We also obtain a signal of quadrupole\nanisotropy which is correlated with the ecliptic poles and can be attributed to\necliptic bias.}\n", "  Gravitational lensing is proven to be one of the most efficient tools for\nstudying the Universe. The spectral confirmation of such sources requires\nextensive calibration. This paper discusses the spectral extraction technique\nfor the case of multiple source spectra being very near each other. Using the\nmasking technique, we first detect high Signal-to-Noise (S/N) peaks in the CCD\nspectral image corresponding to the location of the source spectra. This\ntechnique computes the cumulative signal using a weighted sum, yielding a\nreliable approximation for the total counts contributed by each source\nspectrum. We then proceed with the subtraction of the contaminating spectra.\nApplying this method, we confirm the nature of 11 lensed quasar candidates.\n", "  The variations in Ly$\\alpha$ forest opacity observed at $z>5.3$ between lines\nof sight to different background quasars are too strong to be caused by\nfluctuations in the density field alone. The leading hypothesis for the cause\nof this excess variance is a late, ongoing reionization process at redshifts\nbelow six. Another model proposes strong ionizing background fluctuations\ncoupled to a short, spatially varying mean free path of ionizing photons,\nwithout explicitly invoking incomplete reionization. With recent observations\nsuggesting a short mean free path at $z\\sim6$, and a dramatic improvement in\n$z>5$ Ly$\\alpha$ forest data quality, we revisit this latter possibility. Here\nwe apply the likelihood-free inference technique of approximate Bayesian\ncomputation to jointly constrain the hydrogen photoionization rate $\\Gamma_{\\rm\nHI}$ and the mean free path of ionizing photons $\\lambda_{\\rm mfp}$ from the\neffective optical depth distributions at $z=5.0$-$6.1$ from XQR-30. We find\nthat the observations are well-described by fluctuating mean free path models\nwith average mean free paths that are consistent with the steep trend implied\nby independent measurements at $z\\sim5$-$6$, with a concomitant rapid evolution\nof the photoionization rate.\n", "  The cross-correlation of cosmic voids with the lensing convergence ($\\kappa$)\nmap of the CMB fluctuations offers a powerful tool to refine our understanding\nof the dark sector in the consensus cosmological model. Our principal aim is to\ncompare the lensing signature of our galaxy data set with simulations based on\nthe concordance model and characterize the results with an $A_{\\kappa}$\nconsistency parameter. In particular, our measurements contribute to the\nunderstanding of the \"lensing-is-low\" tension of the $\\Lambda$CDM model. We\nselected luminous red galaxies from the WISE-Pan-STARSS data set, allowing an\nextended 14,200 deg$^2$ sky area, that offers a more precise measurement\ncompared to previous studies. We created 2D and 3D void catalogs to\ncross-correlate their locations with the Planck lensing map and studied their\naverage imprint signal using a stacking methodology. Applying the same\nprocedure, we also generated a mock catalog from the WebSky simulation for\ncomparison. The 2D void analysis revealed good agreement with the standard\ncosmological model with $A_{\\kappa}\\approx1.06 \\pm 0.08$, i.e. $S/N=13.3$,\nshowing a higher $S/N$ than previous studies using voids detected in the Dark\nEnergy Survey data set. The 3D void analysis exhibited a lower $S/N$ and\ndemonstrated worse agreement with our mock catalog than the 2D voids. These\ndeviations might be attributed to limitations in the mock catalog, such as\nimperfections in the LRG selection, as well as a potential asymmetry between\nthe North and South patches of the WISE-Pan-STARSS data set in terms of data\nquality. Overall, we present a significant detection of a CMB lensing signal\nassociated with cosmic voids, largely consistent with the concordance model.\nFuture analyses using even larger data sets also hold great promise of further\nsharpening these results, given their complementary nature to large-scale\nstructure analyses.\n", "  We present a study of the impact of an uncertainty in the beam far side-lobe\nknowledge on the measurement of the Cosmic Microwave Background $B$-mode signal\nat large scale. It is expected to be one of the main source of systematic\neffects in future CMB observations. Because it is crucial for all-sky survey\nmissions to take into account the interplays between beam systematic effects\nand all the data analysis steps, the primary goal of this paper is to provide\nthe methodology to carry out the end-to-end study of their effect for a\nspace-borne CMB polarization experiment, up to the cosmological results in the\nform of a bias $\\delta r$ on the tensor-to-scalar ratio $r$. LiteBIRD is\ndedicated to target the measurement of CMB primordial $B$ modes by reaching a\nsensitivity of $\\sigma \\left( r \\right) \\leq 10^{-3}$ assuming $r=0$. As a\ndemonstration of our framework, we derive the relationship between the\nknowledge of the beam far side-lobes and the tentatively allocated error budget\nunder given assumptions on design, simulation and component separation method.\nWe assume no mitigation of the far side-lobes effect at any stage of the\nanalysis pipeline. We show that $\\delta r$ is mostly due to the integrated\nfractional power difference between the estimated beams and the true beams in\nthe far side-lobes region, with little dependence on the actual shape of the\nbeams, for low enough $\\delta r$. Under our set of assumptions, in particular\nconsidering the specific foreground cleaning method we used, we find that the\nintegrated fractional power in the far side-lobes should be known at a level as\ntight as $\\sim 10^{-4}$, to achieve the required limit on the bias $\\delta r <\n1.9 \\times 10^{-5}$. The framework and tools developed for this study can be\neasily adapted to provide requirements under different design, data analysis\nframeworks and for other future space-borne experiments beyond LiteBIRD.\n", "  Analysing next-generation cosmological data requires balancing accurate\nmodeling of non-linear gravitational structure formation and computational\ndemands. We propose a solution by introducing a machine learning-based\nfield-level emulator, within the Hamiltonian Monte Carlo-based Bayesian Origin\nReconstruction from Galaxies (BORG) inference algorithm. Built on a V-net\nneural network architecture, the emulator enhances the predictions by\nfirst-order Lagrangian perturbation theory to be accurately aligned with full\n$N$-body simulations while significantly reducing evaluation time. We test its\nincorporation in BORG for sampling cosmic initial conditions using mock data\nbased on non-linear large-scale structures from $N$-body simulations and\nGaussian noise. The method efficiently and accurately explores the\nhigh-dimensional parameter space of initial conditions, fully extracting the\ncross-correlation information of the data field binned at a resolution of\n$1.95h^{-1}$ Mpc. Percent-level agreement with the ground truth in the power\nspectrum and bispectrum is achieved up to the Nyquist frequency $k_\\mathrm{N}\n\\approx 2.79h \\; \\mathrm{Mpc}^{-1}$. Posterior resimulations - using the\ninferred initial conditions for $N$-body simulations - show that the recovery\nof information in the initial conditions is sufficient to accurately reproduce\nhalo properties. In particular, we show highly accurate $M_{200\\mathrm{c}}$\nhalo mass function and stacked density profiles of haloes in different mass\nbins $[0.853,16]\\times 10^{14}M_{\\odot}h^{-1}$. As all available\ncross-correlation information is extracted, we acknowledge that limitations in\nrecovering the initial conditions stem from the noise level and data grid\nresolution. This is promising as it underscores the significance of accurate\nnon-linear modeling, indicating the potential for extracting additional\ninformation at smaller scales.\n", "  Recent measurements of the $4$-point correlation functions (4PCF) from\nspectroscopic surveys provide evidence for parity-violations in the large-scale\nstructure of the Universe. If physical in origin, this could point to exotic\nphysics during the epoch of inflation. However, searching for parity-violations\nin the 4PCF signal relies on a large suite of simulations to perform a rank\ntest, or an accurate model of the 4PCF covariance to claim a detection, and\nthis approach is incapable of extracting parity information from the\nhigher-order $N$-point functions. In this work we present an unsupervised\nmethod which overcomes these issues, before demonstrating the approach is\ncapable of detecting parity-violations in a few toy models using convolutional\nneural networks. This technique is complementary to the 4-point method and\ncould be used to discover parity-violations in several upcoming surveys\nincluding DESI, Euclid and Roman.\n", "  The goal of this work is to obtain a Hubble constant estimate through the\nstudy of the quadruply lensed, variable QSO SDSSJ1433+6007. To achieve this we\ncombine multi-filter, archival $\\textit{HST}$ data for lens modelling and a\ndedicated time delay monitoring campaign with the 2.1m Fraunhofer telescope at\nthe $\\textit{Wendelstein Observatory}$. The lens modelling is carried out with\nthe public $\\texttt{lenstronomy}$ Python package for each of the filters\nindividually. Through this approach, we find that the data in one of the\n$\\textit{HST}$ filters (F160W) contain a light contaminant, that would, if\nremained undetected, have severely biased the lensing potentials and thus our\ncosmological inference. After rejecting these data we obtain a combined\nposterior for the Fermat potential differences from the lens modelling in the\nremaining filters (F475X, F814W, F105W and F140W) with a precision of\n$\\sim6\\%$. The analysis of the $\\textit{g'}$-band Wendelstein light curve data\nis carried out with a free-knot spline fitting method implemented in the public\nPython $\\texttt{PyCS3}$ tools. The precision of the time delays between the QSO\nimages has a range between 7.5 and 9.8$\\%$ depending on the brightness of the\nimages and their time delay. We then combine the posteriors for the Fermat\npotential differences and time delays. Assuming a flat $\\Lambda$CDM cosmology,\nwe infer a Hubble parameter of\n$H_0=76.6^{+7.7}_{-7.0}\\frac{\\mathrm{km}}{\\mathrm{Mpc\\;s}}$, reaching $9.6\\%$\nuncertainty for a single system.\n", "  In this paper, we calibrate the luminosity relation of gamma-ray bursts\n(GRBs) with the machine learning (ML) methods for reconstructing\ndistance-redshift relation from the Pantheon+ sample of type Ia supernovae (SNe\nIa) in a cosmology-independent way. The A219 GRB data set at low redshift are\nused to calibrate the Amati relation ($E_{\\rm p}$-$E_{\\rm iso}$) relation by\nthe ML methods selected with the best performance %and the calibrated results\nare extrapolated to the high redshift data to construct the Hubble diagram at\nhigh redshift. We constrain cosmological models via the Markov Chain Monte\nCarlo numerical method with the GRBs at high redshift and the latest\nobservational Hubble data (OHD). By the K-Nearest Neighbors (KNN) methods, we\nobtain $\\Omega_{\\rm m}$ = $0.29^{+0.09}_{-0.06}$, $h$ = $0.66^{+0.04}_{-0.07}$\n, $w_0$ = $-0.83^{+0.66}_{-0.31}$, $w_a$ = $-0.91^{+0.87}_{-0.46}$ at\n1-$\\sigma$ confidence level for the Chevallier-Polarski-Linder (CPL) model in a\nflat space, which favor the dark energy with a possible evolution ($w_a\\neq0$)\nat 1-$\\sigma$. These results are consistent with those obtained from GRBs\ncalibrated via the Gaussian Process.\n", "  Recent attempts at measuring the variation of $c$ using an assortment of\nstandard candles and the redshift-dependent Hubble expansion rate inferred from\nthe currently available catalog of cosmic chronometers have tended to show that\nthe speed of light appears to be constant, at least up to $z\\sim 2$. A notable\nexception is the use of high-redshift UV $+$ X-ray quasars, whose Hubble\ndiagram seems to indicate a $\\sim 2.7\\sigma$ deviation of c from its value\n$c_0$ ($\\equiv 2.99792458 \\times 10^{10}$ cm s$^{-1}$) on Earth. We show in\nthis paper, however, that this anomaly is due to an error in the derived\nrelation between the luminosity distance, $D_L$, and $H(z)$ when $c$ is allowed\nto vary with redshift, and an imprecise calibration of the quasar catalog. When\nthese deficiences are addressed correctly, one finds that $c/c_0=0.95 \\pm 0.14$\nin the redshift range $0\\lesssim z\\lesssim 2$, fully consistent with zero\nvariation within the measurement errors.\n", "  Robust galaxy cluster mass estimates are fundamental for constraining\ncosmological parameters from counts. For this reason, it is essential to search\nfor tracers that, independent of the cluster's dynamical state, have a small\nintrinsic scatter and can be easily inferred from observations. This work uses\na simulated data set to focus on photometric properties and explores different\noptical mass proxies including richness, optical luminosity, and total stellar\nmass. We have developed a probabilistic membership assignment that makes\nminimal assumptions about the galaxy cluster properties, limited to a\ncharacteristic radius, velocity dispersion, and spatial distribution. Applying\nthe estimator to over 919 galaxy clusters with $z_{phot}<$0.45 within a mass\nrange of $10^{12.8}$ to $10^{15}$ M$_\\odot$, we obtain robust richness\nestimates that deviate from the median true value (from simulations) by -0.01$\n\\pm $0.12. The scatter in the mass-observable relations is\n$\\sigma_{log_{10}(M|\\mathcal{R})}=$0.181 $\\pm$ 0.009 dex for richness,\n$\\sigma_{log_{10}(M|L_\\lambda)}=$0.151 $\\pm$ 0.007 dex for optical luminosity,\nand $\\sigma_{log_{10}(M|M_\\lambda^*)}=$0.097 $\\pm$ 0.005 dex for stellar mass.\nWe also discuss membership assignment, completeness and purity, and the\nconsequences of small centre and redshift offsets. We conclude that the\napplication of our method for photometric surveys delivers competitive cluster\nmass proxies.\n", "  We study a generalization of the the Starobinsky model adding a term of the\nform $R^{2p}$ to the Einstien-Hilbert action. We take the power $p$ as a\nparameter of the model and explore the constraints from CMB plus BAO data\nthrough a Bayesian analysis, thus exploring a range of values for the exponent\nparameter. We incorporate a reheating phase to the model through the background\nmatter content (equation of state) and the duration of this period (number of\n$e$-foldings of reheating). We find that incorporating information from\nreheating imposes constraints on cosmological quantities, more stringent than\nthe case of no reheating when tested with the Planck+BAO data. The inferred\nvalue of the exponent parameter is statistically consistent with $p=1$,\nfavoring the original Starobinsky potential. Moreover, we report tighter\nconstraints on $p$ and the number of $e$-folds in comparison with previous\nworks. The obtained values for other inflationary observational parameters,\nsuch as the scalar spectral index $n_s$ and the scalar amplitude of\nperturbations $A_s$, are consistent with prior measurements. Finally we present\nthe alternative use of consistency relations in order to simplify the parameter\nspace and test the generalized Starobinsky potential even more efficiently.\n", "  We utilize the Magneticum suite of state-of-the-art hydrodynamical, as well\nas dark-matter-only simulations to investigate the effects of baryonic physics\non cosmic voids in the highest-resolution study of its kind. This includes the\nsize, shape and inner density distributions of voids, as well as their radial\ndensity and velocity profiles traced by halos, baryonic and cold dark matter\nparticles. Our results reveal observationally insignificant effects that\nslightly increase with the inner densities of voids and are exclusively\nrelevant on scales of only a few Mpc. Most notably, we identify deviations in\nthe distributions of baryons and cold dark matter around halo-defined voids,\nrelevant for weak lensing studies. In contrast, we find that voids identified\nin cold dark matter, as well as in halos of fixed tracer density exhibit nearly\nindistinguishable distributions and profiles between hydrodynamical and\ndark-matter-only simulations, consolidating the universality and robustness of\nthe latter for comparisons of void statistics with observations in upcoming\nsurveys. This corroborates that voids are the components of the cosmic web that\nare least affected by baryonic physics, further enhancing their use as\ncosmological probes.\n", "  Galaxy clusters are an essential tool to understand and constrain the\ncosmological parameters of our Universe. Thanks to its multi-band design, J-PAS\noffers a unique group and cluster detection window using precise photometric\nredshifts and sufficient depths. We produce galaxy cluster catalogues from the\nminiJPAS, which is a pathfinder survey for the wider J-PAS survey, using the\nPZWav algorithm. Relying only on photometric information, we provide optical\nmass tracers for the identified clusters, including richness, optical\nluminosity, and stellar mass. By reanalysing the Chandra mosaic of the AEGIS\nfield, alongside the overlapping XMM-Newton observations, we produce an X-ray\ncatalogue. The analysis reveals the possible presence of structures with masses\nof 4$\\times 10^{13}$ M$_\\odot$ at redshift 0.75, highlighting the depth of the\nsurvey. Comparing results with those from two other cluster catalogues,\nprovided by AMICO and VT, we find $43$ common clusters with cluster centre\noffsets of 100$\\pm$60 kpc and redshift differences below 0.001. We provide a\ncomparison of the cluster catalogues with a catalogue of massive galaxies and\nreport on the significance of cluster selection. In general, we are able to\nrecover approximately 75$\\%$ of the galaxies with $M^{\\star} >$2$\\times\n10^{11}$ M$_\\odot$. This study emphasises the potential of the J-PAS survey and\nthe employed techniques down to the group scales.\n", "  Coupling of black hole mass to the cosmic expansion has been suggested as a\npossible path to understanding the dark energy content of the Universe. We test\nthis hypothesis by comparing the supermassive black hole (SMBH) mass density at\n$z=0$ to the total mass accreted in AGN since $z=6$, to constrain how much of\nthe SMBH mass density can arise from cosmologically-coupled growth, as opposed\nto growth by accretion. Using an estimate of the local SMBH mass density of\n$\\approx 1.0\\times10^{6}\\,$M$_{\\odot}\\,$Mpc$^{-1}$, a radiative accretion\nefficiency, $\\eta$: $0.05<\\eta<0.3$, and the observed AGN luminosity density at\n$z\\approx 4$, we constrain the value of the coupling constant between the scale\nsize of the Universe and the black hole mass, $k$, to lie in the range\n$0<k\\stackrel{<}{_{\\sim}}2$, below the value of $k=3$ needed for black holes to\nbe the source term for dark energy. Initial estimates of the gravitational wave\nbackground using pulsar timing arrays, however, favor a higher SMBH mass\ndensity at $z=0$. We show that if we adopt such a mass density at $z=0$ of\n$\\approx 7.4\\times 10^{6}\\,$M$_{\\odot}\\,$Mpc$^{-1}$, this makes $k=3$ viable\neven for low radiative efficiencies, and may exclude non-zero cosmological\ncoupling. We conclude that, although current estimates of the SMBH mass density\nbased on the black hole mass -- bulge mass relation probably exclude $k=3$, the\npossibility remains open that, if the GWB is due to SMBH mergers, $k>2$ is\npreferred.\n", "  One of the longstanding goals in the framework of inflation is the\nconstruction of tools that can be used to classify models in theory space. An\nidea that has been put forward in this context is to consider the energy\ndependent scaling behavior of observables to characterize different models. We\nimplement this approach in the framework of hilltop and hilltop-squared\ninflation by analyzing their observables when the small-field approximation is\nnot imposed and the energy scale $\\mu$ of these models is varied as a free\nparameter, subject to observational constraints. We show that the scalar\nspectral tilt and the tensor ratio $r$ exhibit $\\mu$-dependent scaling behavior\nand that the scaling exponents as functions of $\\mu$ in turn lead to functional\nforms that are model dependent. Scaling relations of the type discussed here\nare of interest as characteristics of the inflationary theory space as well as\nin the context of the post-inflationary reheating process. We further observe a\nbifurcation behavior in the behavior of $p$-families in the spectral-tensor\nplane for a critical value of $\\mu$.\n", "  Ultralight axion or axionlike particles are one of the most promising\ncandidates for dark matter because they are a well-motivated solution for the\ntheoretical strong $CP$ problem and observational issues on small scales, i.e.\nthe core-cusp problem and the satellite problem. A tiny coupling of axions and\nphotons induces birefringence. We propose the differential birefringence\nmeasurements of multiple images of gravitationally lensed fast radio burst\n(FRB) systems as probes of the Galactic axion dark matter (ADM) background. In\naddition to general advantages of lensing systems, i.e. alleviating systematics\nand intrinsic astrophysical dependencies, precise measurements of lensing time\ndelay and polarization angle in gravitationally lensed FRB systems make them a\nmore robust and powerful probe. We show that, with a single lensed FRB system\n(which may be detected in large numbers in the SKA era), the axion-photon\ncoupling under the ADM background could be constrained to be $g_{a\\gamma} < 7.3\n\\times 10^{-11}~ \\mathrm{GeV^{-1}}$ for an axion mass\n$m_a\\sim10^{-20}~\\mathrm{eV}$. This will be of great significance in achieving\nsynergistic searches of the Galactic ADM with other astrophysical probes and\nlaboratorial experiments.\n", "  We measure the two point correlation function (CF) of 1357 galaxy clusters\nwith a mass of $\\log_{10}{M_{200}}\\geq 13.6$~\\hm~and at a redshift of $z \\leq\n0.125$. This work differs from previous analyses in that it utilizes a\nspectroscopic cluster catalogue, $\\mathtt{SDSS-GalWCat}$, to measure the CF and\ndetect the baryon acoustic oscillation (BAO) signal. Unlike previous studies\nwhich use statistical techniques, we compute covariance errors directly by\ngenerating a set of 1086 galaxy cluster lightcones from the GLAM $N$-body\nsimulation. Fitting the CF with a power-law model of the form $\\xi(s) =\n(s/s_0)^{-\\gamma}$, we determine the best-fit correlation length and power-law\nindex at three mass thresholds. We find that the correlation length increases\nwith increasing the mass threshold while the power-law index is almost\nconstant. For $\\log_{10}{M_{200}}\\geq 13.6$~\\hm, we find $s_0 =\n14.54\\pm0.87$~\\h~and $\\gamma=1.97\\pm0.11$. We detect the BAO signal at $s =\n100$~\\h~with a significance of $1.60 \\sigma$. Fitting the CF with a\n$\\Lambda$CDM model, we find $D_\\mathrm{V}(z =\n0.089)\\mathrm{r}^{fid}_d/\\mathrm{r}_d = 267.62 \\pm 26$ \\h, consistent with\nPlanck 2015 cosmology. We present a set of 108 high-fidelity simulated galaxy\ncluster lightcones from the high-resolution \\U~N-body simulation, employed for\nmethodological validation. We find $D_\\mathrm{V}(z = 0.089)/r_d = 2.666 \\pm\n0.129$, indicating that our method does not introduce any bias in the parameter\nestimation for this small sample of galaxy clusters.\n", "  We investigate the effect of self-interactions on the shape and oscillations\nof the solitonic core profile of condensed fuzzy dark matter systems without\nthe backdrop of a halo, revealing universal features in terms of an\nappropriately scaled interaction strength characterizing the crossover between\nthe weakly- and strongly-interacting regimes. Our semi-analytical results are\nfurther confirmed by spherically symmetric simulations of the\nGross-Pitaevskii-Poisson equations. Inverting our obtained relations, we\nhighlight a degeneracy that could significantly affect constraints on the boson\nmass in the presence of repulsive boson self-interactions and propose the\nsimultaneous extraction of static and dynamical solitonic features as a way to\nuniquely constrain both the boson mass and self-interactions.\n", "  The bispectrum, the three-point correlation in Fourier space, is a crucial\nstatistic for studying many effects targeted by the next-generation galaxy\nsurveys, such as primordial non-Gaussianity (PNG) and general relativistic (GR)\neffects on large scales. In this work we develop a formalism for the bispectrum\nin the Spherical Fourier-Bessel (SFB) basis - a natural basis for computing\ncorrelation functions on the curved sky, as it diagonalizes the Laplacian\noperator in spherical coordinates. Working in the SFB basis allows for\nline-of-sight effects such as redshift space distortions (RSD) and GR to be\naccounted for exactly, i.e without having to resort to perturbative expansions\nto go beyond the plane-parallel approximation. Only analytic results for the\nSFB bispectrum exist in the literature given the intensive computations needed.\nWe numerically calculate the SFB bispectrum for the first time, enabled by a\nfew techniques: We implement a template decomposition of the redshift-space\nkernel $Z_2$ into Legendre polynomials, and separately treat the PNG and\nvelocity-divergence terms. We derive an identity to integrate a product of\nthree spherical harmonics connected by a Dirac delta function as a simple sum,\nand use it to investigate the limit of a homogeneous and isotropic Universe.\nMoreover, we present a formalism for convolving the signal with separable\nwindow functions, and use a toy spherically symmetric window to demonstrate the\ncomputation and give insights into the properties of the observed bispectrum\nsignal. While our implementation remains computationally challenging, it is a\nstep toward a feasible full extraction of information on large scales via a SFB\nbispectrum analysis.\n", "  Spatial variations in survey properties due to selection effects generate\nsubstantial systematic errors in large-scale structure measurements in optical\ngalaxy surveys on very large scales. On such scales, the statistical\nsensitivity of optical surveys is also limited by their finite sky coverage. By\ncontrast, gravitational wave (GW) sources appear to be relatively free of these\nissues, provided the angular sensitivity of GW experiments can be accurately\ncharacterized. We quantify the expected cosmological information gain from\ncombining the forecast LSST 3$\\times$2pt analysis (combination of three 2-point\ncorrelations of galaxy density and weak lensing shear fields) with the\nlarge-scale auto-correlation of GW sources from proposed next-generation GW\nexperiments. We find that in $\\Lambda$CDM and $w$CDM models, there is no\nsignificant improvement in cosmological constraints from combining GW with LSST\n3$\\times$2pt over LSST alone, due to the large shot noise for the former;\nhowever, this combination does enable a $\\sim6\\%$ constraint on the linear\ngalaxy bias of GW sources. More interestingly, the optical-GW data combination\nprovides tight constraints on models with primordial non-Gaussianity (PNG), due\nto the predicted scale-dependent bias in PNG models on large scales. Assuming\nthat the largest angular scales that LSST will probe are comparable to those in\nStage III surveys ($\\ell_{\\rm min}\\sim50$), the inclusion of next-generation GW\nmeasurements could improve constraints on the PNG parameter $f_{\\rm NL}$ by up\nto a factor of $\\simeq6.6$ compared to LSST alone, yielding $\\sigma(f_{\\rm\nNL})=8.5$. These results assume the expected capability of a network of\nEinstein Telescope-like GW observatories, with a detection rate of $10^6$\nevents/year. We investigate the sensitivity of our results to different\nassumptions about future GW detectors as well as different LSST analysis\nchoices.\n", "  I review the use of Type Ia supernovae (SNe Ia) in the 1998 discovery of the\naccelerating expansion of the Universe, as well as the subsequent use of SNe Ia\nto study the expansion history in more detail, determine the equation-of-state\nparameter w, and measure the current value of the Hubble constant. This is the\nlightly edited transcript of a lecture given at the Standard Model at 50\nSymposium held at Case Western University, June 1-4, 2018, and thus corresponds\nto the state of the field in mid-2018; however, a few post-symposium updates\nwere included in 2019. Also, this version includes at the end a brief update\n(December 2023) on the early-time vs. late-time Hubble tension, which has now\nreached a level of 5 sigma based on SNe Ia alone and is supported by several\nother low-redshift determinations of the Hubble constant.\n"]